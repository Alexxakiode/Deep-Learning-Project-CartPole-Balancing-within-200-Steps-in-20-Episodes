{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexxakiode/Deep-Learning-Project-CartPole-Balancing-within-200-Steps-in-20-Episodes/blob/main/CartPole_Balancing_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKK5DA390wRe"
      },
      "source": [
        "# CartPole Balancing within 200 Steps in 20 Episodes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # install keras rl2 (we need to install keras-rl2 so it works with the tensorflow 2 version that comes pre-installed with colab)\n",
        "# !pip install keras-rl2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vigXep7jWbjI",
        "outputId": "3771ea3c-fe0a-4632-caa6-34d79fcfdaa6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.51.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.19.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.31.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.22.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (63.4.3)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.3.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.40.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.2.2)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FRZ3cBYGsXg",
        "outputId": "eb384191-da7b-4c2f-f3f8-f59efe742498"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (2.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gym"
      ],
      "metadata": {
        "id": "e3dLlThnWg4W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install gym[classic_control]"
      ],
      "metadata": {
        "id": "6E9nLhfGeE2R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install pygame"
      ],
      "metadata": {
        "id": "bbtfhWRqeHzq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load other basic modules\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import the usual Keras modules for creating deep neural networks\n",
        "from keras import Sequential\n",
        "from keras.layers import Input, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "RyOml0McTqQX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Random Environment using OpenAI Gym"
      ],
      "metadata": {
        "id": "oKWjToUd-_aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to render the CartPole environment in Colab\n",
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install pyvirtualdisplay\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "# load the gym module\n",
        "import gym\n",
        "import random\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRzsf2rurzhp",
        "outputId": "f0fc60e8-0ba4-41c3-baeb-486d827f216c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "xvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio==2.4.0 in /usr/local/lib/python3.9/dist-packages (2.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from imageio==2.4.0) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from imageio==2.4.0) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.9/dist-packages (3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a virtual display for rendering OpenAI gym environments.\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "\n",
        "# make the CartPole environment\n",
        "\n",
        "ENV_NAME = 'CartPole-v0'\n",
        "# env = gym.make(ENV_NAME, render_mode='human') # update to load the CartPole-v0 environment\n",
        "env = gym.make(ENV_NAME)\n",
        "env.reset()\n",
        "plt.imshow(env.render(mode='rgb_array'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "rgh4w22et4_b",
        "outputId": "7d05cf90-65ba-424a-ca56-bb5cc779fee0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd752ecd0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = env.observation_space.shape[0]\n",
        "actions = env.action_space.n"
      ],
      "metadata": {
        "id": "Q8xbnW9T-7iA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsQp1ueqAF4x",
        "outputId": "0d9255aa-cc9c-4190-f014-2c66818f5b30"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GofNzYapAKhJ",
        "outputId": "ea7de088-b82e-4845-b4a5-36b68db39a97"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pygame\n",
        "\n",
        "\n",
        "# pygame.init()\n",
        "# pygame.display.list_modes()\n",
        "# screen = pygame.display.set_mode((600, 400))\n",
        "\n",
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  score = 0\n",
        "\n",
        "  while not done:\n",
        "    env.render()\n",
        "    action = random.choice([0,1])\n",
        "    n_state, reward, done, info = env.step(action)\n",
        "    score+=reward\n",
        "  print('Episode:{} Score:{}'.format (episode, score))\n",
        "\n",
        "\n",
        "  plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "_9oW-J2rB4SW",
        "outputId": "4af380c7-3657-4e7f-8683-ce95941d30b0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
            "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:14.0\n",
            "Episode:2 Score:14.0\n",
            "Episode:3 Score:29.0\n",
            "Episode:4 Score:23.0\n",
            "Episode:5 Score:22.0\n",
            "Episode:6 Score:15.0\n",
            "Episode:7 Score:25.0\n",
            "Episode:8 Score:32.0\n",
            "Episode:9 Score:13.0\n",
            "Episode:10 Score:22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## rl2 instead of rl"
      ],
      "metadata": {
        "id": "Cr88SuX5m7Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rl\n",
        "from rl.memory import SequentialMemory  # import the exerience replay buffer module\n",
        "from rl.policy import EpsGreedyQPolicy, LinearAnnealedPolicy  # import the policy\n",
        "from rl.agents.dqn import DQNAgent      # import the DQN agent\n"
      ],
      "metadata": {
        "id": "crCTjDiOUUJQ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EpsGreedyQPolicy\n",
        "# setup experience replay buffer\n",
        "# here the sequential memory limit is set up the same as the nb_steps (number of steps)\n",
        "# parameter in the fit method.  This means that all the action-states will fit into the\n",
        "# memory buffer\n",
        "# keep window_length as 1. It's used in other RL methods, but keep it to 1 in DQNs\n",
        "memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "# define the policy (how we select the actions)\n",
        "policy_inner = EpsGreedyQPolicy()"
      ],
      "metadata": {
        "id": "NrHkEYq3VCnJ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-Network\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model.add(Flatten())\n",
        "# add extra layers here\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54qHHh4DXS_D",
        "outputId": "ad296ff6-2c92-4300-efed-8f7bd92497fd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                544       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 690\n",
            "Trainable params: 690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 1.0\n",
        "\n",
        "# value_min = 0.05\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "# target_model_update=1e-2\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "OwhEbMqrXl5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.05, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.001), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-hs05MMPXdc5",
        "outputId": "1031c573-3a16-475d-fc39-598063f694cb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   21/10000: episode: 1, duration: 2.952s, episode steps:  21, steps per second:   7, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 8.694328, mae: 33.710423, mean_q: 73.435162, mean_eps: 0.998527\n",
            "   72/10000: episode: 2, duration: 0.421s, episode steps:  51, steps per second: 121, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 6.412590, mae: 33.805395, mean_q: 72.680757, mean_eps: 0.995630\n",
            "   92/10000: episode: 3, duration: 0.180s, episode steps:  20, steps per second: 111, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.300 [0.000, 1.000],  loss: 11.129038, mae: 32.887500, mean_q: 71.156071, mean_eps: 0.992257\n",
            "  124/10000: episode: 4, duration: 0.274s, episode steps:  32, steps per second: 117, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.344 [0.000, 1.000],  loss: 11.307388, mae: 34.190550, mean_q: 73.333019, mean_eps: 0.989788\n",
            "  160/10000: episode: 5, duration: 0.298s, episode steps:  36, steps per second: 121, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 4.248437, mae: 34.285477, mean_q: 73.634645, mean_eps: 0.986558\n",
            "  178/10000: episode: 6, duration: 0.148s, episode steps:  18, steps per second: 122, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 7.709524, mae: 33.953464, mean_q: 72.248444, mean_eps: 0.983992\n",
            "  191/10000: episode: 7, duration: 0.112s, episode steps:  13, steps per second: 116, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 16.629165, mae: 33.879908, mean_q: 72.775703, mean_eps: 0.982520\n",
            "  207/10000: episode: 8, duration: 0.143s, episode steps:  16, steps per second: 112, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 5.744387, mae: 34.063011, mean_q: 72.698476, mean_eps: 0.981143\n",
            "  251/10000: episode: 9, duration: 0.369s, episode steps:  44, steps per second: 119, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 8.104182, mae: 33.931854, mean_q: 72.445970, mean_eps: 0.978292\n",
            "  282/10000: episode: 10, duration: 0.310s, episode steps:  31, steps per second: 100, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 15.858148, mae: 34.637480, mean_q: 73.561357, mean_eps: 0.974730\n",
            "  297/10000: episode: 11, duration: 0.190s, episode steps:  15, steps per second:  79, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 21.211811, mae: 33.974202, mean_q: 72.780168, mean_eps: 0.972545\n",
            "  318/10000: episode: 12, duration: 0.258s, episode steps:  21, steps per second:  81, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 7.946999, mae: 34.652337, mean_q: 73.788100, mean_eps: 0.970835\n",
            "  338/10000: episode: 13, duration: 0.249s, episode steps:  20, steps per second:  80, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.756451, mae: 34.721856, mean_q: 73.746171, mean_eps: 0.968887\n",
            "  355/10000: episode: 14, duration: 0.193s, episode steps:  17, steps per second:  88, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 7.182042, mae: 33.782602, mean_q: 72.557299, mean_eps: 0.967130\n",
            "  385/10000: episode: 15, duration: 0.359s, episode steps:  30, steps per second:  84, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 6.843216, mae: 34.491081, mean_q: 73.852667, mean_eps: 0.964897\n",
            "  393/10000: episode: 16, duration: 0.106s, episode steps:   8, steps per second:  75, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.125 [0.000, 1.000],  loss: 6.432599, mae: 34.600389, mean_q: 73.461454, mean_eps: 0.963093\n",
            "  407/10000: episode: 17, duration: 0.178s, episode steps:  14, steps per second:  79, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 15.703536, mae: 34.186356, mean_q: 72.711152, mean_eps: 0.962047\n",
            "  421/10000: episode: 18, duration: 0.169s, episode steps:  14, steps per second:  83, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 9.904644, mae: 34.813042, mean_q: 73.742817, mean_eps: 0.960718\n",
            "  451/10000: episode: 19, duration: 0.353s, episode steps:  30, steps per second:  85, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 3.359683, mae: 34.929373, mean_q: 74.731598, mean_eps: 0.958627\n",
            "  484/10000: episode: 20, duration: 0.394s, episode steps:  33, steps per second:  84, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 3.211866, mae: 34.170009, mean_q: 73.658159, mean_eps: 0.955635\n",
            "  495/10000: episode: 21, duration: 0.141s, episode steps:  11, steps per second:  78, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 14.832702, mae: 35.258592, mean_q: 75.925527, mean_eps: 0.953545\n",
            "  508/10000: episode: 22, duration: 0.176s, episode steps:  13, steps per second:  74, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 2.686666, mae: 34.545346, mean_q: 74.749709, mean_eps: 0.952405\n",
            "  524/10000: episode: 23, duration: 0.158s, episode steps:  16, steps per second: 101, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 5.109906, mae: 34.759355, mean_q: 74.429911, mean_eps: 0.951028\n",
            "  533/10000: episode: 24, duration: 0.082s, episode steps:   9, steps per second: 109, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 8.085921, mae: 35.693000, mean_q: 76.574229, mean_eps: 0.949840\n",
            "  542/10000: episode: 25, duration: 0.076s, episode steps:   9, steps per second: 118, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 2.835199, mae: 32.880246, mean_q: 71.408137, mean_eps: 0.948985\n",
            "  576/10000: episode: 26, duration: 0.285s, episode steps:  34, steps per second: 119, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.852707, mae: 34.802662, mean_q: 74.574247, mean_eps: 0.946942\n",
            "  590/10000: episode: 27, duration: 0.122s, episode steps:  14, steps per second: 115, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 2.351673, mae: 35.309640, mean_q: 75.095032, mean_eps: 0.944662\n",
            "  612/10000: episode: 28, duration: 0.192s, episode steps:  22, steps per second: 115, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 8.422683, mae: 34.887825, mean_q: 74.591480, mean_eps: 0.942952\n",
            "  647/10000: episode: 29, duration: 0.303s, episode steps:  35, steps per second: 116, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.343 [0.000, 1.000],  loss: 3.232761, mae: 35.025900, mean_q: 75.713636, mean_eps: 0.940245\n",
            "  682/10000: episode: 30, duration: 0.286s, episode steps:  35, steps per second: 122, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 7.546008, mae: 35.605499, mean_q: 76.179671, mean_eps: 0.936920\n",
            "  720/10000: episode: 31, duration: 0.326s, episode steps:  38, steps per second: 117, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 7.409333, mae: 35.220098, mean_q: 75.637469, mean_eps: 0.933453\n",
            "  738/10000: episode: 32, duration: 0.147s, episode steps:  18, steps per second: 122, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 6.339285, mae: 35.473934, mean_q: 76.222243, mean_eps: 0.930793\n",
            "  779/10000: episode: 33, duration: 0.351s, episode steps:  41, steps per second: 117, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.415 [0.000, 1.000],  loss: 6.107707, mae: 35.132994, mean_q: 75.607272, mean_eps: 0.927990\n",
            "  819/10000: episode: 34, duration: 0.352s, episode steps:  40, steps per second: 114, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.575 [0.000, 1.000],  loss: 8.906969, mae: 34.755566, mean_q: 75.877982, mean_eps: 0.924142\n",
            "  834/10000: episode: 35, duration: 0.146s, episode steps:  15, steps per second: 103, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 8.998110, mae: 35.205485, mean_q: 75.372499, mean_eps: 0.921530\n",
            "  874/10000: episode: 36, duration: 0.343s, episode steps:  40, steps per second: 117, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 10.199986, mae: 35.682145, mean_q: 75.870649, mean_eps: 0.918917\n",
            "  907/10000: episode: 37, duration: 0.272s, episode steps:  33, steps per second: 121, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 4.789252, mae: 35.697081, mean_q: 76.323864, mean_eps: 0.915450\n",
            "  920/10000: episode: 38, duration: 0.112s, episode steps:  13, steps per second: 116, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 4.852707, mae: 35.829798, mean_q: 76.728966, mean_eps: 0.913265\n",
            "  949/10000: episode: 39, duration: 0.251s, episode steps:  29, steps per second: 116, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 7.384671, mae: 36.091460, mean_q: 77.193516, mean_eps: 0.911270\n",
            "  960/10000: episode: 40, duration: 0.092s, episode steps:  11, steps per second: 119, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 3.511272, mae: 34.842264, mean_q: 74.672662, mean_eps: 0.909370\n",
            "  978/10000: episode: 41, duration: 0.165s, episode steps:  18, steps per second: 109, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.103390, mae: 35.106799, mean_q: 76.242730, mean_eps: 0.907993\n",
            "  991/10000: episode: 42, duration: 0.116s, episode steps:  13, steps per second: 112, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 5.593747, mae: 35.031510, mean_q: 75.201879, mean_eps: 0.906520\n",
            " 1004/10000: episode: 43, duration: 0.114s, episode steps:  13, steps per second: 114, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 5.840491, mae: 35.473047, mean_q: 76.241912, mean_eps: 0.905285\n",
            " 1024/10000: episode: 44, duration: 0.170s, episode steps:  20, steps per second: 118, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 2.977242, mae: 36.306192, mean_q: 77.112368, mean_eps: 0.903717\n",
            " 1044/10000: episode: 45, duration: 0.164s, episode steps:  20, steps per second: 122, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.300 [0.000, 1.000],  loss: 8.798251, mae: 35.438667, mean_q: 76.242447, mean_eps: 0.901817\n",
            " 1067/10000: episode: 46, duration: 0.199s, episode steps:  23, steps per second: 115, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 4.141173, mae: 35.749470, mean_q: 77.045740, mean_eps: 0.899775\n",
            " 1083/10000: episode: 47, duration: 0.145s, episode steps:  16, steps per second: 110, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 2.813426, mae: 35.969362, mean_q: 77.443080, mean_eps: 0.897923\n",
            " 1187/10000: episode: 48, duration: 0.849s, episode steps: 104, steps per second: 123, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 6.489869, mae: 36.376159, mean_q: 77.830519, mean_eps: 0.892223\n",
            " 1213/10000: episode: 49, duration: 0.221s, episode steps:  26, steps per second: 118, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 10.278767, mae: 35.844988, mean_q: 76.596163, mean_eps: 0.886048\n",
            " 1236/10000: episode: 50, duration: 0.215s, episode steps:  23, steps per second: 107, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 6.776737, mae: 35.616251, mean_q: 75.999646, mean_eps: 0.883720\n",
            " 1293/10000: episode: 51, duration: 0.473s, episode steps:  57, steps per second: 121, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 5.216175, mae: 36.077569, mean_q: 77.796610, mean_eps: 0.879920\n",
            " 1366/10000: episode: 52, duration: 0.586s, episode steps:  73, steps per second: 124, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 6.581082, mae: 35.862431, mean_q: 77.871026, mean_eps: 0.873745\n",
            " 1382/10000: episode: 53, duration: 0.135s, episode steps:  16, steps per second: 119, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.510253, mae: 36.166525, mean_q: 78.043046, mean_eps: 0.869518\n",
            " 1406/10000: episode: 54, duration: 0.213s, episode steps:  24, steps per second: 113, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 14.105649, mae: 35.832372, mean_q: 77.061963, mean_eps: 0.867618\n",
            " 1428/10000: episode: 55, duration: 0.172s, episode steps:  22, steps per second: 128, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 3.782205, mae: 36.472153, mean_q: 78.718352, mean_eps: 0.865432\n",
            " 1443/10000: episode: 56, duration: 0.131s, episode steps:  15, steps per second: 115, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 5.489773, mae: 36.800423, mean_q: 78.662714, mean_eps: 0.863675\n",
            " 1469/10000: episode: 57, duration: 0.227s, episode steps:  26, steps per second: 115, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.342680, mae: 36.815466, mean_q: 78.532754, mean_eps: 0.861727\n",
            " 1491/10000: episode: 58, duration: 0.174s, episode steps:  22, steps per second: 126, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 2.697343, mae: 35.852885, mean_q: 77.823610, mean_eps: 0.859448\n",
            " 1522/10000: episode: 59, duration: 0.254s, episode steps:  31, steps per second: 122, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 6.867648, mae: 36.498418, mean_q: 78.203078, mean_eps: 0.856930\n",
            " 1534/10000: episode: 60, duration: 0.102s, episode steps:  12, steps per second: 117, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 10.952755, mae: 36.148995, mean_q: 78.039302, mean_eps: 0.854887\n",
            " 1566/10000: episode: 61, duration: 0.267s, episode steps:  32, steps per second: 120, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 11.106928, mae: 36.361668, mean_q: 78.246470, mean_eps: 0.852797\n",
            " 1580/10000: episode: 62, duration: 0.131s, episode steps:  14, steps per second: 107, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 6.554313, mae: 36.577927, mean_q: 78.323741, mean_eps: 0.850612\n",
            " 1604/10000: episode: 63, duration: 0.199s, episode steps:  24, steps per second: 120, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 9.324185, mae: 36.243447, mean_q: 78.223086, mean_eps: 0.848807\n",
            " 1637/10000: episode: 64, duration: 0.273s, episode steps:  33, steps per second: 121, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 2.005006, mae: 36.081346, mean_q: 78.490744, mean_eps: 0.846100\n",
            " 1652/10000: episode: 65, duration: 0.136s, episode steps:  15, steps per second: 110, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 7.919782, mae: 36.215716, mean_q: 77.954339, mean_eps: 0.843820\n",
            " 1666/10000: episode: 66, duration: 0.124s, episode steps:  14, steps per second: 113, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 4.591153, mae: 36.342431, mean_q: 79.382078, mean_eps: 0.842442\n",
            " 1701/10000: episode: 67, duration: 0.360s, episode steps:  35, steps per second:  97, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 11.679276, mae: 37.222723, mean_q: 79.179442, mean_eps: 0.840115\n",
            " 1719/10000: episode: 68, duration: 0.227s, episode steps:  18, steps per second:  79, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 3.711951, mae: 36.683888, mean_q: 78.700914, mean_eps: 0.837598\n",
            " 1734/10000: episode: 69, duration: 0.186s, episode steps:  15, steps per second:  81, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 8.452023, mae: 36.876653, mean_q: 79.171314, mean_eps: 0.836030\n",
            " 1747/10000: episode: 70, duration: 0.166s, episode steps:  13, steps per second:  78, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 3.671284, mae: 37.141030, mean_q: 80.009945, mean_eps: 0.834700\n",
            " 1770/10000: episode: 71, duration: 0.280s, episode steps:  23, steps per second:  82, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 3.243612, mae: 36.737394, mean_q: 79.157360, mean_eps: 0.832990\n",
            " 1781/10000: episode: 72, duration: 0.155s, episode steps:  11, steps per second:  71, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 5.070102, mae: 37.251511, mean_q: 80.073801, mean_eps: 0.831375\n",
            " 1794/10000: episode: 73, duration: 0.164s, episode steps:  13, steps per second:  79, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 9.634373, mae: 37.157403, mean_q: 80.020062, mean_eps: 0.830235\n",
            " 1817/10000: episode: 74, duration: 0.291s, episode steps:  23, steps per second:  79, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.609 [0.000, 1.000],  loss: 5.273067, mae: 37.138008, mean_q: 79.985751, mean_eps: 0.828525\n",
            " 1831/10000: episode: 75, duration: 0.169s, episode steps:  14, steps per second:  83, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 13.523362, mae: 37.081622, mean_q: 79.820697, mean_eps: 0.826767\n",
            " 1875/10000: episode: 76, duration: 0.513s, episode steps:  44, steps per second:  86, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 7.309403, mae: 36.938450, mean_q: 79.506837, mean_eps: 0.824012\n",
            " 1925/10000: episode: 77, duration: 0.607s, episode steps:  50, steps per second:  82, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 8.128339, mae: 37.269537, mean_q: 80.324361, mean_eps: 0.819548\n",
            " 1941/10000: episode: 78, duration: 0.190s, episode steps:  16, steps per second:  84, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.812 [0.000, 1.000],  loss: 7.654380, mae: 36.930867, mean_q: 79.127128, mean_eps: 0.816412\n",
            " 1977/10000: episode: 79, duration: 0.310s, episode steps:  36, steps per second: 116, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 10.338662, mae: 37.369571, mean_q: 80.610379, mean_eps: 0.813943\n",
            " 2005/10000: episode: 80, duration: 0.235s, episode steps:  28, steps per second: 119, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 9.377304, mae: 37.823360, mean_q: 79.855633, mean_eps: 0.810902\n",
            " 2031/10000: episode: 81, duration: 0.219s, episode steps:  26, steps per second: 119, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 7.271702, mae: 37.731371, mean_q: 80.279953, mean_eps: 0.808338\n",
            " 2057/10000: episode: 82, duration: 0.219s, episode steps:  26, steps per second: 119, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 7.742306, mae: 36.951772, mean_q: 79.917756, mean_eps: 0.805867\n",
            " 2091/10000: episode: 83, duration: 0.295s, episode steps:  34, steps per second: 115, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 6.363643, mae: 37.575287, mean_q: 80.464671, mean_eps: 0.803018\n",
            " 2113/10000: episode: 84, duration: 0.188s, episode steps:  22, steps per second: 117, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.668196, mae: 36.895078, mean_q: 79.474248, mean_eps: 0.800358\n",
            " 2156/10000: episode: 85, duration: 0.352s, episode steps:  43, steps per second: 122, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 8.866846, mae: 37.675908, mean_q: 80.173479, mean_eps: 0.797270\n",
            " 2166/10000: episode: 86, duration: 0.100s, episode steps:  10, steps per second: 100, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 4.524459, mae: 37.052465, mean_q: 80.537600, mean_eps: 0.794752\n",
            " 2182/10000: episode: 87, duration: 0.139s, episode steps:  16, steps per second: 115, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 9.458137, mae: 37.910010, mean_q: 81.605546, mean_eps: 0.793517\n",
            " 2201/10000: episode: 88, duration: 0.164s, episode steps:  19, steps per second: 116, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 7.880118, mae: 37.435093, mean_q: 80.732190, mean_eps: 0.791855\n",
            " 2220/10000: episode: 89, duration: 0.166s, episode steps:  19, steps per second: 114, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 6.057441, mae: 38.029403, mean_q: 81.745467, mean_eps: 0.790050\n",
            " 2238/10000: episode: 90, duration: 0.154s, episode steps:  18, steps per second: 117, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 3.826859, mae: 37.515172, mean_q: 80.232579, mean_eps: 0.788293\n",
            " 2295/10000: episode: 91, duration: 0.472s, episode steps:  57, steps per second: 121, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 4.395642, mae: 37.743522, mean_q: 81.661721, mean_eps: 0.784730\n",
            " 2318/10000: episode: 92, duration: 0.193s, episode steps:  23, steps per second: 119, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.652 [0.000, 1.000],  loss: 5.870915, mae: 38.416357, mean_q: 83.031159, mean_eps: 0.780930\n",
            " 2335/10000: episode: 93, duration: 0.151s, episode steps:  17, steps per second: 113, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 12.670488, mae: 37.641790, mean_q: 81.422117, mean_eps: 0.779030\n",
            " 2346/10000: episode: 94, duration: 0.102s, episode steps:  11, steps per second: 108, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 2.055873, mae: 39.352397, mean_q: 83.570403, mean_eps: 0.777700\n",
            " 2362/10000: episode: 95, duration: 0.139s, episode steps:  16, steps per second: 115, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 16.196493, mae: 38.765274, mean_q: 83.463810, mean_eps: 0.776417\n",
            " 2383/10000: episode: 96, duration: 0.177s, episode steps:  21, steps per second: 119, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 3.115814, mae: 37.529738, mean_q: 81.955592, mean_eps: 0.774660\n",
            " 2409/10000: episode: 97, duration: 0.214s, episode steps:  26, steps per second: 122, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 5.246118, mae: 38.148503, mean_q: 82.441338, mean_eps: 0.772427\n",
            " 2452/10000: episode: 98, duration: 0.361s, episode steps:  43, steps per second: 119, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.581 [0.000, 1.000],  loss: 2.131043, mae: 37.920892, mean_q: 82.281776, mean_eps: 0.769150\n",
            " 2475/10000: episode: 99, duration: 0.194s, episode steps:  23, steps per second: 119, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 6.912372, mae: 37.997245, mean_q: 82.156745, mean_eps: 0.766015\n",
            " 2486/10000: episode: 100, duration: 0.098s, episode steps:  11, steps per second: 113, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 4.465566, mae: 36.936857, mean_q: 80.481300, mean_eps: 0.764400\n",
            " 2514/10000: episode: 101, duration: 0.233s, episode steps:  28, steps per second: 120, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 11.571588, mae: 38.480433, mean_q: 82.905461, mean_eps: 0.762548\n",
            " 2541/10000: episode: 102, duration: 0.238s, episode steps:  27, steps per second: 114, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.630 [0.000, 1.000],  loss: 13.792485, mae: 38.642839, mean_q: 82.777527, mean_eps: 0.759935\n",
            " 2587/10000: episode: 103, duration: 0.399s, episode steps:  46, steps per second: 115, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 8.182682, mae: 38.173105, mean_q: 82.091969, mean_eps: 0.756468\n",
            " 2603/10000: episode: 104, duration: 0.131s, episode steps:  16, steps per second: 122, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 13.077943, mae: 39.689309, mean_q: 84.128400, mean_eps: 0.753522\n",
            " 2687/10000: episode: 105, duration: 0.693s, episode steps:  84, steps per second: 121, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 5.731944, mae: 38.405273, mean_q: 82.474274, mean_eps: 0.748772\n",
            " 2706/10000: episode: 106, duration: 0.167s, episode steps:  19, steps per second: 114, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 4.470669, mae: 38.253925, mean_q: 82.325752, mean_eps: 0.743880\n",
            " 2748/10000: episode: 107, duration: 0.358s, episode steps:  42, steps per second: 117, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 16.980275, mae: 38.493429, mean_q: 83.034942, mean_eps: 0.740982\n",
            " 2763/10000: episode: 108, duration: 0.128s, episode steps:  15, steps per second: 117, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 8.317294, mae: 37.974929, mean_q: 81.801378, mean_eps: 0.738275\n",
            " 2788/10000: episode: 109, duration: 0.209s, episode steps:  25, steps per second: 120, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 5.153164, mae: 38.605179, mean_q: 82.362275, mean_eps: 0.736375\n",
            " 2839/10000: episode: 110, duration: 0.419s, episode steps:  51, steps per second: 122, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 3.753222, mae: 38.952346, mean_q: 83.817000, mean_eps: 0.732765\n",
            " 2865/10000: episode: 111, duration: 0.206s, episode steps:  26, steps per second: 126, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 6.008744, mae: 38.295639, mean_q: 83.225243, mean_eps: 0.729108\n",
            " 2884/10000: episode: 112, duration: 0.169s, episode steps:  19, steps per second: 112, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 5.237999, mae: 39.000086, mean_q: 84.355693, mean_eps: 0.726970\n",
            " 2904/10000: episode: 113, duration: 0.161s, episode steps:  20, steps per second: 124, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.605886, mae: 39.337374, mean_q: 84.205544, mean_eps: 0.725117\n",
            " 2959/10000: episode: 114, duration: 0.461s, episode steps:  55, steps per second: 119, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.618 [0.000, 1.000],  loss: 6.553013, mae: 38.704618, mean_q: 83.063659, mean_eps: 0.721555\n",
            " 3009/10000: episode: 115, duration: 0.412s, episode steps:  50, steps per second: 121, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 4.022370, mae: 39.245242, mean_q: 83.556739, mean_eps: 0.716567\n",
            " 3031/10000: episode: 116, duration: 0.186s, episode steps:  22, steps per second: 118, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 11.977996, mae: 40.186148, mean_q: 85.157997, mean_eps: 0.713147\n",
            " 3048/10000: episode: 117, duration: 0.151s, episode steps:  17, steps per second: 113, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 4.455515, mae: 39.652057, mean_q: 85.031973, mean_eps: 0.711295\n",
            " 3113/10000: episode: 118, duration: 0.548s, episode steps:  65, steps per second: 119, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 3.869359, mae: 39.257767, mean_q: 83.773899, mean_eps: 0.707400\n",
            " 3146/10000: episode: 119, duration: 0.422s, episode steps:  33, steps per second:  78, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 4.354919, mae: 39.826077, mean_q: 85.600219, mean_eps: 0.702745\n",
            " 3161/10000: episode: 120, duration: 0.209s, episode steps:  15, steps per second:  72, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 15.471564, mae: 39.378332, mean_q: 84.346110, mean_eps: 0.700465\n",
            " 3178/10000: episode: 121, duration: 0.195s, episode steps:  17, steps per second:  87, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 7.449156, mae: 38.865202, mean_q: 84.252627, mean_eps: 0.698945\n",
            " 3194/10000: episode: 122, duration: 0.229s, episode steps:  16, steps per second:  70, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 11.138638, mae: 39.574752, mean_q: 85.053463, mean_eps: 0.697377\n",
            " 3217/10000: episode: 123, duration: 0.274s, episode steps:  23, steps per second:  84, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.609 [0.000, 1.000],  loss: 8.021954, mae: 39.500322, mean_q: 84.362198, mean_eps: 0.695525\n",
            " 3273/10000: episode: 124, duration: 0.663s, episode steps:  56, steps per second:  84, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 8.289700, mae: 38.962939, mean_q: 83.775842, mean_eps: 0.691773\n",
            " 3286/10000: episode: 125, duration: 0.155s, episode steps:  13, steps per second:  84, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 1.432948, mae: 40.122050, mean_q: 84.747064, mean_eps: 0.688495\n",
            " 3305/10000: episode: 126, duration: 0.244s, episode steps:  19, steps per second:  78, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 1.900414, mae: 39.099369, mean_q: 83.815234, mean_eps: 0.686975\n",
            " 3327/10000: episode: 127, duration: 0.283s, episode steps:  22, steps per second:  78, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 2.780343, mae: 40.195447, mean_q: 85.832955, mean_eps: 0.685027\n",
            " 3346/10000: episode: 128, duration: 0.247s, episode steps:  19, steps per second:  77, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 5.395180, mae: 40.407873, mean_q: 85.905031, mean_eps: 0.683080\n",
            " 3357/10000: episode: 129, duration: 0.137s, episode steps:  11, steps per second:  80, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: 11.606490, mae: 39.425192, mean_q: 84.260788, mean_eps: 0.681655\n",
            " 3385/10000: episode: 130, duration: 0.233s, episode steps:  28, steps per second: 120, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.972215, mae: 38.362330, mean_q: 83.514159, mean_eps: 0.679802\n",
            " 3447/10000: episode: 131, duration: 0.517s, episode steps:  62, steps per second: 120, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 7.227409, mae: 39.595937, mean_q: 84.883431, mean_eps: 0.675528\n",
            " 3477/10000: episode: 132, duration: 0.249s, episode steps:  30, steps per second: 120, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.274961, mae: 39.815811, mean_q: 85.335445, mean_eps: 0.671158\n",
            " 3535/10000: episode: 133, duration: 0.486s, episode steps:  58, steps per second: 119, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 7.977817, mae: 39.411697, mean_q: 85.244878, mean_eps: 0.666978\n",
            " 3610/10000: episode: 134, duration: 0.595s, episode steps:  75, steps per second: 126, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 9.212954, mae: 39.325788, mean_q: 84.581024, mean_eps: 0.660660\n",
            " 3626/10000: episode: 135, duration: 0.142s, episode steps:  16, steps per second: 113, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 12.864618, mae: 38.778349, mean_q: 83.715431, mean_eps: 0.656338\n",
            " 3649/10000: episode: 136, duration: 0.194s, episode steps:  23, steps per second: 119, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 14.646852, mae: 39.512277, mean_q: 85.172482, mean_eps: 0.654485\n",
            " 3691/10000: episode: 137, duration: 0.361s, episode steps:  42, steps per second: 116, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 8.962819, mae: 40.480614, mean_q: 85.685838, mean_eps: 0.651398\n",
            " 3713/10000: episode: 138, duration: 0.179s, episode steps:  22, steps per second: 123, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 4.656635, mae: 39.437111, mean_q: 84.625291, mean_eps: 0.648358\n",
            " 3726/10000: episode: 139, duration: 0.121s, episode steps:  13, steps per second: 107, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 4.136963, mae: 39.267654, mean_q: 85.450651, mean_eps: 0.646695\n",
            " 3750/10000: episode: 140, duration: 0.206s, episode steps:  24, steps per second: 116, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.455366, mae: 39.990508, mean_q: 85.879099, mean_eps: 0.644938\n",
            " 3778/10000: episode: 141, duration: 0.243s, episode steps:  28, steps per second: 115, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.236498, mae: 39.942446, mean_q: 85.491618, mean_eps: 0.642467\n",
            " 3805/10000: episode: 142, duration: 0.224s, episode steps:  27, steps per second: 120, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 12.790272, mae: 40.160345, mean_q: 86.087709, mean_eps: 0.639855\n",
            " 3833/10000: episode: 143, duration: 0.232s, episode steps:  28, steps per second: 121, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.529367, mae: 40.148530, mean_q: 85.989814, mean_eps: 0.637243\n",
            " 3845/10000: episode: 144, duration: 0.102s, episode steps:  12, steps per second: 118, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 3.973824, mae: 40.334319, mean_q: 87.266720, mean_eps: 0.635343\n",
            " 3860/10000: episode: 145, duration: 0.126s, episode steps:  15, steps per second: 119, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 4.039207, mae: 39.837701, mean_q: 86.021002, mean_eps: 0.634060\n",
            " 3911/10000: episode: 146, duration: 0.442s, episode steps:  51, steps per second: 115, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 6.844519, mae: 39.819470, mean_q: 85.270107, mean_eps: 0.630925\n",
            " 3982/10000: episode: 147, duration: 0.567s, episode steps:  71, steps per second: 125, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 4.992320, mae: 40.357837, mean_q: 86.835218, mean_eps: 0.625130\n",
            " 4009/10000: episode: 148, duration: 0.225s, episode steps:  27, steps per second: 120, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 10.304293, mae: 40.250768, mean_q: 86.337374, mean_eps: 0.620475\n",
            " 4027/10000: episode: 149, duration: 0.160s, episode steps:  18, steps per second: 113, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 2.875965, mae: 40.969886, mean_q: 87.222599, mean_eps: 0.618338\n",
            " 4048/10000: episode: 150, duration: 0.182s, episode steps:  21, steps per second: 116, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 5.701178, mae: 39.765899, mean_q: 85.333801, mean_eps: 0.616485\n",
            " 4073/10000: episode: 151, duration: 0.221s, episode steps:  25, steps per second: 113, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 11.828936, mae: 40.647564, mean_q: 86.015757, mean_eps: 0.614300\n",
            " 4091/10000: episode: 152, duration: 0.146s, episode steps:  18, steps per second: 123, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.518079, mae: 39.605646, mean_q: 85.271567, mean_eps: 0.612258\n",
            " 4109/10000: episode: 153, duration: 0.161s, episode steps:  18, steps per second: 112, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 3.904788, mae: 40.831671, mean_q: 86.733623, mean_eps: 0.610548\n",
            " 4133/10000: episode: 154, duration: 0.195s, episode steps:  24, steps per second: 123, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.545828, mae: 40.347300, mean_q: 86.807354, mean_eps: 0.608553\n",
            " 4150/10000: episode: 155, duration: 0.159s, episode steps:  17, steps per second: 107, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 7.746889, mae: 40.214780, mean_q: 85.368643, mean_eps: 0.606605\n",
            " 4176/10000: episode: 156, duration: 0.223s, episode steps:  26, steps per second: 117, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.654199, mae: 40.471064, mean_q: 86.617337, mean_eps: 0.604563\n",
            " 4189/10000: episode: 157, duration: 0.115s, episode steps:  13, steps per second: 113, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 5.302733, mae: 41.088563, mean_q: 87.524676, mean_eps: 0.602710\n",
            " 4227/10000: episode: 158, duration: 0.316s, episode steps:  38, steps per second: 120, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 8.065942, mae: 40.518138, mean_q: 87.129054, mean_eps: 0.600287\n",
            " 4243/10000: episode: 159, duration: 0.137s, episode steps:  16, steps per second: 117, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 7.201984, mae: 40.470174, mean_q: 86.805468, mean_eps: 0.597723\n",
            " 4259/10000: episode: 160, duration: 0.149s, episode steps:  16, steps per second: 107, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 16.213890, mae: 41.020013, mean_q: 86.987741, mean_eps: 0.596203\n",
            " 4319/10000: episode: 161, duration: 0.518s, episode steps:  60, steps per second: 116, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 16.891578, mae: 39.760611, mean_q: 85.256458, mean_eps: 0.592593\n",
            " 4351/10000: episode: 162, duration: 0.271s, episode steps:  32, steps per second: 118, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 6.352325, mae: 40.610727, mean_q: 86.533448, mean_eps: 0.588222\n",
            " 4418/10000: episode: 163, duration: 0.561s, episode steps:  67, steps per second: 119, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 5.219561, mae: 40.149474, mean_q: 86.244118, mean_eps: 0.583520\n",
            " 4437/10000: episode: 164, duration: 0.159s, episode steps:  19, steps per second: 119, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 6.760685, mae: 41.059454, mean_q: 87.473661, mean_eps: 0.579435\n",
            " 4448/10000: episode: 165, duration: 0.098s, episode steps:  11, steps per second: 112, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 9.345932, mae: 39.891091, mean_q: 86.030317, mean_eps: 0.578010\n",
            " 4469/10000: episode: 166, duration: 0.180s, episode steps:  21, steps per second: 117, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 4.268874, mae: 41.289183, mean_q: 87.308249, mean_eps: 0.576490\n",
            " 4480/10000: episode: 167, duration: 0.102s, episode steps:  11, steps per second: 108, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 11.863543, mae: 41.303999, mean_q: 87.179690, mean_eps: 0.574970\n",
            " 4515/10000: episode: 168, duration: 0.291s, episode steps:  35, steps per second: 120, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 10.651773, mae: 40.668500, mean_q: 86.385238, mean_eps: 0.572785\n",
            " 4555/10000: episode: 169, duration: 0.438s, episode steps:  40, steps per second:  91, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 8.733885, mae: 40.964365, mean_q: 87.054804, mean_eps: 0.569222\n",
            " 4602/10000: episode: 170, duration: 0.568s, episode steps:  47, steps per second:  83, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 10.616067, mae: 40.199279, mean_q: 87.056025, mean_eps: 0.565090\n",
            " 4624/10000: episode: 171, duration: 0.259s, episode steps:  22, steps per second:  85, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.324759, mae: 40.323193, mean_q: 86.625846, mean_eps: 0.561812\n",
            " 4645/10000: episode: 172, duration: 0.246s, episode steps:  21, steps per second:  85, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 6.880660, mae: 39.846864, mean_q: 86.008247, mean_eps: 0.559770\n",
            " 4668/10000: episode: 173, duration: 0.276s, episode steps:  23, steps per second:  83, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 6.802563, mae: 40.895916, mean_q: 87.062658, mean_eps: 0.557680\n",
            " 4741/10000: episode: 174, duration: 0.869s, episode steps:  73, steps per second:  84, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 8.273268, mae: 40.440784, mean_q: 86.817940, mean_eps: 0.553120\n",
            " 4786/10000: episode: 175, duration: 0.553s, episode steps:  45, steps per second:  81, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 7.882952, mae: 40.093179, mean_q: 86.137095, mean_eps: 0.547515\n",
            " 4849/10000: episode: 176, duration: 0.513s, episode steps:  63, steps per second: 123, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 4.970856, mae: 40.509981, mean_q: 87.084997, mean_eps: 0.542385\n",
            " 4927/10000: episode: 177, duration: 0.644s, episode steps:  78, steps per second: 121, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 7.786097, mae: 41.266922, mean_q: 87.858579, mean_eps: 0.535688\n",
            " 4942/10000: episode: 178, duration: 0.130s, episode steps:  15, steps per second: 115, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 9.786480, mae: 41.547012, mean_q: 89.127038, mean_eps: 0.531270\n",
            " 4975/10000: episode: 179, duration: 0.276s, episode steps:  33, steps per second: 120, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.394 [0.000, 1.000],  loss: 5.754376, mae: 40.672917, mean_q: 87.417589, mean_eps: 0.528990\n",
            " 4991/10000: episode: 180, duration: 0.136s, episode steps:  16, steps per second: 117, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.167054, mae: 40.932710, mean_q: 87.340794, mean_eps: 0.526663\n",
            " 5005/10000: episode: 181, duration: 0.127s, episode steps:  14, steps per second: 110, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 14.930169, mae: 39.118610, mean_q: 84.674573, mean_eps: 0.525238\n",
            " 5020/10000: episode: 182, duration: 0.130s, episode steps:  15, steps per second: 115, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 3.205087, mae: 41.621639, mean_q: 88.043657, mean_eps: 0.523860\n",
            " 5056/10000: episode: 183, duration: 0.296s, episode steps:  36, steps per second: 122, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 13.086669, mae: 40.592841, mean_q: 87.638074, mean_eps: 0.521437\n",
            " 5065/10000: episode: 184, duration: 0.077s, episode steps:   9, steps per second: 117, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 10.416439, mae: 41.518173, mean_q: 87.549670, mean_eps: 0.519300\n",
            " 5081/10000: episode: 185, duration: 0.145s, episode steps:  16, steps per second: 110, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 17.832714, mae: 40.825201, mean_q: 87.711215, mean_eps: 0.518113\n",
            " 5114/10000: episode: 186, duration: 0.270s, episode steps:  33, steps per second: 122, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.576 [0.000, 1.000],  loss: 10.387950, mae: 40.249263, mean_q: 86.356141, mean_eps: 0.515785\n",
            " 5129/10000: episode: 187, duration: 0.135s, episode steps:  15, steps per second: 111, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 10.352593, mae: 40.734688, mean_q: 88.386309, mean_eps: 0.513505\n",
            " 5182/10000: episode: 188, duration: 0.436s, episode steps:  53, steps per second: 121, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.434 [0.000, 1.000],  loss: 8.133696, mae: 40.728301, mean_q: 88.221158, mean_eps: 0.510275\n",
            " 5221/10000: episode: 189, duration: 0.317s, episode steps:  39, steps per second: 123, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 4.451252, mae: 40.469644, mean_q: 87.204668, mean_eps: 0.505905\n",
            " 5247/10000: episode: 190, duration: 0.229s, episode steps:  26, steps per second: 114, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 7.110715, mae: 40.659061, mean_q: 87.560615, mean_eps: 0.502818\n",
            " 5311/10000: episode: 191, duration: 0.535s, episode steps:  64, steps per second: 120, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 6.675224, mae: 40.325942, mean_q: 86.976755, mean_eps: 0.498542\n",
            " 5360/10000: episode: 192, duration: 0.403s, episode steps:  49, steps per second: 121, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 4.268369, mae: 40.854574, mean_q: 87.367091, mean_eps: 0.493175\n",
            " 5399/10000: episode: 193, duration: 0.352s, episode steps:  39, steps per second: 111, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 4.016757, mae: 41.029143, mean_q: 87.664679, mean_eps: 0.488995\n",
            " 5474/10000: episode: 194, duration: 0.617s, episode steps:  75, steps per second: 122, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 5.431079, mae: 41.853736, mean_q: 89.307526, mean_eps: 0.483580\n",
            " 5485/10000: episode: 195, duration: 0.105s, episode steps:  11, steps per second: 104, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: 6.402107, mae: 41.131725, mean_q: 88.236881, mean_eps: 0.479495\n",
            " 5554/10000: episode: 196, duration: 0.578s, episode steps:  69, steps per second: 119, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: 8.059011, mae: 40.938260, mean_q: 88.218539, mean_eps: 0.475695\n",
            " 5570/10000: episode: 197, duration: 0.133s, episode steps:  16, steps per second: 121, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.759330, mae: 40.540867, mean_q: 87.277380, mean_eps: 0.471658\n",
            " 5622/10000: episode: 198, duration: 0.430s, episode steps:  52, steps per second: 121, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.393122, mae: 41.619510, mean_q: 89.007571, mean_eps: 0.468428\n",
            " 5704/10000: episode: 199, duration: 0.644s, episode steps:  82, steps per second: 127, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.451 [0.000, 1.000],  loss: 7.149245, mae: 41.083801, mean_q: 88.478931, mean_eps: 0.462062\n",
            " 5775/10000: episode: 200, duration: 0.579s, episode steps:  71, steps per second: 123, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 6.982331, mae: 41.682388, mean_q: 89.333530, mean_eps: 0.454795\n",
            " 5831/10000: episode: 201, duration: 0.450s, episode steps:  56, steps per second: 124, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.446 [0.000, 1.000],  loss: 3.812238, mae: 41.777383, mean_q: 89.443739, mean_eps: 0.448763\n",
            " 5868/10000: episode: 202, duration: 0.317s, episode steps:  37, steps per second: 117, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 5.265503, mae: 42.682288, mean_q: 90.673656, mean_eps: 0.444345\n",
            " 5888/10000: episode: 203, duration: 0.171s, episode steps:  20, steps per second: 117, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 12.620439, mae: 40.397996, mean_q: 87.515640, mean_eps: 0.441638\n",
            " 5942/10000: episode: 204, duration: 0.439s, episode steps:  54, steps per second: 123, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 5.735581, mae: 42.201397, mean_q: 89.981249, mean_eps: 0.438123\n",
            " 5988/10000: episode: 205, duration: 0.409s, episode steps:  46, steps per second: 113, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 4.354720, mae: 41.596380, mean_q: 89.233262, mean_eps: 0.433373\n",
            " 6058/10000: episode: 206, duration: 0.848s, episode steps:  70, steps per second:  83, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 7.027265, mae: 41.642996, mean_q: 89.502185, mean_eps: 0.427862\n",
            " 6146/10000: episode: 207, duration: 1.014s, episode steps:  88, steps per second:  87, episode reward: 88.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 5.365279, mae: 42.644325, mean_q: 91.006244, mean_eps: 0.420358\n",
            " 6168/10000: episode: 208, duration: 0.277s, episode steps:  22, steps per second:  79, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 4.908461, mae: 40.810797, mean_q: 88.779358, mean_eps: 0.415133\n",
            " 6195/10000: episode: 209, duration: 0.335s, episode steps:  27, steps per second:  81, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.593 [0.000, 1.000],  loss: 3.186993, mae: 42.525602, mean_q: 90.891648, mean_eps: 0.412805\n",
            " 6227/10000: episode: 210, duration: 0.391s, episode steps:  32, steps per second:  82, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 3.306723, mae: 42.375215, mean_q: 90.480673, mean_eps: 0.410003\n",
            " 6354/10000: episode: 211, duration: 1.028s, episode steps: 127, steps per second: 124, episode reward: 127.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 5.149704, mae: 42.529912, mean_q: 90.892125, mean_eps: 0.402450\n",
            " 6380/10000: episode: 212, duration: 0.214s, episode steps:  26, steps per second: 122, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 4.650879, mae: 42.755493, mean_q: 91.478641, mean_eps: 0.395183\n",
            " 6471/10000: episode: 213, duration: 0.786s, episode steps:  91, steps per second: 116, episode reward: 91.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 7.029318, mae: 42.847869, mean_q: 91.055206, mean_eps: 0.389625\n",
            " 6511/10000: episode: 214, duration: 0.347s, episode steps:  40, steps per second: 115, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.204827, mae: 42.682663, mean_q: 90.380059, mean_eps: 0.383403\n",
            " 6528/10000: episode: 215, duration: 0.147s, episode steps:  17, steps per second: 116, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 4.045508, mae: 43.307588, mean_q: 92.168211, mean_eps: 0.380695\n",
            " 6568/10000: episode: 216, duration: 0.350s, episode steps:  40, steps per second: 114, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 5.441961, mae: 43.041258, mean_q: 91.444695, mean_eps: 0.377988\n",
            " 6627/10000: episode: 217, duration: 0.487s, episode steps:  59, steps per second: 121, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 6.836499, mae: 42.656959, mean_q: 91.107348, mean_eps: 0.373285\n",
            " 6706/10000: episode: 218, duration: 0.643s, episode steps:  79, steps per second: 123, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 5.794140, mae: 42.856397, mean_q: 90.833837, mean_eps: 0.366730\n",
            " 6844/10000: episode: 219, duration: 1.121s, episode steps: 138, steps per second: 123, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.428 [0.000, 1.000],  loss: 5.380474, mae: 42.852445, mean_q: 91.533505, mean_eps: 0.356423\n",
            " 6858/10000: episode: 220, duration: 0.125s, episode steps:  14, steps per second: 112, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 6.967784, mae: 42.782954, mean_q: 90.227632, mean_eps: 0.349203\n",
            " 6885/10000: episode: 221, duration: 0.247s, episode steps:  27, steps per second: 109, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 5.236385, mae: 42.576414, mean_q: 90.841360, mean_eps: 0.347255\n",
            " 6997/10000: episode: 222, duration: 0.940s, episode steps: 112, steps per second: 119, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.411 [0.000, 1.000],  loss: 9.406245, mae: 42.858328, mean_q: 91.094087, mean_eps: 0.340653\n",
            " 7096/10000: episode: 223, duration: 0.826s, episode steps:  99, steps per second: 120, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 4.398957, mae: 43.156717, mean_q: 91.808392, mean_eps: 0.330630\n",
            " 7144/10000: episode: 224, duration: 0.408s, episode steps:  48, steps per second: 118, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 7.046309, mae: 43.089499, mean_q: 90.890381, mean_eps: 0.323648\n",
            " 7183/10000: episode: 225, duration: 0.329s, episode steps:  39, steps per second: 118, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 3.464493, mae: 43.198976, mean_q: 91.372590, mean_eps: 0.319515\n",
            " 7242/10000: episode: 226, duration: 0.510s, episode steps:  59, steps per second: 116, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 6.224938, mae: 43.194697, mean_q: 91.896993, mean_eps: 0.314860\n",
            " 7343/10000: episode: 227, duration: 0.810s, episode steps: 101, steps per second: 125, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 8.974732, mae: 42.539596, mean_q: 91.009182, mean_eps: 0.307260\n",
            " 7400/10000: episode: 228, duration: 0.487s, episode steps:  57, steps per second: 117, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 4.691382, mae: 43.182514, mean_q: 92.000603, mean_eps: 0.299755\n",
            " 7461/10000: episode: 229, duration: 0.684s, episode steps:  61, steps per second:  89, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 9.021790, mae: 42.482414, mean_q: 91.175719, mean_eps: 0.294150\n",
            " 7490/10000: episode: 230, duration: 0.363s, episode steps:  29, steps per second:  80, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.586 [0.000, 1.000],  loss: 10.676694, mae: 42.222473, mean_q: 90.666382, mean_eps: 0.289875\n",
            " 7511/10000: episode: 231, duration: 0.265s, episode steps:  21, steps per second:  79, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 5.430663, mae: 43.697619, mean_q: 92.508167, mean_eps: 0.287500\n",
            " 7550/10000: episode: 232, duration: 0.498s, episode steps:  39, steps per second:  78, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.590 [0.000, 1.000],  loss: 6.519175, mae: 43.461108, mean_q: 91.894997, mean_eps: 0.284650\n",
            " 7601/10000: episode: 233, duration: 0.625s, episode steps:  51, steps per second:  82, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 4.189454, mae: 43.217633, mean_q: 92.090823, mean_eps: 0.280375\n",
            " 7635/10000: episode: 234, duration: 0.449s, episode steps:  34, steps per second:  76, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.382 [0.000, 1.000],  loss: 8.085568, mae: 43.567529, mean_q: 91.971697, mean_eps: 0.276338\n",
            " 7729/10000: episode: 235, duration: 0.922s, episode steps:  94, steps per second: 102, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 4.041224, mae: 42.409690, mean_q: 91.094360, mean_eps: 0.270258\n",
            " 7789/10000: episode: 236, duration: 0.498s, episode steps:  60, steps per second: 121, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 5.090849, mae: 43.338751, mean_q: 91.907884, mean_eps: 0.262943\n",
            " 7862/10000: episode: 237, duration: 0.622s, episode steps:  73, steps per second: 117, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 9.157963, mae: 43.601264, mean_q: 92.605147, mean_eps: 0.256625\n",
            " 7964/10000: episode: 238, duration: 0.859s, episode steps: 102, steps per second: 119, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 7.454861, mae: 43.145782, mean_q: 91.674068, mean_eps: 0.248312\n",
            " 8124/10000: episode: 239, duration: 1.342s, episode steps: 160, steps per second: 119, episode reward: 160.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 7.269801, mae: 43.421262, mean_q: 91.994898, mean_eps: 0.235868\n",
            " 8266/10000: episode: 240, duration: 1.157s, episode steps: 142, steps per second: 123, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 8.370729, mae: 43.133815, mean_q: 91.532329, mean_eps: 0.221523\n",
            " 8277/10000: episode: 241, duration: 0.103s, episode steps:  11, steps per second: 107, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 4.737892, mae: 43.393670, mean_q: 91.697079, mean_eps: 0.214255\n",
            " 8340/10000: episode: 242, duration: 0.549s, episode steps:  63, steps per second: 115, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 5.675498, mae: 43.917994, mean_q: 92.433146, mean_eps: 0.210740\n",
            " 8381/10000: episode: 243, duration: 0.338s, episode steps:  41, steps per second: 121, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 4.384512, mae: 43.634015, mean_q: 92.412242, mean_eps: 0.205800\n",
            " 8434/10000: episode: 244, duration: 0.439s, episode steps:  53, steps per second: 121, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.434 [0.000, 1.000],  loss: 5.909425, mae: 43.636157, mean_q: 92.340429, mean_eps: 0.201335\n",
            " 8529/10000: episode: 245, duration: 0.775s, episode steps:  95, steps per second: 123, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 5.321958, mae: 43.128380, mean_q: 91.757178, mean_eps: 0.194305\n",
            " 8552/10000: episode: 246, duration: 0.189s, episode steps:  23, steps per second: 122, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 2.313699, mae: 43.604759, mean_q: 92.970782, mean_eps: 0.188700\n",
            " 8658/10000: episode: 247, duration: 0.862s, episode steps: 106, steps per second: 123, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 5.740806, mae: 43.538728, mean_q: 92.393660, mean_eps: 0.182573\n",
            " 8702/10000: episode: 248, duration: 0.382s, episode steps:  44, steps per second: 115, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.685307, mae: 43.354132, mean_q: 91.704175, mean_eps: 0.175448\n",
            " 8901/10000: episode: 249, duration: 1.835s, episode steps: 199, steps per second: 108, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 5.452020, mae: 43.339484, mean_q: 92.360974, mean_eps: 0.163905\n",
            " 8940/10000: episode: 250, duration: 0.471s, episode steps:  39, steps per second:  83, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.564 [0.000, 1.000],  loss: 4.245920, mae: 43.258714, mean_q: 92.779968, mean_eps: 0.152600\n",
            " 8984/10000: episode: 251, duration: 0.547s, episode steps:  44, steps per second:  80, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.870366, mae: 42.778829, mean_q: 91.796011, mean_eps: 0.148658\n",
            " 9166/10000: episode: 252, duration: 1.929s, episode steps: 182, steps per second:  94, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 5.610752, mae: 43.541977, mean_q: 92.750287, mean_eps: 0.137923\n",
            " 9181/10000: episode: 253, duration: 0.131s, episode steps:  15, steps per second: 114, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 3.832920, mae: 43.215071, mean_q: 91.557371, mean_eps: 0.128565\n",
            " 9200/10000: episode: 254, duration: 0.173s, episode steps:  19, steps per second: 110, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 6.526495, mae: 44.361648, mean_q: 94.312280, mean_eps: 0.126950\n",
            " 9265/10000: episode: 255, duration: 0.551s, episode steps:  65, steps per second: 118, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 9.361370, mae: 43.778624, mean_q: 93.080994, mean_eps: 0.122960\n",
            " 9340/10000: episode: 256, duration: 0.632s, episode steps:  75, steps per second: 119, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 8.344685, mae: 44.154800, mean_q: 93.879677, mean_eps: 0.116310\n",
            " 9432/10000: episode: 257, duration: 0.757s, episode steps:  92, steps per second: 121, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 8.750450, mae: 43.651156, mean_q: 93.368602, mean_eps: 0.108378\n",
            " 9575/10000: episode: 258, duration: 1.187s, episode steps: 143, steps per second: 120, episode reward: 143.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 6.008444, mae: 43.741445, mean_q: 93.561743, mean_eps: 0.097215\n",
            " 9696/10000: episode: 259, duration: 1.012s, episode steps: 121, steps per second: 120, episode reward: 121.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 4.001113, mae: 43.821652, mean_q: 93.960129, mean_eps: 0.084675\n",
            " 9807/10000: episode: 260, duration: 0.939s, episode steps: 111, steps per second: 118, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 3.980466, mae: 43.571861, mean_q: 93.914511, mean_eps: 0.073655\n",
            " 9945/10000: episode: 261, duration: 1.126s, episode steps: 138, steps per second: 123, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 5.012684, mae: 43.733299, mean_q: 93.749076, mean_eps: 0.061828\n",
            "done, took 93.758 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 174.000, steps: 174\n",
            "Episode 2: reward: 178.000, steps: 178\n",
            "Episode 3: reward: 187.000, steps: 187\n",
            "Episode 4: reward: 173.000, steps: 173\n",
            "Episode 5: reward: 172.000, steps: 172\n",
            "Episode 6: reward: 191.000, steps: 191\n",
            "Episode 7: reward: 177.000, steps: 177\n",
            "Episode 8: reward: 177.000, steps: 177\n",
            "Episode 9: reward: 173.000, steps: 173\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 162.000, steps: 162\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 186.000, steps: 186\n",
            "Episode 14: reward: 157.000, steps: 157\n",
            "Episode 15: reward: 158.000, steps: 158\n",
            "Episode 16: reward: 152.000, steps: 152\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 172.000, steps: 172\n",
            "Episode 19: reward: 175.000, steps: 175\n",
            "Episode 20: reward: 177.000, steps: 177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd751e0f4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Network with 2 hidden layer"
      ],
      "metadata": {
        "id": "LFO5IYBATjwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Q-Network\n",
        "# model = Sequential()\n",
        "# model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "# model.add(Flatten())\n",
        "# # add extra layers here\n",
        "# model.add(Dense(16, activation='relu'))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "# print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58mgFcd5TQBN",
        "outputId": "96a943b1-8b79-4ecc-f5fb-afea389b07ce"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 690\n",
            "Trainable params: 690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 1.0\n",
        "\n",
        "# value_min = 0.01\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "# target_model_update=1e-2\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "bfTkKSwwUdkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.01, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-2_kSkQgUSmv",
        "outputId": "17d398c7-242c-489a-b0b3-9bf8e591d5ea"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   17/10000: episode: 1, duration: 2.419s, episode steps:  17, steps per second:   7, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 0.261790, mae: 0.603373, mean_q: 0.571284, mean_eps: 0.998664\n",
            "   51/10000: episode: 2, duration: 0.271s, episode steps:  34, steps per second: 125, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.382 [0.000, 1.000],  loss: 0.029714, mae: 0.764287, mean_q: 1.433137, mean_eps: 0.996683\n",
            "   62/10000: episode: 3, duration: 0.088s, episode steps:  11, steps per second: 125, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.012866, mae: 0.827941, mean_q: 1.627244, mean_eps: 0.994456\n",
            "   88/10000: episode: 4, duration: 0.215s, episode steps:  26, steps per second: 121, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.008441, mae: 0.904307, mean_q: 1.811396, mean_eps: 0.992624\n",
            "  105/10000: episode: 5, duration: 0.143s, episode steps:  17, steps per second: 119, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 0.012992, mae: 0.989540, mean_q: 1.963803, mean_eps: 0.990496\n",
            "  129/10000: episode: 6, duration: 0.192s, episode steps:  24, steps per second: 125, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 0.012143, mae: 1.072240, mean_q: 2.143177, mean_eps: 0.988466\n",
            "  143/10000: episode: 7, duration: 0.109s, episode steps:  14, steps per second: 128, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 0.006898, mae: 1.152351, mean_q: 2.330191, mean_eps: 0.986586\n",
            "  158/10000: episode: 8, duration: 0.125s, episode steps:  15, steps per second: 120, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.017012, mae: 1.202552, mean_q: 2.416540, mean_eps: 0.985150\n",
            "  168/10000: episode: 9, duration: 0.081s, episode steps:  10, steps per second: 124, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 0.025239, mae: 1.257351, mean_q: 2.530757, mean_eps: 0.983912\n",
            "  179/10000: episode: 10, duration: 0.090s, episode steps:  11, steps per second: 122, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.026510, mae: 1.331167, mean_q: 2.652355, mean_eps: 0.982873\n",
            "  211/10000: episode: 11, duration: 0.253s, episode steps:  32, steps per second: 127, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 0.021791, mae: 1.411259, mean_q: 2.799900, mean_eps: 0.980744\n",
            "  223/10000: episode: 12, duration: 0.111s, episode steps:  12, steps per second: 108, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.018380, mae: 1.523917, mean_q: 3.061358, mean_eps: 0.978567\n",
            "  256/10000: episode: 13, duration: 0.272s, episode steps:  33, steps per second: 121, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 0.036785, mae: 1.617280, mean_q: 3.221755, mean_eps: 0.976339\n",
            "  289/10000: episode: 14, duration: 0.268s, episode steps:  33, steps per second: 123, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.606 [0.000, 1.000],  loss: 0.062577, mae: 1.793451, mean_q: 3.526381, mean_eps: 0.973072\n",
            "  308/10000: episode: 15, duration: 0.151s, episode steps:  19, steps per second: 126, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 0.077660, mae: 1.897076, mean_q: 3.692580, mean_eps: 0.970498\n",
            "  323/10000: episode: 16, duration: 0.125s, episode steps:  15, steps per second: 120, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 0.162998, mae: 2.010032, mean_q: 3.871685, mean_eps: 0.968815\n",
            "  347/10000: episode: 17, duration: 0.198s, episode steps:  24, steps per second: 121, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.063322, mae: 2.074973, mean_q: 4.075947, mean_eps: 0.966884\n",
            "  361/10000: episode: 18, duration: 0.122s, episode steps:  14, steps per second: 115, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.098607, mae: 2.175656, mean_q: 4.226908, mean_eps: 0.965004\n",
            "  373/10000: episode: 19, duration: 0.098s, episode steps:  12, steps per second: 122, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 0.075519, mae: 2.267963, mean_q: 4.413425, mean_eps: 0.963716\n",
            "  393/10000: episode: 20, duration: 0.165s, episode steps:  20, steps per second: 121, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 0.089642, mae: 2.314841, mean_q: 4.566900, mean_eps: 0.962133\n",
            "  419/10000: episode: 21, duration: 0.218s, episode steps:  26, steps per second: 119, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 0.121433, mae: 2.429952, mean_q: 4.751591, mean_eps: 0.959855\n",
            "  445/10000: episode: 22, duration: 0.210s, episode steps:  26, steps per second: 124, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.114118, mae: 2.585611, mean_q: 5.042217, mean_eps: 0.957282\n",
            "  458/10000: episode: 23, duration: 0.114s, episode steps:  13, steps per second: 114, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: 0.123884, mae: 2.660425, mean_q: 5.192313, mean_eps: 0.955351\n",
            "  472/10000: episode: 24, duration: 0.118s, episode steps:  14, steps per second: 119, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 0.143887, mae: 2.742622, mean_q: 5.296695, mean_eps: 0.954014\n",
            "  492/10000: episode: 25, duration: 0.173s, episode steps:  20, steps per second: 115, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 0.131992, mae: 2.807991, mean_q: 5.492612, mean_eps: 0.952331\n",
            "  512/10000: episode: 26, duration: 0.161s, episode steps:  20, steps per second: 125, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 0.113360, mae: 2.890873, mean_q: 5.708288, mean_eps: 0.950352\n",
            "  543/10000: episode: 27, duration: 0.249s, episode steps:  31, steps per second: 124, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.613 [0.000, 1.000],  loss: 0.187849, mae: 3.045291, mean_q: 5.932269, mean_eps: 0.947827\n",
            "  557/10000: episode: 28, duration: 0.115s, episode steps:  14, steps per second: 122, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 0.107745, mae: 3.131198, mean_q: 6.188452, mean_eps: 0.945599\n",
            "  573/10000: episode: 29, duration: 0.140s, episode steps:  16, steps per second: 114, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.169523, mae: 3.194971, mean_q: 6.251881, mean_eps: 0.944114\n",
            "  593/10000: episode: 30, duration: 0.165s, episode steps:  20, steps per second: 121, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.210490, mae: 3.295518, mean_q: 6.449179, mean_eps: 0.942333\n",
            "  607/10000: episode: 31, duration: 0.133s, episode steps:  14, steps per second: 105, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.265575, mae: 3.381560, mean_q: 6.534980, mean_eps: 0.940650\n",
            "  640/10000: episode: 32, duration: 0.365s, episode steps:  33, steps per second:  90, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 0.224886, mae: 3.514016, mean_q: 6.794066, mean_eps: 0.938323\n",
            "  681/10000: episode: 33, duration: 0.481s, episode steps:  41, steps per second:  85, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.585 [0.000, 1.000],  loss: 0.319919, mae: 3.662625, mean_q: 7.057765, mean_eps: 0.934660\n",
            "  718/10000: episode: 34, duration: 0.412s, episode steps:  37, steps per second:  90, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 0.253590, mae: 3.827621, mean_q: 7.476685, mean_eps: 0.930799\n",
            "  735/10000: episode: 35, duration: 0.191s, episode steps:  17, steps per second:  89, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 0.287141, mae: 3.934195, mean_q: 7.622552, mean_eps: 0.928126\n",
            "  754/10000: episode: 36, duration: 0.225s, episode steps:  19, steps per second:  84, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 0.478769, mae: 4.004785, mean_q: 7.716935, mean_eps: 0.926344\n",
            "  768/10000: episode: 37, duration: 0.171s, episode steps:  14, steps per second:  82, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 0.321585, mae: 4.098578, mean_q: 7.884837, mean_eps: 0.924710\n",
            "  780/10000: episode: 38, duration: 0.152s, episode steps:  12, steps per second:  79, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.257472, mae: 4.083985, mean_q: 7.932172, mean_eps: 0.923424\n",
            "  802/10000: episode: 39, duration: 0.259s, episode steps:  22, steps per second:  85, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 0.280048, mae: 4.220817, mean_q: 8.205502, mean_eps: 0.921741\n",
            "  818/10000: episode: 40, duration: 0.188s, episode steps:  16, steps per second:  85, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.127397, mae: 4.302420, mean_q: 8.453548, mean_eps: 0.919860\n",
            "  835/10000: episode: 41, duration: 0.206s, episode steps:  17, steps per second:  83, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 0.422774, mae: 4.430676, mean_q: 8.572868, mean_eps: 0.918226\n",
            "  856/10000: episode: 42, duration: 0.262s, episode steps:  21, steps per second:  80, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.408491, mae: 4.455384, mean_q: 8.696534, mean_eps: 0.916345\n",
            "  890/10000: episode: 43, duration: 0.331s, episode steps:  34, steps per second: 103, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.356171, mae: 4.576169, mean_q: 8.853877, mean_eps: 0.913622\n",
            "  911/10000: episode: 44, duration: 0.171s, episode steps:  21, steps per second: 123, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 0.245244, mae: 4.708051, mean_q: 9.171985, mean_eps: 0.910900\n",
            "  925/10000: episode: 45, duration: 0.126s, episode steps:  14, steps per second: 111, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.786 [0.000, 1.000],  loss: 0.300343, mae: 4.743625, mean_q: 9.301069, mean_eps: 0.909167\n",
            "  941/10000: episode: 46, duration: 0.144s, episode steps:  16, steps per second: 111, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.446986, mae: 4.793532, mean_q: 9.314981, mean_eps: 0.907682\n",
            "  973/10000: episode: 47, duration: 0.252s, episode steps:  32, steps per second: 127, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.412753, mae: 4.928006, mean_q: 9.537692, mean_eps: 0.905307\n",
            " 1000/10000: episode: 48, duration: 0.229s, episode steps:  27, steps per second: 118, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.726032, mae: 5.046869, mean_q: 9.696237, mean_eps: 0.902386\n",
            " 1015/10000: episode: 49, duration: 0.120s, episode steps:  15, steps per second: 125, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 0.572720, mae: 5.299993, mean_q: 10.073945, mean_eps: 0.900307\n",
            " 1044/10000: episode: 50, duration: 0.230s, episode steps:  29, steps per second: 126, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 0.429882, mae: 5.209557, mean_q: 10.033945, mean_eps: 0.898129\n",
            " 1066/10000: episode: 51, duration: 0.182s, episode steps:  22, steps per second: 121, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 0.287684, mae: 5.302478, mean_q: 10.362240, mean_eps: 0.895604\n",
            " 1083/10000: episode: 52, duration: 0.146s, episode steps:  17, steps per second: 117, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.294 [0.000, 1.000],  loss: 0.246291, mae: 5.370320, mean_q: 10.543514, mean_eps: 0.893674\n",
            " 1100/10000: episode: 53, duration: 0.134s, episode steps:  17, steps per second: 127, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.294 [0.000, 1.000],  loss: 0.230953, mae: 5.441079, mean_q: 10.688786, mean_eps: 0.891991\n",
            " 1129/10000: episode: 54, duration: 0.236s, episode steps:  29, steps per second: 123, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 0.354516, mae: 5.540393, mean_q: 10.825167, mean_eps: 0.889714\n",
            " 1143/10000: episode: 55, duration: 0.118s, episode steps:  14, steps per second: 118, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.532758, mae: 5.601325, mean_q: 10.915046, mean_eps: 0.887586\n",
            " 1181/10000: episode: 56, duration: 0.310s, episode steps:  38, steps per second: 123, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 0.545822, mae: 5.764342, mean_q: 11.218993, mean_eps: 0.885012\n",
            " 1205/10000: episode: 57, duration: 0.197s, episode steps:  24, steps per second: 122, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.493619, mae: 5.863273, mean_q: 11.460679, mean_eps: 0.881943\n",
            " 1227/10000: episode: 58, duration: 0.171s, episode steps:  22, steps per second: 129, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 0.529895, mae: 5.994861, mean_q: 11.694310, mean_eps: 0.879666\n",
            " 1244/10000: episode: 59, duration: 0.140s, episode steps:  17, steps per second: 121, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 0.480135, mae: 6.059093, mean_q: 11.870597, mean_eps: 0.877735\n",
            " 1261/10000: episode: 60, duration: 0.148s, episode steps:  17, steps per second: 115, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 0.633204, mae: 6.067481, mean_q: 11.861386, mean_eps: 0.876052\n",
            " 1276/10000: episode: 61, duration: 0.128s, episode steps:  15, steps per second: 117, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 0.546767, mae: 6.132540, mean_q: 12.052258, mean_eps: 0.874468\n",
            " 1297/10000: episode: 62, duration: 0.182s, episode steps:  21, steps per second: 116, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 0.631219, mae: 6.220405, mean_q: 12.161512, mean_eps: 0.872686\n",
            " 1315/10000: episode: 63, duration: 0.154s, episode steps:  18, steps per second: 117, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 0.560872, mae: 6.345960, mean_q: 12.450305, mean_eps: 0.870756\n",
            " 1332/10000: episode: 64, duration: 0.137s, episode steps:  17, steps per second: 124, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 0.707004, mae: 6.411442, mean_q: 12.568750, mean_eps: 0.869023\n",
            " 1351/10000: episode: 65, duration: 0.157s, episode steps:  19, steps per second: 121, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 0.773280, mae: 6.449368, mean_q: 12.642776, mean_eps: 0.867241\n",
            " 1379/10000: episode: 66, duration: 0.230s, episode steps:  28, steps per second: 122, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 0.497642, mae: 6.585957, mean_q: 12.962642, mean_eps: 0.864915\n",
            " 1411/10000: episode: 67, duration: 0.257s, episode steps:  32, steps per second: 124, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.832419, mae: 6.743107, mean_q: 13.130661, mean_eps: 0.861945\n",
            " 1460/10000: episode: 68, duration: 0.391s, episode steps:  49, steps per second: 125, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 0.491558, mae: 6.859992, mean_q: 13.517366, mean_eps: 0.857935\n",
            " 1533/10000: episode: 69, duration: 0.577s, episode steps:  73, steps per second: 127, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 0.883014, mae: 7.076577, mean_q: 14.003946, mean_eps: 0.851896\n",
            " 1564/10000: episode: 70, duration: 0.248s, episode steps:  31, steps per second: 125, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 0.837811, mae: 7.287571, mean_q: 14.477739, mean_eps: 0.846748\n",
            " 1591/10000: episode: 71, duration: 0.217s, episode steps:  27, steps per second: 124, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 0.309601, mae: 7.387268, mean_q: 14.757503, mean_eps: 0.843877\n",
            " 1607/10000: episode: 72, duration: 0.131s, episode steps:  16, steps per second: 122, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.552040, mae: 7.394456, mean_q: 14.868739, mean_eps: 0.841749\n",
            " 1641/10000: episode: 73, duration: 0.283s, episode steps:  34, steps per second: 120, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 0.841957, mae: 7.572697, mean_q: 15.124452, mean_eps: 0.839274\n",
            " 1652/10000: episode: 74, duration: 0.094s, episode steps:  11, steps per second: 117, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: 0.623496, mae: 7.721749, mean_q: 15.493153, mean_eps: 0.837046\n",
            " 1683/10000: episode: 75, duration: 0.251s, episode steps:  31, steps per second: 124, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 1.060913, mae: 7.773343, mean_q: 15.402129, mean_eps: 0.834967\n",
            " 1699/10000: episode: 76, duration: 0.134s, episode steps:  16, steps per second: 120, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.926930, mae: 7.815943, mean_q: 15.536633, mean_eps: 0.832641\n",
            " 1721/10000: episode: 77, duration: 0.179s, episode steps:  22, steps per second: 123, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 0.876973, mae: 7.918768, mean_q: 15.818244, mean_eps: 0.830760\n",
            " 1736/10000: episode: 78, duration: 0.119s, episode steps:  15, steps per second: 126, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.745722, mae: 7.983757, mean_q: 15.875548, mean_eps: 0.828928\n",
            " 1755/10000: episode: 79, duration: 0.155s, episode steps:  19, steps per second: 122, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 0.495869, mae: 8.116245, mean_q: 16.197332, mean_eps: 0.827245\n",
            " 1803/10000: episode: 80, duration: 0.383s, episode steps:  48, steps per second: 125, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.753368, mae: 8.176766, mean_q: 16.373970, mean_eps: 0.823928\n",
            " 1829/10000: episode: 81, duration: 0.205s, episode steps:  26, steps per second: 127, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.611807, mae: 8.400418, mean_q: 16.748849, mean_eps: 0.820266\n",
            " 1904/10000: episode: 82, duration: 0.589s, episode steps:  75, steps per second: 127, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 0.732251, mae: 8.555365, mean_q: 17.240182, mean_eps: 0.815266\n",
            " 1922/10000: episode: 83, duration: 0.144s, episode steps:  18, steps per second: 125, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 1.043848, mae: 8.835454, mean_q: 17.748563, mean_eps: 0.810662\n",
            " 2019/10000: episode: 84, duration: 0.751s, episode steps:  97, steps per second: 129, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 1.166835, mae: 9.048256, mean_q: 18.004902, mean_eps: 0.804970\n",
            " 2027/10000: episode: 85, duration: 0.071s, episode steps:   8, steps per second: 112, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.875 [0.000, 1.000],  loss: 1.269891, mae: 9.261776, mean_q: 18.534754, mean_eps: 0.799772\n",
            " 2043/10000: episode: 86, duration: 0.126s, episode steps:  16, steps per second: 127, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.566088, mae: 9.372454, mean_q: 18.794410, mean_eps: 0.798585\n",
            " 2081/10000: episode: 87, duration: 0.297s, episode steps:  38, steps per second: 128, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 1.434562, mae: 9.401205, mean_q: 18.686168, mean_eps: 0.795912\n",
            " 2097/10000: episode: 88, duration: 0.130s, episode steps:  16, steps per second: 123, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.570422, mae: 9.612994, mean_q: 19.351194, mean_eps: 0.793238\n",
            " 2114/10000: episode: 89, duration: 0.194s, episode steps:  17, steps per second:  88, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 0.395877, mae: 9.573479, mean_q: 19.265850, mean_eps: 0.791605\n",
            " 2208/10000: episode: 90, duration: 1.046s, episode steps:  94, steps per second:  90, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 0.996945, mae: 9.806132, mean_q: 19.777915, mean_eps: 0.786110\n",
            " 2306/10000: episode: 91, duration: 1.076s, episode steps:  98, steps per second:  91, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 0.825312, mae: 10.219577, mean_q: 20.621667, mean_eps: 0.776607\n",
            " 2381/10000: episode: 92, duration: 0.789s, episode steps:  75, steps per second:  95, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.427 [0.000, 1.000],  loss: 1.540517, mae: 10.528100, mean_q: 21.138265, mean_eps: 0.768043\n",
            " 2397/10000: episode: 93, duration: 0.122s, episode steps:  16, steps per second: 132, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 2.069988, mae: 10.868323, mean_q: 21.839875, mean_eps: 0.763539\n",
            " 2455/10000: episode: 94, duration: 0.473s, episode steps:  58, steps per second: 123, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.279111, mae: 11.050787, mean_q: 22.195444, mean_eps: 0.759875\n",
            " 2474/10000: episode: 95, duration: 0.147s, episode steps:  19, steps per second: 129, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 0.984151, mae: 11.044494, mean_q: 22.260552, mean_eps: 0.756064\n",
            " 2486/10000: episode: 96, duration: 0.113s, episode steps:  12, steps per second: 106, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.784039, mae: 11.266825, mean_q: 22.644137, mean_eps: 0.754529\n",
            " 2507/10000: episode: 97, duration: 0.184s, episode steps:  21, steps per second: 114, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 1.192934, mae: 11.215122, mean_q: 22.574576, mean_eps: 0.752896\n",
            " 2532/10000: episode: 98, duration: 0.214s, episode steps:  25, steps per second: 117, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 1.496614, mae: 11.344047, mean_q: 22.748088, mean_eps: 0.750619\n",
            " 2551/10000: episode: 99, duration: 0.158s, episode steps:  19, steps per second: 120, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.684 [0.000, 1.000],  loss: 0.996823, mae: 11.502580, mean_q: 22.962091, mean_eps: 0.748441\n",
            " 2578/10000: episode: 100, duration: 0.226s, episode steps:  27, steps per second: 120, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 0.718415, mae: 11.503948, mean_q: 23.297543, mean_eps: 0.746164\n",
            " 2641/10000: episode: 101, duration: 0.484s, episode steps:  63, steps per second: 130, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 0.882463, mae: 11.587403, mean_q: 23.532275, mean_eps: 0.741709\n",
            " 2712/10000: episode: 102, duration: 0.556s, episode steps:  71, steps per second: 128, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 1.699605, mae: 11.950175, mean_q: 24.032325, mean_eps: 0.735076\n",
            " 2739/10000: episode: 103, duration: 0.216s, episode steps:  27, steps per second: 125, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 1.199996, mae: 11.951416, mean_q: 24.328299, mean_eps: 0.730225\n",
            " 2752/10000: episode: 104, duration: 0.104s, episode steps:  13, steps per second: 125, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.904867, mae: 12.131107, mean_q: 24.695982, mean_eps: 0.728245\n",
            " 2773/10000: episode: 105, duration: 0.172s, episode steps:  21, steps per second: 122, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 1.566659, mae: 12.292777, mean_q: 24.862164, mean_eps: 0.726562\n",
            " 2829/10000: episode: 106, duration: 0.438s, episode steps:  56, steps per second: 128, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 1.102181, mae: 12.377922, mean_q: 24.988310, mean_eps: 0.722751\n",
            " 2843/10000: episode: 107, duration: 0.122s, episode steps:  14, steps per second: 115, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 2.656464, mae: 12.854777, mean_q: 25.845299, mean_eps: 0.719286\n",
            " 2861/10000: episode: 108, duration: 0.146s, episode steps:  18, steps per second: 123, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.498087, mae: 12.617129, mean_q: 25.493529, mean_eps: 0.717701\n",
            " 2906/10000: episode: 109, duration: 0.353s, episode steps:  45, steps per second: 128, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 2.392193, mae: 12.698449, mean_q: 25.729233, mean_eps: 0.714583\n",
            " 2924/10000: episode: 110, duration: 0.165s, episode steps:  18, steps per second: 109, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 2.096484, mae: 12.896263, mean_q: 26.129436, mean_eps: 0.711465\n",
            " 2974/10000: episode: 111, duration: 0.388s, episode steps:  50, steps per second: 129, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 1.459049, mae: 13.076814, mean_q: 26.490223, mean_eps: 0.708098\n",
            " 3016/10000: episode: 112, duration: 0.340s, episode steps:  42, steps per second: 123, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.130523, mae: 13.214906, mean_q: 26.804568, mean_eps: 0.703545\n",
            " 3144/10000: episode: 113, duration: 1.000s, episode steps: 128, steps per second: 128, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 2.152653, mae: 13.615241, mean_q: 27.512819, mean_eps: 0.695129\n",
            " 3161/10000: episode: 114, duration: 0.141s, episode steps:  17, steps per second: 120, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 2.932905, mae: 13.898232, mean_q: 27.956571, mean_eps: 0.687952\n",
            " 3183/10000: episode: 115, duration: 0.195s, episode steps:  22, steps per second: 113, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 2.005222, mae: 14.058527, mean_q: 28.312075, mean_eps: 0.686022\n",
            " 3225/10000: episode: 116, duration: 0.344s, episode steps:  42, steps per second: 122, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.401608, mae: 14.025610, mean_q: 28.439347, mean_eps: 0.682854\n",
            " 3280/10000: episode: 117, duration: 0.423s, episode steps:  55, steps per second: 130, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 1.566774, mae: 14.180443, mean_q: 28.707634, mean_eps: 0.678052\n",
            " 3305/10000: episode: 118, duration: 0.198s, episode steps:  25, steps per second: 126, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 2.240913, mae: 14.546694, mean_q: 29.407299, mean_eps: 0.674092\n",
            " 3324/10000: episode: 119, duration: 0.160s, episode steps:  19, steps per second: 119, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 1.265579, mae: 14.414735, mean_q: 29.352593, mean_eps: 0.671914\n",
            " 3348/10000: episode: 120, duration: 0.188s, episode steps:  24, steps per second: 128, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 2.429835, mae: 14.445791, mean_q: 29.281769, mean_eps: 0.669786\n",
            " 3403/10000: episode: 121, duration: 0.431s, episode steps:  55, steps per second: 128, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 2.242943, mae: 14.566565, mean_q: 29.630151, mean_eps: 0.665875\n",
            " 3440/10000: episode: 122, duration: 0.305s, episode steps:  37, steps per second: 121, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 1.864970, mae: 14.793494, mean_q: 29.908535, mean_eps: 0.661321\n",
            " 3491/10000: episode: 123, duration: 0.401s, episode steps:  51, steps per second: 127, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 2.712339, mae: 15.106674, mean_q: 30.378634, mean_eps: 0.656965\n",
            " 3510/10000: episode: 124, duration: 0.146s, episode steps:  19, steps per second: 130, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 2.113248, mae: 14.906577, mean_q: 30.208100, mean_eps: 0.653500\n",
            " 3532/10000: episode: 125, duration: 0.178s, episode steps:  22, steps per second: 124, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 3.026777, mae: 15.307000, mean_q: 30.744809, mean_eps: 0.651470\n",
            " 3567/10000: episode: 126, duration: 0.284s, episode steps:  35, steps per second: 123, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 1.627525, mae: 15.266278, mean_q: 30.806734, mean_eps: 0.648649\n",
            " 3676/10000: episode: 127, duration: 1.097s, episode steps: 109, steps per second:  99, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 2.231618, mae: 15.481282, mean_q: 31.369131, mean_eps: 0.641521\n",
            " 3777/10000: episode: 128, duration: 1.120s, episode steps: 101, steps per second:  90, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 2.523200, mae: 15.855063, mean_q: 32.099499, mean_eps: 0.631126\n",
            " 3863/10000: episode: 129, duration: 0.975s, episode steps:  86, steps per second:  88, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 1.870784, mae: 16.079349, mean_q: 32.610001, mean_eps: 0.621870\n",
            " 3878/10000: episode: 130, duration: 0.174s, episode steps:  15, steps per second:  86, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.487178, mae: 16.058730, mean_q: 33.001506, mean_eps: 0.616870\n",
            " 3908/10000: episode: 131, duration: 0.253s, episode steps:  30, steps per second: 119, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 2.363688, mae: 16.370961, mean_q: 33.309987, mean_eps: 0.614643\n",
            " 4006/10000: episode: 132, duration: 0.776s, episode steps:  98, steps per second: 126, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 2.382816, mae: 16.676046, mean_q: 33.751473, mean_eps: 0.608306\n",
            " 4025/10000: episode: 133, duration: 0.151s, episode steps:  19, steps per second: 126, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.684 [0.000, 1.000],  loss: 0.937352, mae: 16.850431, mean_q: 34.136922, mean_eps: 0.602515\n",
            " 4069/10000: episode: 134, duration: 0.333s, episode steps:  44, steps per second: 132, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 2.575421, mae: 16.996613, mean_q: 34.418918, mean_eps: 0.599396\n",
            " 4111/10000: episode: 135, duration: 0.351s, episode steps:  42, steps per second: 120, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 1.849276, mae: 16.780877, mean_q: 34.276534, mean_eps: 0.595139\n",
            " 4123/10000: episode: 136, duration: 0.098s, episode steps:  12, steps per second: 122, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.471648, mae: 17.061132, mean_q: 35.082338, mean_eps: 0.592467\n",
            " 4144/10000: episode: 137, duration: 0.168s, episode steps:  21, steps per second: 125, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 1.622721, mae: 16.878955, mean_q: 34.439960, mean_eps: 0.590833\n",
            " 4164/10000: episode: 138, duration: 0.149s, episode steps:  20, steps per second: 134, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 1.338053, mae: 17.254113, mean_q: 35.271096, mean_eps: 0.588803\n",
            " 4272/10000: episode: 139, duration: 0.835s, episode steps: 108, steps per second: 129, episode reward: 108.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 1.891686, mae: 17.408395, mean_q: 35.293451, mean_eps: 0.582468\n",
            " 4306/10000: episode: 140, duration: 0.268s, episode steps:  34, steps per second: 127, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.845487, mae: 17.596414, mean_q: 35.788031, mean_eps: 0.575438\n",
            " 4341/10000: episode: 141, duration: 0.291s, episode steps:  35, steps per second: 120, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 2.894856, mae: 17.773157, mean_q: 36.028004, mean_eps: 0.572023\n",
            " 4367/10000: episode: 142, duration: 0.226s, episode steps:  26, steps per second: 115, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.217741, mae: 18.195764, mean_q: 36.905792, mean_eps: 0.569004\n",
            " 4376/10000: episode: 143, duration: 0.077s, episode steps:   9, steps per second: 117, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 2.130774, mae: 17.926241, mean_q: 36.296933, mean_eps: 0.567271\n",
            " 4415/10000: episode: 144, duration: 0.312s, episode steps:  39, steps per second: 125, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 1.871328, mae: 18.039655, mean_q: 36.791309, mean_eps: 0.564895\n",
            " 4430/10000: episode: 145, duration: 0.116s, episode steps:  15, steps per second: 129, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 2.889184, mae: 18.162306, mean_q: 37.052502, mean_eps: 0.562222\n",
            " 4456/10000: episode: 146, duration: 0.207s, episode steps:  26, steps per second: 126, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 1.982840, mae: 18.107113, mean_q: 36.799314, mean_eps: 0.560192\n",
            " 4522/10000: episode: 147, duration: 0.510s, episode steps:  66, steps per second: 129, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 3.323592, mae: 18.371138, mean_q: 37.123041, mean_eps: 0.555639\n",
            " 4538/10000: episode: 148, duration: 0.126s, episode steps:  16, steps per second: 127, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.543586, mae: 18.581508, mean_q: 37.286663, mean_eps: 0.551580\n",
            " 4568/10000: episode: 149, duration: 0.234s, episode steps:  30, steps per second: 128, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.433 [0.000, 1.000],  loss: 2.124793, mae: 18.354220, mean_q: 37.371637, mean_eps: 0.549303\n",
            " 4727/10000: episode: 150, duration: 1.248s, episode steps: 159, steps per second: 127, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 2.452214, mae: 18.882430, mean_q: 38.417106, mean_eps: 0.539947\n",
            " 4769/10000: episode: 151, duration: 0.332s, episode steps:  42, steps per second: 127, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 2.499678, mae: 19.284919, mean_q: 39.255917, mean_eps: 0.529998\n",
            " 4822/10000: episode: 152, duration: 0.420s, episode steps:  53, steps per second: 126, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 1.876657, mae: 19.506516, mean_q: 39.694884, mean_eps: 0.525295\n",
            " 4841/10000: episode: 153, duration: 0.165s, episode steps:  19, steps per second: 115, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 3.933753, mae: 19.886141, mean_q: 40.079554, mean_eps: 0.521731\n",
            " 4868/10000: episode: 154, duration: 0.239s, episode steps:  27, steps per second: 113, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 4.111349, mae: 19.735380, mean_q: 39.929365, mean_eps: 0.519454\n",
            " 4887/10000: episode: 155, duration: 0.148s, episode steps:  19, steps per second: 129, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 3.619934, mae: 19.754088, mean_q: 40.093846, mean_eps: 0.517177\n",
            " 4902/10000: episode: 156, duration: 0.131s, episode steps:  15, steps per second: 115, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 0.863603, mae: 19.633348, mean_q: 40.269879, mean_eps: 0.515494\n",
            " 4959/10000: episode: 157, duration: 0.448s, episode steps:  57, steps per second: 127, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 2.540999, mae: 19.825834, mean_q: 40.479265, mean_eps: 0.511930\n",
            " 4978/10000: episode: 158, duration: 0.168s, episode steps:  19, steps per second: 113, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 3.314722, mae: 19.813503, mean_q: 40.231134, mean_eps: 0.508168\n",
            " 4997/10000: episode: 159, duration: 0.161s, episode steps:  19, steps per second: 118, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 2.470712, mae: 20.331892, mean_q: 41.179029, mean_eps: 0.506287\n",
            " 5024/10000: episode: 160, duration: 0.222s, episode steps:  27, steps per second: 122, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 2.133516, mae: 19.956712, mean_q: 40.652954, mean_eps: 0.504010\n",
            " 5055/10000: episode: 161, duration: 0.253s, episode steps:  31, steps per second: 122, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 3.788958, mae: 20.250398, mean_q: 41.110588, mean_eps: 0.501139\n",
            " 5118/10000: episode: 162, duration: 0.507s, episode steps:  63, steps per second: 124, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 2.780669, mae: 20.393126, mean_q: 41.223306, mean_eps: 0.496486\n",
            " 5147/10000: episode: 163, duration: 0.347s, episode steps:  29, steps per second:  84, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 6.822249, mae: 20.582074, mean_q: 41.412151, mean_eps: 0.491932\n",
            " 5159/10000: episode: 164, duration: 0.144s, episode steps:  12, steps per second:  83, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 2.352932, mae: 20.893992, mean_q: 42.401603, mean_eps: 0.489903\n",
            " 5300/10000: episode: 165, duration: 1.558s, episode steps: 141, steps per second:  91, episode reward: 141.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.539 [0.000, 1.000],  loss: 2.907435, mae: 20.801997, mean_q: 42.242055, mean_eps: 0.482329\n",
            " 5370/10000: episode: 166, duration: 0.781s, episode steps:  70, steps per second:  90, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.429590, mae: 21.152904, mean_q: 43.155692, mean_eps: 0.471884\n",
            " 5383/10000: episode: 167, duration: 0.156s, episode steps:  13, steps per second:  83, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 3.992356, mae: 21.191461, mean_q: 42.966800, mean_eps: 0.467776\n",
            " 5397/10000: episode: 168, duration: 0.113s, episode steps:  14, steps per second: 124, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 5.169891, mae: 21.319602, mean_q: 43.180273, mean_eps: 0.466440\n",
            " 5410/10000: episode: 169, duration: 0.102s, episode steps:  13, steps per second: 127, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 2.876740, mae: 21.615654, mean_q: 43.571376, mean_eps: 0.465103\n",
            " 5455/10000: episode: 170, duration: 0.351s, episode steps:  45, steps per second: 128, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 3.437776, mae: 21.249162, mean_q: 43.128631, mean_eps: 0.462232\n",
            " 5596/10000: episode: 171, duration: 1.106s, episode steps: 141, steps per second: 127, episode reward: 141.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 4.090270, mae: 21.594093, mean_q: 43.849247, mean_eps: 0.453025\n",
            " 5633/10000: episode: 172, duration: 0.295s, episode steps:  37, steps per second: 126, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 1.742521, mae: 21.966263, mean_q: 44.945641, mean_eps: 0.444214\n",
            " 5680/10000: episode: 173, duration: 0.385s, episode steps:  47, steps per second: 122, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 2.277718, mae: 22.229470, mean_q: 45.424743, mean_eps: 0.440056\n",
            " 5747/10000: episode: 174, duration: 0.539s, episode steps:  67, steps per second: 124, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 6.699325, mae: 22.394332, mean_q: 45.194914, mean_eps: 0.434413\n",
            " 5760/10000: episode: 175, duration: 0.109s, episode steps:  13, steps per second: 119, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 3.349514, mae: 22.560483, mean_q: 45.906535, mean_eps: 0.430453\n",
            " 5773/10000: episode: 176, duration: 0.129s, episode steps:  13, steps per second: 101, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 4.083631, mae: 22.640671, mean_q: 45.771760, mean_eps: 0.429166\n",
            " 5800/10000: episode: 177, duration: 0.222s, episode steps:  27, steps per second: 122, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 3.899394, mae: 22.820865, mean_q: 46.193472, mean_eps: 0.427186\n",
            " 5816/10000: episode: 178, duration: 0.130s, episode steps:  16, steps per second: 123, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 3.249804, mae: 21.929844, mean_q: 45.266867, mean_eps: 0.425058\n",
            " 5830/10000: episode: 179, duration: 0.117s, episode steps:  14, steps per second: 120, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 7.852610, mae: 22.755314, mean_q: 46.138848, mean_eps: 0.423573\n",
            " 5854/10000: episode: 180, duration: 0.183s, episode steps:  24, steps per second: 131, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 4.076866, mae: 22.935660, mean_q: 46.120526, mean_eps: 0.421692\n",
            " 5900/10000: episode: 181, duration: 0.364s, episode steps:  46, steps per second: 126, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 2.020251, mae: 22.439250, mean_q: 45.980505, mean_eps: 0.418227\n",
            " 6053/10000: episode: 182, duration: 1.188s, episode steps: 153, steps per second: 129, episode reward: 153.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 4.354257, mae: 22.992843, mean_q: 46.959986, mean_eps: 0.408376\n",
            " 6123/10000: episode: 183, duration: 0.553s, episode steps:  70, steps per second: 127, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.110830, mae: 23.344823, mean_q: 47.556695, mean_eps: 0.397337\n",
            " 6184/10000: episode: 184, duration: 0.499s, episode steps:  61, steps per second: 122, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 3.742169, mae: 23.721780, mean_q: 48.461181, mean_eps: 0.390853\n",
            " 6208/10000: episode: 185, duration: 0.190s, episode steps:  24, steps per second: 126, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.339791, mae: 23.681719, mean_q: 48.203855, mean_eps: 0.386646\n",
            " 6256/10000: episode: 186, duration: 0.395s, episode steps:  48, steps per second: 121, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 5.142265, mae: 23.743985, mean_q: 48.306232, mean_eps: 0.383082\n",
            " 6286/10000: episode: 187, duration: 0.255s, episode steps:  30, steps per second: 117, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.005955, mae: 24.014151, mean_q: 49.051607, mean_eps: 0.379220\n",
            " 6371/10000: episode: 188, duration: 0.679s, episode steps:  85, steps per second: 125, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 4.567105, mae: 23.761791, mean_q: 49.034334, mean_eps: 0.373528\n",
            " 6406/10000: episode: 189, duration: 0.291s, episode steps:  35, steps per second: 120, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 5.026819, mae: 24.633471, mean_q: 50.008263, mean_eps: 0.367588\n",
            " 6459/10000: episode: 190, duration: 0.431s, episode steps:  53, steps per second: 123, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 9.063569, mae: 24.762661, mean_q: 50.240514, mean_eps: 0.363232\n",
            " 6603/10000: episode: 191, duration: 1.123s, episode steps: 144, steps per second: 128, episode reward: 144.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 5.379482, mae: 24.780817, mean_q: 50.675195, mean_eps: 0.353481\n",
            " 6707/10000: episode: 192, duration: 1.075s, episode steps: 104, steps per second:  97, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 6.128848, mae: 25.203418, mean_q: 51.800477, mean_eps: 0.341205\n",
            " 6907/10000: episode: 193, duration: 2.206s, episode steps: 200, steps per second:  91, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 5.306901, mae: 25.859767, mean_q: 52.794284, mean_eps: 0.326157\n",
            " 7025/10000: episode: 194, duration: 0.911s, episode steps: 118, steps per second: 129, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 4.558484, mae: 26.247915, mean_q: 53.765679, mean_eps: 0.310416\n",
            " 7225/10000: episode: 195, duration: 1.547s, episode steps: 200, steps per second: 129, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 6.699702, mae: 26.794953, mean_q: 55.147671, mean_eps: 0.294675\n",
            " 7282/10000: episode: 196, duration: 0.440s, episode steps:  57, steps per second: 130, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.544 [0.000, 1.000],  loss: 4.274364, mae: 27.083349, mean_q: 55.655338, mean_eps: 0.281953\n",
            " 7309/10000: episode: 197, duration: 0.215s, episode steps:  27, steps per second: 125, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 9.146606, mae: 27.729022, mean_q: 56.616096, mean_eps: 0.277795\n",
            " 7398/10000: episode: 198, duration: 0.706s, episode steps:  89, steps per second: 126, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 15.025681, mae: 27.797842, mean_q: 56.520535, mean_eps: 0.272053\n",
            " 7534/10000: episode: 199, duration: 1.073s, episode steps: 136, steps per second: 127, episode reward: 136.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 7.576870, mae: 27.760044, mean_q: 56.856345, mean_eps: 0.260916\n",
            " 7623/10000: episode: 200, duration: 0.702s, episode steps:  89, steps per second: 127, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 7.497453, mae: 28.029116, mean_q: 57.507720, mean_eps: 0.249778\n",
            " 7646/10000: episode: 201, duration: 0.192s, episode steps:  23, steps per second: 120, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 11.854518, mae: 28.398107, mean_q: 58.405914, mean_eps: 0.244234\n",
            " 7846/10000: episode: 202, duration: 1.529s, episode steps: 200, steps per second: 131, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 10.398858, mae: 28.571091, mean_q: 58.662638, mean_eps: 0.233196\n",
            " 7971/10000: episode: 203, duration: 0.976s, episode steps: 125, steps per second: 128, episode reward: 125.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 5.894167, mae: 28.977726, mean_q: 59.607355, mean_eps: 0.217108\n",
            " 8067/10000: episode: 204, duration: 0.765s, episode steps:  96, steps per second: 125, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.594 [0.000, 1.000],  loss: 9.150792, mae: 29.350462, mean_q: 60.220669, mean_eps: 0.206169\n",
            " 8202/10000: episode: 205, duration: 1.201s, episode steps: 135, steps per second: 112, episode reward: 135.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 7.199585, mae: 29.604305, mean_q: 60.858361, mean_eps: 0.194734\n",
            " 8337/10000: episode: 206, duration: 1.536s, episode steps: 135, steps per second:  88, episode reward: 135.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 11.390354, mae: 29.779573, mean_q: 61.330108, mean_eps: 0.181369\n",
            " 8385/10000: episode: 207, duration: 0.569s, episode steps:  48, steps per second:  84, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 9.138131, mae: 29.986251, mean_q: 61.862929, mean_eps: 0.172311\n",
            " 8492/10000: episode: 208, duration: 1.005s, episode steps: 107, steps per second: 106, episode reward: 107.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.570 [0.000, 1.000],  loss: 11.050425, mae: 30.433123, mean_q: 62.517494, mean_eps: 0.164638\n",
            " 8529/10000: episode: 209, duration: 0.310s, episode steps:  37, steps per second: 119, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 9.916568, mae: 31.040397, mean_q: 63.122907, mean_eps: 0.157510\n",
            " 8634/10000: episode: 210, duration: 0.836s, episode steps: 105, steps per second: 126, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 10.606686, mae: 30.452077, mean_q: 63.021697, mean_eps: 0.150481\n",
            " 8666/10000: episode: 211, duration: 0.272s, episode steps:  32, steps per second: 118, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.364131, mae: 30.701917, mean_q: 63.141271, mean_eps: 0.143700\n",
            " 8709/10000: episode: 212, duration: 0.334s, episode steps:  43, steps per second: 129, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 17.140818, mae: 31.113596, mean_q: 64.232379, mean_eps: 0.139987\n",
            " 8733/10000: episode: 213, duration: 0.197s, episode steps:  24, steps per second: 122, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 5.848662, mae: 30.746264, mean_q: 63.576925, mean_eps: 0.136671\n",
            " 8751/10000: episode: 214, duration: 0.158s, episode steps:  18, steps per second: 114, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 13.127745, mae: 31.225104, mean_q: 64.152791, mean_eps: 0.134592\n",
            " 8865/10000: episode: 215, duration: 0.890s, episode steps: 114, steps per second: 128, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 12.222298, mae: 31.356711, mean_q: 64.483541, mean_eps: 0.128058\n",
            " 9065/10000: episode: 216, duration: 1.593s, episode steps: 200, steps per second: 126, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 9.061859, mae: 31.691667, mean_q: 65.271727, mean_eps: 0.112515\n",
            " 9123/10000: episode: 217, duration: 0.462s, episode steps:  58, steps per second: 126, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 11.937060, mae: 32.118052, mean_q: 66.256126, mean_eps: 0.099744\n",
            " 9267/10000: episode: 218, duration: 1.134s, episode steps: 144, steps per second: 127, episode reward: 144.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 9.915226, mae: 32.079929, mean_q: 66.124838, mean_eps: 0.089745\n",
            " 9317/10000: episode: 219, duration: 0.397s, episode steps:  50, steps per second: 126, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 12.100127, mae: 32.136995, mean_q: 66.110845, mean_eps: 0.080142\n",
            " 9517/10000: episode: 220, duration: 1.537s, episode steps: 200, steps per second: 130, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 9.527181, mae: 32.511065, mean_q: 67.034779, mean_eps: 0.067767\n",
            " 9634/10000: episode: 221, duration: 0.929s, episode steps: 117, steps per second: 126, episode reward: 117.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.564 [0.000, 1.000],  loss: 9.522644, mae: 32.823441, mean_q: 67.649187, mean_eps: 0.052075\n",
            " 9833/10000: episode: 222, duration: 2.068s, episode steps: 199, steps per second:  96, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 10.545412, mae: 33.077591, mean_q: 68.344050, mean_eps: 0.036433\n",
            "done, took 88.657 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 118.000, steps: 118\n",
            "Episode 2: reward: 113.000, steps: 113\n",
            "Episode 3: reward: 118.000, steps: 118\n",
            "Episode 4: reward: 108.000, steps: 108\n",
            "Episode 5: reward: 100.000, steps: 100\n",
            "Episode 6: reward: 118.000, steps: 118\n",
            "Episode 7: reward: 127.000, steps: 127\n",
            "Episode 8: reward: 112.000, steps: 112\n",
            "Episode 9: reward: 108.000, steps: 108\n",
            "Episode 10: reward: 95.000, steps: 95\n",
            "Episode 11: reward: 105.000, steps: 105\n",
            "Episode 12: reward: 119.000, steps: 119\n",
            "Episode 13: reward: 112.000, steps: 112\n",
            "Episode 14: reward: 102.000, steps: 102\n",
            "Episode 15: reward: 153.000, steps: 153\n",
            "Episode 16: reward: 103.000, steps: 103\n",
            "Episode 17: reward: 114.000, steps: 114\n",
            "Episode 18: reward: 101.000, steps: 101\n",
            "Episode 19: reward: 102.000, steps: 102\n",
            "Episode 20: reward: 141.000, steps: 141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd7531bf220>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Network with 1 hidden layer"
      ],
      "metadata": {
        "id": "vLS-XA2oTRX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 1.0\n",
        "\n",
        "# value_min = 0.05\n",
        "\n",
        "#value_test = 0.05\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "# target_model_update=1e-2\n",
        "\n",
        "nb_steps=50000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "nJV18gAqn_rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.05, \n",
        "                               value_test=0.05,\n",
        "                               nb_steps=50000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L4YH3nwon6-A",
        "outputId": "b87657b8-962f-40db-c16b-d771166ce586"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    25/50000: episode: 1, duration: 4.103s, episode steps:  25, steps per second:   6, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 5.628445, mae: 47.717283, mean_q: 94.405688, mean_eps: 0.999668\n",
            "    42/50000: episode: 2, duration: 0.157s, episode steps:  17, steps per second: 108, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 12.853311, mae: 48.908703, mean_q: 97.327906, mean_eps: 0.999373\n",
            "    60/50000: episode: 3, duration: 0.159s, episode steps:  18, steps per second: 113, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 2.043817, mae: 47.343117, mean_q: 94.346959, mean_eps: 0.999040\n",
            "    79/50000: episode: 4, duration: 0.169s, episode steps:  19, steps per second: 113, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 7.855423, mae: 46.523631, mean_q: 92.563156, mean_eps: 0.998689\n",
            "    92/50000: episode: 5, duration: 0.123s, episode steps:  13, steps per second: 106, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 3.883663, mae: 47.910495, mean_q: 95.316971, mean_eps: 0.998385\n",
            "   103/50000: episode: 6, duration: 0.104s, episode steps:  11, steps per second: 106, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 5.918004, mae: 47.083478, mean_q: 93.413943, mean_eps: 0.998157\n",
            "   123/50000: episode: 7, duration: 0.186s, episode steps:  20, steps per second: 108, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 3.738399, mae: 48.906781, mean_q: 97.225325, mean_eps: 0.997863\n",
            "   140/50000: episode: 8, duration: 0.143s, episode steps:  17, steps per second: 119, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 31.648098, mae: 49.241553, mean_q: 97.117634, mean_eps: 0.997511\n",
            "   159/50000: episode: 9, duration: 0.171s, episode steps:  19, steps per second: 111, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 9.601008, mae: 48.183824, mean_q: 95.880779, mean_eps: 0.997169\n",
            "   181/50000: episode: 10, duration: 0.195s, episode steps:  22, steps per second: 113, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 13.008056, mae: 48.005969, mean_q: 94.632531, mean_eps: 0.996780\n",
            "   216/50000: episode: 11, duration: 0.430s, episode steps:  35, steps per second:  81, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 10.541093, mae: 47.646974, mean_q: 94.667185, mean_eps: 0.996238\n",
            "   232/50000: episode: 12, duration: 0.201s, episode steps:  16, steps per second:  79, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 8.091044, mae: 47.632314, mean_q: 94.779271, mean_eps: 0.995753\n",
            "   258/50000: episode: 13, duration: 0.317s, episode steps:  26, steps per second:  82, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 3.105380, mae: 48.809220, mean_q: 97.304620, mean_eps: 0.995355\n",
            "   272/50000: episode: 14, duration: 0.187s, episode steps:  14, steps per second:  75, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 23.984719, mae: 47.351725, mean_q: 94.225572, mean_eps: 0.994975\n",
            "   300/50000: episode: 15, duration: 0.365s, episode steps:  28, steps per second:  77, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 3.922211, mae: 48.631945, mean_q: 96.909491, mean_eps: 0.994575\n",
            "   324/50000: episode: 16, duration: 0.311s, episode steps:  24, steps per second:  77, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.602153, mae: 47.655798, mean_q: 94.533038, mean_eps: 0.994082\n",
            "   342/50000: episode: 17, duration: 0.242s, episode steps:  18, steps per second:  75, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 5.182768, mae: 46.600398, mean_q: 92.262399, mean_eps: 0.993683\n",
            "   363/50000: episode: 18, duration: 0.285s, episode steps:  21, steps per second:  74, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 18.227865, mae: 48.233293, mean_q: 95.546987, mean_eps: 0.993312\n",
            "   395/50000: episode: 19, duration: 0.394s, episode steps:  32, steps per second:  81, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.406 [0.000, 1.000],  loss: 23.382560, mae: 46.559127, mean_q: 92.280458, mean_eps: 0.992808\n",
            "   415/50000: episode: 20, duration: 0.285s, episode steps:  20, steps per second:  70, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.350 [0.000, 1.000],  loss: 3.274101, mae: 48.059376, mean_q: 95.723375, mean_eps: 0.992314\n",
            "   441/50000: episode: 21, duration: 0.265s, episode steps:  26, steps per second:  98, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.423 [0.000, 1.000],  loss: 15.339076, mae: 47.772498, mean_q: 94.786212, mean_eps: 0.991877\n",
            "   492/50000: episode: 22, duration: 0.447s, episode steps:  51, steps per second: 114, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 10.458168, mae: 48.121600, mean_q: 95.678939, mean_eps: 0.991146\n",
            "   511/50000: episode: 23, duration: 0.169s, episode steps:  19, steps per second: 112, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 9.078212, mae: 47.639942, mean_q: 95.086403, mean_eps: 0.990481\n",
            "   524/50000: episode: 24, duration: 0.122s, episode steps:  13, steps per second: 106, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 17.014173, mae: 48.423314, mean_q: 96.145863, mean_eps: 0.990177\n",
            "   541/50000: episode: 25, duration: 0.158s, episode steps:  17, steps per second: 107, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.235 [0.000, 1.000],  loss: 9.750710, mae: 47.343714, mean_q: 94.510186, mean_eps: 0.989892\n",
            "   556/50000: episode: 26, duration: 0.140s, episode steps:  15, steps per second: 107, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 16.479465, mae: 47.307837, mean_q: 94.239982, mean_eps: 0.989588\n",
            "   601/50000: episode: 27, duration: 0.400s, episode steps:  45, steps per second: 112, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 12.106076, mae: 46.675757, mean_q: 93.031950, mean_eps: 0.989018\n",
            "   624/50000: episode: 28, duration: 0.217s, episode steps:  23, steps per second: 106, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 5.192749, mae: 48.497616, mean_q: 96.825484, mean_eps: 0.988372\n",
            "   635/50000: episode: 29, duration: 0.123s, episode steps:  11, steps per second:  89, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 4.489411, mae: 46.531640, mean_q: 93.336197, mean_eps: 0.988049\n",
            "   680/50000: episode: 30, duration: 0.413s, episode steps:  45, steps per second: 109, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 20.427844, mae: 47.903801, mean_q: 95.159512, mean_eps: 0.987517\n",
            "   699/50000: episode: 31, duration: 0.167s, episode steps:  19, steps per second: 113, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 4.861013, mae: 46.703142, mean_q: 93.630000, mean_eps: 0.986909\n",
            "   720/50000: episode: 32, duration: 0.190s, episode steps:  21, steps per second: 110, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 10.280003, mae: 47.111716, mean_q: 94.387259, mean_eps: 0.986529\n",
            "   737/50000: episode: 33, duration: 0.167s, episode steps:  17, steps per second: 102, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 9.241354, mae: 47.037174, mean_q: 93.804631, mean_eps: 0.986168\n",
            "   767/50000: episode: 34, duration: 0.286s, episode steps:  30, steps per second: 105, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 23.435665, mae: 47.665943, mean_q: 94.784751, mean_eps: 0.985722\n",
            "   790/50000: episode: 35, duration: 0.196s, episode steps:  23, steps per second: 117, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 16.231558, mae: 46.602532, mean_q: 92.743565, mean_eps: 0.985218\n",
            "   806/50000: episode: 36, duration: 0.147s, episode steps:  16, steps per second: 109, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 15.643743, mae: 47.521607, mean_q: 94.874632, mean_eps: 0.984848\n",
            "   820/50000: episode: 37, duration: 0.136s, episode steps:  14, steps per second: 103, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 3.246417, mae: 46.344664, mean_q: 93.078936, mean_eps: 0.984563\n",
            "   835/50000: episode: 38, duration: 0.140s, episode steps:  15, steps per second: 107, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 12.982438, mae: 48.565666, mean_q: 97.286287, mean_eps: 0.984287\n",
            "   848/50000: episode: 39, duration: 0.122s, episode steps:  13, steps per second: 106, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.154 [0.000, 1.000],  loss: 3.080007, mae: 46.430846, mean_q: 93.447611, mean_eps: 0.984021\n",
            "   859/50000: episode: 40, duration: 0.106s, episode steps:  11, steps per second: 104, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 19.208492, mae: 47.869720, mean_q: 95.446732, mean_eps: 0.983793\n",
            "   868/50000: episode: 41, duration: 0.084s, episode steps:   9, steps per second: 107, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 31.270169, mae: 47.549188, mean_q: 94.047857, mean_eps: 0.983603\n",
            "   884/50000: episode: 42, duration: 0.154s, episode steps:  16, steps per second: 104, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 13.183449, mae: 48.762412, mean_q: 97.120285, mean_eps: 0.983366\n",
            "   899/50000: episode: 43, duration: 0.137s, episode steps:  15, steps per second: 110, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 11.911359, mae: 48.006472, mean_q: 96.285709, mean_eps: 0.983071\n",
            "   910/50000: episode: 44, duration: 0.110s, episode steps:  11, steps per second: 100, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 19.216822, mae: 47.628767, mean_q: 95.622436, mean_eps: 0.982824\n",
            "   945/50000: episode: 45, duration: 0.314s, episode steps:  35, steps per second: 112, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 6.654786, mae: 46.671707, mean_q: 93.156058, mean_eps: 0.982387\n",
            "   959/50000: episode: 46, duration: 0.135s, episode steps:  14, steps per second: 104, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 4.988695, mae: 47.458951, mean_q: 95.178514, mean_eps: 0.981921\n",
            "   974/50000: episode: 47, duration: 0.140s, episode steps:  15, steps per second: 107, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 7.040358, mae: 48.338817, mean_q: 97.039764, mean_eps: 0.981646\n",
            "  1023/50000: episode: 48, duration: 0.434s, episode steps:  49, steps per second: 113, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.551 [0.000, 1.000],  loss: 12.459795, mae: 47.913342, mean_q: 95.429228, mean_eps: 0.981038\n",
            "  1036/50000: episode: 49, duration: 0.117s, episode steps:  13, steps per second: 111, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 11.022476, mae: 46.870112, mean_q: 93.086276, mean_eps: 0.980449\n",
            "  1050/50000: episode: 50, duration: 0.127s, episode steps:  14, steps per second: 110, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 7.933190, mae: 49.757013, mean_q: 99.320857, mean_eps: 0.980193\n",
            "  1066/50000: episode: 51, duration: 0.153s, episode steps:  16, steps per second: 105, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 3.711149, mae: 46.659866, mean_q: 93.273238, mean_eps: 0.979907\n",
            "  1083/50000: episode: 52, duration: 0.163s, episode steps:  17, steps per second: 104, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 13.319453, mae: 48.246256, mean_q: 96.335229, mean_eps: 0.979594\n",
            "  1109/50000: episode: 53, duration: 0.242s, episode steps:  26, steps per second: 107, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.597256, mae: 48.095883, mean_q: 95.562575, mean_eps: 0.979185\n",
            "  1134/50000: episode: 54, duration: 0.213s, episode steps:  25, steps per second: 117, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 15.110535, mae: 47.477888, mean_q: 94.792826, mean_eps: 0.978701\n",
            "  1143/50000: episode: 55, duration: 0.086s, episode steps:   9, steps per second: 105, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 17.050357, mae: 46.778828, mean_q: 92.973109, mean_eps: 0.978378\n",
            "  1157/50000: episode: 56, duration: 0.128s, episode steps:  14, steps per second: 110, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 18.469599, mae: 47.199165, mean_q: 93.863784, mean_eps: 0.978159\n",
            "  1181/50000: episode: 57, duration: 0.222s, episode steps:  24, steps per second: 108, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 28.808605, mae: 47.732044, mean_q: 94.660043, mean_eps: 0.977799\n",
            "  1202/50000: episode: 58, duration: 0.198s, episode steps:  21, steps per second: 106, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 10.385670, mae: 48.018645, mean_q: 95.501602, mean_eps: 0.977371\n",
            "  1212/50000: episode: 59, duration: 0.094s, episode steps:  10, steps per second: 106, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 6.246548, mae: 46.440922, mean_q: 93.148115, mean_eps: 0.977077\n",
            "  1231/50000: episode: 60, duration: 0.161s, episode steps:  19, steps per second: 118, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 25.922456, mae: 46.034607, mean_q: 91.828882, mean_eps: 0.976801\n",
            "  1305/50000: episode: 61, duration: 0.639s, episode steps:  74, steps per second: 116, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 11.629359, mae: 48.101220, mean_q: 96.171890, mean_eps: 0.975917\n",
            "  1350/50000: episode: 62, duration: 0.404s, episode steps:  45, steps per second: 111, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 10.969272, mae: 47.262893, mean_q: 94.604118, mean_eps: 0.974787\n",
            "  1363/50000: episode: 63, duration: 0.118s, episode steps:  13, steps per second: 110, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 21.160490, mae: 48.868556, mean_q: 97.904954, mean_eps: 0.974236\n",
            "  1374/50000: episode: 64, duration: 0.106s, episode steps:  11, steps per second: 104, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 16.489924, mae: 47.778305, mean_q: 96.092646, mean_eps: 0.974008\n",
            "  1384/50000: episode: 65, duration: 0.092s, episode steps:  10, steps per second: 109, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 16.799314, mae: 49.219019, mean_q: 97.748767, mean_eps: 0.973808\n",
            "  1405/50000: episode: 66, duration: 0.215s, episode steps:  21, steps per second:  97, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 25.337320, mae: 47.257563, mean_q: 94.241399, mean_eps: 0.973514\n",
            "  1419/50000: episode: 67, duration: 0.130s, episode steps:  14, steps per second: 107, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 19.588023, mae: 47.817163, mean_q: 95.469042, mean_eps: 0.973182\n",
            "  1435/50000: episode: 68, duration: 0.147s, episode steps:  16, steps per second: 109, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 9.266368, mae: 48.417709, mean_q: 96.627825, mean_eps: 0.972897\n",
            "  1452/50000: episode: 69, duration: 0.149s, episode steps:  17, steps per second: 114, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 11.775205, mae: 47.942873, mean_q: 95.687145, mean_eps: 0.972583\n",
            "  1465/50000: episode: 70, duration: 0.124s, episode steps:  13, steps per second: 105, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 17.178448, mae: 48.859594, mean_q: 97.684840, mean_eps: 0.972298\n",
            "  1501/50000: episode: 71, duration: 0.321s, episode steps:  36, steps per second: 112, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 11.749231, mae: 47.393675, mean_q: 94.599805, mean_eps: 0.971833\n",
            "  1515/50000: episode: 72, duration: 0.186s, episode steps:  14, steps per second:  75, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 14.740559, mae: 45.754019, mean_q: 91.196272, mean_eps: 0.971358\n",
            "  1533/50000: episode: 73, duration: 0.241s, episode steps:  18, steps per second:  75, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 11.589303, mae: 48.016776, mean_q: 96.110765, mean_eps: 0.971054\n",
            "  1547/50000: episode: 74, duration: 0.186s, episode steps:  14, steps per second:  75, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 6.590687, mae: 47.605598, mean_q: 95.632452, mean_eps: 0.970749\n",
            "  1578/50000: episode: 75, duration: 0.374s, episode steps:  31, steps per second:  83, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.355 [0.000, 1.000],  loss: 19.731593, mae: 48.180959, mean_q: 96.356135, mean_eps: 0.970322\n",
            "  1595/50000: episode: 76, duration: 0.236s, episode steps:  17, steps per second:  72, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 15.557058, mae: 46.737352, mean_q: 92.656018, mean_eps: 0.969866\n",
            "  1643/50000: episode: 77, duration: 0.573s, episode steps:  48, steps per second:  84, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 16.631102, mae: 47.378259, mean_q: 94.484533, mean_eps: 0.969248\n",
            "  1658/50000: episode: 78, duration: 0.185s, episode steps:  15, steps per second:  81, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 10.723513, mae: 48.089510, mean_q: 95.971517, mean_eps: 0.968650\n",
            "  1697/50000: episode: 79, duration: 0.481s, episode steps:  39, steps per second:  81, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.564 [0.000, 1.000],  loss: 13.192485, mae: 48.058034, mean_q: 96.150903, mean_eps: 0.968137\n",
            "  1706/50000: episode: 80, duration: 0.136s, episode steps:   9, steps per second:  66, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 10.974309, mae: 46.547971, mean_q: 92.739103, mean_eps: 0.967681\n",
            "  1717/50000: episode: 81, duration: 0.151s, episode steps:  11, steps per second:  73, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 12.247067, mae: 46.686562, mean_q: 93.055985, mean_eps: 0.967491\n",
            "  1750/50000: episode: 82, duration: 0.390s, episode steps:  33, steps per second:  85, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 18.163441, mae: 48.258895, mean_q: 96.391674, mean_eps: 0.967073\n",
            "  1763/50000: episode: 83, duration: 0.122s, episode steps:  13, steps per second: 107, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 7.232784, mae: 48.198154, mean_q: 96.413043, mean_eps: 0.966636\n",
            "  1777/50000: episode: 84, duration: 0.135s, episode steps:  14, steps per second: 104, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 17.015882, mae: 49.326383, mean_q: 98.356941, mean_eps: 0.966379\n",
            "  1794/50000: episode: 85, duration: 0.147s, episode steps:  17, steps per second: 115, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 19.077336, mae: 47.169433, mean_q: 93.421700, mean_eps: 0.966085\n",
            "  1817/50000: episode: 86, duration: 0.210s, episode steps:  23, steps per second: 110, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.391 [0.000, 1.000],  loss: 26.737504, mae: 47.948346, mean_q: 94.409832, mean_eps: 0.965705\n",
            "  1844/50000: episode: 87, duration: 0.238s, episode steps:  27, steps per second: 113, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 23.447638, mae: 48.735638, mean_q: 97.600598, mean_eps: 0.965230\n",
            "  1856/50000: episode: 88, duration: 0.119s, episode steps:  12, steps per second: 101, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 13.841931, mae: 47.067058, mean_q: 94.119455, mean_eps: 0.964860\n",
            "  1871/50000: episode: 89, duration: 0.155s, episode steps:  15, steps per second:  97, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 14.645169, mae: 46.295392, mean_q: 92.525188, mean_eps: 0.964603\n",
            "  1886/50000: episode: 90, duration: 0.144s, episode steps:  15, steps per second: 104, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 29.995632, mae: 46.240150, mean_q: 92.043534, mean_eps: 0.964318\n",
            "  1898/50000: episode: 91, duration: 0.111s, episode steps:  12, steps per second: 108, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 7.445284, mae: 48.682565, mean_q: 97.438114, mean_eps: 0.964062\n",
            "  1926/50000: episode: 92, duration: 0.254s, episode steps:  28, steps per second: 110, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.831681, mae: 48.474032, mean_q: 96.724350, mean_eps: 0.963681\n",
            "  1977/50000: episode: 93, duration: 0.460s, episode steps:  51, steps per second: 111, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 17.978879, mae: 47.905857, mean_q: 95.652033, mean_eps: 0.962931\n",
            "  2000/50000: episode: 94, duration: 0.208s, episode steps:  23, steps per second: 111, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 8.431595, mae: 47.541055, mean_q: 95.629159, mean_eps: 0.962228\n",
            "  2029/50000: episode: 95, duration: 0.263s, episode steps:  29, steps per second: 110, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.414 [0.000, 1.000],  loss: 31.347685, mae: 47.119084, mean_q: 94.070943, mean_eps: 0.961734\n",
            "  2048/50000: episode: 96, duration: 0.177s, episode steps:  19, steps per second: 107, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 13.573187, mae: 47.419882, mean_q: 94.975016, mean_eps: 0.961278\n",
            "  2059/50000: episode: 97, duration: 0.108s, episode steps:  11, steps per second: 102, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: 13.821197, mae: 47.734861, mean_q: 96.022064, mean_eps: 0.960993\n",
            "  2070/50000: episode: 98, duration: 0.105s, episode steps:  11, steps per second: 105, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 41.054324, mae: 47.700010, mean_q: 95.744565, mean_eps: 0.960784\n",
            "  2106/50000: episode: 99, duration: 0.343s, episode steps:  36, steps per second: 105, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 18.619952, mae: 49.357833, mean_q: 98.884960, mean_eps: 0.960338\n",
            "  2119/50000: episode: 100, duration: 0.125s, episode steps:  13, steps per second: 104, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 19.098195, mae: 47.282896, mean_q: 94.794263, mean_eps: 0.959872\n",
            "  2164/50000: episode: 101, duration: 0.383s, episode steps:  45, steps per second: 117, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 18.401871, mae: 48.646133, mean_q: 96.979457, mean_eps: 0.959321\n",
            "  2181/50000: episode: 102, duration: 0.157s, episode steps:  17, steps per second: 109, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 13.994633, mae: 47.404985, mean_q: 93.836412, mean_eps: 0.958732\n",
            "  2242/50000: episode: 103, duration: 0.541s, episode steps:  61, steps per second: 113, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 18.638768, mae: 48.470452, mean_q: 96.527108, mean_eps: 0.957991\n",
            "  2257/50000: episode: 104, duration: 0.133s, episode steps:  15, steps per second: 113, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 7.300910, mae: 48.260122, mean_q: 96.827117, mean_eps: 0.957269\n",
            "  2268/50000: episode: 105, duration: 0.099s, episode steps:  11, steps per second: 111, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 11.768850, mae: 49.302115, mean_q: 97.802415, mean_eps: 0.957022\n",
            "  2326/50000: episode: 106, duration: 0.525s, episode steps:  58, steps per second: 111, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 13.906278, mae: 48.547853, mean_q: 97.089347, mean_eps: 0.956366\n",
            "  2342/50000: episode: 107, duration: 0.143s, episode steps:  16, steps per second: 112, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 34.434600, mae: 47.203914, mean_q: 93.516849, mean_eps: 0.955663\n",
            "  2383/50000: episode: 108, duration: 0.349s, episode steps:  41, steps per second: 117, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 21.196585, mae: 48.378122, mean_q: 96.644851, mean_eps: 0.955122\n",
            "  2416/50000: episode: 109, duration: 0.294s, episode steps:  33, steps per second: 112, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 31.325268, mae: 47.910765, mean_q: 95.307332, mean_eps: 0.954419\n",
            "  2432/50000: episode: 110, duration: 0.152s, episode steps:  16, steps per second: 105, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 13.997900, mae: 48.931109, mean_q: 98.177082, mean_eps: 0.953954\n",
            "  2444/50000: episode: 111, duration: 0.112s, episode steps:  12, steps per second: 107, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 29.180599, mae: 47.022153, mean_q: 94.151163, mean_eps: 0.953688\n",
            "  2461/50000: episode: 112, duration: 0.148s, episode steps:  17, steps per second: 115, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 17.334794, mae: 49.091028, mean_q: 97.816494, mean_eps: 0.953412\n",
            "  2475/50000: episode: 113, duration: 0.130s, episode steps:  14, steps per second: 108, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 16.852332, mae: 48.925386, mean_q: 98.051840, mean_eps: 0.953118\n",
            "  2490/50000: episode: 114, duration: 0.138s, episode steps:  15, steps per second: 108, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 15.359728, mae: 47.716393, mean_q: 96.122521, mean_eps: 0.952842\n",
            "  2509/50000: episode: 115, duration: 0.173s, episode steps:  19, steps per second: 110, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 14.997210, mae: 49.423100, mean_q: 99.205385, mean_eps: 0.952519\n",
            "  2522/50000: episode: 116, duration: 0.125s, episode steps:  13, steps per second: 104, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 16.268396, mae: 48.347660, mean_q: 96.752970, mean_eps: 0.952215\n",
            "  2544/50000: episode: 117, duration: 0.207s, episode steps:  22, steps per second: 106, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 9.893277, mae: 48.795897, mean_q: 98.275338, mean_eps: 0.951882\n",
            "  2556/50000: episode: 118, duration: 0.113s, episode steps:  12, steps per second: 106, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 11.308747, mae: 49.238248, mean_q: 99.301806, mean_eps: 0.951559\n",
            "  2609/50000: episode: 119, duration: 0.471s, episode steps:  53, steps per second: 113, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 19.256505, mae: 48.600667, mean_q: 97.418714, mean_eps: 0.950942\n",
            "  2620/50000: episode: 120, duration: 0.109s, episode steps:  11, steps per second: 101, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 40.931857, mae: 47.169747, mean_q: 95.091072, mean_eps: 0.950334\n",
            "  2636/50000: episode: 121, duration: 0.161s, episode steps:  16, steps per second: 100, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 25.943898, mae: 47.720257, mean_q: 95.731649, mean_eps: 0.950078\n",
            "  2659/50000: episode: 122, duration: 0.218s, episode steps:  23, steps per second: 105, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 22.598201, mae: 49.100908, mean_q: 98.558703, mean_eps: 0.949707\n",
            "  2693/50000: episode: 123, duration: 0.289s, episode steps:  34, steps per second: 118, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 19.361227, mae: 48.418456, mean_q: 97.075878, mean_eps: 0.949166\n",
            "  2703/50000: episode: 124, duration: 0.094s, episode steps:  10, steps per second: 106, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 17.950224, mae: 48.140169, mean_q: 96.580128, mean_eps: 0.948748\n",
            "  2729/50000: episode: 125, duration: 0.239s, episode steps:  26, steps per second: 109, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 27.819692, mae: 48.262561, mean_q: 96.252414, mean_eps: 0.948406\n",
            "  2741/50000: episode: 126, duration: 0.116s, episode steps:  12, steps per second: 103, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 47.995517, mae: 48.412628, mean_q: 96.670231, mean_eps: 0.948044\n",
            "  2754/50000: episode: 127, duration: 0.131s, episode steps:  13, steps per second:  99, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 16.106215, mae: 47.728014, mean_q: 96.618202, mean_eps: 0.947807\n",
            "  2767/50000: episode: 128, duration: 0.119s, episode steps:  13, steps per second: 109, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 26.064363, mae: 48.386738, mean_q: 96.866942, mean_eps: 0.947560\n",
            "  2785/50000: episode: 129, duration: 0.160s, episode steps:  18, steps per second: 112, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 14.221245, mae: 47.866657, mean_q: 95.611219, mean_eps: 0.947266\n",
            "  2804/50000: episode: 130, duration: 0.191s, episode steps:  19, steps per second:  99, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 18.126363, mae: 48.188909, mean_q: 96.760152, mean_eps: 0.946914\n",
            "  2823/50000: episode: 131, duration: 0.192s, episode steps:  19, steps per second:  99, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.737 [0.000, 1.000],  loss: 35.631936, mae: 49.917759, mean_q: 100.313587, mean_eps: 0.946553\n",
            "  2846/50000: episode: 132, duration: 0.306s, episode steps:  23, steps per second:  75, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 18.994808, mae: 49.800115, mean_q: 99.975396, mean_eps: 0.946154\n",
            "  2881/50000: episode: 133, duration: 0.449s, episode steps:  35, steps per second:  78, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 20.523182, mae: 49.594523, mean_q: 99.738966, mean_eps: 0.945603\n",
            "  2939/50000: episode: 134, duration: 0.717s, episode steps:  58, steps per second:  81, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 26.432597, mae: 49.348604, mean_q: 99.370711, mean_eps: 0.944720\n",
            "  2959/50000: episode: 135, duration: 0.264s, episode steps:  20, steps per second:  76, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 24.148793, mae: 48.992617, mean_q: 98.831807, mean_eps: 0.943979\n",
            "  2986/50000: episode: 136, duration: 0.345s, episode steps:  27, steps per second:  78, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 17.232037, mae: 50.817721, mean_q: 102.645844, mean_eps: 0.943532\n",
            "  3053/50000: episode: 137, duration: 0.842s, episode steps:  67, steps per second:  80, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.403 [0.000, 1.000],  loss: 19.541923, mae: 50.230223, mean_q: 100.926180, mean_eps: 0.942639\n",
            "  3079/50000: episode: 138, duration: 0.284s, episode steps:  26, steps per second:  92, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.423 [0.000, 1.000],  loss: 17.343597, mae: 49.019259, mean_q: 98.707566, mean_eps: 0.941755\n",
            "  3097/50000: episode: 139, duration: 0.163s, episode steps:  18, steps per second: 111, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 10.627251, mae: 50.807938, mean_q: 103.022909, mean_eps: 0.941337\n",
            "  3118/50000: episode: 140, duration: 0.193s, episode steps:  21, steps per second: 109, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 14.934334, mae: 49.531744, mean_q: 100.116471, mean_eps: 0.940967\n",
            "  3184/50000: episode: 141, duration: 0.577s, episode steps:  66, steps per second: 114, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 25.210934, mae: 49.037579, mean_q: 98.334727, mean_eps: 0.940141\n",
            "  3203/50000: episode: 142, duration: 0.177s, episode steps:  19, steps per second: 107, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 18.464411, mae: 49.330352, mean_q: 99.632368, mean_eps: 0.939333\n",
            "  3224/50000: episode: 143, duration: 0.192s, episode steps:  21, steps per second: 109, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 15.330123, mae: 49.617315, mean_q: 99.930009, mean_eps: 0.938953\n",
            "  3284/50000: episode: 144, duration: 0.520s, episode steps:  60, steps per second: 115, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 20.513357, mae: 50.107202, mean_q: 101.400356, mean_eps: 0.938183\n",
            "  3306/50000: episode: 145, duration: 0.210s, episode steps:  22, steps per second: 105, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 20.828713, mae: 49.984347, mean_q: 101.061786, mean_eps: 0.937404\n",
            "  3331/50000: episode: 146, duration: 0.230s, episode steps:  25, steps per second: 109, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 11.106862, mae: 48.493009, mean_q: 98.767646, mean_eps: 0.936958\n",
            "  3352/50000: episode: 147, duration: 0.187s, episode steps:  21, steps per second: 112, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 28.660084, mae: 49.145719, mean_q: 99.162348, mean_eps: 0.936521\n",
            "  3377/50000: episode: 148, duration: 0.226s, episode steps:  25, steps per second: 110, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 17.070440, mae: 50.276140, mean_q: 101.280273, mean_eps: 0.936084\n",
            "  3396/50000: episode: 149, duration: 0.177s, episode steps:  19, steps per second: 107, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 19.875337, mae: 49.988335, mean_q: 100.398415, mean_eps: 0.935666\n",
            "  3412/50000: episode: 150, duration: 0.150s, episode steps:  16, steps per second: 107, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 23.994205, mae: 50.237357, mean_q: 101.174064, mean_eps: 0.935334\n",
            "  3433/50000: episode: 151, duration: 0.189s, episode steps:  21, steps per second: 111, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 21.061595, mae: 50.836949, mean_q: 102.762988, mean_eps: 0.934982\n",
            "  3467/50000: episode: 152, duration: 0.314s, episode steps:  34, steps per second: 108, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 22.689772, mae: 50.021704, mean_q: 100.914640, mean_eps: 0.934459\n",
            "  3495/50000: episode: 153, duration: 0.243s, episode steps:  28, steps per second: 115, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.822447, mae: 49.485043, mean_q: 100.447907, mean_eps: 0.933870\n",
            "  3529/50000: episode: 154, duration: 0.310s, episode steps:  34, steps per second: 110, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 23.921551, mae: 49.937811, mean_q: 101.183177, mean_eps: 0.933282\n",
            "  3542/50000: episode: 155, duration: 0.118s, episode steps:  13, steps per second: 110, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 16.500358, mae: 49.757369, mean_q: 99.828002, mean_eps: 0.932835\n",
            "  3582/50000: episode: 156, duration: 0.358s, episode steps:  40, steps per second: 112, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 28.970707, mae: 50.591561, mean_q: 102.094248, mean_eps: 0.932332\n",
            "  3593/50000: episode: 157, duration: 0.101s, episode steps:  11, steps per second: 109, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 21.260947, mae: 50.762422, mean_q: 102.395047, mean_eps: 0.931847\n",
            "  3608/50000: episode: 158, duration: 0.143s, episode steps:  15, steps per second: 105, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 17.046164, mae: 51.732909, mean_q: 105.280924, mean_eps: 0.931600\n",
            "  3635/50000: episode: 159, duration: 0.247s, episode steps:  27, steps per second: 109, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 21.702585, mae: 50.675240, mean_q: 102.816471, mean_eps: 0.931201\n",
            "  3663/50000: episode: 160, duration: 0.256s, episode steps:  28, steps per second: 109, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 23.057764, mae: 51.464534, mean_q: 104.303104, mean_eps: 0.930678\n",
            "  3688/50000: episode: 161, duration: 0.231s, episode steps:  25, steps per second: 108, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 18.485749, mae: 51.805654, mean_q: 104.443843, mean_eps: 0.930175\n",
            "  3703/50000: episode: 162, duration: 0.136s, episode steps:  15, steps per second: 110, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 31.557936, mae: 51.455783, mean_q: 103.022548, mean_eps: 0.929795\n",
            "  3752/50000: episode: 163, duration: 0.440s, episode steps:  49, steps per second: 111, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 14.085562, mae: 50.949994, mean_q: 102.996083, mean_eps: 0.929187\n",
            "  3764/50000: episode: 164, duration: 0.106s, episode steps:  12, steps per second: 113, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 12.070301, mae: 51.719168, mean_q: 104.919296, mean_eps: 0.928608\n",
            "  3839/50000: episode: 165, duration: 0.660s, episode steps:  75, steps per second: 114, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 24.026370, mae: 51.661717, mean_q: 104.016154, mean_eps: 0.927781\n",
            "  3851/50000: episode: 166, duration: 0.120s, episode steps:  12, steps per second: 100, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 23.123556, mae: 51.063632, mean_q: 102.914597, mean_eps: 0.926955\n",
            "  3869/50000: episode: 167, duration: 0.163s, episode steps:  18, steps per second: 111, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 41.161669, mae: 49.660355, mean_q: 100.463904, mean_eps: 0.926669\n",
            "  3890/50000: episode: 168, duration: 0.178s, episode steps:  21, steps per second: 118, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 17.988927, mae: 51.174445, mean_q: 103.834606, mean_eps: 0.926299\n",
            "  3923/50000: episode: 169, duration: 0.288s, episode steps:  33, steps per second: 115, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.394 [0.000, 1.000],  loss: 14.436711, mae: 51.912014, mean_q: 105.608332, mean_eps: 0.925786\n",
            "  3942/50000: episode: 170, duration: 0.163s, episode steps:  19, steps per second: 116, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 19.045267, mae: 52.591983, mean_q: 106.697501, mean_eps: 0.925292\n",
            "  3956/50000: episode: 171, duration: 0.132s, episode steps:  14, steps per second: 106, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 33.368900, mae: 52.107490, mean_q: 104.657531, mean_eps: 0.924978\n",
            "  3985/50000: episode: 172, duration: 0.266s, episode steps:  29, steps per second: 109, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 18.332137, mae: 52.203434, mean_q: 105.455581, mean_eps: 0.924570\n",
            "  4002/50000: episode: 173, duration: 0.148s, episode steps:  17, steps per second: 115, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 31.332089, mae: 51.512625, mean_q: 103.529489, mean_eps: 0.924133\n",
            "  4044/50000: episode: 174, duration: 0.380s, episode steps:  42, steps per second: 111, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 26.509906, mae: 52.769051, mean_q: 106.131031, mean_eps: 0.923573\n",
            "  4074/50000: episode: 175, duration: 0.273s, episode steps:  30, steps per second: 110, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 11.725327, mae: 52.688442, mean_q: 106.770724, mean_eps: 0.922888\n",
            "  4100/50000: episode: 176, duration: 0.226s, episode steps:  26, steps per second: 115, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 39.866851, mae: 52.530347, mean_q: 106.216839, mean_eps: 0.922356\n",
            "  4117/50000: episode: 177, duration: 0.164s, episode steps:  17, steps per second: 104, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 20.646970, mae: 52.692940, mean_q: 106.301879, mean_eps: 0.921948\n",
            "  4134/50000: episode: 178, duration: 0.161s, episode steps:  17, steps per second: 106, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 23.345591, mae: 52.179536, mean_q: 106.092919, mean_eps: 0.921625\n",
            "  4149/50000: episode: 179, duration: 0.127s, episode steps:  15, steps per second: 118, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 17.247210, mae: 52.666002, mean_q: 106.640517, mean_eps: 0.921321\n",
            "  4202/50000: episode: 180, duration: 0.575s, episode steps:  53, steps per second:  92, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 32.425938, mae: 52.321461, mean_q: 105.459363, mean_eps: 0.920675\n",
            "  4239/50000: episode: 181, duration: 0.450s, episode steps:  37, steps per second:  82, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 12.996401, mae: 53.982238, mean_q: 109.616890, mean_eps: 0.919820\n",
            "  4253/50000: episode: 182, duration: 0.182s, episode steps:  14, steps per second:  77, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 40.644234, mae: 52.597213, mean_q: 106.188949, mean_eps: 0.919335\n",
            "  4267/50000: episode: 183, duration: 0.199s, episode steps:  14, steps per second:  70, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 23.499986, mae: 53.931546, mean_q: 109.800810, mean_eps: 0.919069\n",
            "  4324/50000: episode: 184, duration: 0.688s, episode steps:  57, steps per second:  83, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 25.808466, mae: 53.930423, mean_q: 109.572523, mean_eps: 0.918395\n",
            "  4340/50000: episode: 185, duration: 0.199s, episode steps:  16, steps per second:  80, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 17.604793, mae: 51.442537, mean_q: 104.443763, mean_eps: 0.917701\n",
            "  4360/50000: episode: 186, duration: 0.260s, episode steps:  20, steps per second:  77, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 17.972367, mae: 53.650648, mean_q: 109.058873, mean_eps: 0.917360\n",
            "  4372/50000: episode: 187, duration: 0.155s, episode steps:  12, steps per second:  77, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 46.933945, mae: 53.207493, mean_q: 107.720200, mean_eps: 0.917056\n",
            "  4412/50000: episode: 188, duration: 0.495s, episode steps:  40, steps per second:  81, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 19.937410, mae: 53.123654, mean_q: 108.133727, mean_eps: 0.916561\n",
            "  4427/50000: episode: 189, duration: 0.138s, episode steps:  15, steps per second: 109, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 18.694035, mae: 53.632366, mean_q: 108.836327, mean_eps: 0.916039\n",
            "  4463/50000: episode: 190, duration: 0.306s, episode steps:  36, steps per second: 118, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 31.407983, mae: 53.351326, mean_q: 108.444255, mean_eps: 0.915554\n",
            "  4474/50000: episode: 191, duration: 0.098s, episode steps:  11, steps per second: 112, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 24.894031, mae: 53.569173, mean_q: 109.320360, mean_eps: 0.915108\n",
            "  4540/50000: episode: 192, duration: 0.567s, episode steps:  66, steps per second: 116, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 19.081718, mae: 53.976351, mean_q: 109.747518, mean_eps: 0.914376\n",
            "  4569/50000: episode: 193, duration: 0.254s, episode steps:  29, steps per second: 114, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 23.603910, mae: 54.327161, mean_q: 110.287106, mean_eps: 0.913474\n",
            "  4625/50000: episode: 194, duration: 0.502s, episode steps:  56, steps per second: 112, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 23.005494, mae: 54.779467, mean_q: 111.269264, mean_eps: 0.912667\n",
            "  4639/50000: episode: 195, duration: 0.128s, episode steps:  14, steps per second: 109, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 31.592860, mae: 53.819589, mean_q: 108.579863, mean_eps: 0.912001\n",
            "  4693/50000: episode: 196, duration: 0.474s, episode steps:  54, steps per second: 114, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 21.942686, mae: 55.069091, mean_q: 111.383725, mean_eps: 0.911355\n",
            "  4711/50000: episode: 197, duration: 0.162s, episode steps:  18, steps per second: 111, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 19.069389, mae: 54.895006, mean_q: 111.975913, mean_eps: 0.910671\n",
            "  4732/50000: episode: 198, duration: 0.193s, episode steps:  21, steps per second: 109, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 23.346042, mae: 55.420309, mean_q: 112.086293, mean_eps: 0.910301\n",
            "  4761/50000: episode: 199, duration: 0.268s, episode steps:  29, steps per second: 108, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 25.509561, mae: 54.865681, mean_q: 111.886228, mean_eps: 0.909826\n",
            "  4776/50000: episode: 200, duration: 0.135s, episode steps:  15, steps per second: 111, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 22.202704, mae: 55.352508, mean_q: 112.340582, mean_eps: 0.909408\n",
            "  4795/50000: episode: 201, duration: 0.178s, episode steps:  19, steps per second: 107, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 23.090945, mae: 53.183093, mean_q: 108.819691, mean_eps: 0.909085\n",
            "  4812/50000: episode: 202, duration: 0.153s, episode steps:  17, steps per second: 111, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 21.634309, mae: 54.606575, mean_q: 111.779363, mean_eps: 0.908743\n",
            "  4827/50000: episode: 203, duration: 0.143s, episode steps:  15, steps per second: 105, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 22.461936, mae: 55.694591, mean_q: 113.264468, mean_eps: 0.908439\n",
            "  4851/50000: episode: 204, duration: 0.225s, episode steps:  24, steps per second: 107, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 21.417388, mae: 54.855276, mean_q: 111.839536, mean_eps: 0.908069\n",
            "  4891/50000: episode: 205, duration: 0.351s, episode steps:  40, steps per second: 114, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 22.292658, mae: 55.289740, mean_q: 113.215622, mean_eps: 0.907461\n",
            "  4912/50000: episode: 206, duration: 0.196s, episode steps:  21, steps per second: 107, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 18.742346, mae: 56.005249, mean_q: 113.895277, mean_eps: 0.906881\n",
            "  4933/50000: episode: 207, duration: 0.195s, episode steps:  21, steps per second: 107, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 34.973076, mae: 56.973797, mean_q: 115.620834, mean_eps: 0.906482\n",
            "  4952/50000: episode: 208, duration: 0.184s, episode steps:  19, steps per second: 103, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 19.950012, mae: 55.235385, mean_q: 111.752101, mean_eps: 0.906102\n",
            "  4966/50000: episode: 209, duration: 0.134s, episode steps:  14, steps per second: 104, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 33.907120, mae: 55.630145, mean_q: 112.916796, mean_eps: 0.905789\n",
            "  4982/50000: episode: 210, duration: 0.151s, episode steps:  16, steps per second: 106, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.165536, mae: 54.836890, mean_q: 111.701279, mean_eps: 0.905504\n",
            "  5001/50000: episode: 211, duration: 0.172s, episode steps:  19, steps per second: 110, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.684 [0.000, 1.000],  loss: 21.247308, mae: 55.573638, mean_q: 113.081972, mean_eps: 0.905171\n",
            "  5051/50000: episode: 212, duration: 0.432s, episode steps:  50, steps per second: 116, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 47.290011, mae: 56.352111, mean_q: 114.078420, mean_eps: 0.904516\n",
            "  5109/50000: episode: 213, duration: 0.515s, episode steps:  58, steps per second: 113, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 26.356144, mae: 55.812252, mean_q: 113.780918, mean_eps: 0.903490\n",
            "  5158/50000: episode: 214, duration: 0.418s, episode steps:  49, steps per second: 117, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.551 [0.000, 1.000],  loss: 20.210886, mae: 57.178109, mean_q: 116.617160, mean_eps: 0.902473\n",
            "  5173/50000: episode: 215, duration: 0.146s, episode steps:  15, steps per second: 103, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 12.439505, mae: 56.223495, mean_q: 115.262474, mean_eps: 0.901865\n",
            "  5202/50000: episode: 216, duration: 0.266s, episode steps:  29, steps per second: 109, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 20.239159, mae: 57.264083, mean_q: 116.847828, mean_eps: 0.901447\n",
            "  5252/50000: episode: 217, duration: 0.440s, episode steps:  50, steps per second: 114, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 28.416240, mae: 57.234218, mean_q: 116.469307, mean_eps: 0.900697\n",
            "  5272/50000: episode: 218, duration: 0.171s, episode steps:  20, steps per second: 117, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 40.689180, mae: 58.355938, mean_q: 118.041981, mean_eps: 0.900032\n",
            "  5314/50000: episode: 219, duration: 0.374s, episode steps:  42, steps per second: 112, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 23.164155, mae: 57.051983, mean_q: 116.300715, mean_eps: 0.899443\n",
            "  5340/50000: episode: 220, duration: 0.234s, episode steps:  26, steps per second: 111, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 20.680890, mae: 58.335410, mean_q: 118.770724, mean_eps: 0.898796\n",
            "  5365/50000: episode: 221, duration: 0.236s, episode steps:  25, steps per second: 106, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 30.899495, mae: 58.102579, mean_q: 117.933454, mean_eps: 0.898312\n",
            "  5376/50000: episode: 222, duration: 0.117s, episode steps:  11, steps per second:  94, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 14.117389, mae: 57.195289, mean_q: 116.591986, mean_eps: 0.897970\n",
            "  5401/50000: episode: 223, duration: 0.228s, episode steps:  25, steps per second: 110, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 21.189574, mae: 56.188782, mean_q: 114.793351, mean_eps: 0.897628\n",
            "  5412/50000: episode: 224, duration: 0.101s, episode steps:  11, steps per second: 109, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 29.015570, mae: 57.341310, mean_q: 117.079532, mean_eps: 0.897286\n",
            "  5437/50000: episode: 225, duration: 0.224s, episode steps:  25, steps per second: 112, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 44.294249, mae: 59.591076, mean_q: 120.328807, mean_eps: 0.896944\n",
            "  5455/50000: episode: 226, duration: 0.152s, episode steps:  18, steps per second: 118, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 27.276670, mae: 58.605173, mean_q: 119.836682, mean_eps: 0.896536\n",
            "  5468/50000: episode: 227, duration: 0.129s, episode steps:  13, steps per second: 101, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 18.698960, mae: 58.533593, mean_q: 119.000981, mean_eps: 0.896241\n",
            "  5487/50000: episode: 228, duration: 0.164s, episode steps:  19, steps per second: 116, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 36.311604, mae: 57.442442, mean_q: 117.075381, mean_eps: 0.895937\n",
            "  5519/50000: episode: 229, duration: 0.302s, episode steps:  32, steps per second: 106, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 35.546883, mae: 58.191554, mean_q: 117.749545, mean_eps: 0.895452\n",
            "  5565/50000: episode: 230, duration: 0.573s, episode steps:  46, steps per second:  80, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 32.005245, mae: 58.391960, mean_q: 118.438712, mean_eps: 0.894711\n",
            "  5585/50000: episode: 231, duration: 0.258s, episode steps:  20, steps per second:  78, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 18.608884, mae: 59.210484, mean_q: 121.081512, mean_eps: 0.894084\n",
            "  5602/50000: episode: 232, duration: 0.221s, episode steps:  17, steps per second:  77, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 26.910722, mae: 59.053623, mean_q: 120.875850, mean_eps: 0.893733\n",
            "  5635/50000: episode: 233, duration: 0.418s, episode steps:  33, steps per second:  79, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 50.262134, mae: 58.261338, mean_q: 118.076731, mean_eps: 0.893258\n",
            "  5656/50000: episode: 234, duration: 0.288s, episode steps:  21, steps per second:  73, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 16.570687, mae: 58.862885, mean_q: 119.952223, mean_eps: 0.892745\n",
            "  5681/50000: episode: 235, duration: 0.327s, episode steps:  25, steps per second:  76, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 18.141635, mae: 58.329689, mean_q: 119.569659, mean_eps: 0.892308\n",
            "  5691/50000: episode: 236, duration: 0.132s, episode steps:  10, steps per second:  76, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 71.028135, mae: 59.846522, mean_q: 120.390540, mean_eps: 0.891976\n",
            "  5734/50000: episode: 237, duration: 0.534s, episode steps:  43, steps per second:  81, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 39.078731, mae: 58.633036, mean_q: 119.278280, mean_eps: 0.891472\n",
            "  5744/50000: episode: 238, duration: 0.137s, episode steps:  10, steps per second:  73, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 28.610751, mae: 58.160392, mean_q: 118.464901, mean_eps: 0.890969\n",
            "  5760/50000: episode: 239, duration: 0.185s, episode steps:  16, steps per second:  86, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 22.985947, mae: 58.586847, mean_q: 120.083917, mean_eps: 0.890721\n",
            "  5783/50000: episode: 240, duration: 0.201s, episode steps:  23, steps per second: 114, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 33.226442, mae: 57.470610, mean_q: 117.646458, mean_eps: 0.890351\n",
            "  5822/50000: episode: 241, duration: 0.341s, episode steps:  39, steps per second: 114, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 26.572711, mae: 59.759641, mean_q: 122.066467, mean_eps: 0.889762\n",
            "  5850/50000: episode: 242, duration: 0.257s, episode steps:  28, steps per second: 109, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 25.982006, mae: 59.157243, mean_q: 121.085673, mean_eps: 0.889126\n",
            "  5866/50000: episode: 243, duration: 0.151s, episode steps:  16, steps per second: 106, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 34.997933, mae: 59.320702, mean_q: 121.151675, mean_eps: 0.888707\n",
            "  5877/50000: episode: 244, duration: 0.111s, episode steps:  11, steps per second:  99, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 22.172188, mae: 59.926486, mean_q: 122.538584, mean_eps: 0.888451\n",
            "  5895/50000: episode: 245, duration: 0.160s, episode steps:  18, steps per second: 113, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 47.237060, mae: 59.745677, mean_q: 121.913820, mean_eps: 0.888176\n",
            "  5905/50000: episode: 246, duration: 0.096s, episode steps:  10, steps per second: 104, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 34.106648, mae: 59.869646, mean_q: 122.456496, mean_eps: 0.887909\n",
            "  5922/50000: episode: 247, duration: 0.151s, episode steps:  17, steps per second: 112, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 38.027096, mae: 59.762843, mean_q: 122.785284, mean_eps: 0.887653\n",
            "  5936/50000: episode: 248, duration: 0.135s, episode steps:  14, steps per second: 104, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 28.652027, mae: 60.121668, mean_q: 122.342996, mean_eps: 0.887359\n",
            "  6004/50000: episode: 249, duration: 0.584s, episode steps:  68, steps per second: 116, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.456 [0.000, 1.000],  loss: 19.960069, mae: 59.918484, mean_q: 122.582157, mean_eps: 0.886580\n",
            "  6034/50000: episode: 250, duration: 0.266s, episode steps:  30, steps per second: 113, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 21.942306, mae: 60.144363, mean_q: 123.377882, mean_eps: 0.885649\n",
            "  6087/50000: episode: 251, duration: 0.458s, episode steps:  53, steps per second: 116, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 34.642207, mae: 61.304328, mean_q: 125.105088, mean_eps: 0.884860\n",
            "  6109/50000: episode: 252, duration: 0.219s, episode steps:  22, steps per second: 100, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 26.934141, mae: 60.701152, mean_q: 124.740832, mean_eps: 0.884147\n",
            "  6139/50000: episode: 253, duration: 0.265s, episode steps:  30, steps per second: 113, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 23.387276, mae: 61.975282, mean_q: 126.626194, mean_eps: 0.883653\n",
            "  6175/50000: episode: 254, duration: 0.315s, episode steps:  36, steps per second: 114, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 51.172338, mae: 62.008346, mean_q: 126.250625, mean_eps: 0.883027\n",
            "  6209/50000: episode: 255, duration: 0.299s, episode steps:  34, steps per second: 114, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 43.223473, mae: 61.596951, mean_q: 125.408033, mean_eps: 0.882362\n",
            "  6231/50000: episode: 256, duration: 0.188s, episode steps:  22, steps per second: 117, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 32.814490, mae: 61.656757, mean_q: 124.908518, mean_eps: 0.881830\n",
            "  6251/50000: episode: 257, duration: 0.195s, episode steps:  20, steps per second: 103, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 41.418800, mae: 61.837236, mean_q: 126.053071, mean_eps: 0.881431\n",
            "  6278/50000: episode: 258, duration: 0.235s, episode steps:  27, steps per second: 115, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 25.102214, mae: 62.121899, mean_q: 126.367380, mean_eps: 0.880984\n",
            "  6297/50000: episode: 259, duration: 0.177s, episode steps:  19, steps per second: 107, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 32.461752, mae: 62.221289, mean_q: 126.996806, mean_eps: 0.880547\n",
            "  6310/50000: episode: 260, duration: 0.125s, episode steps:  13, steps per second: 104, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 61.337605, mae: 60.534955, mean_q: 123.151621, mean_eps: 0.880243\n",
            "  6329/50000: episode: 261, duration: 0.170s, episode steps:  19, steps per second: 112, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 47.013226, mae: 62.238487, mean_q: 126.536469, mean_eps: 0.879939\n",
            "  6392/50000: episode: 262, duration: 0.541s, episode steps:  63, steps per second: 116, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 41.782051, mae: 62.098215, mean_q: 126.626047, mean_eps: 0.879160\n",
            "  6417/50000: episode: 263, duration: 0.220s, episode steps:  25, steps per second: 114, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 37.402720, mae: 63.066029, mean_q: 127.894922, mean_eps: 0.878324\n",
            "  6446/50000: episode: 264, duration: 0.260s, episode steps:  29, steps per second: 112, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 38.528463, mae: 62.235988, mean_q: 126.628317, mean_eps: 0.877811\n",
            "  6468/50000: episode: 265, duration: 0.208s, episode steps:  22, steps per second: 106, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 31.638089, mae: 62.885502, mean_q: 129.142470, mean_eps: 0.877327\n",
            "  6489/50000: episode: 266, duration: 0.185s, episode steps:  21, steps per second: 113, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 49.918632, mae: 61.974370, mean_q: 126.207130, mean_eps: 0.876918\n",
            "  6524/50000: episode: 267, duration: 0.320s, episode steps:  35, steps per second: 109, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 32.448359, mae: 62.053497, mean_q: 126.242327, mean_eps: 0.876386\n",
            "  6549/50000: episode: 268, duration: 0.233s, episode steps:  25, steps per second: 107, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.320 [0.000, 1.000],  loss: 35.396695, mae: 62.926138, mean_q: 127.708921, mean_eps: 0.875816\n",
            "  6569/50000: episode: 269, duration: 0.175s, episode steps:  20, steps per second: 115, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 37.778303, mae: 63.582838, mean_q: 128.993258, mean_eps: 0.875389\n",
            "  6610/50000: episode: 270, duration: 0.371s, episode steps:  41, steps per second: 110, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 52.741551, mae: 63.374521, mean_q: 129.491714, mean_eps: 0.874809\n",
            "  6635/50000: episode: 271, duration: 0.228s, episode steps:  25, steps per second: 110, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 34.936861, mae: 63.034805, mean_q: 128.444151, mean_eps: 0.874182\n",
            "  6664/50000: episode: 272, duration: 0.270s, episode steps:  29, steps per second: 107, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.586 [0.000, 1.000],  loss: 25.772701, mae: 63.271060, mean_q: 129.700781, mean_eps: 0.873669\n",
            "  6705/50000: episode: 273, duration: 0.373s, episode steps:  41, steps per second: 110, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.585 [0.000, 1.000],  loss: 36.810893, mae: 63.581526, mean_q: 130.288254, mean_eps: 0.873004\n",
            "  6721/50000: episode: 274, duration: 0.153s, episode steps:  16, steps per second: 104, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 45.326572, mae: 63.360455, mean_q: 129.711527, mean_eps: 0.872462\n",
            "  6731/50000: episode: 275, duration: 0.104s, episode steps:  10, steps per second:  96, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 35.293449, mae: 63.302964, mean_q: 129.543846, mean_eps: 0.872216\n",
            "  6748/50000: episode: 276, duration: 0.161s, episode steps:  17, steps per second: 106, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 53.337640, mae: 63.682198, mean_q: 130.698843, mean_eps: 0.871959\n",
            "  6789/50000: episode: 277, duration: 0.377s, episode steps:  41, steps per second: 109, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 24.310774, mae: 64.969324, mean_q: 132.463290, mean_eps: 0.871408\n",
            "  6802/50000: episode: 278, duration: 0.115s, episode steps:  13, steps per second: 113, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.154 [0.000, 1.000],  loss: 23.946491, mae: 64.893549, mean_q: 132.871382, mean_eps: 0.870895\n",
            "  6827/50000: episode: 279, duration: 0.215s, episode steps:  25, steps per second: 116, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 55.144646, mae: 64.536531, mean_q: 130.691548, mean_eps: 0.870534\n",
            "  6844/50000: episode: 280, duration: 0.157s, episode steps:  17, steps per second: 108, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 48.781387, mae: 63.945507, mean_q: 130.914974, mean_eps: 0.870135\n",
            "  6861/50000: episode: 281, duration: 0.185s, episode steps:  17, steps per second:  92, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 43.376326, mae: 63.544952, mean_q: 130.303481, mean_eps: 0.869812\n",
            "  6894/50000: episode: 282, duration: 0.440s, episode steps:  33, steps per second:  75, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 45.991793, mae: 64.562602, mean_q: 131.174943, mean_eps: 0.869337\n",
            "  6930/50000: episode: 283, duration: 0.456s, episode steps:  36, steps per second:  79, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 28.373251, mae: 64.882750, mean_q: 132.828932, mean_eps: 0.868681\n",
            "  6962/50000: episode: 284, duration: 0.404s, episode steps:  32, steps per second:  79, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 20.546912, mae: 65.020133, mean_q: 133.332286, mean_eps: 0.868035\n",
            "  6988/50000: episode: 285, duration: 0.315s, episode steps:  26, steps per second:  83, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 54.309833, mae: 66.196455, mean_q: 135.242798, mean_eps: 0.867484\n",
            "  7039/50000: episode: 286, duration: 0.603s, episode steps:  51, steps per second:  85, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.451 [0.000, 1.000],  loss: 42.368982, mae: 65.796766, mean_q: 134.294973, mean_eps: 0.866753\n",
            "  7068/50000: episode: 287, duration: 0.392s, episode steps:  29, steps per second:  74, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 42.940785, mae: 65.158030, mean_q: 133.567036, mean_eps: 0.865993\n",
            "  7080/50000: episode: 288, duration: 0.152s, episode steps:  12, steps per second:  79, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 55.698856, mae: 66.150722, mean_q: 135.374678, mean_eps: 0.865603\n",
            "  7108/50000: episode: 289, duration: 0.328s, episode steps:  28, steps per second:  85, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 26.197526, mae: 65.216472, mean_q: 134.589792, mean_eps: 0.865223\n",
            "  7118/50000: episode: 290, duration: 0.091s, episode steps:  10, steps per second: 109, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 37.499285, mae: 66.228331, mean_q: 135.473816, mean_eps: 0.864863\n",
            "  7154/50000: episode: 291, duration: 0.325s, episode steps:  36, steps per second: 111, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 51.657474, mae: 66.137464, mean_q: 134.918810, mean_eps: 0.864425\n",
            "  7184/50000: episode: 292, duration: 0.270s, episode steps:  30, steps per second: 111, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 58.597277, mae: 66.254006, mean_q: 135.100934, mean_eps: 0.863798\n",
            "  7201/50000: episode: 293, duration: 0.151s, episode steps:  17, steps per second: 113, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 28.723648, mae: 66.441771, mean_q: 136.803439, mean_eps: 0.863352\n",
            "  7245/50000: episode: 294, duration: 0.385s, episode steps:  44, steps per second: 114, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.432 [0.000, 1.000],  loss: 31.956864, mae: 66.995632, mean_q: 137.268824, mean_eps: 0.862773\n",
            "  7257/50000: episode: 295, duration: 0.107s, episode steps:  12, steps per second: 112, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 40.786414, mae: 67.368328, mean_q: 137.606040, mean_eps: 0.862240\n",
            "  7306/50000: episode: 296, duration: 0.415s, episode steps:  49, steps per second: 118, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 43.443355, mae: 67.515610, mean_q: 137.271278, mean_eps: 0.861661\n",
            "  7328/50000: episode: 297, duration: 0.214s, episode steps:  22, steps per second: 103, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 38.660216, mae: 66.722098, mean_q: 136.260199, mean_eps: 0.860986\n",
            "  7339/50000: episode: 298, duration: 0.096s, episode steps:  11, steps per second: 115, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 32.161297, mae: 68.668477, mean_q: 139.330949, mean_eps: 0.860673\n",
            "  7351/50000: episode: 299, duration: 0.107s, episode steps:  12, steps per second: 112, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 42.698635, mae: 68.457263, mean_q: 140.321924, mean_eps: 0.860455\n",
            "  7390/50000: episode: 300, duration: 0.344s, episode steps:  39, steps per second: 114, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 52.616790, mae: 67.263611, mean_q: 137.396553, mean_eps: 0.859970\n",
            "  7407/50000: episode: 301, duration: 0.150s, episode steps:  17, steps per second: 113, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 43.213575, mae: 68.603987, mean_q: 141.014109, mean_eps: 0.859438\n",
            "  7432/50000: episode: 302, duration: 0.223s, episode steps:  25, steps per second: 112, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.360 [0.000, 1.000],  loss: 44.808940, mae: 67.359524, mean_q: 137.842878, mean_eps: 0.859039\n",
            "  7450/50000: episode: 303, duration: 0.155s, episode steps:  18, steps per second: 116, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 49.997533, mae: 68.794849, mean_q: 140.340180, mean_eps: 0.858630\n",
            "  7465/50000: episode: 304, duration: 0.139s, episode steps:  15, steps per second: 108, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 21.466850, mae: 69.991041, mean_q: 144.205140, mean_eps: 0.858317\n",
            "  7477/50000: episode: 305, duration: 0.118s, episode steps:  12, steps per second: 101, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 42.776474, mae: 67.922544, mean_q: 140.310988, mean_eps: 0.858061\n",
            "  7518/50000: episode: 306, duration: 0.370s, episode steps:  41, steps per second: 111, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 37.961365, mae: 68.279344, mean_q: 140.078530, mean_eps: 0.857557\n",
            "  7559/50000: episode: 307, duration: 0.364s, episode steps:  41, steps per second: 112, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 61.807049, mae: 68.792953, mean_q: 140.105833, mean_eps: 0.856778\n",
            "  7632/50000: episode: 308, duration: 0.616s, episode steps:  73, steps per second: 118, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 44.308377, mae: 69.080794, mean_q: 141.576463, mean_eps: 0.855695\n",
            "  7660/50000: episode: 309, duration: 0.242s, episode steps:  28, steps per second: 116, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.393 [0.000, 1.000],  loss: 42.540963, mae: 69.163819, mean_q: 141.674962, mean_eps: 0.854736\n",
            "  7669/50000: episode: 310, duration: 0.084s, episode steps:   9, steps per second: 107, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 24.748143, mae: 70.139651, mean_q: 142.817946, mean_eps: 0.854384\n",
            "  7689/50000: episode: 311, duration: 0.187s, episode steps:  20, steps per second: 107, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 47.523608, mae: 68.761264, mean_q: 140.607684, mean_eps: 0.854108\n",
            "  7785/50000: episode: 312, duration: 0.832s, episode steps:  96, steps per second: 115, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 42.114483, mae: 71.154310, mean_q: 145.594547, mean_eps: 0.853007\n",
            "  7801/50000: episode: 313, duration: 0.143s, episode steps:  16, steps per second: 112, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 53.143732, mae: 70.692047, mean_q: 146.356153, mean_eps: 0.851943\n",
            "  7821/50000: episode: 314, duration: 0.183s, episode steps:  20, steps per second: 109, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 44.914757, mae: 70.918593, mean_q: 145.307562, mean_eps: 0.851600\n",
            "  7841/50000: episode: 315, duration: 0.170s, episode steps:  20, steps per second: 118, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 64.671711, mae: 72.228479, mean_q: 148.412846, mean_eps: 0.851220\n",
            "  7867/50000: episode: 316, duration: 0.238s, episode steps:  26, steps per second: 109, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 42.940931, mae: 71.826001, mean_q: 147.430136, mean_eps: 0.850784\n",
            "  7926/50000: episode: 317, duration: 0.505s, episode steps:  59, steps per second: 117, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 52.884310, mae: 72.023551, mean_q: 147.056471, mean_eps: 0.849976\n",
            "  7937/50000: episode: 318, duration: 0.107s, episode steps:  11, steps per second: 103, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 50.220552, mae: 72.670140, mean_q: 149.266455, mean_eps: 0.849311\n",
            "  7979/50000: episode: 319, duration: 0.356s, episode steps:  42, steps per second: 118, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 46.087739, mae: 73.115958, mean_q: 149.142798, mean_eps: 0.848808\n",
            "  8001/50000: episode: 320, duration: 0.196s, episode steps:  22, steps per second: 112, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 53.901480, mae: 71.495878, mean_q: 146.693073, mean_eps: 0.848199\n",
            "  8021/50000: episode: 321, duration: 0.196s, episode steps:  20, steps per second: 102, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 44.205837, mae: 73.069222, mean_q: 149.862320, mean_eps: 0.847800\n",
            "  8040/50000: episode: 322, duration: 0.163s, episode steps:  19, steps per second: 117, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 42.729945, mae: 72.944014, mean_q: 149.880063, mean_eps: 0.847430\n",
            "  8071/50000: episode: 323, duration: 0.279s, episode steps:  31, steps per second: 111, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 36.310509, mae: 72.817988, mean_q: 149.128603, mean_eps: 0.846955\n",
            "  8088/50000: episode: 324, duration: 0.155s, episode steps:  17, steps per second: 110, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 90.408665, mae: 71.210272, mean_q: 144.933516, mean_eps: 0.846499\n",
            "  8116/50000: episode: 325, duration: 0.248s, episode steps:  28, steps per second: 113, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 45.059333, mae: 73.802433, mean_q: 151.487196, mean_eps: 0.846071\n",
            "  8129/50000: episode: 326, duration: 0.112s, episode steps:  13, steps per second: 116, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 46.475273, mae: 75.179621, mean_q: 153.727847, mean_eps: 0.845682\n",
            "  8167/50000: episode: 327, duration: 0.337s, episode steps:  38, steps per second: 113, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 60.863955, mae: 73.867797, mean_q: 152.316256, mean_eps: 0.845197\n",
            "  8182/50000: episode: 328, duration: 0.139s, episode steps:  15, steps per second: 108, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 38.941429, mae: 75.094326, mean_q: 154.837073, mean_eps: 0.844694\n",
            "  8198/50000: episode: 329, duration: 0.178s, episode steps:  16, steps per second:  90, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 67.574744, mae: 74.353124, mean_q: 152.714659, mean_eps: 0.844399\n",
            "  8275/50000: episode: 330, duration: 0.898s, episode steps:  77, steps per second:  86, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 53.500182, mae: 74.451029, mean_q: 152.803018, mean_eps: 0.843516\n",
            "  8335/50000: episode: 331, duration: 0.752s, episode steps:  60, steps per second:  80, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 49.759815, mae: 74.704851, mean_q: 153.329649, mean_eps: 0.842214\n",
            "  8381/50000: episode: 332, duration: 0.587s, episode steps:  46, steps per second:  78, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 63.800087, mae: 76.191107, mean_q: 155.220205, mean_eps: 0.841207\n",
            "  8436/50000: episode: 333, duration: 0.664s, episode steps:  55, steps per second:  83, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 57.401599, mae: 76.983725, mean_q: 157.688841, mean_eps: 0.840248\n",
            "  8461/50000: episode: 334, duration: 0.315s, episode steps:  25, steps per second:  79, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 55.935522, mae: 76.117964, mean_q: 156.775822, mean_eps: 0.839488\n",
            "  8495/50000: episode: 335, duration: 0.288s, episode steps:  34, steps per second: 118, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 61.269441, mae: 76.429883, mean_q: 155.951506, mean_eps: 0.838928\n",
            "  8523/50000: episode: 336, duration: 0.242s, episode steps:  28, steps per second: 116, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 63.593628, mae: 76.503718, mean_q: 157.169359, mean_eps: 0.838338\n",
            "  8549/50000: episode: 337, duration: 0.241s, episode steps:  26, steps per second: 108, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.423 [0.000, 1.000],  loss: 55.424306, mae: 76.559750, mean_q: 158.118257, mean_eps: 0.837826\n",
            "  8583/50000: episode: 338, duration: 0.294s, episode steps:  34, steps per second: 116, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 44.192602, mae: 78.041072, mean_q: 160.444582, mean_eps: 0.837256\n",
            "  8597/50000: episode: 339, duration: 0.126s, episode steps:  14, steps per second: 111, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 69.526236, mae: 80.206538, mean_q: 163.675198, mean_eps: 0.836800\n",
            "  8649/50000: episode: 340, duration: 0.465s, episode steps:  52, steps per second: 112, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 51.209896, mae: 78.341601, mean_q: 160.570175, mean_eps: 0.836172\n",
            "  8723/50000: episode: 341, duration: 0.623s, episode steps:  74, steps per second: 119, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 60.912785, mae: 77.665637, mean_q: 160.313842, mean_eps: 0.834975\n",
            "  8764/50000: episode: 342, duration: 0.363s, episode steps:  41, steps per second: 113, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 68.146064, mae: 77.772124, mean_q: 159.321418, mean_eps: 0.833883\n",
            "  8779/50000: episode: 343, duration: 0.137s, episode steps:  15, steps per second: 110, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 81.366060, mae: 78.194069, mean_q: 159.995475, mean_eps: 0.833351\n",
            "  8800/50000: episode: 344, duration: 0.203s, episode steps:  21, steps per second: 104, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 72.831546, mae: 79.212244, mean_q: 163.334073, mean_eps: 0.833009\n",
            "  8845/50000: episode: 345, duration: 0.385s, episode steps:  45, steps per second: 117, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.622 [0.000, 1.000],  loss: 65.779985, mae: 80.610998, mean_q: 165.197825, mean_eps: 0.832382\n",
            "  8860/50000: episode: 346, duration: 0.138s, episode steps:  15, steps per second: 109, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 89.434066, mae: 78.122866, mean_q: 160.496776, mean_eps: 0.831812\n",
            "  8875/50000: episode: 347, duration: 0.137s, episode steps:  15, steps per second: 110, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 49.607314, mae: 79.411718, mean_q: 163.834748, mean_eps: 0.831527\n",
            "  8960/50000: episode: 348, duration: 0.720s, episode steps:  85, steps per second: 118, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 70.167503, mae: 80.638587, mean_q: 166.208663, mean_eps: 0.830577\n",
            "  8980/50000: episode: 349, duration: 0.176s, episode steps:  20, steps per second: 113, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 60.878518, mae: 80.582836, mean_q: 166.953352, mean_eps: 0.829580\n",
            "  8998/50000: episode: 350, duration: 0.179s, episode steps:  18, steps per second: 101, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 62.783605, mae: 81.226845, mean_q: 168.326290, mean_eps: 0.829219\n",
            "  9021/50000: episode: 351, duration: 0.490s, episode steps:  23, steps per second:  47, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.348 [0.000, 1.000],  loss: 82.236616, mae: 81.687642, mean_q: 168.007465, mean_eps: 0.828829\n",
            "  9047/50000: episode: 352, duration: 0.337s, episode steps:  26, steps per second:  77, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 95.908786, mae: 81.281054, mean_q: 166.600090, mean_eps: 0.828364\n",
            "  9110/50000: episode: 353, duration: 0.962s, episode steps:  63, steps per second:  66, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 79.894394, mae: 81.863714, mean_q: 167.935508, mean_eps: 0.827518\n",
            "  9142/50000: episode: 354, duration: 0.286s, episode steps:  32, steps per second: 112, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 88.485353, mae: 81.567256, mean_q: 167.848875, mean_eps: 0.826615\n",
            "  9162/50000: episode: 355, duration: 0.193s, episode steps:  20, steps per second: 104, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 70.654760, mae: 83.681987, mean_q: 172.893811, mean_eps: 0.826121\n",
            "  9180/50000: episode: 356, duration: 0.549s, episode steps:  18, steps per second:  33, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 46.515562, mae: 82.506744, mean_q: 170.643290, mean_eps: 0.825761\n",
            "  9217/50000: episode: 357, duration: 0.334s, episode steps:  37, steps per second: 111, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 72.995077, mae: 83.842255, mean_q: 172.758918, mean_eps: 0.825238\n",
            "  9272/50000: episode: 358, duration: 0.455s, episode steps:  55, steps per second: 121, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 74.357655, mae: 84.281199, mean_q: 173.898288, mean_eps: 0.824364\n",
            "  9324/50000: episode: 359, duration: 0.445s, episode steps:  52, steps per second: 117, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 74.179914, mae: 85.491024, mean_q: 176.349813, mean_eps: 0.823348\n",
            "  9390/50000: episode: 360, duration: 0.573s, episode steps:  66, steps per second: 115, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 83.176248, mae: 84.648987, mean_q: 174.652687, mean_eps: 0.822227\n",
            "  9435/50000: episode: 361, duration: 0.379s, episode steps:  45, steps per second: 119, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.578 [0.000, 1.000],  loss: 93.380233, mae: 84.556833, mean_q: 174.249362, mean_eps: 0.821172\n",
            "  9468/50000: episode: 362, duration: 0.345s, episode steps:  33, steps per second:  96, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 116.774835, mae: 86.615221, mean_q: 178.002697, mean_eps: 0.820431\n",
            "  9481/50000: episode: 363, duration: 0.172s, episode steps:  13, steps per second:  76, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 72.858295, mae: 85.584792, mean_q: 175.177617, mean_eps: 0.819994\n",
            "  9500/50000: episode: 364, duration: 0.250s, episode steps:  19, steps per second:  76, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 81.104553, mae: 87.917398, mean_q: 182.123939, mean_eps: 0.819690\n",
            "  9526/50000: episode: 365, duration: 0.380s, episode steps:  26, steps per second:  68, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 96.034986, mae: 87.557564, mean_q: 178.076543, mean_eps: 0.819263\n",
            "  9553/50000: episode: 366, duration: 0.339s, episode steps:  27, steps per second:  80, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 106.772142, mae: 88.304911, mean_q: 181.515633, mean_eps: 0.818759\n",
            "  9570/50000: episode: 367, duration: 0.237s, episode steps:  17, steps per second:  72, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 52.460435, mae: 88.505109, mean_q: 183.219382, mean_eps: 0.818341\n",
            "  9586/50000: episode: 368, duration: 0.222s, episode steps:  16, steps per second:  72, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 112.005375, mae: 89.234500, mean_q: 181.753257, mean_eps: 0.818028\n",
            "  9631/50000: episode: 369, duration: 0.560s, episode steps:  45, steps per second:  80, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 78.586763, mae: 86.969556, mean_q: 179.668304, mean_eps: 0.817448\n",
            "  9672/50000: episode: 370, duration: 0.522s, episode steps:  41, steps per second:  79, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 86.496497, mae: 88.162640, mean_q: 180.342264, mean_eps: 0.816631\n",
            "  9689/50000: episode: 371, duration: 0.199s, episode steps:  17, steps per second:  86, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 90.546085, mae: 87.131717, mean_q: 179.513211, mean_eps: 0.816080\n",
            "  9773/50000: episode: 372, duration: 0.708s, episode steps:  84, steps per second: 119, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 80.355701, mae: 89.529173, mean_q: 184.796443, mean_eps: 0.815121\n",
            "  9799/50000: episode: 373, duration: 0.256s, episode steps:  26, steps per second: 101, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 80.150371, mae: 90.656582, mean_q: 188.277032, mean_eps: 0.814076\n",
            "  9829/50000: episode: 374, duration: 0.265s, episode steps:  30, steps per second: 113, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 77.704620, mae: 90.692757, mean_q: 187.944952, mean_eps: 0.813543\n",
            "  9856/50000: episode: 375, duration: 0.251s, episode steps:  27, steps per second: 108, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 77.563411, mae: 90.166339, mean_q: 187.759251, mean_eps: 0.813002\n",
            "  9879/50000: episode: 376, duration: 0.207s, episode steps:  23, steps per second: 111, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 77.779858, mae: 92.205763, mean_q: 189.145930, mean_eps: 0.812527\n",
            "  9892/50000: episode: 377, duration: 0.120s, episode steps:  13, steps per second: 109, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 108.434271, mae: 90.596974, mean_q: 188.652113, mean_eps: 0.812185\n",
            "  9927/50000: episode: 378, duration: 0.312s, episode steps:  35, steps per second: 112, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 92.783433, mae: 91.373893, mean_q: 188.545660, mean_eps: 0.811729\n",
            "  9984/50000: episode: 379, duration: 0.492s, episode steps:  57, steps per second: 116, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 77.017279, mae: 92.815694, mean_q: 191.734097, mean_eps: 0.810855\n",
            " 10028/50000: episode: 380, duration: 0.391s, episode steps:  44, steps per second: 112, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 104.958448, mae: 92.782266, mean_q: 190.164752, mean_eps: 0.809895\n",
            " 10042/50000: episode: 381, duration: 0.121s, episode steps:  14, steps per second: 116, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 112.241844, mae: 94.769744, mean_q: 194.896683, mean_eps: 0.809345\n",
            " 10073/50000: episode: 382, duration: 0.266s, episode steps:  31, steps per second: 116, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 93.894159, mae: 94.355505, mean_q: 193.844167, mean_eps: 0.808917\n",
            " 10099/50000: episode: 383, duration: 0.228s, episode steps:  26, steps per second: 114, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 96.645970, mae: 93.645527, mean_q: 193.123921, mean_eps: 0.808376\n",
            " 10132/50000: episode: 384, duration: 0.303s, episode steps:  33, steps per second: 109, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 116.010189, mae: 92.782306, mean_q: 190.929793, mean_eps: 0.807815\n",
            " 10168/50000: episode: 385, duration: 0.330s, episode steps:  36, steps per second: 109, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 150.937515, mae: 94.054733, mean_q: 192.762506, mean_eps: 0.807159\n",
            " 10211/50000: episode: 386, duration: 0.379s, episode steps:  43, steps per second: 114, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 107.066420, mae: 96.925592, mean_q: 198.653248, mean_eps: 0.806409\n",
            " 10252/50000: episode: 387, duration: 0.350s, episode steps:  41, steps per second: 117, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 127.596861, mae: 95.948647, mean_q: 196.613680, mean_eps: 0.805611\n",
            " 10278/50000: episode: 388, duration: 0.227s, episode steps:  26, steps per second: 115, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 108.205623, mae: 97.286895, mean_q: 200.162808, mean_eps: 0.804975\n",
            " 10287/50000: episode: 389, duration: 0.081s, episode steps:   9, steps per second: 112, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 120.281731, mae: 96.670197, mean_q: 199.916051, mean_eps: 0.804642\n",
            " 10312/50000: episode: 390, duration: 0.217s, episode steps:  25, steps per second: 115, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 112.907015, mae: 96.386001, mean_q: 199.373345, mean_eps: 0.804319\n",
            " 10376/50000: episode: 391, duration: 0.589s, episode steps:  64, steps per second: 109, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 93.423872, mae: 95.726897, mean_q: 198.619100, mean_eps: 0.803473\n",
            " 10427/50000: episode: 392, duration: 0.432s, episode steps:  51, steps per second: 118, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 117.291559, mae: 97.068057, mean_q: 199.740990, mean_eps: 0.802381\n",
            " 10441/50000: episode: 393, duration: 0.124s, episode steps:  14, steps per second: 113, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 110.530838, mae: 97.694016, mean_q: 198.968727, mean_eps: 0.801764\n",
            " 10476/50000: episode: 394, duration: 0.306s, episode steps:  35, steps per second: 114, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 81.020970, mae: 99.463575, mean_q: 205.760616, mean_eps: 0.801298\n",
            " 10533/50000: episode: 395, duration: 0.496s, episode steps:  57, steps per second: 115, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 90.740979, mae: 98.557454, mean_q: 204.423473, mean_eps: 0.800424\n",
            " 10569/50000: episode: 396, duration: 0.311s, episode steps:  36, steps per second: 116, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 106.281594, mae: 99.388503, mean_q: 204.196517, mean_eps: 0.799540\n",
            " 10586/50000: episode: 397, duration: 0.152s, episode steps:  17, steps per second: 112, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 104.365755, mae: 101.880925, mean_q: 210.794554, mean_eps: 0.799037\n",
            " 10598/50000: episode: 398, duration: 0.115s, episode steps:  12, steps per second: 105, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 120.028436, mae: 101.468757, mean_q: 208.324309, mean_eps: 0.798762\n",
            " 10614/50000: episode: 399, duration: 0.146s, episode steps:  16, steps per second: 110, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 108.423418, mae: 102.783727, mean_q: 211.182601, mean_eps: 0.798496\n",
            " 10655/50000: episode: 400, duration: 0.360s, episode steps:  41, steps per second: 114, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 100.244335, mae: 101.309878, mean_q: 209.108716, mean_eps: 0.797954\n",
            " 10733/50000: episode: 401, duration: 0.673s, episode steps:  78, steps per second: 116, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 117.637667, mae: 102.085533, mean_q: 210.227784, mean_eps: 0.796824\n",
            " 10797/50000: episode: 402, duration: 0.540s, episode steps:  64, steps per second: 118, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 155.066042, mae: 102.126164, mean_q: 209.793828, mean_eps: 0.795475\n",
            " 10823/50000: episode: 403, duration: 0.289s, episode steps:  26, steps per second:  90, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 147.030632, mae: 102.933581, mean_q: 212.421701, mean_eps: 0.794620\n",
            " 10870/50000: episode: 404, duration: 0.595s, episode steps:  47, steps per second:  79, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.553 [0.000, 1.000],  loss: 114.064338, mae: 103.049912, mean_q: 212.248255, mean_eps: 0.793926\n",
            " 10892/50000: episode: 405, duration: 0.284s, episode steps:  22, steps per second:  78, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 139.263968, mae: 103.201759, mean_q: 211.787459, mean_eps: 0.793270\n",
            " 10907/50000: episode: 406, duration: 0.187s, episode steps:  15, steps per second:  80, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 106.516081, mae: 102.972207, mean_q: 214.145462, mean_eps: 0.792919\n",
            " 11003/50000: episode: 407, duration: 1.152s, episode steps:  96, steps per second:  83, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 115.476109, mae: 104.700441, mean_q: 216.621758, mean_eps: 0.791864\n",
            " 11051/50000: episode: 408, duration: 0.611s, episode steps:  48, steps per second:  79, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 106.184487, mae: 107.315075, mean_q: 221.936572, mean_eps: 0.790497\n",
            " 11075/50000: episode: 409, duration: 0.212s, episode steps:  24, steps per second: 113, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 103.328175, mae: 107.210540, mean_q: 221.578493, mean_eps: 0.789813\n",
            " 11087/50000: episode: 410, duration: 0.105s, episode steps:  12, steps per second: 114, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 131.141583, mae: 105.646971, mean_q: 216.465869, mean_eps: 0.789470\n",
            " 11112/50000: episode: 411, duration: 0.230s, episode steps:  25, steps per second: 109, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 112.777239, mae: 105.570806, mean_q: 217.581827, mean_eps: 0.789119\n",
            " 11181/50000: episode: 412, duration: 0.601s, episode steps:  69, steps per second: 115, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: 131.965312, mae: 108.840794, mean_q: 223.602662, mean_eps: 0.788226\n",
            " 11196/50000: episode: 413, duration: 0.128s, episode steps:  15, steps per second: 117, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 130.659349, mae: 109.762156, mean_q: 225.422598, mean_eps: 0.787428\n",
            " 11223/50000: episode: 414, duration: 0.248s, episode steps:  27, steps per second: 109, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.370 [0.000, 1.000],  loss: 90.973405, mae: 110.860395, mean_q: 229.708537, mean_eps: 0.787029\n",
            " 11257/50000: episode: 415, duration: 0.317s, episode steps:  34, steps per second: 107, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 123.244466, mae: 109.997717, mean_q: 227.488484, mean_eps: 0.786450\n",
            " 11300/50000: episode: 416, duration: 0.373s, episode steps:  43, steps per second: 115, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 126.766858, mae: 111.267511, mean_q: 228.811950, mean_eps: 0.785718\n",
            " 11313/50000: episode: 417, duration: 0.116s, episode steps:  13, steps per second: 112, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 108.005537, mae: 108.902361, mean_q: 225.220319, mean_eps: 0.785186\n",
            " 11371/50000: episode: 418, duration: 0.493s, episode steps:  58, steps per second: 118, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 161.928882, mae: 111.826399, mean_q: 229.798607, mean_eps: 0.784511\n",
            " 11391/50000: episode: 419, duration: 0.178s, episode steps:  20, steps per second: 112, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 113.491932, mae: 112.390284, mean_q: 230.940487, mean_eps: 0.783771\n",
            " 11426/50000: episode: 420, duration: 0.306s, episode steps:  35, steps per second: 114, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 140.492220, mae: 111.704917, mean_q: 230.486349, mean_eps: 0.783248\n",
            " 11471/50000: episode: 421, duration: 0.401s, episode steps:  45, steps per second: 112, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 173.401070, mae: 112.155943, mean_q: 231.230768, mean_eps: 0.782488\n",
            " 11513/50000: episode: 422, duration: 0.362s, episode steps:  42, steps per second: 116, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 131.099937, mae: 112.803726, mean_q: 231.948190, mean_eps: 0.781662\n",
            " 11547/50000: episode: 423, duration: 0.283s, episode steps:  34, steps per second: 120, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 125.060386, mae: 115.648382, mean_q: 237.078457, mean_eps: 0.780940\n",
            " 11567/50000: episode: 424, duration: 0.177s, episode steps:  20, steps per second: 113, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 125.164526, mae: 113.929921, mean_q: 234.979031, mean_eps: 0.780427\n",
            " 11596/50000: episode: 425, duration: 0.243s, episode steps:  29, steps per second: 119, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 118.879202, mae: 113.179514, mean_q: 234.257859, mean_eps: 0.779961\n",
            " 11633/50000: episode: 426, duration: 0.324s, episode steps:  37, steps per second: 114, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 137.620663, mae: 115.872118, mean_q: 238.595191, mean_eps: 0.779334\n",
            " 11737/50000: episode: 427, duration: 0.863s, episode steps: 104, steps per second: 121, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 153.547183, mae: 116.254510, mean_q: 239.763636, mean_eps: 0.777995\n",
            " 11866/50000: episode: 428, duration: 1.088s, episode steps: 129, steps per second: 119, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 173.758981, mae: 117.953602, mean_q: 242.840906, mean_eps: 0.775781\n",
            " 11898/50000: episode: 429, duration: 0.268s, episode steps:  32, steps per second: 120, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.594 [0.000, 1.000],  loss: 186.791958, mae: 115.916120, mean_q: 239.082405, mean_eps: 0.774252\n",
            " 11987/50000: episode: 430, duration: 0.759s, episode steps:  89, steps per second: 117, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 147.952997, mae: 120.201554, mean_q: 247.893660, mean_eps: 0.773102\n",
            " 12034/50000: episode: 431, duration: 0.398s, episode steps:  47, steps per second: 118, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 148.054844, mae: 121.762660, mean_q: 249.705308, mean_eps: 0.771810\n",
            " 12130/50000: episode: 432, duration: 0.815s, episode steps:  96, steps per second: 118, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 154.723011, mae: 122.038133, mean_q: 251.491545, mean_eps: 0.770452\n",
            " 12158/50000: episode: 433, duration: 0.252s, episode steps:  28, steps per second: 111, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 173.616097, mae: 123.171750, mean_q: 254.303925, mean_eps: 0.769274\n",
            " 12173/50000: episode: 434, duration: 0.130s, episode steps:  15, steps per second: 116, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 240.074701, mae: 123.833930, mean_q: 252.007147, mean_eps: 0.768865\n",
            " 12254/50000: episode: 435, duration: 0.855s, episode steps:  81, steps per second:  95, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 141.527063, mae: 123.699499, mean_q: 255.760374, mean_eps: 0.767953\n",
            " 12276/50000: episode: 436, duration: 0.298s, episode steps:  22, steps per second:  74, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 229.592945, mae: 126.626933, mean_q: 260.258249, mean_eps: 0.766975\n",
            " 12305/50000: episode: 437, duration: 0.365s, episode steps:  29, steps per second:  80, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 129.047858, mae: 127.128813, mean_q: 262.085820, mean_eps: 0.766490\n",
            " 12398/50000: episode: 438, duration: 1.130s, episode steps:  93, steps per second:  82, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 183.909123, mae: 128.055706, mean_q: 263.126493, mean_eps: 0.765331\n",
            " 12424/50000: episode: 439, duration: 0.338s, episode steps:  26, steps per second:  77, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 181.271078, mae: 128.857445, mean_q: 264.556155, mean_eps: 0.764200\n",
            " 12456/50000: episode: 440, duration: 0.370s, episode steps:  32, steps per second:  87, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 168.250010, mae: 128.027255, mean_q: 264.922729, mean_eps: 0.763650\n",
            " 12504/50000: episode: 441, duration: 0.401s, episode steps:  48, steps per second: 120, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 154.008544, mae: 127.374261, mean_q: 263.617307, mean_eps: 0.762889\n",
            " 12517/50000: episode: 442, duration: 0.115s, episode steps:  13, steps per second: 113, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 108.888269, mae: 129.644112, mean_q: 268.421779, mean_eps: 0.762310\n",
            " 12566/50000: episode: 443, duration: 0.412s, episode steps:  49, steps per second: 119, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: 185.644308, mae: 128.995671, mean_q: 266.324157, mean_eps: 0.761721\n",
            " 12598/50000: episode: 444, duration: 0.273s, episode steps:  32, steps per second: 117, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 185.861989, mae: 129.791694, mean_q: 267.018289, mean_eps: 0.760952\n",
            " 12613/50000: episode: 445, duration: 0.130s, episode steps:  15, steps per second: 115, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 198.269581, mae: 131.790024, mean_q: 269.968325, mean_eps: 0.760505\n",
            " 12659/50000: episode: 446, duration: 0.410s, episode steps:  46, steps per second: 112, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 188.139750, mae: 128.867645, mean_q: 264.150336, mean_eps: 0.759926\n",
            " 12675/50000: episode: 447, duration: 0.149s, episode steps:  16, steps per second: 108, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 158.458130, mae: 134.174943, mean_q: 274.606224, mean_eps: 0.759337\n",
            " 12754/50000: episode: 448, duration: 0.670s, episode steps:  79, steps per second: 118, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 154.224076, mae: 131.595146, mean_q: 270.733536, mean_eps: 0.758434\n",
            " 12779/50000: episode: 449, duration: 0.236s, episode steps:  25, steps per second: 106, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.360 [0.000, 1.000],  loss: 186.831636, mae: 132.428167, mean_q: 271.934789, mean_eps: 0.757446\n",
            " 12843/50000: episode: 450, duration: 0.572s, episode steps:  64, steps per second: 112, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 170.829553, mae: 134.048689, mean_q: 276.901974, mean_eps: 0.756601\n",
            " 12856/50000: episode: 451, duration: 0.115s, episode steps:  13, steps per second: 113, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 189.456904, mae: 134.588922, mean_q: 275.661642, mean_eps: 0.755869\n",
            " 12893/50000: episode: 452, duration: 0.330s, episode steps:  37, steps per second: 112, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 159.521535, mae: 134.976812, mean_q: 277.942495, mean_eps: 0.755394\n",
            " 12930/50000: episode: 453, duration: 0.333s, episode steps:  37, steps per second: 111, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 246.679944, mae: 135.059933, mean_q: 277.491642, mean_eps: 0.754691\n",
            " 12965/50000: episode: 454, duration: 0.305s, episode steps:  35, steps per second: 115, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 222.994636, mae: 134.239150, mean_q: 277.730755, mean_eps: 0.754007\n",
            " 13026/50000: episode: 455, duration: 0.534s, episode steps:  61, steps per second: 114, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 201.075401, mae: 136.390480, mean_q: 281.133535, mean_eps: 0.753095\n",
            " 13052/50000: episode: 456, duration: 0.224s, episode steps:  26, steps per second: 116, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 199.736976, mae: 136.089159, mean_q: 279.433195, mean_eps: 0.752269\n",
            " 13105/50000: episode: 457, duration: 0.449s, episode steps:  53, steps per second: 118, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 162.786547, mae: 136.822141, mean_q: 281.340433, mean_eps: 0.751518\n",
            " 13134/50000: episode: 458, duration: 0.265s, episode steps:  29, steps per second: 109, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 155.797545, mae: 137.826592, mean_q: 284.212550, mean_eps: 0.750739\n",
            " 13151/50000: episode: 459, duration: 0.154s, episode steps:  17, steps per second: 110, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 131.694896, mae: 139.930443, mean_q: 289.121440, mean_eps: 0.750302\n",
            " 13192/50000: episode: 460, duration: 0.354s, episode steps:  41, steps per second: 116, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 274.752003, mae: 138.722995, mean_q: 283.697221, mean_eps: 0.749751\n",
            " 13233/50000: episode: 461, duration: 0.362s, episode steps:  41, steps per second: 113, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 223.043889, mae: 138.950297, mean_q: 285.569680, mean_eps: 0.748972\n",
            " 13294/50000: episode: 462, duration: 0.525s, episode steps:  61, steps per second: 116, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 221.556093, mae: 139.407329, mean_q: 285.919163, mean_eps: 0.748003\n",
            " 13324/50000: episode: 463, duration: 0.258s, episode steps:  30, steps per second: 116, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.433 [0.000, 1.000],  loss: 211.641188, mae: 140.572482, mean_q: 289.498965, mean_eps: 0.747139\n",
            " 13335/50000: episode: 464, duration: 0.098s, episode steps:  11, steps per second: 112, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 237.384896, mae: 141.218080, mean_q: 291.861128, mean_eps: 0.746749\n",
            " 13360/50000: episode: 465, duration: 0.222s, episode steps:  25, steps per second: 112, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 268.503886, mae: 141.308439, mean_q: 290.654240, mean_eps: 0.746407\n",
            " 13413/50000: episode: 466, duration: 0.452s, episode steps:  53, steps per second: 117, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.547 [0.000, 1.000],  loss: 238.825794, mae: 141.604434, mean_q: 290.798917, mean_eps: 0.745666\n",
            " 13474/50000: episode: 467, duration: 0.523s, episode steps:  61, steps per second: 117, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 194.056291, mae: 141.755804, mean_q: 291.234301, mean_eps: 0.744583\n",
            " 13524/50000: episode: 468, duration: 0.442s, episode steps:  50, steps per second: 113, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 233.028438, mae: 141.756297, mean_q: 290.913602, mean_eps: 0.743529\n",
            " 13589/50000: episode: 469, duration: 0.565s, episode steps:  65, steps per second: 115, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 207.387520, mae: 143.532485, mean_q: 295.165321, mean_eps: 0.742436\n",
            " 13627/50000: episode: 470, duration: 0.483s, episode steps:  38, steps per second:  79, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 315.124277, mae: 145.075561, mean_q: 296.734995, mean_eps: 0.741457\n",
            " 13642/50000: episode: 471, duration: 0.194s, episode steps:  15, steps per second:  77, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 277.978048, mae: 141.946215, mean_q: 290.723364, mean_eps: 0.740954\n",
            " 13657/50000: episode: 472, duration: 0.195s, episode steps:  15, steps per second:  77, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 180.277325, mae: 144.389646, mean_q: 295.112793, mean_eps: 0.740669\n",
            " 13673/50000: episode: 473, duration: 0.219s, episode steps:  16, steps per second:  73, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 252.876098, mae: 144.373394, mean_q: 295.821972, mean_eps: 0.740374\n",
            " 13687/50000: episode: 474, duration: 0.173s, episode steps:  14, steps per second:  81, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 88.383097, mae: 145.248247, mean_q: 300.157357, mean_eps: 0.740090\n",
            " 13705/50000: episode: 475, duration: 0.223s, episode steps:  18, steps per second:  81, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 268.060038, mae: 146.805592, mean_q: 301.461790, mean_eps: 0.739785\n",
            " 13748/50000: episode: 476, duration: 0.539s, episode steps:  43, steps per second:  80, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 227.338024, mae: 146.788746, mean_q: 300.480692, mean_eps: 0.739206\n",
            " 13779/50000: episode: 477, duration: 0.395s, episode steps:  31, steps per second:  78, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 238.491172, mae: 146.859625, mean_q: 302.940559, mean_eps: 0.738503\n",
            " 13815/50000: episode: 478, duration: 0.461s, episode steps:  36, steps per second:  78, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 224.114853, mae: 147.711505, mean_q: 301.738815, mean_eps: 0.737866\n",
            " 13857/50000: episode: 479, duration: 0.414s, episode steps:  42, steps per second: 102, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 187.767117, mae: 147.573433, mean_q: 303.714662, mean_eps: 0.737125\n",
            " 13890/50000: episode: 480, duration: 0.278s, episode steps:  33, steps per second: 119, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 240.666177, mae: 147.382777, mean_q: 303.197848, mean_eps: 0.736413\n",
            " 13936/50000: episode: 481, duration: 0.411s, episode steps:  46, steps per second: 112, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 252.592821, mae: 148.258524, mean_q: 304.126745, mean_eps: 0.735663\n",
            " 13950/50000: episode: 482, duration: 0.134s, episode steps:  14, steps per second: 105, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 227.917016, mae: 149.760876, mean_q: 303.664995, mean_eps: 0.735093\n",
            " 14010/50000: episode: 483, duration: 0.508s, episode steps:  60, steps per second: 118, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 305.785119, mae: 147.354891, mean_q: 301.735350, mean_eps: 0.734390\n",
            " 14028/50000: episode: 484, duration: 0.157s, episode steps:  18, steps per second: 115, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 153.243516, mae: 148.777718, mean_q: 306.307137, mean_eps: 0.733649\n",
            " 14041/50000: episode: 485, duration: 0.120s, episode steps:  13, steps per second: 109, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 252.924636, mae: 144.009793, mean_q: 296.628819, mean_eps: 0.733354\n",
            " 14055/50000: episode: 486, duration: 0.128s, episode steps:  14, steps per second: 109, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 284.077569, mae: 149.438828, mean_q: 306.045907, mean_eps: 0.733098\n",
            " 14068/50000: episode: 487, duration: 0.130s, episode steps:  13, steps per second: 100, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 258.959779, mae: 153.535412, mean_q: 314.557617, mean_eps: 0.732841\n",
            " 14083/50000: episode: 488, duration: 0.133s, episode steps:  15, steps per second: 113, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 219.991801, mae: 150.647830, mean_q: 308.659121, mean_eps: 0.732575\n",
            " 14105/50000: episode: 489, duration: 0.202s, episode steps:  22, steps per second: 109, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 150.381708, mae: 147.390454, mean_q: 304.909846, mean_eps: 0.732224\n",
            " 14137/50000: episode: 490, duration: 0.280s, episode steps:  32, steps per second: 114, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.406 [0.000, 1.000],  loss: 253.473114, mae: 153.658579, mean_q: 314.985904, mean_eps: 0.731711\n",
            " 14260/50000: episode: 491, duration: 1.065s, episode steps: 123, steps per second: 116, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 251.998639, mae: 151.202467, mean_q: 309.794981, mean_eps: 0.730238\n",
            " 14281/50000: episode: 492, duration: 0.188s, episode steps:  21, steps per second: 112, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 307.458730, mae: 152.370962, mean_q: 313.727401, mean_eps: 0.728870\n",
            " 14352/50000: episode: 493, duration: 0.617s, episode steps:  71, steps per second: 115, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 256.702087, mae: 151.786816, mean_q: 310.738194, mean_eps: 0.727996\n",
            " 14415/50000: episode: 494, duration: 0.551s, episode steps:  63, steps per second: 114, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 236.590094, mae: 153.247835, mean_q: 314.001140, mean_eps: 0.726723\n",
            " 14449/50000: episode: 495, duration: 0.305s, episode steps:  34, steps per second: 112, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 204.090046, mae: 154.047956, mean_q: 316.820398, mean_eps: 0.725802\n",
            " 14464/50000: episode: 496, duration: 0.141s, episode steps:  15, steps per second: 107, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 230.733454, mae: 155.687735, mean_q: 322.728809, mean_eps: 0.725336\n",
            " 14485/50000: episode: 497, duration: 0.194s, episode steps:  21, steps per second: 108, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 173.012116, mae: 155.736140, mean_q: 319.319074, mean_eps: 0.724994\n",
            " 14529/50000: episode: 498, duration: 0.396s, episode steps:  44, steps per second: 111, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 335.767317, mae: 154.200670, mean_q: 315.006473, mean_eps: 0.724377\n",
            " 14557/50000: episode: 499, duration: 0.244s, episode steps:  28, steps per second: 115, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 220.368343, mae: 155.557719, mean_q: 319.139587, mean_eps: 0.723693\n",
            " 14577/50000: episode: 500, duration: 0.177s, episode steps:  20, steps per second: 113, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.350 [0.000, 1.000],  loss: 238.398753, mae: 154.537635, mean_q: 317.342296, mean_eps: 0.723236\n",
            " 14624/50000: episode: 501, duration: 0.407s, episode steps:  47, steps per second: 115, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 233.602750, mae: 155.358723, mean_q: 320.050775, mean_eps: 0.722600\n",
            " 14765/50000: episode: 502, duration: 1.194s, episode steps: 141, steps per second: 118, episode reward: 141.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 211.629284, mae: 159.320876, mean_q: 327.472421, mean_eps: 0.720814\n",
            " 14779/50000: episode: 503, duration: 0.119s, episode steps:  14, steps per second: 117, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 327.058365, mae: 159.770971, mean_q: 326.744350, mean_eps: 0.719341\n",
            " 14792/50000: episode: 504, duration: 0.120s, episode steps:  13, steps per second: 108, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 195.890440, mae: 161.204802, mean_q: 330.069733, mean_eps: 0.719085\n",
            " 14904/50000: episode: 505, duration: 0.951s, episode steps: 112, steps per second: 118, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 284.213408, mae: 161.652728, mean_q: 331.521244, mean_eps: 0.717898\n",
            " 15069/50000: episode: 506, duration: 1.757s, episode steps: 165, steps per second:  94, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 258.246921, mae: 163.350421, mean_q: 334.929272, mean_eps: 0.715266\n",
            " 15133/50000: episode: 507, duration: 0.766s, episode steps:  64, steps per second:  84, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 252.773494, mae: 164.401211, mean_q: 336.844778, mean_eps: 0.713091\n",
            " 15188/50000: episode: 508, duration: 0.708s, episode steps:  55, steps per second:  78, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 283.157426, mae: 164.908363, mean_q: 339.058799, mean_eps: 0.711960\n",
            " 15206/50000: episode: 509, duration: 0.250s, episode steps:  18, steps per second:  72, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 184.165665, mae: 164.877211, mean_q: 337.956356, mean_eps: 0.711267\n",
            " 15312/50000: episode: 510, duration: 0.907s, episode steps: 106, steps per second: 117, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 239.717830, mae: 165.985121, mean_q: 342.387314, mean_eps: 0.710089\n",
            " 15470/50000: episode: 511, duration: 1.366s, episode steps: 158, steps per second: 116, episode reward: 158.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 329.886999, mae: 169.324546, mean_q: 346.378133, mean_eps: 0.707581\n",
            " 15587/50000: episode: 512, duration: 1.001s, episode steps: 117, steps per second: 117, episode reward: 117.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 327.445631, mae: 171.390567, mean_q: 350.504176, mean_eps: 0.704968\n",
            " 15608/50000: episode: 513, duration: 0.175s, episode steps:  21, steps per second: 120, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 253.834323, mae: 171.197489, mean_q: 351.228707, mean_eps: 0.703657\n",
            " 15668/50000: episode: 514, duration: 0.516s, episode steps:  60, steps per second: 116, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 265.391520, mae: 173.576204, mean_q: 355.438398, mean_eps: 0.702887\n",
            " 15698/50000: episode: 515, duration: 0.265s, episode steps:  30, steps per second: 113, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 296.880703, mae: 171.076109, mean_q: 351.661022, mean_eps: 0.702032\n",
            " 15738/50000: episode: 516, duration: 0.352s, episode steps:  40, steps per second: 113, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 324.732398, mae: 172.720039, mean_q: 353.918104, mean_eps: 0.701368\n",
            " 15816/50000: episode: 517, duration: 0.660s, episode steps:  78, steps per second: 118, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 276.465596, mae: 174.506256, mean_q: 357.277565, mean_eps: 0.700246\n",
            " 15854/50000: episode: 518, duration: 0.342s, episode steps:  38, steps per second: 111, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 263.230043, mae: 173.091757, mean_q: 354.671106, mean_eps: 0.699144\n",
            " 15969/50000: episode: 519, duration: 0.983s, episode steps: 115, steps per second: 117, episode reward: 115.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.557 [0.000, 1.000],  loss: 266.333707, mae: 176.313551, mean_q: 362.197696, mean_eps: 0.697691\n",
            " 15999/50000: episode: 520, duration: 0.286s, episode steps:  30, steps per second: 105, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.433 [0.000, 1.000],  loss: 250.164635, mae: 175.673718, mean_q: 363.389293, mean_eps: 0.696314\n",
            " 16016/50000: episode: 521, duration: 0.154s, episode steps:  17, steps per second: 110, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.765 [0.000, 1.000],  loss: 261.223948, mae: 175.057411, mean_q: 358.931721, mean_eps: 0.695867\n",
            " 16036/50000: episode: 522, duration: 0.196s, episode steps:  20, steps per second: 102, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 256.305056, mae: 176.362693, mean_q: 363.758081, mean_eps: 0.695516\n",
            " 16073/50000: episode: 523, duration: 0.317s, episode steps:  37, steps per second: 117, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 311.540206, mae: 174.764870, mean_q: 360.464597, mean_eps: 0.694974\n",
            " 16093/50000: episode: 524, duration: 0.185s, episode steps:  20, steps per second: 108, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 408.619279, mae: 179.047529, mean_q: 364.958122, mean_eps: 0.694433\n",
            " 16211/50000: episode: 525, duration: 1.015s, episode steps: 118, steps per second: 116, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 324.845329, mae: 179.564919, mean_q: 367.144410, mean_eps: 0.693121\n",
            " 16294/50000: episode: 526, duration: 0.701s, episode steps:  83, steps per second: 118, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 327.742581, mae: 181.237418, mean_q: 370.215688, mean_eps: 0.691212\n",
            " 16339/50000: episode: 527, duration: 0.385s, episode steps:  45, steps per second: 117, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 278.598749, mae: 183.228335, mean_q: 375.051684, mean_eps: 0.689996\n",
            " 16434/50000: episode: 528, duration: 1.161s, episode steps:  95, steps per second:  82, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 255.100197, mae: 182.548093, mean_q: 374.382738, mean_eps: 0.688666\n",
            " 16567/50000: episode: 529, duration: 1.582s, episode steps: 133, steps per second:  84, episode reward: 133.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 369.319529, mae: 183.816543, mean_q: 375.967217, mean_eps: 0.686500\n",
            " 16653/50000: episode: 530, duration: 0.844s, episode steps:  86, steps per second: 102, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 285.373366, mae: 184.787845, mean_q: 378.972026, mean_eps: 0.684419\n",
            " 16677/50000: episode: 531, duration: 0.200s, episode steps:  24, steps per second: 120, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 426.948222, mae: 185.321847, mean_q: 379.394992, mean_eps: 0.683374\n",
            " 16733/50000: episode: 532, duration: 0.495s, episode steps:  56, steps per second: 113, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 298.151006, mae: 187.115605, mean_q: 381.872271, mean_eps: 0.682614\n",
            " 16928/50000: episode: 533, duration: 1.642s, episode steps: 195, steps per second: 119, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 271.945352, mae: 187.629328, mean_q: 385.704756, mean_eps: 0.680230\n",
            " 16942/50000: episode: 534, duration: 0.130s, episode steps:  14, steps per second: 108, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 218.615227, mae: 192.843813, mean_q: 396.407039, mean_eps: 0.678245\n",
            " 17005/50000: episode: 535, duration: 0.528s, episode steps:  63, steps per second: 119, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 497.646323, mae: 189.678809, mean_q: 387.848005, mean_eps: 0.677513\n",
            " 17170/50000: episode: 536, duration: 1.362s, episode steps: 165, steps per second: 121, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 376.027252, mae: 193.644019, mean_q: 395.170895, mean_eps: 0.675347\n",
            " 17321/50000: episode: 537, duration: 1.286s, episode steps: 151, steps per second: 117, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 386.629051, mae: 194.603349, mean_q: 398.305061, mean_eps: 0.672345\n",
            " 17357/50000: episode: 538, duration: 0.306s, episode steps:  36, steps per second: 117, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 339.898530, mae: 195.726700, mean_q: 401.778573, mean_eps: 0.670569\n",
            " 17408/50000: episode: 539, duration: 0.430s, episode steps:  51, steps per second: 119, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 322.901868, mae: 195.721676, mean_q: 401.037531, mean_eps: 0.669742\n",
            " 17535/50000: episode: 540, duration: 1.079s, episode steps: 127, steps per second: 118, episode reward: 127.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 434.276606, mae: 197.665183, mean_q: 403.475920, mean_eps: 0.668051\n",
            " 17547/50000: episode: 541, duration: 0.123s, episode steps:  12, steps per second:  98, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 514.863561, mae: 199.064677, mean_q: 404.638451, mean_eps: 0.666731\n",
            " 17747/50000: episode: 542, duration: 1.696s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 395.490138, mae: 197.220337, mean_q: 404.151370, mean_eps: 0.664717\n",
            " 17868/50000: episode: 543, duration: 1.408s, episode steps: 121, steps per second:  86, episode reward: 121.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 466.577237, mae: 199.306968, mean_q: 406.114910, mean_eps: 0.661667\n",
            " 17922/50000: episode: 544, duration: 0.654s, episode steps:  54, steps per second:  83, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 414.658520, mae: 199.558759, mean_q: 406.616278, mean_eps: 0.660004\n",
            " 18054/50000: episode: 545, duration: 1.457s, episode steps: 132, steps per second:  91, episode reward: 132.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 386.309257, mae: 201.240089, mean_q: 409.761814, mean_eps: 0.658238\n",
            " 18073/50000: episode: 546, duration: 0.169s, episode steps:  19, steps per second: 113, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 200.275409, mae: 198.433427, mean_q: 408.564127, mean_eps: 0.656803\n",
            " 18233/50000: episode: 547, duration: 1.327s, episode steps: 160, steps per second: 121, episode reward: 160.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 405.148974, mae: 203.044852, mean_q: 414.104476, mean_eps: 0.655103\n",
            " 18298/50000: episode: 548, duration: 0.554s, episode steps:  65, steps per second: 117, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 563.372848, mae: 203.141400, mean_q: 413.405983, mean_eps: 0.652965\n",
            " 18328/50000: episode: 549, duration: 0.257s, episode steps:  30, steps per second: 117, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 542.381676, mae: 199.769476, mean_q: 409.126148, mean_eps: 0.652062\n",
            " 18345/50000: episode: 550, duration: 0.158s, episode steps:  17, steps per second: 107, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 404.898121, mae: 205.163525, mean_q: 416.763135, mean_eps: 0.651616\n",
            " 18371/50000: episode: 551, duration: 0.235s, episode steps:  26, steps per second: 111, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 363.234496, mae: 203.184948, mean_q: 415.841664, mean_eps: 0.651208\n",
            " 18382/50000: episode: 552, duration: 0.100s, episode steps:  11, steps per second: 110, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 214.548594, mae: 199.198919, mean_q: 411.611414, mean_eps: 0.650856\n",
            " 18537/50000: episode: 553, duration: 1.318s, episode steps: 155, steps per second: 118, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 393.664563, mae: 204.675406, mean_q: 418.083033, mean_eps: 0.649279\n",
            " 18635/50000: episode: 554, duration: 0.828s, episode steps:  98, steps per second: 118, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 432.564961, mae: 205.744811, mean_q: 420.392707, mean_eps: 0.646876\n",
            " 18681/50000: episode: 555, duration: 0.396s, episode steps:  46, steps per second: 116, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 453.685500, mae: 205.054429, mean_q: 416.539209, mean_eps: 0.645508\n",
            " 18758/50000: episode: 556, duration: 0.655s, episode steps:  77, steps per second: 118, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 369.639200, mae: 204.617371, mean_q: 417.668100, mean_eps: 0.644339\n",
            " 18782/50000: episode: 557, duration: 0.211s, episode steps:  24, steps per second: 114, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 526.985117, mae: 204.902885, mean_q: 419.633987, mean_eps: 0.643379\n",
            " 18816/50000: episode: 558, duration: 0.316s, episode steps:  34, steps per second: 108, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 381.126087, mae: 205.458923, mean_q: 420.307472, mean_eps: 0.642829\n",
            " 18931/50000: episode: 559, duration: 0.973s, episode steps: 115, steps per second: 118, episode reward: 115.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 388.863678, mae: 207.219965, mean_q: 425.762121, mean_eps: 0.641413\n",
            " 19089/50000: episode: 560, duration: 1.338s, episode steps: 158, steps per second: 118, episode reward: 158.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 323.707189, mae: 208.278089, mean_q: 426.968652, mean_eps: 0.638819\n",
            " 19126/50000: episode: 561, duration: 0.336s, episode steps:  37, steps per second: 110, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.595 [0.000, 1.000],  loss: 554.910815, mae: 208.664358, mean_q: 425.371309, mean_eps: 0.636967\n",
            " 19171/50000: episode: 562, duration: 0.386s, episode steps:  45, steps per second: 117, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 437.146749, mae: 209.733954, mean_q: 429.042919, mean_eps: 0.636188\n",
            " 19287/50000: episode: 563, duration: 1.384s, episode steps: 116, steps per second:  84, episode reward: 116.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 373.347368, mae: 210.411894, mean_q: 430.249354, mean_eps: 0.634659\n",
            " 19351/50000: episode: 564, duration: 0.785s, episode steps:  64, steps per second:  82, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 430.251886, mae: 210.444089, mean_q: 429.549416, mean_eps: 0.632949\n",
            " 19404/50000: episode: 565, duration: 0.680s, episode steps:  53, steps per second:  78, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.434 [0.000, 1.000],  loss: 396.827771, mae: 213.361395, mean_q: 434.662937, mean_eps: 0.631837\n",
            " 19418/50000: episode: 566, duration: 0.195s, episode steps:  14, steps per second:  72, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 347.765440, mae: 212.794034, mean_q: 433.711866, mean_eps: 0.631201\n",
            " 19454/50000: episode: 567, duration: 0.363s, episode steps:  36, steps per second:  99, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 343.973163, mae: 212.393375, mean_q: 432.628175, mean_eps: 0.630726\n",
            " 19473/50000: episode: 568, duration: 0.158s, episode steps:  19, steps per second: 120, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 420.525568, mae: 212.371536, mean_q: 431.025622, mean_eps: 0.630203\n",
            " 19618/50000: episode: 569, duration: 1.251s, episode steps: 145, steps per second: 116, episode reward: 145.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 422.010538, mae: 213.046763, mean_q: 435.583248, mean_eps: 0.628645\n",
            " 19665/50000: episode: 570, duration: 0.430s, episode steps:  47, steps per second: 109, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.426 [0.000, 1.000],  loss: 382.072059, mae: 213.468461, mean_q: 435.748552, mean_eps: 0.626821\n",
            " 19764/50000: episode: 571, duration: 0.855s, episode steps:  99, steps per second: 116, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 328.665115, mae: 213.744626, mean_q: 436.166274, mean_eps: 0.625434\n",
            " 19955/50000: episode: 572, duration: 1.661s, episode steps: 191, steps per second: 115, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 323.937799, mae: 215.596059, mean_q: 441.000264, mean_eps: 0.622679\n",
            " 20042/50000: episode: 573, duration: 0.744s, episode steps:  87, steps per second: 117, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 502.065546, mae: 216.684030, mean_q: 442.054670, mean_eps: 0.620038\n",
            " 20068/50000: episode: 574, duration: 0.227s, episode steps:  26, steps per second: 114, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 228.911202, mae: 215.174269, mean_q: 442.615101, mean_eps: 0.618965\n",
            " 20228/50000: episode: 575, duration: 1.361s, episode steps: 160, steps per second: 118, episode reward: 160.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 380.898102, mae: 218.244624, mean_q: 445.156706, mean_eps: 0.617198\n",
            " 20254/50000: episode: 576, duration: 0.245s, episode steps:  26, steps per second: 106, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 516.553455, mae: 218.803477, mean_q: 445.844678, mean_eps: 0.615430\n",
            " 20283/50000: episode: 577, duration: 0.253s, episode steps:  29, steps per second: 114, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 790.069323, mae: 219.987783, mean_q: 446.341591, mean_eps: 0.614908\n",
            " 20344/50000: episode: 578, duration: 0.537s, episode steps:  61, steps per second: 114, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 529.281581, mae: 219.776931, mean_q: 446.301456, mean_eps: 0.614053\n",
            " 20384/50000: episode: 579, duration: 0.348s, episode steps:  40, steps per second: 115, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 406.340017, mae: 218.099389, mean_q: 446.562901, mean_eps: 0.613094\n",
            " 20431/50000: episode: 580, duration: 0.407s, episode steps:  47, steps per second: 116, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 262.576127, mae: 221.318367, mean_q: 451.972202, mean_eps: 0.612267\n",
            " 20488/50000: episode: 581, duration: 0.488s, episode steps:  57, steps per second: 117, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 290.979554, mae: 221.773202, mean_q: 455.095700, mean_eps: 0.611279\n",
            " 20688/50000: episode: 582, duration: 2.084s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 404.286714, mae: 221.070624, mean_q: 450.292568, mean_eps: 0.608838\n",
            " 20778/50000: episode: 583, duration: 1.155s, episode steps:  90, steps per second:  78, episode reward: 90.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 439.891164, mae: 222.151931, mean_q: 452.853464, mean_eps: 0.606083\n",
            " 20901/50000: episode: 584, duration: 1.204s, episode steps: 123, steps per second: 102, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 543.315628, mae: 221.945092, mean_q: 452.569202, mean_eps: 0.604059\n",
            " 20994/50000: episode: 585, duration: 0.820s, episode steps:  93, steps per second: 113, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 489.482862, mae: 222.666937, mean_q: 453.583490, mean_eps: 0.602007\n",
            " 21045/50000: episode: 586, duration: 0.453s, episode steps:  51, steps per second: 113, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 519.165986, mae: 223.587892, mean_q: 456.831386, mean_eps: 0.600639\n",
            " 21229/50000: episode: 587, duration: 1.593s, episode steps: 184, steps per second: 116, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 399.093901, mae: 223.607729, mean_q: 456.211699, mean_eps: 0.598407\n",
            " 21253/50000: episode: 588, duration: 0.218s, episode steps:  24, steps per second: 110, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 626.239319, mae: 224.227134, mean_q: 455.144793, mean_eps: 0.596430\n",
            " 21287/50000: episode: 589, duration: 0.317s, episode steps:  34, steps per second: 107, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 721.241184, mae: 225.884423, mean_q: 459.056098, mean_eps: 0.595880\n",
            " 21301/50000: episode: 590, duration: 0.129s, episode steps:  14, steps per second: 108, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 491.430514, mae: 224.672423, mean_q: 456.226044, mean_eps: 0.595423\n",
            " 21393/50000: episode: 591, duration: 0.805s, episode steps:  92, steps per second: 114, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 475.437682, mae: 225.548513, mean_q: 458.665442, mean_eps: 0.594417\n",
            " 21429/50000: episode: 592, duration: 0.324s, episode steps:  36, steps per second: 111, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 465.909977, mae: 225.360236, mean_q: 457.616616, mean_eps: 0.593201\n",
            " 21629/50000: episode: 593, duration: 1.677s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 412.892799, mae: 225.605556, mean_q: 460.776071, mean_eps: 0.590958\n",
            " 21736/50000: episode: 594, duration: 0.933s, episode steps: 107, steps per second: 115, episode reward: 107.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 519.859077, mae: 225.217697, mean_q: 457.523682, mean_eps: 0.588042\n",
            " 21764/50000: episode: 595, duration: 0.263s, episode steps:  28, steps per second: 107, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 407.192787, mae: 227.347038, mean_q: 464.483091, mean_eps: 0.586760\n",
            " 21921/50000: episode: 596, duration: 1.354s, episode steps: 157, steps per second: 116, episode reward: 157.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 542.169537, mae: 225.954585, mean_q: 459.540603, mean_eps: 0.585002\n",
            " 22076/50000: episode: 597, duration: 1.770s, episode steps: 155, steps per second:  88, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 426.886625, mae: 225.809247, mean_q: 459.899633, mean_eps: 0.582038\n",
            " 22156/50000: episode: 598, duration: 0.967s, episode steps:  80, steps per second:  83, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 342.984423, mae: 227.372720, mean_q: 462.211677, mean_eps: 0.579806\n",
            " 22214/50000: episode: 599, duration: 0.672s, episode steps:  58, steps per second:  86, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 632.986635, mae: 228.348775, mean_q: 462.916316, mean_eps: 0.578495\n",
            " 22234/50000: episode: 600, duration: 0.194s, episode steps:  20, steps per second: 103, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 929.180968, mae: 227.941412, mean_q: 461.187686, mean_eps: 0.577754\n",
            " 22295/50000: episode: 601, duration: 0.525s, episode steps:  61, steps per second: 116, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 587.103692, mae: 227.597918, mean_q: 459.874049, mean_eps: 0.576984\n",
            " 22423/50000: episode: 602, duration: 1.145s, episode steps: 128, steps per second: 112, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 511.017662, mae: 227.079095, mean_q: 461.456393, mean_eps: 0.575189\n",
            " 22518/50000: episode: 603, duration: 0.847s, episode steps:  95, steps per second: 112, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 411.515428, mae: 225.629432, mean_q: 459.221666, mean_eps: 0.573070\n",
            " 22535/50000: episode: 604, duration: 0.158s, episode steps:  17, steps per second: 107, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 632.496172, mae: 224.884493, mean_q: 455.422062, mean_eps: 0.572006\n",
            " 22735/50000: episode: 605, duration: 1.743s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 393.713812, mae: 226.742014, mean_q: 461.181686, mean_eps: 0.569944\n",
            " 22861/50000: episode: 606, duration: 1.103s, episode steps: 126, steps per second: 114, episode reward: 126.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 412.759725, mae: 227.835707, mean_q: 460.587353, mean_eps: 0.566848\n",
            " 22969/50000: episode: 607, duration: 0.956s, episode steps: 108, steps per second: 113, episode reward: 108.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 415.016274, mae: 227.468343, mean_q: 461.204202, mean_eps: 0.564624\n",
            " 23169/50000: episode: 608, duration: 1.748s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 342.849127, mae: 227.117677, mean_q: 460.095936, mean_eps: 0.561698\n",
            " 23369/50000: episode: 609, duration: 1.821s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 390.059311, mae: 225.977472, mean_q: 459.033232, mean_eps: 0.557898\n",
            " 23387/50000: episode: 610, duration: 0.246s, episode steps:  18, steps per second:  73, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 178.443066, mae: 226.168697, mean_q: 457.592992, mean_eps: 0.555828\n",
            " 23449/50000: episode: 611, duration: 0.760s, episode steps:  62, steps per second:  82, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 435.153078, mae: 225.437027, mean_q: 456.458643, mean_eps: 0.555068\n",
            " 23480/50000: episode: 612, duration: 0.407s, episode steps:  31, steps per second:  76, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 224.317342, mae: 226.390012, mean_q: 459.909577, mean_eps: 0.554184\n",
            " 23587/50000: episode: 613, duration: 1.291s, episode steps: 107, steps per second:  83, episode reward: 107.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 298.682525, mae: 223.718710, mean_q: 455.704264, mean_eps: 0.552873\n",
            " 23674/50000: episode: 614, duration: 0.778s, episode steps:  87, steps per second: 112, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 400.517622, mae: 225.194257, mean_q: 456.545711, mean_eps: 0.551030\n",
            " 23722/50000: episode: 615, duration: 0.427s, episode steps:  48, steps per second: 112, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 258.720674, mae: 224.987882, mean_q: 456.847125, mean_eps: 0.549748\n",
            " 23827/50000: episode: 616, duration: 0.931s, episode steps: 105, steps per second: 113, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 464.749375, mae: 225.169428, mean_q: 456.926121, mean_eps: 0.548294\n",
            " 23979/50000: episode: 617, duration: 1.321s, episode steps: 152, steps per second: 115, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 303.690920, mae: 224.653939, mean_q: 456.344816, mean_eps: 0.545853\n",
            " 24094/50000: episode: 618, duration: 1.014s, episode steps: 115, steps per second: 113, episode reward: 115.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 489.061595, mae: 224.647131, mean_q: 453.695535, mean_eps: 0.543316\n",
            " 24294/50000: episode: 619, duration: 1.747s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 340.415644, mae: 223.593119, mean_q: 454.301679, mean_eps: 0.540324\n",
            " 24351/50000: episode: 620, duration: 0.516s, episode steps:  57, steps per second: 111, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 310.962721, mae: 222.913526, mean_q: 452.786575, mean_eps: 0.537882\n",
            " 24404/50000: episode: 621, duration: 0.470s, episode steps:  53, steps per second: 113, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.547 [0.000, 1.000],  loss: 411.908895, mae: 224.433071, mean_q: 454.750988, mean_eps: 0.536837\n",
            " 24488/50000: episode: 622, duration: 0.728s, episode steps:  84, steps per second: 115, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 464.949038, mae: 223.835217, mean_q: 453.446871, mean_eps: 0.535536\n",
            " 24582/50000: episode: 623, duration: 0.811s, episode steps:  94, steps per second: 116, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 301.417371, mae: 222.513851, mean_q: 450.883910, mean_eps: 0.533845\n",
            " 24633/50000: episode: 624, duration: 0.449s, episode steps:  51, steps per second: 114, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 417.372549, mae: 221.781433, mean_q: 448.320751, mean_eps: 0.532467\n",
            " 24833/50000: episode: 625, duration: 2.163s, episode steps: 200, steps per second:  92, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 325.431915, mae: 221.503192, mean_q: 449.198659, mean_eps: 0.530083\n",
            " 24906/50000: episode: 626, duration: 0.908s, episode steps:  73, steps per second:  80, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 248.553986, mae: 221.479007, mean_q: 448.839807, mean_eps: 0.527489\n",
            " 25069/50000: episode: 627, duration: 1.530s, episode steps: 163, steps per second: 107, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 288.418351, mae: 220.739865, mean_q: 447.755043, mean_eps: 0.525247\n",
            " 25117/50000: episode: 628, duration: 0.417s, episode steps:  48, steps per second: 115, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 157.483253, mae: 221.500985, mean_q: 449.374130, mean_eps: 0.523242\n",
            " 25145/50000: episode: 629, duration: 0.245s, episode steps:  28, steps per second: 114, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 460.995454, mae: 220.553698, mean_q: 446.854490, mean_eps: 0.522521\n",
            " 25323/50000: episode: 630, duration: 1.522s, episode steps: 178, steps per second: 117, episode reward: 178.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 407.484141, mae: 218.397275, mean_q: 442.070233, mean_eps: 0.520564\n",
            " 25484/50000: episode: 631, duration: 1.351s, episode steps: 161, steps per second: 119, episode reward: 161.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 312.367634, mae: 217.816924, mean_q: 441.943267, mean_eps: 0.517343\n",
            " 25576/50000: episode: 632, duration: 0.792s, episode steps:  92, steps per second: 116, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 265.750613, mae: 216.143068, mean_q: 438.310813, mean_eps: 0.514940\n",
            " 25758/50000: episode: 633, duration: 1.552s, episode steps: 182, steps per second: 117, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 273.840336, mae: 215.746998, mean_q: 436.628726, mean_eps: 0.512337\n",
            " 25947/50000: episode: 634, duration: 1.613s, episode steps: 189, steps per second: 117, episode reward: 189.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 253.956711, mae: 212.965417, mean_q: 431.886421, mean_eps: 0.508812\n",
            " 26044/50000: episode: 635, duration: 0.815s, episode steps:  97, steps per second: 119, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 240.073452, mae: 213.033346, mean_q: 431.720513, mean_eps: 0.506095\n",
            " 26237/50000: episode: 636, duration: 2.059s, episode steps: 193, steps per second:  94, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 256.492802, mae: 211.580295, mean_q: 429.085968, mean_eps: 0.503340\n",
            " 26271/50000: episode: 637, duration: 0.409s, episode steps:  34, steps per second:  83, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 200.521059, mae: 211.679026, mean_q: 428.121162, mean_eps: 0.501184\n",
            " 26458/50000: episode: 638, duration: 1.941s, episode steps: 187, steps per second:  96, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 368.213560, mae: 210.035693, mean_q: 423.978562, mean_eps: 0.499084\n",
            " 26482/50000: episode: 639, duration: 0.204s, episode steps:  24, steps per second: 117, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 208.847244, mae: 208.602302, mean_q: 420.639469, mean_eps: 0.497080\n",
            " 26682/50000: episode: 640, duration: 1.687s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 250.333483, mae: 207.885428, mean_q: 420.680952, mean_eps: 0.494951\n",
            " 26722/50000: episode: 641, duration: 0.348s, episode steps:  40, steps per second: 115, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 185.631509, mae: 204.196132, mean_q: 413.106519, mean_eps: 0.492672\n",
            " 26921/50000: episode: 642, duration: 1.694s, episode steps: 199, steps per second: 118, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 226.269729, mae: 206.112715, mean_q: 416.907352, mean_eps: 0.490401\n",
            " 27053/50000: episode: 643, duration: 1.117s, episode steps: 132, steps per second: 118, episode reward: 132.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 243.372772, mae: 204.094665, mean_q: 412.683594, mean_eps: 0.487257\n",
            " 27232/50000: episode: 644, duration: 1.535s, episode steps: 179, steps per second: 117, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 229.357229, mae: 202.733281, mean_q: 409.873670, mean_eps: 0.484302\n",
            " 27425/50000: episode: 645, duration: 1.647s, episode steps: 193, steps per second: 117, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 234.938159, mae: 200.453774, mean_q: 405.657727, mean_eps: 0.480768\n",
            " 27457/50000: episode: 646, duration: 0.287s, episode steps:  32, steps per second: 111, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 171.399223, mae: 201.133740, mean_q: 405.677336, mean_eps: 0.478631\n",
            " 27627/50000: episode: 647, duration: 1.790s, episode steps: 170, steps per second:  95, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 217.580292, mae: 198.879981, mean_q: 402.677152, mean_eps: 0.476712\n",
            " 27805/50000: episode: 648, duration: 2.027s, episode steps: 178, steps per second:  88, episode reward: 178.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 177.732082, mae: 197.072242, mean_q: 398.422485, mean_eps: 0.473406\n",
            " 28005/50000: episode: 649, duration: 1.717s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 213.162479, mae: 195.245915, mean_q: 394.482773, mean_eps: 0.469815\n",
            " 28194/50000: episode: 650, duration: 1.584s, episode steps: 189, steps per second: 119, episode reward: 189.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 166.563210, mae: 192.839418, mean_q: 390.464650, mean_eps: 0.466119\n",
            " 28298/50000: episode: 651, duration: 0.873s, episode steps: 104, steps per second: 119, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 177.838589, mae: 191.085332, mean_q: 386.122546, mean_eps: 0.463336\n",
            " 28384/50000: episode: 652, duration: 0.733s, episode steps:  86, steps per second: 117, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 117.150221, mae: 191.045788, mean_q: 385.781922, mean_eps: 0.461531\n",
            " 28584/50000: episode: 653, duration: 1.675s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 159.543564, mae: 191.384553, mean_q: 386.822202, mean_eps: 0.458814\n",
            " 28625/50000: episode: 654, duration: 0.349s, episode steps:  41, steps per second: 118, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 239.239878, mae: 189.099667, mean_q: 381.550101, mean_eps: 0.456524\n",
            " 28693/50000: episode: 655, duration: 0.598s, episode steps:  68, steps per second: 114, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 119.268380, mae: 190.036837, mean_q: 384.927207, mean_eps: 0.455489\n",
            " 28893/50000: episode: 656, duration: 1.712s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 146.654927, mae: 187.897964, mean_q: 380.406916, mean_eps: 0.452943\n",
            " 29093/50000: episode: 657, duration: 2.218s, episode steps: 200, steps per second:  90, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 122.053383, mae: 188.091866, mean_q: 380.325765, mean_eps: 0.449143\n",
            " 29293/50000: episode: 658, duration: 2.083s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 160.485565, mae: 184.495322, mean_q: 372.795539, mean_eps: 0.445343\n",
            " 29358/50000: episode: 659, duration: 0.573s, episode steps:  65, steps per second: 113, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 181.643041, mae: 183.676260, mean_q: 369.724804, mean_eps: 0.442825\n",
            " 29558/50000: episode: 660, duration: 1.692s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 145.758637, mae: 183.539821, mean_q: 370.410301, mean_eps: 0.440308\n",
            " 29758/50000: episode: 661, duration: 1.699s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 159.237720, mae: 180.982696, mean_q: 365.577355, mean_eps: 0.436508\n",
            " 29958/50000: episode: 662, duration: 1.673s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 182.515307, mae: 179.626286, mean_q: 362.194212, mean_eps: 0.432708\n",
            " 30158/50000: episode: 663, duration: 1.654s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 121.486680, mae: 177.344738, mean_q: 357.469514, mean_eps: 0.428908\n",
            " 30358/50000: episode: 664, duration: 1.697s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 133.949370, mae: 174.545417, mean_q: 352.191604, mean_eps: 0.425108\n",
            " 30391/50000: episode: 665, duration: 0.354s, episode steps:  33, steps per second:  93, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 220.056262, mae: 172.938899, mean_q: 347.766201, mean_eps: 0.422894\n",
            " 30591/50000: episode: 666, duration: 2.437s, episode steps: 200, steps per second:  82, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 217.636220, mae: 171.548641, mean_q: 344.910524, mean_eps: 0.420681\n",
            " 30791/50000: episode: 667, duration: 1.845s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 175.361563, mae: 169.692873, mean_q: 341.634808, mean_eps: 0.416881\n",
            " 30991/50000: episode: 668, duration: 1.690s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 109.729932, mae: 165.568301, mean_q: 333.645451, mean_eps: 0.413081\n",
            " 31191/50000: episode: 669, duration: 1.665s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 117.707768, mae: 163.148908, mean_q: 328.362280, mean_eps: 0.409281\n",
            " 31391/50000: episode: 670, duration: 1.660s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 164.571033, mae: 163.753130, mean_q: 329.488913, mean_eps: 0.405481\n",
            " 31591/50000: episode: 671, duration: 1.674s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 114.888391, mae: 159.586686, mean_q: 320.831359, mean_eps: 0.401681\n",
            " 31706/50000: episode: 672, duration: 0.969s, episode steps: 115, steps per second: 119, episode reward: 115.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 225.737018, mae: 156.347301, mean_q: 314.475372, mean_eps: 0.398688\n",
            " 31770/50000: episode: 673, duration: 0.535s, episode steps:  64, steps per second: 120, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 68.765359, mae: 156.306095, mean_q: 315.318591, mean_eps: 0.396988\n",
            " 31882/50000: episode: 674, duration: 1.276s, episode steps: 112, steps per second:  88, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 156.971055, mae: 156.637377, mean_q: 314.912954, mean_eps: 0.395316\n",
            " 32082/50000: episode: 675, duration: 2.248s, episode steps: 200, steps per second:  89, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 115.348972, mae: 155.001646, mean_q: 312.156939, mean_eps: 0.392352\n",
            " 32279/50000: episode: 676, duration: 1.677s, episode steps: 197, steps per second: 117, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 101.467135, mae: 153.602961, mean_q: 309.305806, mean_eps: 0.388580\n",
            " 32479/50000: episode: 677, duration: 1.716s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 78.518841, mae: 150.122118, mean_q: 302.328898, mean_eps: 0.384809\n",
            " 32546/50000: episode: 678, duration: 0.574s, episode steps:  67, steps per second: 117, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 52.353241, mae: 148.557352, mean_q: 298.661026, mean_eps: 0.382272\n",
            " 32729/50000: episode: 679, duration: 1.583s, episode steps: 183, steps per second: 116, episode reward: 183.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 135.401354, mae: 146.606269, mean_q: 295.219245, mean_eps: 0.379897\n",
            " 32929/50000: episode: 680, duration: 1.691s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 105.737216, mae: 146.080505, mean_q: 293.381298, mean_eps: 0.376259\n",
            " 33129/50000: episode: 681, duration: 1.754s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 54.583298, mae: 142.436906, mean_q: 286.468365, mean_eps: 0.372459\n",
            " 33329/50000: episode: 682, duration: 2.348s, episode steps: 200, steps per second:  85, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 120.322309, mae: 142.574723, mean_q: 286.384111, mean_eps: 0.368659\n",
            " 33529/50000: episode: 683, duration: 2.091s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 108.013361, mae: 139.391170, mean_q: 279.635517, mean_eps: 0.364859\n",
            " 33729/50000: episode: 684, duration: 1.664s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 79.163237, mae: 137.374933, mean_q: 275.878082, mean_eps: 0.361059\n",
            " 33929/50000: episode: 685, duration: 1.697s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 129.580578, mae: 134.913228, mean_q: 270.259758, mean_eps: 0.357259\n",
            " 34059/50000: episode: 686, duration: 1.116s, episode steps: 130, steps per second: 116, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 145.066406, mae: 132.114984, mean_q: 264.986472, mean_eps: 0.354124\n",
            " 34214/50000: episode: 687, duration: 1.312s, episode steps: 155, steps per second: 118, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 120.943223, mae: 129.100236, mean_q: 258.035187, mean_eps: 0.351416\n",
            " 34376/50000: episode: 688, duration: 1.343s, episode steps: 162, steps per second: 121, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 112.853613, mae: 128.628353, mean_q: 257.403142, mean_eps: 0.348405\n",
            " 34576/50000: episode: 689, duration: 1.699s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 70.440139, mae: 126.617776, mean_q: 253.666396, mean_eps: 0.344966\n",
            " 34776/50000: episode: 690, duration: 2.244s, episode steps: 200, steps per second:  89, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 68.030537, mae: 123.669938, mean_q: 247.825997, mean_eps: 0.341166\n",
            " 34958/50000: episode: 691, duration: 1.888s, episode steps: 182, steps per second:  96, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 124.025660, mae: 121.158187, mean_q: 241.868068, mean_eps: 0.337537\n",
            " 35158/50000: episode: 692, duration: 1.697s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 142.285992, mae: 120.140852, mean_q: 239.831568, mean_eps: 0.333908\n",
            " 35325/50000: episode: 693, duration: 1.419s, episode steps: 167, steps per second: 118, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 53.194700, mae: 116.638926, mean_q: 232.904655, mean_eps: 0.330421\n",
            " 35525/50000: episode: 694, duration: 1.695s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 65.432169, mae: 116.253738, mean_q: 232.011617, mean_eps: 0.326934\n",
            " 35725/50000: episode: 695, duration: 1.692s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 108.533692, mae: 114.358827, mean_q: 228.190044, mean_eps: 0.323135\n",
            " 35883/50000: episode: 696, duration: 1.334s, episode steps: 158, steps per second: 118, episode reward: 158.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 52.258900, mae: 112.982948, mean_q: 225.325325, mean_eps: 0.319734\n",
            " 36083/50000: episode: 697, duration: 1.953s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 82.607506, mae: 110.975427, mean_q: 221.451467, mean_eps: 0.316333\n",
            " 36283/50000: episode: 698, duration: 2.458s, episode steps: 200, steps per second:  81, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 85.510756, mae: 109.127269, mean_q: 217.434051, mean_eps: 0.312533\n",
            " 36483/50000: episode: 699, duration: 1.685s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 61.244480, mae: 106.173434, mean_q: 212.147631, mean_eps: 0.308733\n",
            " 36620/50000: episode: 700, duration: 1.151s, episode steps: 137, steps per second: 119, episode reward: 137.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.496 [0.000, 1.000],  loss: 59.770119, mae: 104.677125, mean_q: 208.114827, mean_eps: 0.305531\n",
            " 36686/50000: episode: 701, duration: 0.579s, episode steps:  66, steps per second: 114, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 109.875225, mae: 104.479269, mean_q: 207.093481, mean_eps: 0.303603\n",
            " 36886/50000: episode: 702, duration: 1.701s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 92.013548, mae: 103.991702, mean_q: 207.423876, mean_eps: 0.301076\n",
            " 37086/50000: episode: 703, duration: 1.719s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 73.038071, mae: 103.016400, mean_q: 204.949101, mean_eps: 0.297276\n",
            " 37154/50000: episode: 704, duration: 0.594s, episode steps:  68, steps per second: 114, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 187.057624, mae: 102.954243, mean_q: 204.228659, mean_eps: 0.294730\n",
            " 37354/50000: episode: 705, duration: 1.742s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 91.441526, mae: 100.841202, mean_q: 201.513687, mean_eps: 0.292184\n",
            " 37390/50000: episode: 706, duration: 0.326s, episode steps:  36, steps per second: 110, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 181.126818, mae: 98.301252, mean_q: 194.581660, mean_eps: 0.289942\n",
            " 37492/50000: episode: 707, duration: 1.111s, episode steps: 102, steps per second:  92, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 73.298137, mae: 98.342662, mean_q: 196.327034, mean_eps: 0.288631\n",
            " 37692/50000: episode: 708, duration: 2.363s, episode steps: 200, steps per second:  85, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 61.698818, mae: 97.405802, mean_q: 194.560934, mean_eps: 0.285762\n",
            " 37892/50000: episode: 709, duration: 1.699s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 68.778944, mae: 96.197905, mean_q: 191.858337, mean_eps: 0.281962\n",
            " 37930/50000: episode: 710, duration: 0.335s, episode steps:  38, steps per second: 113, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 58.949596, mae: 95.837467, mean_q: 190.898552, mean_eps: 0.279701\n",
            " 37976/50000: episode: 711, duration: 0.399s, episode steps:  46, steps per second: 115, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 101.106404, mae: 94.312213, mean_q: 187.682441, mean_eps: 0.278903\n",
            " 38077/50000: episode: 712, duration: 0.859s, episode steps: 101, steps per second: 118, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 77.882819, mae: 94.964706, mean_q: 189.463544, mean_eps: 0.277506\n",
            " 38277/50000: episode: 713, duration: 1.681s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 129.839004, mae: 93.728369, mean_q: 186.627155, mean_eps: 0.274647\n",
            " 38477/50000: episode: 714, duration: 1.676s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 84.511542, mae: 91.908144, mean_q: 183.274794, mean_eps: 0.270847\n",
            " 38601/50000: episode: 715, duration: 1.066s, episode steps: 124, steps per second: 116, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 45.888670, mae: 90.314948, mean_q: 180.377159, mean_eps: 0.267769\n",
            " 38633/50000: episode: 716, duration: 0.274s, episode steps:  32, steps per second: 117, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 51.178801, mae: 90.033654, mean_q: 179.655471, mean_eps: 0.266287\n",
            " 38718/50000: episode: 717, duration: 0.728s, episode steps:  85, steps per second: 117, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 43.338676, mae: 89.857512, mean_q: 179.733162, mean_eps: 0.265175\n",
            " 38894/50000: episode: 718, duration: 1.689s, episode steps: 176, steps per second: 104, episode reward: 176.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 61.152501, mae: 89.503868, mean_q: 179.276447, mean_eps: 0.262696\n",
            " 38966/50000: episode: 719, duration: 0.901s, episode steps:  72, steps per second:  80, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 29.795952, mae: 89.559377, mean_q: 179.402562, mean_eps: 0.260340\n",
            " 39166/50000: episode: 720, duration: 2.168s, episode steps: 200, steps per second:  92, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 33.401544, mae: 88.943426, mean_q: 178.384826, mean_eps: 0.257756\n",
            " 39366/50000: episode: 721, duration: 1.733s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 56.539403, mae: 89.047191, mean_q: 178.132130, mean_eps: 0.253956\n",
            " 39445/50000: episode: 722, duration: 0.687s, episode steps:  79, steps per second: 115, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 57.658955, mae: 87.709054, mean_q: 175.249721, mean_eps: 0.251305\n",
            " 39645/50000: episode: 723, duration: 1.665s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 37.374651, mae: 86.258987, mean_q: 172.599911, mean_eps: 0.248655\n",
            " 39845/50000: episode: 724, duration: 1.713s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 106.090745, mae: 85.110935, mean_q: 169.421177, mean_eps: 0.244855\n",
            " 40045/50000: episode: 725, duration: 1.707s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 73.677915, mae: 84.544517, mean_q: 169.243713, mean_eps: 0.241055\n",
            " 40099/50000: episode: 726, duration: 0.457s, episode steps:  54, steps per second: 118, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 36.734944, mae: 84.926115, mean_q: 170.600703, mean_eps: 0.238642\n",
            " 40267/50000: episode: 727, duration: 1.432s, episode steps: 168, steps per second: 117, episode reward: 168.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 74.685036, mae: 84.876441, mean_q: 169.638899, mean_eps: 0.236533\n",
            " 40467/50000: episode: 728, duration: 2.445s, episode steps: 200, steps per second:  82, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 74.629128, mae: 82.931977, mean_q: 166.097385, mean_eps: 0.233037\n",
            " 40667/50000: episode: 729, duration: 1.850s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 69.903561, mae: 82.990921, mean_q: 166.372624, mean_eps: 0.229237\n",
            " 40867/50000: episode: 730, duration: 1.657s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 60.041207, mae: 82.452461, mean_q: 165.105525, mean_eps: 0.225437\n",
            " 41067/50000: episode: 731, duration: 1.695s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 66.620248, mae: 82.721505, mean_q: 165.433893, mean_eps: 0.221637\n",
            " 41267/50000: episode: 732, duration: 1.694s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 68.043019, mae: 80.476253, mean_q: 160.800181, mean_eps: 0.217837\n",
            " 41467/50000: episode: 733, duration: 1.648s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 50.156094, mae: 80.673734, mean_q: 161.235045, mean_eps: 0.214037\n",
            " 41655/50000: episode: 734, duration: 1.598s, episode steps: 188, steps per second: 118, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 39.579417, mae: 79.388316, mean_q: 159.509065, mean_eps: 0.210351\n",
            " 41855/50000: episode: 735, duration: 2.270s, episode steps: 200, steps per second:  88, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 59.176769, mae: 78.954325, mean_q: 157.911937, mean_eps: 0.206665\n",
            " 42055/50000: episode: 736, duration: 2.010s, episode steps: 200, steps per second:  99, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 60.820010, mae: 77.995255, mean_q: 156.206264, mean_eps: 0.202865\n",
            " 42255/50000: episode: 737, duration: 1.716s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 50.920546, mae: 78.482407, mean_q: 157.319671, mean_eps: 0.199065\n",
            " 42455/50000: episode: 738, duration: 1.658s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 58.983059, mae: 77.042051, mean_q: 154.548358, mean_eps: 0.195265\n",
            " 42655/50000: episode: 739, duration: 1.663s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 33.485695, mae: 76.411363, mean_q: 153.577505, mean_eps: 0.191465\n",
            " 42855/50000: episode: 740, duration: 1.648s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 52.034310, mae: 77.187077, mean_q: 154.715431, mean_eps: 0.187665\n",
            " 43055/50000: episode: 741, duration: 1.681s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 41.769705, mae: 76.832108, mean_q: 154.172948, mean_eps: 0.183865\n",
            " 43255/50000: episode: 742, duration: 2.170s, episode steps: 200, steps per second:  92, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 61.430672, mae: 76.643952, mean_q: 153.574865, mean_eps: 0.180065\n",
            " 43455/50000: episode: 743, duration: 2.087s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 77.307756, mae: 77.177584, mean_q: 154.319787, mean_eps: 0.176265\n",
            " 43655/50000: episode: 744, duration: 1.697s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 61.409244, mae: 76.605160, mean_q: 153.438551, mean_eps: 0.172465\n",
            " 43795/50000: episode: 745, duration: 1.200s, episode steps: 140, steps per second: 117, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 62.707117, mae: 76.925373, mean_q: 153.951188, mean_eps: 0.169235\n",
            " 43992/50000: episode: 746, duration: 1.670s, episode steps: 197, steps per second: 118, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 76.690475, mae: 77.376382, mean_q: 154.649520, mean_eps: 0.166033\n",
            " 44192/50000: episode: 747, duration: 1.672s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 65.194782, mae: 77.072728, mean_q: 154.120519, mean_eps: 0.162262\n",
            " 44392/50000: episode: 748, duration: 1.645s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 58.744154, mae: 76.592789, mean_q: 153.355763, mean_eps: 0.158462\n",
            " 44578/50000: episode: 749, duration: 1.662s, episode steps: 186, steps per second: 112, episode reward: 186.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 61.815308, mae: 77.044587, mean_q: 154.675481, mean_eps: 0.154795\n",
            " 44778/50000: episode: 750, duration: 2.377s, episode steps: 200, steps per second:  84, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 77.466319, mae: 77.366976, mean_q: 154.638328, mean_eps: 0.151128\n",
            " 44978/50000: episode: 751, duration: 1.806s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 60.028710, mae: 77.753337, mean_q: 155.673842, mean_eps: 0.147328\n",
            " 45178/50000: episode: 752, duration: 1.690s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 72.346007, mae: 78.152798, mean_q: 156.664298, mean_eps: 0.143528\n",
            " 45378/50000: episode: 753, duration: 1.711s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 88.598469, mae: 78.453301, mean_q: 156.946769, mean_eps: 0.139728\n",
            " 45510/50000: episode: 754, duration: 1.114s, episode steps: 132, steps per second: 118, episode reward: 132.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 105.199243, mae: 78.241654, mean_q: 156.373129, mean_eps: 0.136574\n",
            " 45682/50000: episode: 755, duration: 1.445s, episode steps: 172, steps per second: 119, episode reward: 172.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 91.460100, mae: 79.046244, mean_q: 157.785469, mean_eps: 0.133686\n",
            " 45882/50000: episode: 756, duration: 1.670s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 61.411315, mae: 78.458129, mean_q: 157.025806, mean_eps: 0.130152\n",
            " 46082/50000: episode: 757, duration: 2.051s, episode steps: 200, steps per second:  98, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 59.549661, mae: 78.006221, mean_q: 156.710149, mean_eps: 0.126352\n",
            " 46282/50000: episode: 758, duration: 2.214s, episode steps: 200, steps per second:  90, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 76.803039, mae: 78.346877, mean_q: 157.084187, mean_eps: 0.122552\n",
            " 46482/50000: episode: 759, duration: 1.690s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 82.699242, mae: 77.938186, mean_q: 156.037623, mean_eps: 0.118752\n",
            " 46682/50000: episode: 760, duration: 1.678s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 97.778298, mae: 77.975201, mean_q: 156.343962, mean_eps: 0.114952\n",
            " 46882/50000: episode: 761, duration: 1.672s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 94.856661, mae: 77.791562, mean_q: 155.921298, mean_eps: 0.111152\n",
            " 47082/50000: episode: 762, duration: 1.672s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 70.556708, mae: 77.581410, mean_q: 155.546981, mean_eps: 0.107352\n",
            " 47194/50000: episode: 763, duration: 0.965s, episode steps: 112, steps per second: 116, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 100.395027, mae: 78.018416, mean_q: 155.403578, mean_eps: 0.104388\n",
            " 47362/50000: episode: 764, duration: 1.421s, episode steps: 168, steps per second: 118, episode reward: 168.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 81.530292, mae: 77.331806, mean_q: 154.762631, mean_eps: 0.101728\n",
            " 47562/50000: episode: 765, duration: 2.233s, episode steps: 200, steps per second:  90, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 58.277645, mae: 77.309803, mean_q: 155.218428, mean_eps: 0.098232\n",
            " 47762/50000: episode: 766, duration: 2.043s, episode steps: 200, steps per second:  98, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 62.417075, mae: 77.437532, mean_q: 155.196426, mean_eps: 0.094432\n",
            " 47926/50000: episode: 767, duration: 1.391s, episode steps: 164, steps per second: 118, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 66.228498, mae: 77.650101, mean_q: 155.561261, mean_eps: 0.090974\n",
            " 48116/50000: episode: 768, duration: 1.598s, episode steps: 190, steps per second: 119, episode reward: 190.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 52.941159, mae: 77.446407, mean_q: 155.379095, mean_eps: 0.087611\n",
            " 48316/50000: episode: 769, duration: 1.689s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 80.908475, mae: 77.517500, mean_q: 155.306867, mean_eps: 0.083906\n",
            " 48426/50000: episode: 770, duration: 0.931s, episode steps: 110, steps per second: 118, episode reward: 110.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 74.665771, mae: 77.263860, mean_q: 154.525288, mean_eps: 0.080961\n",
            " 48626/50000: episode: 771, duration: 1.684s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 56.130898, mae: 76.918954, mean_q: 154.393874, mean_eps: 0.078016\n",
            " 48826/50000: episode: 772, duration: 1.749s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 94.291747, mae: 76.690184, mean_q: 152.914079, mean_eps: 0.074216\n",
            " 48896/50000: episode: 773, duration: 0.919s, episode steps:  70, steps per second:  76, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 89.414231, mae: 76.342564, mean_q: 152.344795, mean_eps: 0.071651\n",
            " 48961/50000: episode: 774, duration: 0.803s, episode steps:  65, steps per second:  81, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 44.766547, mae: 75.972170, mean_q: 152.158010, mean_eps: 0.070368\n",
            " 49161/50000: episode: 775, duration: 2.045s, episode steps: 200, steps per second:  98, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 77.489150, mae: 75.539095, mean_q: 150.904890, mean_eps: 0.067851\n",
            " 49273/50000: episode: 776, duration: 0.956s, episode steps: 112, steps per second: 117, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 68.595656, mae: 74.631592, mean_q: 148.975097, mean_eps: 0.064887\n",
            " 49337/50000: episode: 777, duration: 0.552s, episode steps:  64, steps per second: 116, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 65.781029, mae: 74.625267, mean_q: 149.006380, mean_eps: 0.063215\n",
            " 49537/50000: episode: 778, duration: 1.664s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 63.485020, mae: 74.197967, mean_q: 148.183195, mean_eps: 0.060707\n",
            " 49737/50000: episode: 779, duration: 1.656s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 66.156132, mae: 73.550435, mean_q: 147.398057, mean_eps: 0.056907\n",
            " 49849/50000: episode: 780, duration: 0.953s, episode steps: 112, steps per second: 118, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 83.516660, mae: 73.457058, mean_q: 146.518183, mean_eps: 0.053943\n",
            "done, took 470.436 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd751539460>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.05, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.001), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vSk0WMjrf6aE",
        "outputId": "3904d455-c8a3-4b21-f45f-48b3fd523092"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   35/10000: episode: 1, duration: 3.230s, episode steps:  35, steps per second:  11, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 0.579747, mae: 0.652844, mean_q: 0.297383, mean_eps: 0.997863\n",
            "   57/10000: episode: 2, duration: 0.176s, episode steps:  22, steps per second: 125, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.473724, mae: 0.648804, mean_q: 0.430338, mean_eps: 0.995677\n",
            "   75/10000: episode: 3, duration: 0.149s, episode steps:  18, steps per second: 121, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 0.410939, mae: 0.667866, mean_q: 0.559406, mean_eps: 0.993777\n",
            "  108/10000: episode: 4, duration: 0.263s, episode steps:  33, steps per second: 125, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.576 [0.000, 1.000],  loss: 0.362695, mae: 0.677788, mean_q: 0.669186, mean_eps: 0.991355\n",
            "  121/10000: episode: 5, duration: 0.110s, episode steps:  13, steps per second: 118, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 0.309011, mae: 0.702720, mean_q: 0.788509, mean_eps: 0.989170\n",
            "  136/10000: episode: 6, duration: 0.128s, episode steps:  15, steps per second: 118, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 0.278062, mae: 0.726107, mean_q: 0.909123, mean_eps: 0.987840\n",
            "  151/10000: episode: 7, duration: 0.125s, episode steps:  15, steps per second: 120, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 0.255324, mae: 0.774483, mean_q: 1.021801, mean_eps: 0.986415\n",
            "  171/10000: episode: 8, duration: 0.165s, episode steps:  20, steps per second: 121, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.221552, mae: 0.801995, mean_q: 1.146471, mean_eps: 0.984752\n",
            "  186/10000: episode: 9, duration: 0.135s, episode steps:  15, steps per second: 111, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 0.213823, mae: 0.839123, mean_q: 1.227682, mean_eps: 0.983090\n",
            "  199/10000: episode: 10, duration: 0.112s, episode steps:  13, steps per second: 116, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 0.190499, mae: 0.904260, mean_q: 1.429688, mean_eps: 0.981760\n",
            "  213/10000: episode: 11, duration: 0.117s, episode steps:  14, steps per second: 120, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.171200, mae: 0.935669, mean_q: 1.517422, mean_eps: 0.980478\n",
            "  226/10000: episode: 12, duration: 0.110s, episode steps:  13, steps per second: 118, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.154 [0.000, 1.000],  loss: 0.161787, mae: 0.963675, mean_q: 1.558602, mean_eps: 0.979195\n",
            "  240/10000: episode: 13, duration: 0.114s, episode steps:  14, steps per second: 123, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.153171, mae: 1.032120, mean_q: 1.739928, mean_eps: 0.977912\n",
            "  255/10000: episode: 14, duration: 0.145s, episode steps:  15, steps per second: 103, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.134224, mae: 1.045807, mean_q: 1.784216, mean_eps: 0.976535\n",
            "  280/10000: episode: 15, duration: 0.293s, episode steps:  25, steps per second:  85, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 0.137193, mae: 1.164723, mean_q: 2.054940, mean_eps: 0.974635\n",
            "  346/10000: episode: 16, duration: 0.768s, episode steps:  66, steps per second:  86, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 0.115582, mae: 1.298791, mean_q: 2.406580, mean_eps: 0.970313\n",
            "  372/10000: episode: 17, duration: 0.311s, episode steps:  26, steps per second:  83, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.132150, mae: 1.484756, mean_q: 2.809205, mean_eps: 0.965942\n",
            "  429/10000: episode: 18, duration: 0.654s, episode steps:  57, steps per second:  87, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 0.129969, mae: 1.679961, mean_q: 3.266431, mean_eps: 0.962000\n",
            "  455/10000: episode: 19, duration: 0.313s, episode steps:  26, steps per second:  83, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.139124, mae: 1.814201, mean_q: 3.550183, mean_eps: 0.958058\n",
            "  490/10000: episode: 20, duration: 0.429s, episode steps:  35, steps per second:  82, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.178290, mae: 1.997504, mean_q: 3.916113, mean_eps: 0.955160\n",
            "  515/10000: episode: 21, duration: 0.270s, episode steps:  25, steps per second:  92, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 0.204446, mae: 2.104009, mean_q: 4.095908, mean_eps: 0.952310\n",
            "  529/10000: episode: 22, duration: 0.113s, episode steps:  14, steps per second: 124, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.197684, mae: 2.233112, mean_q: 4.392699, mean_eps: 0.950457\n",
            "  561/10000: episode: 23, duration: 0.258s, episode steps:  32, steps per second: 124, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.406 [0.000, 1.000],  loss: 0.268755, mae: 2.332951, mean_q: 4.524184, mean_eps: 0.948273\n",
            "  571/10000: episode: 24, duration: 0.084s, episode steps:  10, steps per second: 119, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.181191, mae: 2.414090, mean_q: 4.733649, mean_eps: 0.946278\n",
            "  595/10000: episode: 25, duration: 0.207s, episode steps:  24, steps per second: 116, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 0.214723, mae: 2.482085, mean_q: 4.896167, mean_eps: 0.944663\n",
            "  619/10000: episode: 26, duration: 0.196s, episode steps:  24, steps per second: 123, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.299779, mae: 2.612940, mean_q: 5.123417, mean_eps: 0.942383\n",
            "  640/10000: episode: 27, duration: 0.182s, episode steps:  21, steps per second: 116, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.318587, mae: 2.707684, mean_q: 5.358217, mean_eps: 0.940245\n",
            "  662/10000: episode: 28, duration: 0.176s, episode steps:  22, steps per second: 125, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 0.394872, mae: 2.867483, mean_q: 5.615005, mean_eps: 0.938202\n",
            "  706/10000: episode: 29, duration: 0.368s, episode steps:  44, steps per second: 120, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 0.320037, mae: 3.008420, mean_q: 5.947140, mean_eps: 0.935068\n",
            "  718/10000: episode: 30, duration: 0.106s, episode steps:  12, steps per second: 114, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 0.512877, mae: 3.130966, mean_q: 6.049165, mean_eps: 0.932407\n",
            "  727/10000: episode: 31, duration: 0.080s, episode steps:   9, steps per second: 112, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 0.756324, mae: 3.241639, mean_q: 6.241346, mean_eps: 0.931410\n",
            "  742/10000: episode: 32, duration: 0.132s, episode steps:  15, steps per second: 114, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.447782, mae: 3.191874, mean_q: 6.221631, mean_eps: 0.930270\n",
            "  780/10000: episode: 33, duration: 0.320s, episode steps:  38, steps per second: 119, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.553 [0.000, 1.000],  loss: 0.426865, mae: 3.350409, mean_q: 6.661756, mean_eps: 0.927752\n",
            "  792/10000: episode: 34, duration: 0.105s, episode steps:  12, steps per second: 115, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.287911, mae: 3.451073, mean_q: 6.909031, mean_eps: 0.925378\n",
            "  802/10000: episode: 35, duration: 0.086s, episode steps:  10, steps per second: 116, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.300 [0.000, 1.000],  loss: 0.458225, mae: 3.560283, mean_q: 7.117755, mean_eps: 0.924333\n",
            "  831/10000: episode: 36, duration: 0.250s, episode steps:  29, steps per second: 116, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 0.519379, mae: 3.686615, mean_q: 7.349503, mean_eps: 0.922480\n",
            "  873/10000: episode: 37, duration: 0.353s, episode steps:  42, steps per second: 119, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.569722, mae: 3.853229, mean_q: 7.630440, mean_eps: 0.919108\n",
            "  890/10000: episode: 38, duration: 0.141s, episode steps:  17, steps per second: 120, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 0.567793, mae: 3.978384, mean_q: 7.925011, mean_eps: 0.916305\n",
            "  913/10000: episode: 39, duration: 0.189s, episode steps:  23, steps per second: 122, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 0.837490, mae: 4.147629, mean_q: 8.196909, mean_eps: 0.914405\n",
            "  940/10000: episode: 40, duration: 0.225s, episode steps:  27, steps per second: 120, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.370 [0.000, 1.000],  loss: 0.584547, mae: 4.208423, mean_q: 8.367337, mean_eps: 0.912030\n",
            "  956/10000: episode: 41, duration: 0.138s, episode steps:  16, steps per second: 116, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 0.678671, mae: 4.314479, mean_q: 8.584747, mean_eps: 0.909988\n",
            "  967/10000: episode: 42, duration: 0.112s, episode steps:  11, steps per second:  98, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 0.305377, mae: 4.353306, mean_q: 8.767113, mean_eps: 0.908705\n",
            "  988/10000: episode: 43, duration: 0.180s, episode steps:  21, steps per second: 117, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.238 [0.000, 1.000],  loss: 0.704527, mae: 4.539155, mean_q: 9.065858, mean_eps: 0.907185\n",
            "  998/10000: episode: 44, duration: 0.099s, episode steps:  10, steps per second: 101, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 0.906765, mae: 4.603889, mean_q: 9.097624, mean_eps: 0.905712\n",
            " 1030/10000: episode: 45, duration: 0.267s, episode steps:  32, steps per second: 120, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.406 [0.000, 1.000],  loss: 0.992944, mae: 4.664682, mean_q: 9.158929, mean_eps: 0.903718\n",
            " 1046/10000: episode: 46, duration: 0.134s, episode steps:  16, steps per second: 120, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 1.093659, mae: 4.798024, mean_q: 9.514410, mean_eps: 0.901438\n",
            " 1066/10000: episode: 47, duration: 0.188s, episode steps:  20, steps per second: 106, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 0.827874, mae: 4.887018, mean_q: 9.756878, mean_eps: 0.899728\n",
            " 1088/10000: episode: 48, duration: 0.188s, episode steps:  22, steps per second: 117, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 1.111801, mae: 5.002279, mean_q: 9.899691, mean_eps: 0.897733\n",
            " 1119/10000: episode: 49, duration: 0.253s, episode steps:  31, steps per second: 122, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.581 [0.000, 1.000],  loss: 1.482368, mae: 5.145653, mean_q: 10.062025, mean_eps: 0.895215\n",
            " 1133/10000: episode: 50, duration: 0.116s, episode steps:  14, steps per second: 121, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 1.207072, mae: 5.222071, mean_q: 10.183996, mean_eps: 0.893077\n",
            " 1147/10000: episode: 51, duration: 0.122s, episode steps:  14, steps per second: 115, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 1.122674, mae: 5.349258, mean_q: 10.472532, mean_eps: 0.891748\n",
            " 1156/10000: episode: 52, duration: 0.086s, episode steps:   9, steps per second: 105, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.305317, mae: 5.362534, mean_q: 10.471527, mean_eps: 0.890655\n",
            " 1177/10000: episode: 53, duration: 0.186s, episode steps:  21, steps per second: 113, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 1.291778, mae: 5.452597, mean_q: 10.785320, mean_eps: 0.889230\n",
            " 1191/10000: episode: 54, duration: 0.121s, episode steps:  14, steps per second: 116, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 1.157694, mae: 5.509812, mean_q: 10.960259, mean_eps: 0.887568\n",
            " 1214/10000: episode: 55, duration: 0.185s, episode steps:  23, steps per second: 124, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.652 [0.000, 1.000],  loss: 1.119613, mae: 5.625552, mean_q: 11.209067, mean_eps: 0.885810\n",
            " 1231/10000: episode: 56, duration: 0.142s, episode steps:  17, steps per second: 120, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 1.052702, mae: 5.657504, mean_q: 11.291649, mean_eps: 0.883910\n",
            " 1246/10000: episode: 57, duration: 0.128s, episode steps:  15, steps per second: 117, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 1.400257, mae: 5.801244, mean_q: 11.433268, mean_eps: 0.882390\n",
            " 1258/10000: episode: 58, duration: 0.100s, episode steps:  12, steps per second: 120, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 1.196539, mae: 5.860441, mean_q: 11.631873, mean_eps: 0.881108\n",
            " 1296/10000: episode: 59, duration: 0.313s, episode steps:  38, steps per second: 121, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 1.463425, mae: 6.019907, mean_q: 11.826488, mean_eps: 0.878733\n",
            " 1312/10000: episode: 60, duration: 0.141s, episode steps:  16, steps per second: 114, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 1.259231, mae: 6.114711, mean_q: 12.130616, mean_eps: 0.876167\n",
            " 1340/10000: episode: 61, duration: 0.222s, episode steps:  28, steps per second: 126, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 1.074843, mae: 6.148894, mean_q: 12.311972, mean_eps: 0.874078\n",
            " 1371/10000: episode: 62, duration: 0.248s, episode steps:  31, steps per second: 125, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.613 [0.000, 1.000],  loss: 2.101235, mae: 6.402961, mean_q: 12.590211, mean_eps: 0.871275\n",
            " 1387/10000: episode: 63, duration: 0.139s, episode steps:  16, steps per second: 115, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 1.821923, mae: 6.531638, mean_q: 12.808960, mean_eps: 0.869043\n",
            " 1444/10000: episode: 64, duration: 0.470s, episode steps:  57, steps per second: 121, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 1.932737, mae: 6.650722, mean_q: 13.090047, mean_eps: 0.865575\n",
            " 1462/10000: episode: 65, duration: 0.155s, episode steps:  18, steps per second: 116, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 1.214342, mae: 6.751952, mean_q: 13.422618, mean_eps: 0.862013\n",
            " 1498/10000: episode: 66, duration: 0.310s, episode steps:  36, steps per second: 116, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 2.030242, mae: 6.971084, mean_q: 13.656383, mean_eps: 0.859448\n",
            " 1548/10000: episode: 67, duration: 0.400s, episode steps:  50, steps per second: 125, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.656669, mae: 7.076225, mean_q: 13.945306, mean_eps: 0.855362\n",
            " 1569/10000: episode: 68, duration: 0.170s, episode steps:  21, steps per second: 123, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 2.272669, mae: 7.304273, mean_q: 14.331762, mean_eps: 0.851990\n",
            " 1605/10000: episode: 69, duration: 0.298s, episode steps:  36, steps per second: 121, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 1.643638, mae: 7.401833, mean_q: 14.515322, mean_eps: 0.849282\n",
            " 1621/10000: episode: 70, duration: 0.133s, episode steps:  16, steps per second: 121, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 2.731703, mae: 7.526723, mean_q: 14.616306, mean_eps: 0.846812\n",
            " 1632/10000: episode: 71, duration: 0.105s, episode steps:  11, steps per second: 104, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 2.661906, mae: 7.580579, mean_q: 14.713695, mean_eps: 0.845530\n",
            " 1645/10000: episode: 72, duration: 0.119s, episode steps:  13, steps per second: 110, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 2.356184, mae: 7.600863, mean_q: 14.751178, mean_eps: 0.844390\n",
            " 1672/10000: episode: 73, duration: 0.234s, episode steps:  27, steps per second: 115, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.370 [0.000, 1.000],  loss: 3.527475, mae: 7.709520, mean_q: 14.824185, mean_eps: 0.842490\n",
            " 1707/10000: episode: 74, duration: 0.395s, episode steps:  35, steps per second:  89, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.371 [0.000, 1.000],  loss: 2.103860, mae: 7.744366, mean_q: 15.257709, mean_eps: 0.839545\n",
            " 1721/10000: episode: 75, duration: 0.169s, episode steps:  14, steps per second:  83, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 2.670002, mae: 7.902443, mean_q: 15.462049, mean_eps: 0.837218\n",
            " 1743/10000: episode: 76, duration: 0.270s, episode steps:  22, steps per second:  81, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 2.716854, mae: 7.938091, mean_q: 15.497928, mean_eps: 0.835508\n",
            " 1764/10000: episode: 77, duration: 0.246s, episode steps:  21, steps per second:  85, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 3.106856, mae: 8.074969, mean_q: 15.668003, mean_eps: 0.833465\n",
            " 1778/10000: episode: 78, duration: 0.163s, episode steps:  14, steps per second:  86, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 2.545131, mae: 8.080075, mean_q: 15.752001, mean_eps: 0.831802\n",
            " 1807/10000: episode: 79, duration: 0.347s, episode steps:  29, steps per second:  84, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 2.243251, mae: 8.140060, mean_q: 15.955535, mean_eps: 0.829760\n",
            " 1827/10000: episode: 80, duration: 0.236s, episode steps:  20, steps per second:  85, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.291563, mae: 8.238731, mean_q: 16.073312, mean_eps: 0.827433\n",
            " 1846/10000: episode: 81, duration: 0.224s, episode steps:  19, steps per second:  85, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 3.485930, mae: 8.357102, mean_q: 16.044047, mean_eps: 0.825580\n",
            " 1865/10000: episode: 82, duration: 0.212s, episode steps:  19, steps per second:  89, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 2.653179, mae: 8.384281, mean_q: 16.317432, mean_eps: 0.823775\n",
            " 1885/10000: episode: 83, duration: 0.246s, episode steps:  20, steps per second:  81, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.482555, mae: 8.485874, mean_q: 16.345068, mean_eps: 0.821923\n",
            " 1901/10000: episode: 84, duration: 0.187s, episode steps:  16, steps per second:  85, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 3.646501, mae: 8.513055, mean_q: 16.462881, mean_eps: 0.820213\n",
            " 1914/10000: episode: 85, duration: 0.176s, episode steps:  13, steps per second:  74, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 4.035043, mae: 8.586084, mean_q: 16.649637, mean_eps: 0.818835\n",
            " 1925/10000: episode: 86, duration: 0.137s, episode steps:  11, steps per second:  80, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 3.256627, mae: 8.611295, mean_q: 16.699672, mean_eps: 0.817695\n",
            " 1955/10000: episode: 87, duration: 0.273s, episode steps:  30, steps per second: 110, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.433 [0.000, 1.000],  loss: 3.992359, mae: 8.728287, mean_q: 16.838715, mean_eps: 0.815747\n",
            " 1969/10000: episode: 88, duration: 0.112s, episode steps:  14, steps per second: 125, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 2.202079, mae: 8.685147, mean_q: 16.781917, mean_eps: 0.813658\n",
            " 1996/10000: episode: 89, duration: 0.234s, episode steps:  27, steps per second: 115, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 2.400974, mae: 8.742532, mean_q: 17.089684, mean_eps: 0.811710\n",
            " 2010/10000: episode: 90, duration: 0.121s, episode steps:  14, steps per second: 116, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 1.228590, mae: 8.726361, mean_q: 17.203917, mean_eps: 0.809763\n",
            " 2045/10000: episode: 91, duration: 0.291s, episode steps:  35, steps per second: 120, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 3.622532, mae: 8.942567, mean_q: 17.356474, mean_eps: 0.807435\n",
            " 2074/10000: episode: 92, duration: 0.234s, episode steps:  29, steps per second: 124, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 4.760162, mae: 9.081690, mean_q: 17.272552, mean_eps: 0.804395\n",
            " 2090/10000: episode: 93, duration: 0.136s, episode steps:  16, steps per second: 117, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 3.490343, mae: 9.051735, mean_q: 17.440264, mean_eps: 0.802258\n",
            " 2108/10000: episode: 94, duration: 0.159s, episode steps:  18, steps per second: 113, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 3.506566, mae: 9.114159, mean_q: 17.716378, mean_eps: 0.800642\n",
            " 2125/10000: episode: 95, duration: 0.135s, episode steps:  17, steps per second: 126, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.088629, mae: 9.128007, mean_q: 17.693036, mean_eps: 0.798980\n",
            " 2139/10000: episode: 96, duration: 0.132s, episode steps:  14, steps per second: 106, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 3.020217, mae: 9.154830, mean_q: 17.781327, mean_eps: 0.797507\n",
            " 2158/10000: episode: 97, duration: 0.158s, episode steps:  19, steps per second: 121, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 3.023988, mae: 9.236262, mean_q: 18.026623, mean_eps: 0.795940\n",
            " 2172/10000: episode: 98, duration: 0.136s, episode steps:  14, steps per second: 103, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.773897, mae: 9.385830, mean_q: 18.070290, mean_eps: 0.794373\n",
            " 2206/10000: episode: 99, duration: 0.282s, episode steps:  34, steps per second: 121, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.011137, mae: 9.323103, mean_q: 18.049469, mean_eps: 0.792092\n",
            " 2225/10000: episode: 100, duration: 0.160s, episode steps:  19, steps per second: 119, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.316 [0.000, 1.000],  loss: 3.000530, mae: 9.423917, mean_q: 18.355199, mean_eps: 0.789575\n",
            " 2238/10000: episode: 101, duration: 0.117s, episode steps:  13, steps per second: 111, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 5.917788, mae: 9.641505, mean_q: 18.392188, mean_eps: 0.788055\n",
            " 2287/10000: episode: 102, duration: 0.416s, episode steps:  49, steps per second: 118, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 4.379326, mae: 9.584202, mean_q: 18.325857, mean_eps: 0.785110\n",
            " 2311/10000: episode: 103, duration: 0.200s, episode steps:  24, steps per second: 120, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 2.551055, mae: 9.540453, mean_q: 18.583521, mean_eps: 0.781643\n",
            " 2328/10000: episode: 104, duration: 0.145s, episode steps:  17, steps per second: 117, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.474491, mae: 9.638657, mean_q: 18.617958, mean_eps: 0.779695\n",
            " 2394/10000: episode: 105, duration: 0.543s, episode steps:  66, steps per second: 122, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 4.586972, mae: 9.788691, mean_q: 18.740307, mean_eps: 0.775753\n",
            " 2424/10000: episode: 106, duration: 0.236s, episode steps:  30, steps per second: 127, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 3.610755, mae: 9.805909, mean_q: 18.992376, mean_eps: 0.771193\n",
            " 2446/10000: episode: 107, duration: 0.179s, episode steps:  22, steps per second: 123, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 5.923820, mae: 10.029625, mean_q: 19.092851, mean_eps: 0.768723\n",
            " 2470/10000: episode: 108, duration: 0.210s, episode steps:  24, steps per second: 114, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 3.762183, mae: 9.923473, mean_q: 19.066682, mean_eps: 0.766538\n",
            " 2489/10000: episode: 109, duration: 0.161s, episode steps:  19, steps per second: 118, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 4.248848, mae: 10.001433, mean_q: 19.243207, mean_eps: 0.764495\n",
            " 2529/10000: episode: 110, duration: 0.327s, episode steps:  40, steps per second: 122, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.932027, mae: 10.035065, mean_q: 19.370893, mean_eps: 0.761692\n",
            " 2546/10000: episode: 111, duration: 0.142s, episode steps:  17, steps per second: 119, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 4.836545, mae: 10.150414, mean_q: 19.600936, mean_eps: 0.758985\n",
            " 2569/10000: episode: 112, duration: 0.192s, episode steps:  23, steps per second: 120, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 5.173987, mae: 10.210901, mean_q: 19.601794, mean_eps: 0.757085\n",
            " 2605/10000: episode: 113, duration: 0.305s, episode steps:  36, steps per second: 118, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 4.572648, mae: 10.233853, mean_q: 19.627661, mean_eps: 0.754282\n",
            " 2626/10000: episode: 114, duration: 0.175s, episode steps:  21, steps per second: 120, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 3.947986, mae: 10.222605, mean_q: 19.804728, mean_eps: 0.751575\n",
            " 2656/10000: episode: 115, duration: 0.252s, episode steps:  30, steps per second: 119, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 5.033537, mae: 10.353273, mean_q: 19.808413, mean_eps: 0.749152\n",
            " 2687/10000: episode: 116, duration: 0.259s, episode steps:  31, steps per second: 120, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 5.162024, mae: 10.384457, mean_q: 19.916235, mean_eps: 0.746255\n",
            " 2705/10000: episode: 117, duration: 0.148s, episode steps:  18, steps per second: 122, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 3.541564, mae: 10.351613, mean_q: 20.034914, mean_eps: 0.743927\n",
            " 2755/10000: episode: 118, duration: 0.418s, episode steps:  50, steps per second: 120, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 3.770740, mae: 10.446784, mean_q: 20.258482, mean_eps: 0.740698\n",
            " 2775/10000: episode: 119, duration: 0.170s, episode steps:  20, steps per second: 117, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.788926, mae: 10.523703, mean_q: 20.479385, mean_eps: 0.737373\n",
            " 2844/10000: episode: 120, duration: 0.551s, episode steps:  69, steps per second: 125, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 5.475961, mae: 10.686236, mean_q: 20.468691, mean_eps: 0.733145\n",
            " 2871/10000: episode: 121, duration: 0.224s, episode steps:  27, steps per second: 120, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 4.897093, mae: 10.712183, mean_q: 20.541169, mean_eps: 0.728585\n",
            " 2923/10000: episode: 122, duration: 0.419s, episode steps:  52, steps per second: 124, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 6.396424, mae: 10.840393, mean_q: 20.576410, mean_eps: 0.724832\n",
            " 2944/10000: episode: 123, duration: 0.171s, episode steps:  21, steps per second: 123, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 6.202615, mae: 10.864638, mean_q: 20.588952, mean_eps: 0.721365\n",
            " 2972/10000: episode: 124, duration: 0.239s, episode steps:  28, steps per second: 117, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.393 [0.000, 1.000],  loss: 4.251445, mae: 10.781354, mean_q: 20.753694, mean_eps: 0.719037\n",
            " 3003/10000: episode: 125, duration: 0.256s, episode steps:  31, steps per second: 121, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 6.351400, mae: 10.945458, mean_q: 20.874637, mean_eps: 0.716235\n",
            " 3023/10000: episode: 126, duration: 0.156s, episode steps:  20, steps per second: 128, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 4.461842, mae: 10.883471, mean_q: 20.794359, mean_eps: 0.713813\n",
            " 3064/10000: episode: 127, duration: 0.323s, episode steps:  41, steps per second: 127, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 4.224487, mae: 10.935461, mean_q: 21.179308, mean_eps: 0.710915\n",
            " 3114/10000: episode: 128, duration: 0.427s, episode steps:  50, steps per second: 117, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 5.417217, mae: 11.049331, mean_q: 21.179687, mean_eps: 0.706592\n",
            " 3200/10000: episode: 129, duration: 0.965s, episode steps:  86, steps per second:  89, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 5.390361, mae: 11.139987, mean_q: 21.435993, mean_eps: 0.700133\n",
            " 3213/10000: episode: 130, duration: 0.152s, episode steps:  13, steps per second:  86, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 6.390761, mae: 11.281731, mean_q: 21.599722, mean_eps: 0.695430\n",
            " 3333/10000: episode: 131, duration: 1.342s, episode steps: 120, steps per second:  89, episode reward: 120.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 5.554531, mae: 11.294196, mean_q: 21.668783, mean_eps: 0.689113\n",
            " 3368/10000: episode: 132, duration: 0.417s, episode steps:  35, steps per second:  84, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 5.577540, mae: 11.404368, mean_q: 22.003301, mean_eps: 0.681750\n",
            " 3416/10000: episode: 133, duration: 0.460s, episode steps:  48, steps per second: 104, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 5.390959, mae: 11.483431, mean_q: 22.195907, mean_eps: 0.677808\n",
            " 3526/10000: episode: 134, duration: 0.867s, episode steps: 110, steps per second: 127, episode reward: 110.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 5.511853, mae: 11.608030, mean_q: 22.395440, mean_eps: 0.670303\n",
            " 3550/10000: episode: 135, duration: 0.188s, episode steps:  24, steps per second: 127, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 4.891665, mae: 11.686543, mean_q: 22.627086, mean_eps: 0.663937\n",
            " 3573/10000: episode: 136, duration: 0.191s, episode steps:  23, steps per second: 121, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 7.714491, mae: 11.850988, mean_q: 22.718982, mean_eps: 0.661705\n",
            " 3658/10000: episode: 137, duration: 0.684s, episode steps:  85, steps per second: 124, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 4.656893, mae: 11.786244, mean_q: 22.861860, mean_eps: 0.656575\n",
            " 3699/10000: episode: 138, duration: 0.336s, episode steps:  41, steps per second: 122, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 5.676458, mae: 11.963655, mean_q: 23.149465, mean_eps: 0.650590\n",
            " 3750/10000: episode: 139, duration: 0.421s, episode steps:  51, steps per second: 121, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 7.133886, mae: 12.111409, mean_q: 23.221026, mean_eps: 0.646220\n",
            " 3825/10000: episode: 140, duration: 0.605s, episode steps:  75, steps per second: 124, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 6.007664, mae: 12.129726, mean_q: 23.397269, mean_eps: 0.640235\n",
            " 3841/10000: episode: 141, duration: 0.135s, episode steps:  16, steps per second: 119, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 7.895608, mae: 12.264260, mean_q: 23.504869, mean_eps: 0.635912\n",
            " 3911/10000: episode: 142, duration: 0.564s, episode steps:  70, steps per second: 124, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 4.869544, mae: 12.231524, mean_q: 23.775748, mean_eps: 0.631827\n",
            " 3942/10000: episode: 143, duration: 0.246s, episode steps:  31, steps per second: 126, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 3.781267, mae: 12.305112, mean_q: 24.032055, mean_eps: 0.627030\n",
            " 3969/10000: episode: 144, duration: 0.236s, episode steps:  27, steps per second: 114, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 6.520444, mae: 12.431201, mean_q: 24.118952, mean_eps: 0.624275\n",
            " 4022/10000: episode: 145, duration: 0.441s, episode steps:  53, steps per second: 120, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 5.214973, mae: 12.479466, mean_q: 24.192641, mean_eps: 0.620475\n",
            " 4069/10000: episode: 146, duration: 0.381s, episode steps:  47, steps per second: 123, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 7.148970, mae: 12.615351, mean_q: 24.161230, mean_eps: 0.615725\n",
            " 4087/10000: episode: 147, duration: 0.153s, episode steps:  18, steps per second: 118, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 4.410990, mae: 12.556193, mean_q: 24.483905, mean_eps: 0.612637\n",
            " 4100/10000: episode: 148, duration: 0.123s, episode steps:  13, steps per second: 106, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 6.323930, mae: 12.686133, mean_q: 24.671980, mean_eps: 0.611165\n",
            " 4132/10000: episode: 149, duration: 0.278s, episode steps:  32, steps per second: 115, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 6.240196, mae: 12.715100, mean_q: 24.704826, mean_eps: 0.609028\n",
            " 4160/10000: episode: 150, duration: 0.243s, episode steps:  28, steps per second: 115, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 7.780443, mae: 12.828275, mean_q: 24.678964, mean_eps: 0.606178\n",
            " 4175/10000: episode: 151, duration: 0.129s, episode steps:  15, steps per second: 116, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 6.933332, mae: 12.750006, mean_q: 24.523177, mean_eps: 0.604135\n",
            " 4227/10000: episode: 152, duration: 0.452s, episode steps:  52, steps per second: 115, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 6.003363, mae: 12.802400, mean_q: 24.805461, mean_eps: 0.600952\n",
            " 4244/10000: episode: 153, duration: 0.146s, episode steps:  17, steps per second: 116, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 7.216127, mae: 12.929721, mean_q: 25.008707, mean_eps: 0.597675\n",
            " 4324/10000: episode: 154, duration: 0.645s, episode steps:  80, steps per second: 124, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 7.401160, mae: 12.972217, mean_q: 25.074136, mean_eps: 0.593067\n",
            " 4386/10000: episode: 155, duration: 0.519s, episode steps:  62, steps per second: 119, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 6.277543, mae: 13.002087, mean_q: 25.126619, mean_eps: 0.586323\n",
            " 4415/10000: episode: 156, duration: 0.246s, episode steps:  29, steps per second: 118, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 8.113856, mae: 13.102014, mean_q: 25.353111, mean_eps: 0.582000\n",
            " 4435/10000: episode: 157, duration: 0.168s, episode steps:  20, steps per second: 119, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 6.031267, mae: 13.147116, mean_q: 25.383016, mean_eps: 0.579673\n",
            " 4475/10000: episode: 158, duration: 0.347s, episode steps:  40, steps per second: 115, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 5.100096, mae: 13.127417, mean_q: 25.577287, mean_eps: 0.576823\n",
            " 4492/10000: episode: 159, duration: 0.151s, episode steps:  17, steps per second: 113, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 7.014958, mae: 13.256753, mean_q: 25.834643, mean_eps: 0.574115\n",
            " 4548/10000: episode: 160, duration: 0.455s, episode steps:  56, steps per second: 123, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 5.834806, mae: 13.299409, mean_q: 25.871741, mean_eps: 0.570648\n",
            " 4571/10000: episode: 161, duration: 0.199s, episode steps:  23, steps per second: 116, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 7.259993, mae: 13.415728, mean_q: 25.991589, mean_eps: 0.566895\n",
            " 4673/10000: episode: 162, duration: 1.088s, episode steps: 102, steps per second:  94, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.539 [0.000, 1.000],  loss: 7.832662, mae: 13.477105, mean_q: 25.969008, mean_eps: 0.560957\n",
            " 4699/10000: episode: 163, duration: 0.312s, episode steps:  26, steps per second:  83, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.460478, mae: 13.431721, mean_q: 26.190634, mean_eps: 0.554878\n",
            " 4742/10000: episode: 164, duration: 0.488s, episode steps:  43, steps per second:  88, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 8.007300, mae: 13.610327, mean_q: 26.299044, mean_eps: 0.551600\n",
            " 4762/10000: episode: 165, duration: 0.237s, episode steps:  20, steps per second:  84, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 6.005984, mae: 13.566963, mean_q: 26.316370, mean_eps: 0.548608\n",
            " 4810/10000: episode: 166, duration: 0.579s, episode steps:  48, steps per second:  83, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 7.437545, mae: 13.662279, mean_q: 26.505746, mean_eps: 0.545377\n",
            " 4878/10000: episode: 167, duration: 0.696s, episode steps:  68, steps per second:  98, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.221666, mae: 13.737655, mean_q: 26.605777, mean_eps: 0.539868\n",
            " 4907/10000: episode: 168, duration: 0.226s, episode steps:  29, steps per second: 128, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 7.700091, mae: 13.824383, mean_q: 26.853958, mean_eps: 0.535260\n",
            " 4989/10000: episode: 169, duration: 0.672s, episode steps:  82, steps per second: 122, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 7.016633, mae: 13.880573, mean_q: 26.977287, mean_eps: 0.529988\n",
            " 5046/10000: episode: 170, duration: 0.459s, episode steps:  57, steps per second: 124, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 7.889381, mae: 13.990727, mean_q: 27.071653, mean_eps: 0.523385\n",
            " 5091/10000: episode: 171, duration: 0.360s, episode steps:  45, steps per second: 125, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 6.730769, mae: 14.037459, mean_q: 27.263226, mean_eps: 0.518540\n",
            " 5130/10000: episode: 172, duration: 0.312s, episode steps:  39, steps per second: 125, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 5.326951, mae: 14.024577, mean_q: 27.487379, mean_eps: 0.514550\n",
            " 5162/10000: episode: 173, duration: 0.255s, episode steps:  32, steps per second: 125, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 6.538200, mae: 14.125520, mean_q: 27.552687, mean_eps: 0.511177\n",
            " 5189/10000: episode: 174, duration: 0.219s, episode steps:  27, steps per second: 123, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.593 [0.000, 1.000],  loss: 6.330791, mae: 14.177020, mean_q: 27.577134, mean_eps: 0.508375\n",
            " 5230/10000: episode: 175, duration: 0.328s, episode steps:  41, steps per second: 125, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 7.664031, mae: 14.280636, mean_q: 27.740963, mean_eps: 0.505145\n",
            " 5257/10000: episode: 176, duration: 0.227s, episode steps:  27, steps per second: 119, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 6.992065, mae: 14.287608, mean_q: 27.753916, mean_eps: 0.501915\n",
            " 5334/10000: episode: 177, duration: 0.634s, episode steps:  77, steps per second: 122, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 8.658565, mae: 14.421054, mean_q: 27.882447, mean_eps: 0.496975\n",
            " 5405/10000: episode: 178, duration: 0.568s, episode steps:  71, steps per second: 125, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 9.250971, mae: 14.490932, mean_q: 27.944441, mean_eps: 0.489945\n",
            " 5489/10000: episode: 179, duration: 0.670s, episode steps:  84, steps per second: 125, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 7.350299, mae: 14.487310, mean_q: 28.166943, mean_eps: 0.482582\n",
            " 5530/10000: episode: 180, duration: 0.332s, episode steps:  41, steps per second: 124, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 8.717533, mae: 14.645512, mean_q: 28.355200, mean_eps: 0.476645\n",
            " 5572/10000: episode: 181, duration: 0.355s, episode steps:  42, steps per second: 118, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 9.059829, mae: 14.686509, mean_q: 28.451553, mean_eps: 0.472703\n",
            " 5595/10000: episode: 182, duration: 0.183s, episode steps:  23, steps per second: 126, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 8.442161, mae: 14.730995, mean_q: 28.482667, mean_eps: 0.469615\n",
            " 5635/10000: episode: 183, duration: 0.330s, episode steps:  40, steps per second: 121, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 7.075690, mae: 14.672486, mean_q: 28.604599, mean_eps: 0.466623\n",
            " 5723/10000: episode: 184, duration: 0.724s, episode steps:  88, steps per second: 121, episode reward: 88.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 10.379314, mae: 14.868536, mean_q: 28.612306, mean_eps: 0.460543\n",
            " 5770/10000: episode: 185, duration: 0.374s, episode steps:  47, steps per second: 126, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 6.924852, mae: 14.847373, mean_q: 28.994358, mean_eps: 0.454130\n",
            " 5820/10000: episode: 186, duration: 0.413s, episode steps:  50, steps per second: 121, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 10.426353, mae: 15.015902, mean_q: 28.976529, mean_eps: 0.449523\n",
            " 5865/10000: episode: 187, duration: 0.372s, episode steps:  45, steps per second: 121, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 7.503462, mae: 14.992253, mean_q: 29.129996, mean_eps: 0.445010\n",
            " 5960/10000: episode: 188, duration: 0.783s, episode steps:  95, steps per second: 121, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 8.479201, mae: 15.087902, mean_q: 29.324807, mean_eps: 0.438360\n",
            " 6041/10000: episode: 189, duration: 0.653s, episode steps:  81, steps per second: 124, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 8.140331, mae: 15.153430, mean_q: 29.468123, mean_eps: 0.430000\n",
            " 6124/10000: episode: 190, duration: 0.848s, episode steps:  83, steps per second:  98, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.446 [0.000, 1.000],  loss: 9.789893, mae: 15.317397, mean_q: 29.632195, mean_eps: 0.422210\n",
            " 6192/10000: episode: 191, duration: 0.750s, episode steps:  68, steps per second:  91, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 10.352947, mae: 15.381555, mean_q: 29.659870, mean_eps: 0.415038\n",
            " 6250/10000: episode: 192, duration: 0.691s, episode steps:  58, steps per second:  84, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 8.600654, mae: 15.382798, mean_q: 29.840298, mean_eps: 0.409053\n",
            " 6294/10000: episode: 193, duration: 0.530s, episode steps:  44, steps per second:  83, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 8.420599, mae: 15.478786, mean_q: 30.185097, mean_eps: 0.404208\n",
            " 6368/10000: episode: 194, duration: 0.761s, episode steps:  74, steps per second:  97, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.446 [0.000, 1.000],  loss: 8.601303, mae: 15.507249, mean_q: 30.115987, mean_eps: 0.398603\n",
            " 6421/10000: episode: 195, duration: 0.428s, episode steps:  53, steps per second: 124, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 7.314512, mae: 15.541706, mean_q: 30.460546, mean_eps: 0.392570\n",
            " 6467/10000: episode: 196, duration: 0.385s, episode steps:  46, steps per second: 119, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 9.432632, mae: 15.684092, mean_q: 30.509155, mean_eps: 0.387868\n",
            " 6513/10000: episode: 197, duration: 0.370s, episode steps:  46, steps per second: 124, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 6.545314, mae: 15.667420, mean_q: 30.691199, mean_eps: 0.383497\n",
            " 6547/10000: episode: 198, duration: 0.288s, episode steps:  34, steps per second: 118, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.441 [0.000, 1.000],  loss: 6.837723, mae: 15.760560, mean_q: 30.928703, mean_eps: 0.379698\n",
            " 6608/10000: episode: 199, duration: 0.506s, episode steps:  61, steps per second: 121, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 10.524808, mae: 15.932299, mean_q: 30.927012, mean_eps: 0.375185\n",
            " 6686/10000: episode: 200, duration: 0.654s, episode steps:  78, steps per second: 119, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 7.568976, mae: 15.892270, mean_q: 31.096887, mean_eps: 0.368583\n",
            " 6746/10000: episode: 201, duration: 0.470s, episode steps:  60, steps per second: 128, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 9.577714, mae: 16.073355, mean_q: 31.235609, mean_eps: 0.362028\n",
            " 6825/10000: episode: 202, duration: 0.646s, episode steps:  79, steps per second: 122, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 9.652428, mae: 16.114245, mean_q: 31.365822, mean_eps: 0.355425\n",
            " 6902/10000: episode: 203, duration: 0.624s, episode steps:  77, steps per second: 123, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 8.750075, mae: 16.188816, mean_q: 31.550931, mean_eps: 0.348015\n",
            " 6943/10000: episode: 204, duration: 0.339s, episode steps:  41, steps per second: 121, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 7.643769, mae: 16.331616, mean_q: 32.053925, mean_eps: 0.342410\n",
            " 7010/10000: episode: 205, duration: 0.528s, episode steps:  67, steps per second: 127, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.433 [0.000, 1.000],  loss: 10.878452, mae: 16.404048, mean_q: 31.826491, mean_eps: 0.337280\n",
            " 7082/10000: episode: 206, duration: 0.687s, episode steps:  72, steps per second: 105, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 11.562387, mae: 16.443580, mean_q: 31.797137, mean_eps: 0.330678\n",
            " 7180/10000: episode: 207, duration: 1.157s, episode steps:  98, steps per second:  85, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 9.299006, mae: 16.439574, mean_q: 32.054327, mean_eps: 0.322603\n",
            " 7274/10000: episode: 208, duration: 1.003s, episode steps:  94, steps per second:  94, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 8.979167, mae: 16.530549, mean_q: 32.224711, mean_eps: 0.313482\n",
            " 7340/10000: episode: 209, duration: 1.173s, episode steps:  66, steps per second:  56, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 11.683634, mae: 16.640128, mean_q: 32.176259, mean_eps: 0.305883\n",
            " 7422/10000: episode: 210, duration: 0.771s, episode steps:  82, steps per second: 106, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.451 [0.000, 1.000],  loss: 10.388168, mae: 16.656247, mean_q: 32.333786, mean_eps: 0.298853\n",
            " 7470/10000: episode: 211, duration: 0.581s, episode steps:  48, steps per second:  83, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.542150, mae: 16.715118, mean_q: 32.474938, mean_eps: 0.292678\n",
            " 7516/10000: episode: 212, duration: 0.535s, episode steps:  46, steps per second:  86, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 9.701308, mae: 16.682977, mean_q: 32.470513, mean_eps: 0.288213\n",
            " 7603/10000: episode: 213, duration: 1.021s, episode steps:  87, steps per second:  85, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 7.559338, mae: 16.682389, mean_q: 32.633954, mean_eps: 0.281895\n",
            " 7692/10000: episode: 214, duration: 1.578s, episode steps:  89, steps per second:  56, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.461 [0.000, 1.000],  loss: 6.873958, mae: 16.845532, mean_q: 33.067758, mean_eps: 0.273535\n",
            " 7752/10000: episode: 215, duration: 0.613s, episode steps:  60, steps per second:  98, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 9.377153, mae: 17.014222, mean_q: 33.230253, mean_eps: 0.266458\n",
            " 7778/10000: episode: 216, duration: 0.230s, episode steps:  26, steps per second: 113, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 11.678457, mae: 17.117955, mean_q: 33.172920, mean_eps: 0.262373\n",
            " 7852/10000: episode: 217, duration: 0.580s, episode steps:  74, steps per second: 128, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.446 [0.000, 1.000],  loss: 9.883767, mae: 17.053769, mean_q: 33.226567, mean_eps: 0.257623\n",
            " 7887/10000: episode: 218, duration: 0.289s, episode steps:  35, steps per second: 121, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 9.208827, mae: 17.131605, mean_q: 33.364976, mean_eps: 0.252445\n",
            " 7954/10000: episode: 219, duration: 0.791s, episode steps:  67, steps per second:  85, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.433 [0.000, 1.000],  loss: 10.484989, mae: 17.180730, mean_q: 33.400050, mean_eps: 0.247600\n",
            " 7997/10000: episode: 220, duration: 0.703s, episode steps:  43, steps per second:  61, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.442 [0.000, 1.000],  loss: 10.124654, mae: 17.226941, mean_q: 33.456649, mean_eps: 0.242375\n",
            " 8075/10000: episode: 221, duration: 0.807s, episode steps:  78, steps per second:  97, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: 9.323728, mae: 17.187755, mean_q: 33.587382, mean_eps: 0.236628\n",
            " 8143/10000: episode: 222, duration: 0.564s, episode steps:  68, steps per second: 121, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.441 [0.000, 1.000],  loss: 9.049625, mae: 17.283954, mean_q: 33.767890, mean_eps: 0.229693\n",
            " 8182/10000: episode: 223, duration: 0.319s, episode steps:  39, steps per second: 122, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 7.481536, mae: 17.264322, mean_q: 33.919744, mean_eps: 0.224610\n",
            " 8236/10000: episode: 224, duration: 0.443s, episode steps:  54, steps per second: 122, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.426 [0.000, 1.000],  loss: 11.514734, mae: 17.452758, mean_q: 33.928088, mean_eps: 0.220193\n",
            " 8316/10000: episode: 225, duration: 0.651s, episode steps:  80, steps per second: 123, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 9.369500, mae: 17.438847, mean_q: 33.994904, mean_eps: 0.213828\n",
            " 8427/10000: episode: 226, duration: 0.865s, episode steps: 111, steps per second: 128, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 10.497689, mae: 17.445134, mean_q: 33.990004, mean_eps: 0.204755\n",
            " 8520/10000: episode: 227, duration: 0.854s, episode steps:  93, steps per second: 109, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 11.340312, mae: 17.507167, mean_q: 34.035551, mean_eps: 0.195065\n",
            " 8606/10000: episode: 228, duration: 0.780s, episode steps:  86, steps per second: 110, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.442 [0.000, 1.000],  loss: 7.236143, mae: 17.500011, mean_q: 34.351399, mean_eps: 0.186563\n",
            " 8648/10000: episode: 229, duration: 0.422s, episode steps:  42, steps per second: 100, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 10.292712, mae: 17.650405, mean_q: 34.399951, mean_eps: 0.180483\n",
            " 8704/10000: episode: 230, duration: 0.831s, episode steps:  56, steps per second:  67, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 9.178681, mae: 17.750320, mean_q: 34.681737, mean_eps: 0.175828\n",
            " 8775/10000: episode: 231, duration: 1.265s, episode steps:  71, steps per second:  56, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.437 [0.000, 1.000],  loss: 9.015797, mae: 17.763302, mean_q: 34.705083, mean_eps: 0.169795\n",
            " 8845/10000: episode: 232, duration: 1.484s, episode steps:  70, steps per second:  47, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 8.729023, mae: 17.791627, mean_q: 34.799939, mean_eps: 0.163098\n",
            " 8913/10000: episode: 233, duration: 0.575s, episode steps:  68, steps per second: 118, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.441 [0.000, 1.000],  loss: 11.263508, mae: 17.869263, mean_q: 34.769794, mean_eps: 0.156543\n",
            " 8988/10000: episode: 234, duration: 0.604s, episode steps:  75, steps per second: 124, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 10.606223, mae: 17.868165, mean_q: 34.750805, mean_eps: 0.149750\n",
            " 9062/10000: episode: 235, duration: 0.626s, episode steps:  74, steps per second: 118, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.446 [0.000, 1.000],  loss: 10.251700, mae: 17.866382, mean_q: 34.700815, mean_eps: 0.142673\n",
            " 9154/10000: episode: 236, duration: 0.750s, episode steps:  92, steps per second: 123, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 10.207149, mae: 17.880184, mean_q: 34.812988, mean_eps: 0.134788\n",
            " 9277/10000: episode: 237, duration: 0.979s, episode steps: 123, steps per second: 126, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 9.142922, mae: 17.866453, mean_q: 34.894469, mean_eps: 0.124575\n",
            " 9377/10000: episode: 238, duration: 0.797s, episode steps: 100, steps per second: 126, episode reward: 100.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 9.674720, mae: 17.978608, mean_q: 35.058118, mean_eps: 0.113983\n",
            " 9407/10000: episode: 239, duration: 0.240s, episode steps:  30, steps per second: 125, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 9.669563, mae: 17.913068, mean_q: 34.848652, mean_eps: 0.107808\n",
            " 9470/10000: episode: 240, duration: 0.517s, episode steps:  63, steps per second: 122, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 10.142983, mae: 18.041569, mean_q: 35.069935, mean_eps: 0.103390\n",
            " 9543/10000: episode: 241, duration: 0.602s, episode steps:  73, steps per second: 121, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 10.656931, mae: 18.018667, mean_q: 34.954271, mean_eps: 0.096930\n",
            " 9615/10000: episode: 242, duration: 0.594s, episode steps:  72, steps per second: 121, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.431 [0.000, 1.000],  loss: 11.438944, mae: 18.114396, mean_q: 35.166123, mean_eps: 0.090043\n",
            " 9730/10000: episode: 243, duration: 0.902s, episode steps: 115, steps per second: 127, episode reward: 115.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 9.795044, mae: 17.971520, mean_q: 35.020546, mean_eps: 0.081160\n",
            " 9827/10000: episode: 244, duration: 0.764s, episode steps:  97, steps per second: 127, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 10.631158, mae: 17.998021, mean_q: 34.997796, mean_eps: 0.071090\n",
            " 9891/10000: episode: 245, duration: 0.520s, episode steps:  64, steps per second: 123, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 10.892325, mae: 18.004788, mean_q: 34.913655, mean_eps: 0.063443\n",
            " 9966/10000: episode: 246, duration: 0.621s, episode steps:  75, steps per second: 121, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.427 [0.000, 1.000],  loss: 9.782308, mae: 17.930503, mean_q: 34.986495, mean_eps: 0.056840\n",
            "done, took 95.999 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 94.000, steps: 94\n",
            "Episode 2: reward: 82.000, steps: 82\n",
            "Episode 3: reward: 90.000, steps: 90\n",
            "Episode 4: reward: 80.000, steps: 80\n",
            "Episode 5: reward: 85.000, steps: 85\n",
            "Episode 6: reward: 88.000, steps: 88\n",
            "Episode 7: reward: 83.000, steps: 83\n",
            "Episode 8: reward: 96.000, steps: 96\n",
            "Episode 9: reward: 93.000, steps: 93\n",
            "Episode 10: reward: 79.000, steps: 79\n",
            "Episode 11: reward: 92.000, steps: 92\n",
            "Episode 12: reward: 79.000, steps: 79\n",
            "Episode 13: reward: 86.000, steps: 86\n",
            "Episode 14: reward: 78.000, steps: 78\n",
            "Episode 15: reward: 73.000, steps: 73\n",
            "Episode 16: reward: 83.000, steps: 83\n",
            "Episode 17: reward: 88.000, steps: 88\n",
            "Episode 18: reward: 96.000, steps: 96\n",
            "Episode 19: reward: 86.000, steps: 86\n",
            "Episode 20: reward: 94.000, steps: 94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd751bf9ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Q-Network\n",
        "# model = Sequential()\n",
        "# model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "# model.add(Flatten())\n",
        "# # add extra layers here\n",
        "# model.add(Dense(16, activation='relu'))\n",
        "# model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "# print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qr9G2ChZLGt",
        "outputId": "1c226c61-bd2a-4dd0-e6c9-0fe9ffe049b7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 1.0\n",
        "\n",
        "# value_min = 0.05\n",
        "\n",
        "#value_test = 0.05\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "# target_model_update=1e-2\n",
        "\n",
        "nb_steps=50000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=5"
      ],
      "metadata": {
        "id": "Wrux_DNyymd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.05, \n",
        "                               value_test=0.05,\n",
        "                               nb_steps=50000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=5, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RxAOYMfyydc_",
        "outputId": "9b8a65de-0038-4835-d7c2-a9fe5dc407ef"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    46/50000: episode: 1, duration: 4.608s, episode steps:  46, steps per second:  10, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 27.383996, mae: 72.990434, mean_q: 146.653826, mean_eps: 0.999468\n",
            "    82/50000: episode: 2, duration: 0.335s, episode steps:  36, steps per second: 107, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 74.980317, mae: 73.636779, mean_q: 146.523461, mean_eps: 0.998794\n",
            "    97/50000: episode: 3, duration: 0.138s, episode steps:  15, steps per second: 109, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 67.980470, mae: 73.921759, mean_q: 148.205053, mean_eps: 0.998309\n",
            "   112/50000: episode: 4, duration: 0.138s, episode steps:  15, steps per second: 109, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 35.495042, mae: 72.311088, mean_q: 145.398633, mean_eps: 0.998024\n",
            "   122/50000: episode: 5, duration: 0.094s, episode steps:  10, steps per second: 106, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 66.996949, mae: 72.514736, mean_q: 144.178035, mean_eps: 0.997786\n",
            "   130/50000: episode: 6, duration: 0.079s, episode steps:   8, steps per second: 101, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.875 [0.000, 1.000],  loss: 62.932275, mae: 74.394016, mean_q: 148.129286, mean_eps: 0.997615\n",
            "   147/50000: episode: 7, duration: 0.158s, episode steps:  17, steps per second: 107, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.294 [0.000, 1.000],  loss: 45.249078, mae: 72.748150, mean_q: 145.015069, mean_eps: 0.997378\n",
            "   163/50000: episode: 8, duration: 0.152s, episode steps:  16, steps per second: 106, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 29.811561, mae: 72.290370, mean_q: 145.161081, mean_eps: 0.997065\n",
            "   179/50000: episode: 9, duration: 0.184s, episode steps:  16, steps per second:  87, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 56.823297, mae: 72.191255, mean_q: 145.257858, mean_eps: 0.996760\n",
            "   192/50000: episode: 10, duration: 0.119s, episode steps:  13, steps per second: 109, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 14.711496, mae: 71.891514, mean_q: 144.288409, mean_eps: 0.996485\n",
            "   233/50000: episode: 11, duration: 0.370s, episode steps:  41, steps per second: 111, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.415 [0.000, 1.000],  loss: 64.799232, mae: 72.830943, mean_q: 145.089454, mean_eps: 0.995972\n",
            "   253/50000: episode: 12, duration: 0.197s, episode steps:  20, steps per second: 101, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 54.743507, mae: 72.562119, mean_q: 144.811020, mean_eps: 0.995392\n",
            "   273/50000: episode: 13, duration: 0.296s, episode steps:  20, steps per second:  68, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 84.895257, mae: 72.592436, mean_q: 144.719578, mean_eps: 0.995012\n",
            "   301/50000: episode: 14, duration: 0.381s, episode steps:  28, steps per second:  73, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 35.698843, mae: 72.862405, mean_q: 144.972418, mean_eps: 0.994556\n",
            "   326/50000: episode: 15, duration: 0.326s, episode steps:  25, steps per second:  77, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 168.895275, mae: 73.735307, mean_q: 145.218027, mean_eps: 0.994053\n",
            "   342/50000: episode: 16, duration: 0.222s, episode steps:  16, steps per second:  72, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 52.910449, mae: 72.260388, mean_q: 145.246141, mean_eps: 0.993664\n",
            "   368/50000: episode: 17, duration: 0.346s, episode steps:  26, steps per second:  75, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 88.336688, mae: 72.797393, mean_q: 144.176324, mean_eps: 0.993264\n",
            "   378/50000: episode: 18, duration: 0.131s, episode steps:  10, steps per second:  76, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 77.852630, mae: 73.432291, mean_q: 146.369423, mean_eps: 0.992922\n",
            "   408/50000: episode: 19, duration: 0.369s, episode steps:  30, steps per second:  81, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 88.112941, mae: 71.976247, mean_q: 143.686369, mean_eps: 0.992542\n",
            "   420/50000: episode: 20, duration: 0.166s, episode steps:  12, steps per second:  72, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 80.894175, mae: 72.759116, mean_q: 143.981325, mean_eps: 0.992144\n",
            "   451/50000: episode: 21, duration: 0.401s, episode steps:  31, steps per second:  77, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 70.997064, mae: 71.259374, mean_q: 141.871564, mean_eps: 0.991735\n",
            "   463/50000: episode: 22, duration: 0.171s, episode steps:  12, steps per second:  70, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 140.012772, mae: 72.460363, mean_q: 142.230548, mean_eps: 0.991327\n",
            "   498/50000: episode: 23, duration: 0.366s, episode steps:  35, steps per second:  96, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 67.733247, mae: 72.149789, mean_q: 143.232486, mean_eps: 0.990880\n",
            "   540/50000: episode: 24, duration: 0.383s, episode steps:  42, steps per second: 110, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 44.718229, mae: 71.766737, mean_q: 142.515915, mean_eps: 0.990149\n",
            "   552/50000: episode: 25, duration: 0.114s, episode steps:  12, steps per second: 106, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 25.061369, mae: 71.056669, mean_q: 142.978223, mean_eps: 0.989635\n",
            "   577/50000: episode: 26, duration: 0.219s, episode steps:  25, steps per second: 114, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 44.737774, mae: 71.410341, mean_q: 141.607763, mean_eps: 0.989284\n",
            "   592/50000: episode: 27, duration: 0.136s, episode steps:  15, steps per second: 111, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 30.515909, mae: 71.122298, mean_q: 142.636859, mean_eps: 0.988904\n",
            "   618/50000: episode: 28, duration: 0.236s, episode steps:  26, steps per second: 110, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 41.703083, mae: 70.427835, mean_q: 141.308171, mean_eps: 0.988514\n",
            "   637/50000: episode: 29, duration: 0.169s, episode steps:  19, steps per second: 112, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 7.898118, mae: 70.515243, mean_q: 142.513171, mean_eps: 0.988087\n",
            "   658/50000: episode: 30, duration: 0.185s, episode steps:  21, steps per second: 114, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 42.237313, mae: 70.092294, mean_q: 141.539441, mean_eps: 0.987707\n",
            "   670/50000: episode: 31, duration: 0.108s, episode steps:  12, steps per second: 111, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 37.361123, mae: 70.403552, mean_q: 140.449362, mean_eps: 0.987394\n",
            "   689/50000: episode: 32, duration: 0.173s, episode steps:  19, steps per second: 110, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.684 [0.000, 1.000],  loss: 165.672894, mae: 72.792119, mean_q: 141.731429, mean_eps: 0.987099\n",
            "   710/50000: episode: 33, duration: 0.176s, episode steps:  21, steps per second: 119, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 59.948489, mae: 71.403936, mean_q: 142.494202, mean_eps: 0.986719\n",
            "   736/50000: episode: 34, duration: 0.257s, episode steps:  26, steps per second: 101, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 45.985945, mae: 70.720383, mean_q: 141.306617, mean_eps: 0.986273\n",
            "   764/50000: episode: 35, duration: 0.250s, episode steps:  28, steps per second: 112, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 54.558078, mae: 70.636503, mean_q: 140.656334, mean_eps: 0.985760\n",
            "   796/50000: episode: 36, duration: 0.275s, episode steps:  32, steps per second: 116, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 73.785457, mae: 70.606882, mean_q: 140.770045, mean_eps: 0.985189\n",
            "   811/50000: episode: 37, duration: 0.135s, episode steps:  15, steps per second: 111, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 75.367411, mae: 69.995360, mean_q: 139.808161, mean_eps: 0.984743\n",
            "   823/50000: episode: 38, duration: 0.112s, episode steps:  12, steps per second: 107, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 55.045205, mae: 71.002078, mean_q: 141.198531, mean_eps: 0.984487\n",
            "   835/50000: episode: 39, duration: 0.115s, episode steps:  12, steps per second: 105, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 104.622641, mae: 70.256406, mean_q: 139.150059, mean_eps: 0.984259\n",
            "   887/50000: episode: 40, duration: 0.472s, episode steps:  52, steps per second: 110, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 56.391014, mae: 70.673160, mean_q: 140.402989, mean_eps: 0.983650\n",
            "   901/50000: episode: 41, duration: 0.125s, episode steps:  14, steps per second: 112, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 16.288574, mae: 69.092661, mean_q: 138.217673, mean_eps: 0.983024\n",
            "   911/50000: episode: 42, duration: 0.103s, episode steps:  10, steps per second:  97, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 55.078959, mae: 71.298234, mean_q: 141.579236, mean_eps: 0.982795\n",
            "   966/50000: episode: 43, duration: 0.506s, episode steps:  55, steps per second: 109, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 70.963487, mae: 70.379078, mean_q: 139.859116, mean_eps: 0.982178\n",
            "   987/50000: episode: 44, duration: 0.184s, episode steps:  21, steps per second: 114, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 93.584319, mae: 69.454294, mean_q: 137.601284, mean_eps: 0.981456\n",
            "  1001/50000: episode: 45, duration: 0.127s, episode steps:  14, steps per second: 110, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 112.785878, mae: 70.531588, mean_q: 138.883954, mean_eps: 0.981123\n",
            "  1016/50000: episode: 46, duration: 0.141s, episode steps:  15, steps per second: 106, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 12.817263, mae: 70.360011, mean_q: 139.825181, mean_eps: 0.980848\n",
            "  1027/50000: episode: 47, duration: 0.104s, episode steps:  11, steps per second: 106, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 44.375274, mae: 69.333884, mean_q: 138.777367, mean_eps: 0.980601\n",
            "  1054/50000: episode: 48, duration: 0.243s, episode steps:  27, steps per second: 111, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.407 [0.000, 1.000],  loss: 72.968716, mae: 69.975208, mean_q: 139.364161, mean_eps: 0.980240\n",
            "  1067/50000: episode: 49, duration: 0.128s, episode steps:  13, steps per second: 101, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 39.352976, mae: 69.182459, mean_q: 137.241138, mean_eps: 0.979860\n",
            "  1078/50000: episode: 50, duration: 0.101s, episode steps:  11, steps per second: 109, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 18.968305, mae: 70.662184, mean_q: 140.590392, mean_eps: 0.979632\n",
            "  1114/50000: episode: 51, duration: 0.324s, episode steps:  36, steps per second: 111, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 71.135117, mae: 69.667358, mean_q: 138.412308, mean_eps: 0.979186\n",
            "  1129/50000: episode: 52, duration: 0.135s, episode steps:  15, steps per second: 111, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 60.735695, mae: 69.935728, mean_q: 139.000990, mean_eps: 0.978701\n",
            "  1139/50000: episode: 53, duration: 0.098s, episode steps:  10, steps per second: 102, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 28.389708, mae: 69.318692, mean_q: 138.594044, mean_eps: 0.978463\n",
            "  1158/50000: episode: 54, duration: 0.173s, episode steps:  19, steps per second: 110, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 59.574936, mae: 68.843024, mean_q: 137.640647, mean_eps: 0.978188\n",
            "  1170/50000: episode: 55, duration: 0.122s, episode steps:  12, steps per second:  98, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 111.518621, mae: 69.216616, mean_q: 136.898294, mean_eps: 0.977893\n",
            "  1187/50000: episode: 56, duration: 0.162s, episode steps:  17, steps per second: 105, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 41.136761, mae: 69.757488, mean_q: 137.576222, mean_eps: 0.977618\n",
            "  1196/50000: episode: 57, duration: 0.090s, episode steps:   9, steps per second: 100, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 13.866839, mae: 68.714174, mean_q: 138.034870, mean_eps: 0.977371\n",
            "  1209/50000: episode: 58, duration: 0.115s, episode steps:  13, steps per second: 113, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 112.839352, mae: 69.506330, mean_q: 138.130532, mean_eps: 0.977162\n",
            "  1228/50000: episode: 59, duration: 0.174s, episode steps:  19, steps per second: 109, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.316 [0.000, 1.000],  loss: 59.372476, mae: 69.020543, mean_q: 137.523003, mean_eps: 0.976858\n",
            "  1243/50000: episode: 60, duration: 0.132s, episode steps:  15, steps per second: 114, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 73.221725, mae: 69.378736, mean_q: 138.163925, mean_eps: 0.976535\n",
            "  1256/50000: episode: 61, duration: 0.117s, episode steps:  13, steps per second: 111, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 78.535737, mae: 68.131603, mean_q: 135.898320, mean_eps: 0.976269\n",
            "  1274/50000: episode: 62, duration: 0.164s, episode steps:  18, steps per second: 110, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 17.335739, mae: 68.944399, mean_q: 138.231693, mean_eps: 0.975974\n",
            "  1302/50000: episode: 63, duration: 0.260s, episode steps:  28, steps per second: 108, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 93.771574, mae: 68.844169, mean_q: 135.975559, mean_eps: 0.975537\n",
            "  1324/50000: episode: 64, duration: 0.190s, episode steps:  22, steps per second: 116, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 38.683462, mae: 68.461278, mean_q: 136.863032, mean_eps: 0.975062\n",
            "  1345/50000: episode: 65, duration: 0.195s, episode steps:  21, steps per second: 108, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 47.769402, mae: 68.306314, mean_q: 136.537355, mean_eps: 0.974654\n",
            "  1394/50000: episode: 66, duration: 0.460s, episode steps:  49, steps per second: 106, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.551 [0.000, 1.000],  loss: 68.298870, mae: 68.581046, mean_q: 136.168420, mean_eps: 0.973989\n",
            "  1420/50000: episode: 67, duration: 0.232s, episode steps:  26, steps per second: 112, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 104.135821, mae: 68.306766, mean_q: 135.465165, mean_eps: 0.973276\n",
            "  1433/50000: episode: 68, duration: 0.115s, episode steps:  13, steps per second: 113, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 116.805854, mae: 70.079555, mean_q: 137.978764, mean_eps: 0.972906\n",
            "  1450/50000: episode: 69, duration: 0.160s, episode steps:  17, steps per second: 106, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 39.125043, mae: 68.986085, mean_q: 138.110308, mean_eps: 0.972621\n",
            "  1467/50000: episode: 70, duration: 0.148s, episode steps:  17, steps per second: 115, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 78.391824, mae: 67.981210, mean_q: 134.420580, mean_eps: 0.972298\n",
            "  1491/50000: episode: 71, duration: 0.221s, episode steps:  24, steps per second: 109, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 26.548988, mae: 67.275573, mean_q: 134.698811, mean_eps: 0.971909\n",
            "  1506/50000: episode: 72, duration: 0.139s, episode steps:  15, steps per second: 108, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 105.717310, mae: 67.826267, mean_q: 135.154773, mean_eps: 0.971538\n",
            "  1554/50000: episode: 73, duration: 0.434s, episode steps:  48, steps per second: 111, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 61.284684, mae: 68.395685, mean_q: 135.427398, mean_eps: 0.970940\n",
            "  1573/50000: episode: 74, duration: 0.223s, episode steps:  19, steps per second:  85, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 10.909957, mae: 68.224069, mean_q: 136.662126, mean_eps: 0.970303\n",
            "  1597/50000: episode: 75, duration: 0.322s, episode steps:  24, steps per second:  74, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 62.042790, mae: 67.211166, mean_q: 134.208274, mean_eps: 0.969894\n",
            "  1643/50000: episode: 76, duration: 0.588s, episode steps:  46, steps per second:  78, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 47.347191, mae: 68.247737, mean_q: 135.594073, mean_eps: 0.969229\n",
            "  1654/50000: episode: 77, duration: 0.142s, episode steps:  11, steps per second:  78, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: 91.615859, mae: 69.855200, mean_q: 137.407808, mean_eps: 0.968688\n",
            "  1671/50000: episode: 78, duration: 0.234s, episode steps:  17, steps per second:  73, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 46.128219, mae: 67.749300, mean_q: 132.888284, mean_eps: 0.968422\n",
            "  1682/50000: episode: 79, duration: 0.152s, episode steps:  11, steps per second:  73, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 27.392918, mae: 67.193672, mean_q: 135.766742, mean_eps: 0.968156\n",
            "  1729/50000: episode: 80, duration: 0.591s, episode steps:  47, steps per second:  80, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 78.607404, mae: 67.513621, mean_q: 133.627581, mean_eps: 0.967605\n",
            "  1777/50000: episode: 81, duration: 0.650s, episode steps:  48, steps per second:  74, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 61.591695, mae: 67.038591, mean_q: 132.871596, mean_eps: 0.966703\n",
            "  1789/50000: episode: 82, duration: 0.171s, episode steps:  12, steps per second:  70, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 14.757904, mae: 66.529098, mean_q: 134.055962, mean_eps: 0.966132\n",
            "  1811/50000: episode: 83, duration: 0.223s, episode steps:  22, steps per second:  99, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 96.583769, mae: 66.625035, mean_q: 131.895660, mean_eps: 0.965810\n",
            "  1837/50000: episode: 84, duration: 0.249s, episode steps:  26, steps per second: 105, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 48.510105, mae: 67.116944, mean_q: 133.328870, mean_eps: 0.965353\n",
            "  1854/50000: episode: 85, duration: 0.163s, episode steps:  17, steps per second: 104, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 45.035525, mae: 65.832657, mean_q: 131.223059, mean_eps: 0.964945\n",
            "  1867/50000: episode: 86, duration: 0.130s, episode steps:  13, steps per second: 100, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: 62.154071, mae: 66.565200, mean_q: 132.545893, mean_eps: 0.964660\n",
            "  1887/50000: episode: 87, duration: 0.181s, episode steps:  20, steps per second: 110, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 67.556621, mae: 66.312517, mean_q: 131.490240, mean_eps: 0.964346\n",
            "  1907/50000: episode: 88, duration: 0.183s, episode steps:  20, steps per second: 109, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 27.757121, mae: 66.435212, mean_q: 132.485990, mean_eps: 0.963966\n",
            "  1925/50000: episode: 89, duration: 0.179s, episode steps:  18, steps per second: 101, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 83.503051, mae: 66.768401, mean_q: 132.625721, mean_eps: 0.963605\n",
            "  1943/50000: episode: 90, duration: 0.171s, episode steps:  18, steps per second: 105, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 28.516405, mae: 65.864454, mean_q: 132.212072, mean_eps: 0.963264\n",
            "  1957/50000: episode: 91, duration: 0.127s, episode steps:  14, steps per second: 110, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 26.701910, mae: 65.860865, mean_q: 132.308788, mean_eps: 0.962959\n",
            "  1984/50000: episode: 92, duration: 0.276s, episode steps:  27, steps per second:  98, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.593 [0.000, 1.000],  loss: 46.357645, mae: 66.000504, mean_q: 131.941961, mean_eps: 0.962570\n",
            "  2000/50000: episode: 93, duration: 0.146s, episode steps:  16, steps per second: 110, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 41.830334, mae: 66.106002, mean_q: 132.445410, mean_eps: 0.962162\n",
            "  2016/50000: episode: 94, duration: 0.159s, episode steps:  16, steps per second: 100, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 61.835197, mae: 65.941162, mean_q: 131.428414, mean_eps: 0.961858\n",
            "  2069/50000: episode: 95, duration: 0.485s, episode steps:  53, steps per second: 109, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 40.919182, mae: 65.981511, mean_q: 132.544248, mean_eps: 0.961202\n",
            "  2109/50000: episode: 96, duration: 0.379s, episode steps:  40, steps per second: 106, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 80.928704, mae: 66.785426, mean_q: 132.317233, mean_eps: 0.960318\n",
            "  2134/50000: episode: 97, duration: 0.260s, episode steps:  25, steps per second:  96, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 80.302943, mae: 66.057792, mean_q: 130.195402, mean_eps: 0.959701\n",
            "  2146/50000: episode: 98, duration: 0.117s, episode steps:  12, steps per second: 103, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 42.957860, mae: 64.934317, mean_q: 131.160233, mean_eps: 0.959349\n",
            "  2158/50000: episode: 99, duration: 0.116s, episode steps:  12, steps per second: 104, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 38.905761, mae: 65.501194, mean_q: 129.345651, mean_eps: 0.959121\n",
            "  2168/50000: episode: 100, duration: 0.099s, episode steps:  10, steps per second: 101, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 64.267737, mae: 63.900888, mean_q: 128.372002, mean_eps: 0.958912\n",
            "  2182/50000: episode: 101, duration: 0.137s, episode steps:  14, steps per second: 103, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 54.963418, mae: 66.079692, mean_q: 131.594646, mean_eps: 0.958684\n",
            "  2205/50000: episode: 102, duration: 0.220s, episode steps:  23, steps per second: 105, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.348 [0.000, 1.000],  loss: 71.559050, mae: 64.950453, mean_q: 129.059415, mean_eps: 0.958333\n",
            "  2224/50000: episode: 103, duration: 0.171s, episode steps:  19, steps per second: 111, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 47.147357, mae: 66.031342, mean_q: 131.752504, mean_eps: 0.957934\n",
            "  2248/50000: episode: 104, duration: 0.243s, episode steps:  24, steps per second:  99, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 88.403245, mae: 66.233655, mean_q: 131.304480, mean_eps: 0.957526\n",
            "  2267/50000: episode: 105, duration: 0.175s, episode steps:  19, steps per second: 109, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 68.467578, mae: 65.165634, mean_q: 128.228940, mean_eps: 0.957117\n",
            "  2319/50000: episode: 106, duration: 0.476s, episode steps:  52, steps per second: 109, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.442 [0.000, 1.000],  loss: 35.132539, mae: 65.154627, mean_q: 130.465398, mean_eps: 0.956442\n",
            "  2356/50000: episode: 107, duration: 0.336s, episode steps:  37, steps per second: 110, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.622 [0.000, 1.000],  loss: 81.852189, mae: 66.558670, mean_q: 131.550869, mean_eps: 0.955597\n",
            "  2366/50000: episode: 108, duration: 0.089s, episode steps:  10, steps per second: 112, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 165.001674, mae: 66.491755, mean_q: 131.006913, mean_eps: 0.955150\n",
            "  2390/50000: episode: 109, duration: 0.214s, episode steps:  24, steps per second: 112, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 44.538016, mae: 64.870577, mean_q: 129.711948, mean_eps: 0.954828\n",
            "  2406/50000: episode: 110, duration: 0.150s, episode steps:  16, steps per second: 106, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 19.555305, mae: 64.177999, mean_q: 129.710282, mean_eps: 0.954448\n",
            "  2432/50000: episode: 111, duration: 0.250s, episode steps:  26, steps per second: 104, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 48.746548, mae: 65.073119, mean_q: 130.400909, mean_eps: 0.954049\n",
            "  2458/50000: episode: 112, duration: 0.253s, episode steps:  26, steps per second: 103, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 58.951084, mae: 65.476682, mean_q: 130.708934, mean_eps: 0.953554\n",
            "  2472/50000: episode: 113, duration: 0.127s, episode steps:  14, steps per second: 110, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 66.057081, mae: 64.859027, mean_q: 128.762433, mean_eps: 0.953175\n",
            "  2483/50000: episode: 114, duration: 0.116s, episode steps:  11, steps per second:  95, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 77.190386, mae: 64.817205, mean_q: 128.166833, mean_eps: 0.952937\n",
            "  2518/50000: episode: 115, duration: 0.319s, episode steps:  35, steps per second: 110, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 45.268560, mae: 64.329815, mean_q: 128.700387, mean_eps: 0.952500\n",
            "  2545/50000: episode: 116, duration: 0.253s, episode steps:  27, steps per second: 107, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 47.965732, mae: 64.622453, mean_q: 129.244194, mean_eps: 0.951911\n",
            "  2558/50000: episode: 117, duration: 0.128s, episode steps:  13, steps per second: 101, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 58.783875, mae: 63.995524, mean_q: 128.043140, mean_eps: 0.951531\n",
            "  2579/50000: episode: 118, duration: 0.199s, episode steps:  21, steps per second: 106, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 71.822219, mae: 64.650418, mean_q: 127.782693, mean_eps: 0.951208\n",
            "  2611/50000: episode: 119, duration: 0.307s, episode steps:  32, steps per second: 104, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 63.668660, mae: 65.254206, mean_q: 128.490747, mean_eps: 0.950705\n",
            "  2654/50000: episode: 120, duration: 0.401s, episode steps:  43, steps per second: 107, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 74.764609, mae: 65.082083, mean_q: 129.035511, mean_eps: 0.949992\n",
            "  2664/50000: episode: 121, duration: 0.099s, episode steps:  10, steps per second: 101, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 63.578305, mae: 64.489894, mean_q: 127.332550, mean_eps: 0.949488\n",
            "  2677/50000: episode: 122, duration: 0.126s, episode steps:  13, steps per second: 103, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 25.367495, mae: 65.305650, mean_q: 130.413274, mean_eps: 0.949270\n",
            "  2694/50000: episode: 123, duration: 0.153s, episode steps:  17, steps per second: 111, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 29.879995, mae: 63.648903, mean_q: 128.044867, mean_eps: 0.948985\n",
            "  2740/50000: episode: 124, duration: 0.416s, episode steps:  46, steps per second: 111, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 65.889393, mae: 64.880275, mean_q: 128.966591, mean_eps: 0.948386\n",
            "  2749/50000: episode: 125, duration: 0.090s, episode steps:   9, steps per second: 100, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 38.762976, mae: 66.441494, mean_q: 130.956043, mean_eps: 0.947864\n",
            "  2766/50000: episode: 126, duration: 0.163s, episode steps:  17, steps per second: 105, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 23.621886, mae: 64.038295, mean_q: 129.178445, mean_eps: 0.947617\n",
            "  2778/50000: episode: 127, duration: 0.118s, episode steps:  12, steps per second: 101, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 62.992815, mae: 65.705372, mean_q: 131.713029, mean_eps: 0.947341\n",
            "  2820/50000: episode: 128, duration: 0.394s, episode steps:  42, steps per second: 106, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.548 [0.000, 1.000],  loss: 46.260446, mae: 64.723163, mean_q: 128.776779, mean_eps: 0.946828\n",
            "  2840/50000: episode: 129, duration: 0.192s, episode steps:  20, steps per second: 104, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 70.323226, mae: 64.749982, mean_q: 127.874589, mean_eps: 0.946240\n",
            "  2885/50000: episode: 130, duration: 0.577s, episode steps:  45, steps per second:  78, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 54.475116, mae: 64.237534, mean_q: 128.442552, mean_eps: 0.945622\n",
            "  2901/50000: episode: 131, duration: 0.216s, episode steps:  16, steps per second:  74, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 35.651008, mae: 65.115232, mean_q: 129.417067, mean_eps: 0.945043\n",
            "  2921/50000: episode: 132, duration: 0.284s, episode steps:  20, steps per second:  70, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 33.578047, mae: 64.952589, mean_q: 130.106217, mean_eps: 0.944700\n",
            "  2959/50000: episode: 133, duration: 0.486s, episode steps:  38, steps per second:  78, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 73.403405, mae: 64.936799, mean_q: 128.426375, mean_eps: 0.944149\n",
            "  2974/50000: episode: 134, duration: 0.187s, episode steps:  15, steps per second:  80, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 140.752058, mae: 64.918393, mean_q: 128.443761, mean_eps: 0.943646\n",
            "  2988/50000: episode: 135, duration: 0.181s, episode steps:  14, steps per second:  77, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 57.298328, mae: 65.896089, mean_q: 129.918647, mean_eps: 0.943370\n",
            "  3013/50000: episode: 136, duration: 0.340s, episode steps:  25, steps per second:  74, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 63.974313, mae: 65.160701, mean_q: 130.609532, mean_eps: 0.943000\n",
            "  3024/50000: episode: 137, duration: 0.163s, episode steps:  11, steps per second:  68, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 68.552822, mae: 62.793933, mean_q: 123.697664, mean_eps: 0.942658\n",
            "  3044/50000: episode: 138, duration: 0.266s, episode steps:  20, steps per second:  75, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 12.594630, mae: 63.981054, mean_q: 128.766807, mean_eps: 0.942364\n",
            "  3077/50000: episode: 139, duration: 0.413s, episode steps:  33, steps per second:  80, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 59.622702, mae: 64.583024, mean_q: 128.498363, mean_eps: 0.941860\n",
            "  3092/50000: episode: 140, duration: 0.145s, episode steps:  15, steps per second: 103, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 70.286620, mae: 64.052996, mean_q: 127.085935, mean_eps: 0.941404\n",
            "  3108/50000: episode: 141, duration: 0.157s, episode steps:  16, steps per second: 102, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 45.577112, mae: 64.866336, mean_q: 127.998198, mean_eps: 0.941110\n",
            "  3122/50000: episode: 142, duration: 0.129s, episode steps:  14, steps per second: 109, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 68.124009, mae: 62.500704, mean_q: 125.401124, mean_eps: 0.940825\n",
            "  3146/50000: episode: 143, duration: 0.219s, episode steps:  24, steps per second: 110, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 54.528177, mae: 64.109340, mean_q: 127.215016, mean_eps: 0.940463\n",
            "  3176/50000: episode: 144, duration: 0.283s, episode steps:  30, steps per second: 106, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.433 [0.000, 1.000],  loss: 35.281249, mae: 63.760373, mean_q: 126.582190, mean_eps: 0.939951\n",
            "  3206/50000: episode: 145, duration: 0.290s, episode steps:  30, steps per second: 103, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 15.111935, mae: 63.446300, mean_q: 127.822035, mean_eps: 0.939381\n",
            "  3235/50000: episode: 146, duration: 0.261s, episode steps:  29, steps per second: 111, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 41.460244, mae: 63.301606, mean_q: 127.402270, mean_eps: 0.938820\n",
            "  3260/50000: episode: 147, duration: 0.225s, episode steps:  25, steps per second: 111, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 26.894111, mae: 63.574642, mean_q: 127.303578, mean_eps: 0.938307\n",
            "  3280/50000: episode: 148, duration: 0.180s, episode steps:  20, steps per second: 111, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 57.557402, mae: 63.965047, mean_q: 126.290200, mean_eps: 0.937879\n",
            "  3301/50000: episode: 149, duration: 0.211s, episode steps:  21, steps per second:  99, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 76.046891, mae: 62.934592, mean_q: 124.875438, mean_eps: 0.937490\n",
            "  3340/50000: episode: 150, duration: 0.369s, episode steps:  39, steps per second: 106, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.410 [0.000, 1.000],  loss: 33.073878, mae: 63.652429, mean_q: 127.269494, mean_eps: 0.936920\n",
            "  3354/50000: episode: 151, duration: 0.137s, episode steps:  14, steps per second: 102, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 89.771619, mae: 64.073321, mean_q: 127.498185, mean_eps: 0.936416\n",
            "  3371/50000: episode: 152, duration: 0.157s, episode steps:  17, steps per second: 108, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 45.539995, mae: 64.122677, mean_q: 127.688892, mean_eps: 0.936122\n",
            "  3398/50000: episode: 153, duration: 0.255s, episode steps:  27, steps per second: 106, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 51.699537, mae: 63.700512, mean_q: 127.602357, mean_eps: 0.935704\n",
            "  3420/50000: episode: 154, duration: 0.207s, episode steps:  22, steps per second: 106, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 55.567463, mae: 64.024951, mean_q: 127.379324, mean_eps: 0.935239\n",
            "  3461/50000: episode: 155, duration: 0.355s, episode steps:  41, steps per second: 116, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 97.499526, mae: 64.354414, mean_q: 126.905698, mean_eps: 0.934640\n",
            "  3521/50000: episode: 156, duration: 0.535s, episode steps:  60, steps per second: 112, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 58.816245, mae: 63.397065, mean_q: 126.192578, mean_eps: 0.933680\n",
            "  3549/50000: episode: 157, duration: 0.258s, episode steps:  28, steps per second: 108, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 27.074831, mae: 63.373569, mean_q: 127.103303, mean_eps: 0.932844\n",
            "  3565/50000: episode: 158, duration: 0.142s, episode steps:  16, steps per second: 113, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 97.343516, mae: 64.537194, mean_q: 126.424252, mean_eps: 0.932427\n",
            "  3602/50000: episode: 159, duration: 0.318s, episode steps:  37, steps per second: 116, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 52.716910, mae: 63.332939, mean_q: 126.214544, mean_eps: 0.931923\n",
            "  3629/50000: episode: 160, duration: 0.255s, episode steps:  27, steps per second: 106, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 50.113738, mae: 63.194813, mean_q: 126.765548, mean_eps: 0.931315\n",
            "  3643/50000: episode: 161, duration: 0.132s, episode steps:  14, steps per second: 106, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 22.434152, mae: 63.229178, mean_q: 125.617456, mean_eps: 0.930925\n",
            "  3664/50000: episode: 162, duration: 0.190s, episode steps:  21, steps per second: 110, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 76.535355, mae: 63.344524, mean_q: 126.098809, mean_eps: 0.930593\n",
            "  3680/50000: episode: 163, duration: 0.145s, episode steps:  16, steps per second: 110, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 44.960710, mae: 64.476609, mean_q: 127.700239, mean_eps: 0.930241\n",
            "  3696/50000: episode: 164, duration: 0.152s, episode steps:  16, steps per second: 105, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 36.990152, mae: 63.150406, mean_q: 125.998912, mean_eps: 0.929938\n",
            "  3744/50000: episode: 165, duration: 0.431s, episode steps:  48, steps per second: 111, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 78.345563, mae: 63.486569, mean_q: 125.869730, mean_eps: 0.929330\n",
            "  3774/50000: episode: 166, duration: 0.279s, episode steps:  30, steps per second: 108, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 60.955111, mae: 62.793863, mean_q: 124.943634, mean_eps: 0.928589\n",
            "  3799/50000: episode: 167, duration: 0.226s, episode steps:  25, steps per second: 111, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 25.617074, mae: 62.879548, mean_q: 125.788271, mean_eps: 0.928066\n",
            "  3845/50000: episode: 168, duration: 0.425s, episode steps:  46, steps per second: 108, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 54.997568, mae: 63.377273, mean_q: 126.011685, mean_eps: 0.927392\n",
            "  3855/50000: episode: 169, duration: 0.102s, episode steps:  10, steps per second:  98, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 17.018472, mae: 63.015441, mean_q: 126.600315, mean_eps: 0.926859\n",
            "  3887/50000: episode: 170, duration: 0.290s, episode steps:  32, steps per second: 110, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 62.396495, mae: 62.766979, mean_q: 125.426910, mean_eps: 0.926461\n",
            "  3923/50000: episode: 171, duration: 0.317s, episode steps:  36, steps per second: 113, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 37.330758, mae: 63.037929, mean_q: 126.373158, mean_eps: 0.925814\n",
            "  3968/50000: episode: 172, duration: 0.411s, episode steps:  45, steps per second: 109, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 41.950066, mae: 62.960508, mean_q: 126.575682, mean_eps: 0.925045\n",
            "  3978/50000: episode: 173, duration: 0.093s, episode steps:  10, steps per second: 107, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 76.841066, mae: 63.581112, mean_q: 125.117987, mean_eps: 0.924522\n",
            "  3995/50000: episode: 174, duration: 0.150s, episode steps:  17, steps per second: 113, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 27.033574, mae: 63.519147, mean_q: 128.741925, mean_eps: 0.924266\n",
            "  4020/50000: episode: 175, duration: 0.223s, episode steps:  25, steps per second: 112, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.360 [0.000, 1.000],  loss: 93.161362, mae: 64.567153, mean_q: 127.137891, mean_eps: 0.923867\n",
            "  4091/50000: episode: 176, duration: 0.628s, episode steps:  71, steps per second: 113, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.451 [0.000, 1.000],  loss: 74.644742, mae: 63.259336, mean_q: 125.374892, mean_eps: 0.922955\n",
            "  4117/50000: episode: 177, duration: 0.238s, episode steps:  26, steps per second: 109, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 59.274695, mae: 63.119069, mean_q: 126.208927, mean_eps: 0.922034\n",
            "  4127/50000: episode: 178, duration: 0.097s, episode steps:  10, steps per second: 103, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 18.118625, mae: 63.690250, mean_q: 129.774231, mean_eps: 0.921692\n",
            "  4175/50000: episode: 179, duration: 0.521s, episode steps:  48, steps per second:  92, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 51.135892, mae: 62.762458, mean_q: 125.390318, mean_eps: 0.921141\n",
            "  4195/50000: episode: 180, duration: 0.271s, episode steps:  20, steps per second:  74, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 63.650247, mae: 63.158201, mean_q: 126.619468, mean_eps: 0.920494\n",
            "  4231/50000: episode: 181, duration: 0.456s, episode steps:  36, steps per second:  79, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 37.522995, mae: 64.164670, mean_q: 127.744879, mean_eps: 0.919963\n",
            "  4248/50000: episode: 182, duration: 0.231s, episode steps:  17, steps per second:  74, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 16.732836, mae: 62.213517, mean_q: 125.463036, mean_eps: 0.919459\n",
            "  4276/50000: episode: 183, duration: 0.362s, episode steps:  28, steps per second:  77, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 47.621254, mae: 63.902965, mean_q: 128.728612, mean_eps: 0.919031\n",
            "  4291/50000: episode: 184, duration: 0.193s, episode steps:  15, steps per second:  78, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 63.449709, mae: 64.602293, mean_q: 126.896000, mean_eps: 0.918623\n",
            "  4310/50000: episode: 185, duration: 0.245s, episode steps:  19, steps per second:  77, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 31.133192, mae: 63.513129, mean_q: 127.897104, mean_eps: 0.918300\n",
            "  4321/50000: episode: 186, duration: 0.145s, episode steps:  11, steps per second:  76, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 84.161151, mae: 62.699759, mean_q: 124.501744, mean_eps: 0.918015\n",
            "  4337/50000: episode: 187, duration: 0.234s, episode steps:  16, steps per second:  68, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 16.400102, mae: 63.112154, mean_q: 128.922343, mean_eps: 0.917758\n",
            "  4388/50000: episode: 188, duration: 0.621s, episode steps:  51, steps per second:  82, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.431 [0.000, 1.000],  loss: 62.987156, mae: 63.653201, mean_q: 127.012299, mean_eps: 0.917122\n",
            "  4408/50000: episode: 189, duration: 0.172s, episode steps:  20, steps per second: 116, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 34.558674, mae: 63.792901, mean_q: 126.583044, mean_eps: 0.916448\n",
            "  4437/50000: episode: 190, duration: 0.265s, episode steps:  29, steps per second: 110, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.414 [0.000, 1.000],  loss: 81.329587, mae: 64.110791, mean_q: 126.159359, mean_eps: 0.915982\n",
            "  4454/50000: episode: 191, duration: 0.150s, episode steps:  17, steps per second: 114, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 49.295850, mae: 64.288886, mean_q: 127.966866, mean_eps: 0.915545\n",
            "  4490/50000: episode: 192, duration: 0.319s, episode steps:  36, steps per second: 113, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 64.052967, mae: 63.154470, mean_q: 125.315406, mean_eps: 0.915041\n",
            "  4525/50000: episode: 193, duration: 0.305s, episode steps:  35, steps per second: 115, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 69.242021, mae: 63.676636, mean_q: 126.704333, mean_eps: 0.914367\n",
            "  4547/50000: episode: 194, duration: 0.217s, episode steps:  22, steps per second: 102, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 75.502978, mae: 62.714198, mean_q: 124.838327, mean_eps: 0.913825\n",
            "  4558/50000: episode: 195, duration: 0.096s, episode steps:  11, steps per second: 114, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 59.650515, mae: 63.450352, mean_q: 125.054599, mean_eps: 0.913512\n",
            "  4573/50000: episode: 196, duration: 0.138s, episode steps:  15, steps per second: 109, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 55.797796, mae: 62.837035, mean_q: 125.000660, mean_eps: 0.913265\n",
            "  4584/50000: episode: 197, duration: 0.097s, episode steps:  11, steps per second: 114, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 28.444451, mae: 62.595136, mean_q: 125.134447, mean_eps: 0.913018\n",
            "  4600/50000: episode: 198, duration: 0.145s, episode steps:  16, steps per second: 110, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 78.036397, mae: 63.320996, mean_q: 126.640063, mean_eps: 0.912762\n",
            "  4610/50000: episode: 199, duration: 0.092s, episode steps:  10, steps per second: 109, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 101.731830, mae: 65.683729, mean_q: 129.311826, mean_eps: 0.912515\n",
            "  4619/50000: episode: 200, duration: 0.089s, episode steps:   9, steps per second: 101, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 29.621813, mae: 63.714150, mean_q: 127.386406, mean_eps: 0.912334\n",
            "  4648/50000: episode: 201, duration: 0.279s, episode steps:  29, steps per second: 104, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 93.586087, mae: 63.330654, mean_q: 124.934882, mean_eps: 0.911973\n",
            "  4665/50000: episode: 202, duration: 0.145s, episode steps:  17, steps per second: 118, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 19.907462, mae: 63.608258, mean_q: 128.587463, mean_eps: 0.911536\n",
            "  4684/50000: episode: 203, duration: 0.172s, episode steps:  19, steps per second: 110, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.737 [0.000, 1.000],  loss: 44.679225, mae: 62.617537, mean_q: 124.723179, mean_eps: 0.911194\n",
            "  4726/50000: episode: 204, duration: 0.373s, episode steps:  42, steps per second: 113, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 58.035096, mae: 62.135737, mean_q: 124.179381, mean_eps: 0.910614\n",
            "  4737/50000: episode: 205, duration: 0.108s, episode steps:  11, steps per second: 102, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 12.238838, mae: 62.223382, mean_q: 126.815638, mean_eps: 0.910111\n",
            "  4763/50000: episode: 206, duration: 0.241s, episode steps:  26, steps per second: 108, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 46.782931, mae: 63.079070, mean_q: 126.385073, mean_eps: 0.909759\n",
            "  4798/50000: episode: 207, duration: 0.306s, episode steps:  35, steps per second: 115, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.629 [0.000, 1.000],  loss: 46.089951, mae: 62.279809, mean_q: 124.869071, mean_eps: 0.909180\n",
            "  4814/50000: episode: 208, duration: 0.147s, episode steps:  16, steps per second: 109, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 88.062844, mae: 63.832732, mean_q: 126.003665, mean_eps: 0.908696\n",
            "  4844/50000: episode: 209, duration: 0.277s, episode steps:  30, steps per second: 108, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 70.197464, mae: 63.086711, mean_q: 124.562869, mean_eps: 0.908259\n",
            "  4857/50000: episode: 210, duration: 0.125s, episode steps:  13, steps per second: 104, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 54.510650, mae: 63.580631, mean_q: 127.259450, mean_eps: 0.907850\n",
            "  4871/50000: episode: 211, duration: 0.143s, episode steps:  14, steps per second:  98, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 53.479392, mae: 62.581943, mean_q: 126.541203, mean_eps: 0.907594\n",
            "  4890/50000: episode: 212, duration: 0.175s, episode steps:  19, steps per second: 108, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 65.979473, mae: 62.913556, mean_q: 123.168326, mean_eps: 0.907280\n",
            "  4918/50000: episode: 213, duration: 0.252s, episode steps:  28, steps per second: 111, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.393 [0.000, 1.000],  loss: 73.690246, mae: 63.544461, mean_q: 126.110582, mean_eps: 0.906833\n",
            "  4948/50000: episode: 214, duration: 0.272s, episode steps:  30, steps per second: 110, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.433 [0.000, 1.000],  loss: 52.962215, mae: 63.038241, mean_q: 124.735417, mean_eps: 0.906282\n",
            "  4965/50000: episode: 215, duration: 0.155s, episode steps:  17, steps per second: 110, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 81.238781, mae: 62.850759, mean_q: 123.823653, mean_eps: 0.905836\n",
            "  4994/50000: episode: 216, duration: 0.277s, episode steps:  29, steps per second: 105, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 54.970238, mae: 61.628907, mean_q: 123.901537, mean_eps: 0.905399\n",
            "  5006/50000: episode: 217, duration: 0.110s, episode steps:  12, steps per second: 109, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: 46.735955, mae: 63.321886, mean_q: 124.876909, mean_eps: 0.905009\n",
            "  5025/50000: episode: 218, duration: 0.193s, episode steps:  19, steps per second:  98, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 84.370667, mae: 62.992366, mean_q: 125.203616, mean_eps: 0.904715\n",
            "  5036/50000: episode: 219, duration: 0.101s, episode steps:  11, steps per second: 109, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 21.246025, mae: 60.828429, mean_q: 123.006339, mean_eps: 0.904430\n",
            "  5053/50000: episode: 220, duration: 0.163s, episode steps:  17, steps per second: 105, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 91.717695, mae: 62.781074, mean_q: 124.990610, mean_eps: 0.904164\n",
            "  5072/50000: episode: 221, duration: 0.404s, episode steps:  19, steps per second:  47, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 43.056063, mae: 63.778587, mean_q: 126.437800, mean_eps: 0.903822\n",
            "  5093/50000: episode: 222, duration: 0.386s, episode steps:  21, steps per second:  54, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 28.447477, mae: 62.269641, mean_q: 124.979151, mean_eps: 0.903442\n",
            "  5118/50000: episode: 223, duration: 0.227s, episode steps:  25, steps per second: 110, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 65.709769, mae: 61.733825, mean_q: 122.167992, mean_eps: 0.903005\n",
            "  5135/50000: episode: 224, duration: 0.276s, episode steps:  17, steps per second:  62, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 40.951617, mae: 61.683629, mean_q: 123.642497, mean_eps: 0.902606\n",
            "  5152/50000: episode: 225, duration: 0.477s, episode steps:  17, steps per second:  36, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 75.466659, mae: 62.236768, mean_q: 123.247260, mean_eps: 0.902283\n",
            "  5195/50000: episode: 226, duration: 0.381s, episode steps:  43, steps per second: 113, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 46.113514, mae: 61.914707, mean_q: 123.144875, mean_eps: 0.901713\n",
            "  5277/50000: episode: 227, duration: 1.128s, episode steps:  82, steps per second:  73, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 82.577566, mae: 62.289949, mean_q: 123.277236, mean_eps: 0.900525\n",
            "  5289/50000: episode: 228, duration: 0.112s, episode steps:  12, steps per second: 107, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 21.606986, mae: 62.431376, mean_q: 124.197140, mean_eps: 0.899633\n",
            "  5317/50000: episode: 229, duration: 0.246s, episode steps:  28, steps per second: 114, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.679 [0.000, 1.000],  loss: 29.571542, mae: 62.559029, mean_q: 124.470809, mean_eps: 0.899252\n",
            "  5327/50000: episode: 230, duration: 0.097s, episode steps:  10, steps per second: 103, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.300 [0.000, 1.000],  loss: 25.635757, mae: 61.692685, mean_q: 123.836536, mean_eps: 0.898892\n",
            "  5377/50000: episode: 231, duration: 0.580s, episode steps:  50, steps per second:  86, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 66.784970, mae: 61.430061, mean_q: 122.114941, mean_eps: 0.898321\n",
            "  5391/50000: episode: 232, duration: 0.211s, episode steps:  14, steps per second:  66, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 89.259215, mae: 61.638099, mean_q: 121.199661, mean_eps: 0.897713\n",
            "  5401/50000: episode: 233, duration: 0.134s, episode steps:  10, steps per second:  75, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 65.200171, mae: 61.343070, mean_q: 122.297840, mean_eps: 0.897485\n",
            "  5414/50000: episode: 234, duration: 0.186s, episode steps:  13, steps per second:  70, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 160.830653, mae: 63.042621, mean_q: 122.965241, mean_eps: 0.897267\n",
            "  5428/50000: episode: 235, duration: 0.193s, episode steps:  14, steps per second:  73, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 55.311771, mae: 62.181144, mean_q: 122.890076, mean_eps: 0.897010\n",
            "  5446/50000: episode: 236, duration: 0.242s, episode steps:  18, steps per second:  74, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 81.119591, mae: 61.243030, mean_q: 120.777109, mean_eps: 0.896707\n",
            "  5464/50000: episode: 237, duration: 0.253s, episode steps:  18, steps per second:  71, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 80.109311, mae: 60.162449, mean_q: 119.396751, mean_eps: 0.896365\n",
            "  5483/50000: episode: 238, duration: 0.243s, episode steps:  19, steps per second:  78, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 48.069400, mae: 61.106619, mean_q: 120.946238, mean_eps: 0.896013\n",
            "  5495/50000: episode: 239, duration: 0.153s, episode steps:  12, steps per second:  78, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 37.622242, mae: 62.032254, mean_q: 123.375598, mean_eps: 0.895719\n",
            "  5508/50000: episode: 240, duration: 0.187s, episode steps:  13, steps per second:  69, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 39.268559, mae: 61.070753, mean_q: 120.520552, mean_eps: 0.895481\n",
            "  5536/50000: episode: 241, duration: 0.376s, episode steps:  28, steps per second:  74, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 24.117778, mae: 61.204008, mean_q: 122.332719, mean_eps: 0.895092\n",
            "  5558/50000: episode: 242, duration: 0.301s, episode steps:  22, steps per second:  73, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 44.629450, mae: 61.565775, mean_q: 122.238894, mean_eps: 0.894617\n",
            "  5585/50000: episode: 243, duration: 0.241s, episode steps:  27, steps per second: 112, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.593 [0.000, 1.000],  loss: 75.734469, mae: 61.888704, mean_q: 122.388279, mean_eps: 0.894151\n",
            "  5610/50000: episode: 244, duration: 0.231s, episode steps:  25, steps per second: 108, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.640 [0.000, 1.000],  loss: 82.376737, mae: 62.271421, mean_q: 122.736771, mean_eps: 0.893657\n",
            "  5626/50000: episode: 245, duration: 0.156s, episode steps:  16, steps per second: 103, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 49.950832, mae: 60.621632, mean_q: 120.172562, mean_eps: 0.893268\n",
            "  5656/50000: episode: 246, duration: 0.282s, episode steps:  30, steps per second: 106, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 67.079299, mae: 61.554869, mean_q: 121.757075, mean_eps: 0.892831\n",
            "  5683/50000: episode: 247, duration: 0.246s, episode steps:  27, steps per second: 110, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 53.199170, mae: 60.731560, mean_q: 121.379260, mean_eps: 0.892289\n",
            "  5703/50000: episode: 248, duration: 0.190s, episode steps:  20, steps per second: 105, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 73.310324, mae: 60.883592, mean_q: 119.467302, mean_eps: 0.891842\n",
            "  5726/50000: episode: 249, duration: 0.209s, episode steps:  23, steps per second: 110, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.652 [0.000, 1.000],  loss: 59.160944, mae: 61.405381, mean_q: 122.501949, mean_eps: 0.891434\n",
            "  5750/50000: episode: 250, duration: 0.235s, episode steps:  24, steps per second: 102, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 38.030113, mae: 59.953244, mean_q: 119.437165, mean_eps: 0.890988\n",
            "  5787/50000: episode: 251, duration: 0.332s, episode steps:  37, steps per second: 112, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 68.033802, mae: 60.284506, mean_q: 120.154655, mean_eps: 0.890408\n",
            "  5803/50000: episode: 252, duration: 0.153s, episode steps:  16, steps per second: 105, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 84.656873, mae: 60.961758, mean_q: 120.781327, mean_eps: 0.889905\n",
            "  5820/50000: episode: 253, duration: 0.166s, episode steps:  17, steps per second: 103, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 65.621713, mae: 59.654084, mean_q: 119.142024, mean_eps: 0.889591\n",
            "  5837/50000: episode: 254, duration: 0.159s, episode steps:  17, steps per second: 107, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 88.947474, mae: 61.126402, mean_q: 120.792201, mean_eps: 0.889268\n",
            "  5868/50000: episode: 255, duration: 0.291s, episode steps:  31, steps per second: 106, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 53.696139, mae: 60.968161, mean_q: 121.114144, mean_eps: 0.888812\n",
            "  5890/50000: episode: 256, duration: 0.209s, episode steps:  22, steps per second: 105, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 35.512401, mae: 60.226087, mean_q: 120.327050, mean_eps: 0.888308\n",
            "  5911/50000: episode: 257, duration: 0.196s, episode steps:  21, steps per second: 107, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 93.002506, mae: 59.129499, mean_q: 116.631041, mean_eps: 0.887900\n",
            "  5936/50000: episode: 258, duration: 0.241s, episode steps:  25, steps per second: 104, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 67.072577, mae: 60.891330, mean_q: 119.768359, mean_eps: 0.887463\n",
            "  5949/50000: episode: 259, duration: 0.119s, episode steps:  13, steps per second: 110, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 53.311023, mae: 60.265764, mean_q: 119.882604, mean_eps: 0.887102\n",
            "  5959/50000: episode: 260, duration: 0.097s, episode steps:  10, steps per second: 103, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 57.878349, mae: 61.232145, mean_q: 122.024603, mean_eps: 0.886883\n",
            "  5988/50000: episode: 261, duration: 0.265s, episode steps:  29, steps per second: 109, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.621 [0.000, 1.000],  loss: 54.235288, mae: 59.992347, mean_q: 118.378979, mean_eps: 0.886513\n",
            "  6011/50000: episode: 262, duration: 0.219s, episode steps:  23, steps per second: 105, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 58.738784, mae: 59.750597, mean_q: 118.756442, mean_eps: 0.886019\n",
            "  6025/50000: episode: 263, duration: 0.141s, episode steps:  14, steps per second:  99, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 30.733604, mae: 59.372484, mean_q: 118.757182, mean_eps: 0.885667\n",
            "  6049/50000: episode: 264, duration: 0.219s, episode steps:  24, steps per second: 110, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 50.541971, mae: 59.448016, mean_q: 118.669042, mean_eps: 0.885306\n",
            "  6067/50000: episode: 265, duration: 0.165s, episode steps:  18, steps per second: 109, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 47.164143, mae: 60.149321, mean_q: 119.901462, mean_eps: 0.884907\n",
            "  6102/50000: episode: 266, duration: 0.324s, episode steps:  35, steps per second: 108, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 44.848064, mae: 60.022346, mean_q: 118.969375, mean_eps: 0.884404\n",
            "  6115/50000: episode: 267, duration: 0.127s, episode steps:  13, steps per second: 102, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 47.549871, mae: 61.192483, mean_q: 121.190230, mean_eps: 0.883948\n",
            "  6127/50000: episode: 268, duration: 0.117s, episode steps:  12, steps per second: 103, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 33.364589, mae: 60.081457, mean_q: 119.305609, mean_eps: 0.883711\n",
            "  6143/50000: episode: 269, duration: 0.154s, episode steps:  16, steps per second: 104, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 58.913805, mae: 60.047608, mean_q: 119.848000, mean_eps: 0.883444\n",
            "  6157/50000: episode: 270, duration: 0.138s, episode steps:  14, steps per second: 102, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 140.315067, mae: 61.425901, mean_q: 118.521048, mean_eps: 0.883160\n",
            "  6176/50000: episode: 271, duration: 0.172s, episode steps:  19, steps per second: 110, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 54.684084, mae: 61.242012, mean_q: 120.284637, mean_eps: 0.882846\n",
            "  6252/50000: episode: 272, duration: 0.718s, episode steps:  76, steps per second: 106, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 61.613792, mae: 59.854808, mean_q: 117.889191, mean_eps: 0.881944\n",
            "  6265/50000: episode: 273, duration: 0.122s, episode steps:  13, steps per second: 107, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 85.600383, mae: 59.157288, mean_q: 117.160248, mean_eps: 0.881098\n",
            "  6274/50000: episode: 274, duration: 0.094s, episode steps:   9, steps per second:  95, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 30.540819, mae: 58.876599, mean_q: 115.860049, mean_eps: 0.880889\n",
            "  6313/50000: episode: 275, duration: 0.366s, episode steps:  39, steps per second: 106, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.564 [0.000, 1.000],  loss: 39.895251, mae: 59.255934, mean_q: 118.067606, mean_eps: 0.880433\n",
            "  6351/50000: episode: 276, duration: 0.349s, episode steps:  38, steps per second: 109, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.553 [0.000, 1.000],  loss: 49.724417, mae: 58.922488, mean_q: 116.906350, mean_eps: 0.879702\n",
            "  6376/50000: episode: 277, duration: 0.229s, episode steps:  25, steps per second: 109, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 78.222951, mae: 60.648566, mean_q: 118.810306, mean_eps: 0.879103\n",
            "  6391/50000: episode: 278, duration: 0.143s, episode steps:  15, steps per second: 105, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 85.034514, mae: 60.905388, mean_q: 119.516474, mean_eps: 0.878723\n",
            "  6414/50000: episode: 279, duration: 0.229s, episode steps:  23, steps per second: 100, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.609 [0.000, 1.000],  loss: 62.357206, mae: 59.679307, mean_q: 118.686904, mean_eps: 0.878362\n",
            "  6432/50000: episode: 280, duration: 0.173s, episode steps:  18, steps per second: 104, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 49.200384, mae: 59.912386, mean_q: 120.197335, mean_eps: 0.877972\n",
            "  6442/50000: episode: 281, duration: 0.108s, episode steps:  10, steps per second:  92, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 94.215327, mae: 58.712817, mean_q: 115.115332, mean_eps: 0.877706\n",
            "  6476/50000: episode: 282, duration: 0.321s, episode steps:  34, steps per second: 106, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.441 [0.000, 1.000],  loss: 49.860506, mae: 58.296560, mean_q: 115.846543, mean_eps: 0.877289\n",
            "  6490/50000: episode: 283, duration: 0.131s, episode steps:  14, steps per second: 107, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 29.853432, mae: 58.884437, mean_q: 117.641491, mean_eps: 0.876833\n",
            "  6514/50000: episode: 284, duration: 0.225s, episode steps:  24, steps per second: 107, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 28.649978, mae: 58.501962, mean_q: 117.077676, mean_eps: 0.876472\n",
            "  6563/50000: episode: 285, duration: 0.441s, episode steps:  49, steps per second: 111, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.408 [0.000, 1.000],  loss: 50.406723, mae: 58.845925, mean_q: 115.928378, mean_eps: 0.875778\n",
            "  6576/50000: episode: 286, duration: 0.113s, episode steps:  13, steps per second: 115, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 104.375047, mae: 58.439460, mean_q: 115.301207, mean_eps: 0.875189\n",
            "  6609/50000: episode: 287, duration: 0.287s, episode steps:  33, steps per second: 115, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 64.940451, mae: 58.955098, mean_q: 116.552991, mean_eps: 0.874752\n",
            "  6623/50000: episode: 288, duration: 0.154s, episode steps:  14, steps per second:  91, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 78.174315, mae: 60.250341, mean_q: 118.404417, mean_eps: 0.874305\n",
            "  6635/50000: episode: 289, duration: 0.162s, episode steps:  12, steps per second:  74, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 45.612411, mae: 58.798122, mean_q: 117.167465, mean_eps: 0.874058\n",
            "  6678/50000: episode: 290, duration: 0.548s, episode steps:  43, steps per second:  78, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 76.195125, mae: 58.126728, mean_q: 115.092612, mean_eps: 0.873536\n",
            "  6692/50000: episode: 291, duration: 0.184s, episode steps:  14, steps per second:  76, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 36.678699, mae: 58.737470, mean_q: 117.043259, mean_eps: 0.872995\n",
            "  6702/50000: episode: 292, duration: 0.152s, episode steps:  10, steps per second:  66, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 55.140846, mae: 55.312488, mean_q: 111.183987, mean_eps: 0.872767\n",
            "  6717/50000: episode: 293, duration: 0.200s, episode steps:  15, steps per second:  75, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 59.115431, mae: 57.984379, mean_q: 115.288953, mean_eps: 0.872529\n",
            "  6743/50000: episode: 294, duration: 0.332s, episode steps:  26, steps per second:  78, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.731 [0.000, 1.000],  loss: 76.225871, mae: 59.236116, mean_q: 116.786281, mean_eps: 0.872139\n",
            "  6752/50000: episode: 295, duration: 0.116s, episode steps:   9, steps per second:  77, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 61.261070, mae: 57.112533, mean_q: 111.770065, mean_eps: 0.871807\n",
            "  6768/50000: episode: 296, duration: 0.202s, episode steps:  16, steps per second:  79, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 51.191955, mae: 59.112870, mean_q: 117.618530, mean_eps: 0.871570\n",
            "  6783/50000: episode: 297, duration: 0.205s, episode steps:  15, steps per second:  73, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 56.934890, mae: 59.349171, mean_q: 117.050286, mean_eps: 0.871275\n",
            "  6793/50000: episode: 298, duration: 0.151s, episode steps:  10, steps per second:  66, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 35.354467, mae: 57.394619, mean_q: 116.147239, mean_eps: 0.871037\n",
            "  6803/50000: episode: 299, duration: 0.141s, episode steps:  10, steps per second:  71, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 35.609008, mae: 58.820135, mean_q: 118.803579, mean_eps: 0.870847\n",
            "  6856/50000: episode: 300, duration: 0.675s, episode steps:  53, steps per second:  79, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.547 [0.000, 1.000],  loss: 39.511155, mae: 57.774907, mean_q: 115.412977, mean_eps: 0.870249\n",
            "  6880/50000: episode: 301, duration: 0.223s, episode steps:  24, steps per second: 108, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 46.612019, mae: 58.038605, mean_q: 115.483967, mean_eps: 0.869518\n",
            "  6898/50000: episode: 302, duration: 0.158s, episode steps:  18, steps per second: 114, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 44.355569, mae: 58.780685, mean_q: 115.685800, mean_eps: 0.869119\n",
            "  6918/50000: episode: 303, duration: 0.183s, episode steps:  20, steps per second: 109, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 60.030974, mae: 57.998880, mean_q: 114.278951, mean_eps: 0.868757\n",
            "  7017/50000: episode: 304, duration: 0.879s, episode steps:  99, steps per second: 113, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 54.219700, mae: 57.676265, mean_q: 114.619620, mean_eps: 0.867627\n",
            "  7033/50000: episode: 305, duration: 0.138s, episode steps:  16, steps per second: 116, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 81.873584, mae: 56.196700, mean_q: 111.204619, mean_eps: 0.866534\n",
            "  7048/50000: episode: 306, duration: 0.139s, episode steps:  15, steps per second: 108, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 28.978538, mae: 57.621588, mean_q: 114.497002, mean_eps: 0.866240\n",
            "  7060/50000: episode: 307, duration: 0.108s, episode steps:  12, steps per second: 111, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 58.105533, mae: 57.874332, mean_q: 113.523852, mean_eps: 0.865983\n",
            "  7091/50000: episode: 308, duration: 0.295s, episode steps:  31, steps per second: 105, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 79.346314, mae: 58.207708, mean_q: 114.500312, mean_eps: 0.865575\n",
            "  7120/50000: episode: 309, duration: 0.256s, episode steps:  29, steps per second: 113, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 55.194657, mae: 57.983125, mean_q: 114.226526, mean_eps: 0.865005\n",
            "  7135/50000: episode: 310, duration: 0.138s, episode steps:  15, steps per second: 109, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 58.363407, mae: 57.262638, mean_q: 114.047984, mean_eps: 0.864587\n",
            "  7214/50000: episode: 311, duration: 0.712s, episode steps:  79, steps per second: 111, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 55.979026, mae: 58.179034, mean_q: 115.381877, mean_eps: 0.863694\n",
            "  7237/50000: episode: 312, duration: 0.215s, episode steps:  23, steps per second: 107, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 67.680808, mae: 57.845315, mean_q: 113.635879, mean_eps: 0.862725\n",
            "  7303/50000: episode: 313, duration: 0.568s, episode steps:  66, steps per second: 116, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 50.888770, mae: 56.895235, mean_q: 112.865030, mean_eps: 0.861879\n",
            "  7327/50000: episode: 314, duration: 0.229s, episode steps:  24, steps per second: 105, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 89.128615, mae: 58.163131, mean_q: 113.759102, mean_eps: 0.861025\n",
            "  7349/50000: episode: 315, duration: 0.193s, episode steps:  22, steps per second: 114, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 70.928353, mae: 57.770319, mean_q: 112.546879, mean_eps: 0.860588\n",
            "  7398/50000: episode: 316, duration: 0.429s, episode steps:  49, steps per second: 114, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 47.165195, mae: 56.810989, mean_q: 112.755611, mean_eps: 0.859913\n",
            "  7412/50000: episode: 317, duration: 0.134s, episode steps:  14, steps per second: 105, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 33.070995, mae: 56.611429, mean_q: 112.390596, mean_eps: 0.859314\n",
            "  7443/50000: episode: 318, duration: 0.294s, episode steps:  31, steps per second: 105, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 46.734578, mae: 55.536765, mean_q: 110.977206, mean_eps: 0.858887\n",
            "  7462/50000: episode: 319, duration: 0.171s, episode steps:  19, steps per second: 111, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 44.602372, mae: 56.190612, mean_q: 113.140351, mean_eps: 0.858412\n",
            "  7475/50000: episode: 320, duration: 0.123s, episode steps:  13, steps per second: 106, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 46.832758, mae: 56.191371, mean_q: 110.754954, mean_eps: 0.858108\n",
            "  7495/50000: episode: 321, duration: 0.185s, episode steps:  20, steps per second: 108, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 30.486941, mae: 56.501859, mean_q: 112.192670, mean_eps: 0.857795\n",
            "  7507/50000: episode: 322, duration: 0.119s, episode steps:  12, steps per second: 100, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 65.932381, mae: 57.368993, mean_q: 113.483615, mean_eps: 0.857491\n",
            "  7548/50000: episode: 323, duration: 0.384s, episode steps:  41, steps per second: 107, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 39.829261, mae: 57.510218, mean_q: 114.578851, mean_eps: 0.856987\n",
            "  7622/50000: episode: 324, duration: 0.660s, episode steps:  74, steps per second: 112, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 64.708073, mae: 57.011734, mean_q: 113.021492, mean_eps: 0.855895\n",
            "  7641/50000: episode: 325, duration: 0.182s, episode steps:  19, steps per second: 105, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 39.172578, mae: 55.936349, mean_q: 111.288247, mean_eps: 0.855011\n",
            "  7666/50000: episode: 326, duration: 0.224s, episode steps:  25, steps per second: 112, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 27.948926, mae: 57.014205, mean_q: 113.078164, mean_eps: 0.854593\n",
            "  7699/50000: episode: 327, duration: 0.298s, episode steps:  33, steps per second: 111, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 50.826775, mae: 55.989112, mean_q: 113.301767, mean_eps: 0.854042\n",
            "  7709/50000: episode: 328, duration: 0.091s, episode steps:  10, steps per second: 110, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 68.547305, mae: 54.490413, mean_q: 108.040627, mean_eps: 0.853633\n",
            "  7750/50000: episode: 329, duration: 0.372s, episode steps:  41, steps per second: 110, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 58.625069, mae: 56.915936, mean_q: 113.384419, mean_eps: 0.853149\n",
            "  7789/50000: episode: 330, duration: 0.358s, episode steps:  39, steps per second: 109, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 45.884927, mae: 55.879388, mean_q: 111.436551, mean_eps: 0.852389\n",
            "  7824/50000: episode: 331, duration: 0.313s, episode steps:  35, steps per second: 112, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 61.898212, mae: 56.236912, mean_q: 111.285424, mean_eps: 0.851686\n",
            "  7847/50000: episode: 332, duration: 0.217s, episode steps:  23, steps per second: 106, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 62.691008, mae: 57.008465, mean_q: 112.388885, mean_eps: 0.851135\n",
            "  7877/50000: episode: 333, duration: 0.285s, episode steps:  30, steps per second: 105, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 41.815061, mae: 55.374755, mean_q: 110.665735, mean_eps: 0.850632\n",
            "  7891/50000: episode: 334, duration: 0.126s, episode steps:  14, steps per second: 111, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 51.276948, mae: 57.088200, mean_q: 114.350438, mean_eps: 0.850213\n",
            "  7914/50000: episode: 335, duration: 0.205s, episode steps:  23, steps per second: 112, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.609 [0.000, 1.000],  loss: 48.738498, mae: 57.304381, mean_q: 112.759567, mean_eps: 0.849862\n",
            "  7938/50000: episode: 336, duration: 0.240s, episode steps:  24, steps per second: 100, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 46.440405, mae: 56.227508, mean_q: 112.339096, mean_eps: 0.849416\n",
            "  7950/50000: episode: 337, duration: 0.143s, episode steps:  12, steps per second:  84, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 59.927485, mae: 56.312619, mean_q: 111.834311, mean_eps: 0.849074\n",
            "  7970/50000: episode: 338, duration: 0.265s, episode steps:  20, steps per second:  76, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 25.417411, mae: 55.517108, mean_q: 110.735338, mean_eps: 0.848770\n",
            "  7988/50000: episode: 339, duration: 0.240s, episode steps:  18, steps per second:  75, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 33.941031, mae: 55.721503, mean_q: 112.650467, mean_eps: 0.848409\n",
            "  8006/50000: episode: 340, duration: 0.316s, episode steps:  18, steps per second:  57, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 57.215756, mae: 57.057445, mean_q: 112.908783, mean_eps: 0.848067\n",
            "  8039/50000: episode: 341, duration: 1.198s, episode steps:  33, steps per second:  28, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.606 [0.000, 1.000],  loss: 64.877824, mae: 55.360582, mean_q: 109.489632, mean_eps: 0.847582\n",
            "  8095/50000: episode: 342, duration: 1.389s, episode steps:  56, steps per second:  40, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.554 [0.000, 1.000],  loss: 33.580108, mae: 56.294581, mean_q: 112.253848, mean_eps: 0.846736\n",
            "  8186/50000: episode: 343, duration: 1.182s, episode steps:  91, steps per second:  77, episode reward: 91.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 54.614441, mae: 56.155578, mean_q: 111.041848, mean_eps: 0.845340\n",
            "  8255/50000: episode: 344, duration: 0.602s, episode steps:  69, steps per second: 115, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 52.327306, mae: 56.777398, mean_q: 112.966682, mean_eps: 0.843820\n",
            "  8280/50000: episode: 345, duration: 0.235s, episode steps:  25, steps per second: 106, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.360 [0.000, 1.000],  loss: 65.966923, mae: 56.814803, mean_q: 113.786805, mean_eps: 0.842927\n",
            "  8328/50000: episode: 346, duration: 0.427s, episode steps:  48, steps per second: 112, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 34.271504, mae: 56.350600, mean_q: 111.899870, mean_eps: 0.842233\n",
            "  8349/50000: episode: 347, duration: 0.189s, episode steps:  21, steps per second: 111, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 25.557262, mae: 56.029294, mean_q: 112.427692, mean_eps: 0.841578\n",
            "  8362/50000: episode: 348, duration: 0.129s, episode steps:  13, steps per second: 101, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 57.298161, mae: 57.265935, mean_q: 113.695915, mean_eps: 0.841255\n",
            "  8373/50000: episode: 349, duration: 0.105s, episode steps:  11, steps per second: 105, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 37.332416, mae: 56.280905, mean_q: 111.244296, mean_eps: 0.841027\n",
            "  8437/50000: episode: 350, duration: 0.551s, episode steps:  64, steps per second: 116, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 42.569860, mae: 56.740995, mean_q: 112.957121, mean_eps: 0.840315\n",
            "  8484/50000: episode: 351, duration: 0.410s, episode steps:  47, steps per second: 115, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 56.558654, mae: 56.614979, mean_q: 112.906122, mean_eps: 0.839260\n",
            "  8506/50000: episode: 352, duration: 0.208s, episode steps:  22, steps per second: 106, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 38.082143, mae: 57.298274, mean_q: 114.909616, mean_eps: 0.838604\n",
            "  8536/50000: episode: 353, duration: 0.273s, episode steps:  30, steps per second: 110, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 51.962740, mae: 57.323039, mean_q: 114.042962, mean_eps: 0.838110\n",
            "  8549/50000: episode: 354, duration: 0.117s, episode steps:  13, steps per second: 111, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 30.375417, mae: 56.082448, mean_q: 112.224609, mean_eps: 0.837702\n",
            "  8563/50000: episode: 355, duration: 0.140s, episode steps:  14, steps per second: 100, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 37.809916, mae: 57.629630, mean_q: 116.198316, mean_eps: 0.837446\n",
            "  8588/50000: episode: 356, duration: 0.218s, episode steps:  25, steps per second: 114, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 56.425540, mae: 57.464250, mean_q: 114.260814, mean_eps: 0.837075\n",
            "  8606/50000: episode: 357, duration: 0.160s, episode steps:  18, steps per second: 112, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 35.180344, mae: 56.492703, mean_q: 113.162153, mean_eps: 0.836667\n",
            "  8628/50000: episode: 358, duration: 0.206s, episode steps:  22, steps per second: 107, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 28.305977, mae: 54.854256, mean_q: 110.183423, mean_eps: 0.836286\n",
            "  8641/50000: episode: 359, duration: 0.119s, episode steps:  13, steps per second: 110, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 20.618593, mae: 56.944664, mean_q: 114.467927, mean_eps: 0.835954\n",
            "  8705/50000: episode: 360, duration: 0.555s, episode steps:  64, steps per second: 115, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 46.678724, mae: 56.648143, mean_q: 113.227108, mean_eps: 0.835222\n",
            "  8725/50000: episode: 361, duration: 0.186s, episode steps:  20, steps per second: 107, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.350 [0.000, 1.000],  loss: 32.023115, mae: 55.332791, mean_q: 112.264037, mean_eps: 0.834425\n",
            "  8761/50000: episode: 362, duration: 0.317s, episode steps:  36, steps per second: 114, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 41.957133, mae: 56.176698, mean_q: 112.479810, mean_eps: 0.833893\n",
            "  8780/50000: episode: 363, duration: 0.165s, episode steps:  19, steps per second: 115, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 83.155568, mae: 57.552103, mean_q: 114.424765, mean_eps: 0.833370\n",
            "  8815/50000: episode: 364, duration: 0.308s, episode steps:  35, steps per second: 114, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 34.723394, mae: 56.436675, mean_q: 112.588411, mean_eps: 0.832857\n",
            "  8824/50000: episode: 365, duration: 0.080s, episode steps:   9, steps per second: 112, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 29.517300, mae: 57.724390, mean_q: 115.525200, mean_eps: 0.832439\n",
            "  8853/50000: episode: 366, duration: 0.257s, episode steps:  29, steps per second: 113, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 32.503003, mae: 55.627288, mean_q: 112.104419, mean_eps: 0.832078\n",
            "  8884/50000: episode: 367, duration: 0.270s, episode steps:  31, steps per second: 115, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.613 [0.000, 1.000],  loss: 31.290023, mae: 56.308498, mean_q: 113.165612, mean_eps: 0.831508\n",
            "  8906/50000: episode: 368, duration: 0.214s, episode steps:  22, steps per second: 103, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 55.119684, mae: 57.056879, mean_q: 112.944973, mean_eps: 0.831005\n",
            "  8919/50000: episode: 369, duration: 0.122s, episode steps:  13, steps per second: 106, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 33.587497, mae: 55.574956, mean_q: 109.703585, mean_eps: 0.830672\n",
            "  8941/50000: episode: 370, duration: 0.214s, episode steps:  22, steps per second: 103, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 34.072506, mae: 57.171208, mean_q: 114.414696, mean_eps: 0.830339\n",
            "  8956/50000: episode: 371, duration: 0.137s, episode steps:  15, steps per second: 110, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 30.110263, mae: 55.428966, mean_q: 111.960189, mean_eps: 0.829988\n",
            "  8970/50000: episode: 372, duration: 0.134s, episode steps:  14, steps per second: 105, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 43.828116, mae: 55.539185, mean_q: 110.538426, mean_eps: 0.829713\n",
            "  9016/50000: episode: 373, duration: 0.404s, episode steps:  46, steps per second: 114, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 33.658281, mae: 56.184511, mean_q: 113.248997, mean_eps: 0.829143\n",
            "  9054/50000: episode: 374, duration: 0.340s, episode steps:  38, steps per second: 112, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.395 [0.000, 1.000],  loss: 34.532765, mae: 57.014219, mean_q: 114.012618, mean_eps: 0.828345\n",
            "  9069/50000: episode: 375, duration: 0.148s, episode steps:  15, steps per second: 101, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 50.957302, mae: 57.851987, mean_q: 115.699899, mean_eps: 0.827841\n",
            "  9115/50000: episode: 376, duration: 0.416s, episode steps:  46, steps per second: 111, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 25.254068, mae: 56.934205, mean_q: 114.113106, mean_eps: 0.827261\n",
            "  9161/50000: episode: 377, duration: 0.510s, episode steps:  46, steps per second:  90, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.413 [0.000, 1.000],  loss: 38.841894, mae: 57.807503, mean_q: 115.780234, mean_eps: 0.826387\n",
            "  9171/50000: episode: 378, duration: 0.140s, episode steps:  10, steps per second:  71, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 49.928498, mae: 58.032286, mean_q: 114.551667, mean_eps: 0.825856\n",
            "  9188/50000: episode: 379, duration: 0.239s, episode steps:  17, steps per second:  71, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 27.381934, mae: 58.388968, mean_q: 116.219194, mean_eps: 0.825599\n",
            "  9207/50000: episode: 380, duration: 0.245s, episode steps:  19, steps per second:  78, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 38.110360, mae: 58.806201, mean_q: 117.967123, mean_eps: 0.825257\n",
            "  9240/50000: episode: 381, duration: 0.411s, episode steps:  33, steps per second:  80, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 35.792665, mae: 57.262559, mean_q: 115.310785, mean_eps: 0.824763\n",
            "  9252/50000: episode: 382, duration: 0.156s, episode steps:  12, steps per second:  77, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 43.377167, mae: 59.158361, mean_q: 118.316115, mean_eps: 0.824335\n",
            "  9269/50000: episode: 383, duration: 0.228s, episode steps:  17, steps per second:  74, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 63.127691, mae: 58.267832, mean_q: 114.922050, mean_eps: 0.824060\n",
            "  9288/50000: episode: 384, duration: 0.252s, episode steps:  19, steps per second:  75, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 39.194775, mae: 58.988994, mean_q: 117.314702, mean_eps: 0.823718\n",
            "  9425/50000: episode: 385, duration: 1.516s, episode steps: 137, steps per second:  90, episode reward: 137.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 32.553329, mae: 56.984340, mean_q: 114.594650, mean_eps: 0.822236\n",
            "  9483/50000: episode: 386, duration: 0.513s, episode steps:  58, steps per second: 113, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 38.792913, mae: 57.996160, mean_q: 116.233058, mean_eps: 0.820384\n",
            "  9540/50000: episode: 387, duration: 0.500s, episode steps:  57, steps per second: 114, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.544 [0.000, 1.000],  loss: 30.692917, mae: 57.674468, mean_q: 115.822380, mean_eps: 0.819291\n",
            "  9562/50000: episode: 388, duration: 0.195s, episode steps:  22, steps per second: 113, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 23.165648, mae: 56.511323, mean_q: 115.038584, mean_eps: 0.818541\n",
            "  9629/50000: episode: 389, duration: 0.584s, episode steps:  67, steps per second: 115, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 36.869937, mae: 57.165892, mean_q: 115.261134, mean_eps: 0.817695\n",
            "  9702/50000: episode: 390, duration: 0.657s, episode steps:  73, steps per second: 111, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 34.968769, mae: 57.518760, mean_q: 115.284807, mean_eps: 0.816365\n",
            "  9718/50000: episode: 391, duration: 0.144s, episode steps:  16, steps per second: 111, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 47.956321, mae: 60.234720, mean_q: 119.962434, mean_eps: 0.815519\n",
            "  9820/50000: episode: 392, duration: 0.888s, episode steps: 102, steps per second: 115, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.451 [0.000, 1.000],  loss: 35.510475, mae: 57.739191, mean_q: 115.977892, mean_eps: 0.814399\n",
            "  9842/50000: episode: 393, duration: 0.195s, episode steps:  22, steps per second: 113, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 46.046707, mae: 58.486342, mean_q: 117.201542, mean_eps: 0.813221\n",
            "  9856/50000: episode: 394, duration: 0.131s, episode steps:  14, steps per second: 107, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 40.494530, mae: 58.584827, mean_q: 115.243814, mean_eps: 0.812878\n",
            "  9875/50000: episode: 395, duration: 0.181s, episode steps:  19, steps per second: 105, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 43.502434, mae: 59.078989, mean_q: 118.277576, mean_eps: 0.812565\n",
            "  9906/50000: episode: 396, duration: 0.285s, episode steps:  31, steps per second: 109, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 27.561746, mae: 58.769405, mean_q: 118.236212, mean_eps: 0.812090\n",
            "  9942/50000: episode: 397, duration: 0.328s, episode steps:  36, steps per second: 110, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 26.059376, mae: 57.883020, mean_q: 117.432855, mean_eps: 0.811453\n",
            " 10026/50000: episode: 398, duration: 0.713s, episode steps:  84, steps per second: 118, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 27.754663, mae: 58.014690, mean_q: 117.291526, mean_eps: 0.810314\n",
            " 10052/50000: episode: 399, duration: 0.241s, episode steps:  26, steps per second: 108, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 35.055635, mae: 58.525409, mean_q: 117.857676, mean_eps: 0.809268\n",
            " 10063/50000: episode: 400, duration: 0.097s, episode steps:  11, steps per second: 114, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 41.048443, mae: 60.152236, mean_q: 119.813026, mean_eps: 0.808917\n",
            " 10108/50000: episode: 401, duration: 0.407s, episode steps:  45, steps per second: 111, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 37.400402, mae: 58.254604, mean_q: 116.945395, mean_eps: 0.808385\n",
            " 10124/50000: episode: 402, duration: 0.141s, episode steps:  16, steps per second: 113, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 46.170645, mae: 59.757601, mean_q: 119.212070, mean_eps: 0.807805\n",
            " 10208/50000: episode: 403, duration: 0.736s, episode steps:  84, steps per second: 114, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 38.424921, mae: 59.253624, mean_q: 118.848458, mean_eps: 0.806856\n",
            " 10258/50000: episode: 404, duration: 0.452s, episode steps:  50, steps per second: 111, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 42.688805, mae: 58.297324, mean_q: 116.609479, mean_eps: 0.805582\n",
            " 10328/50000: episode: 405, duration: 0.621s, episode steps:  70, steps per second: 113, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 26.601874, mae: 59.370620, mean_q: 120.317593, mean_eps: 0.804442\n",
            " 10339/50000: episode: 406, duration: 0.109s, episode steps:  11, steps per second: 101, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 25.869000, mae: 59.159162, mean_q: 119.546869, mean_eps: 0.803673\n",
            " 10404/50000: episode: 407, duration: 0.572s, episode steps:  65, steps per second: 114, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 35.914089, mae: 58.829872, mean_q: 118.751864, mean_eps: 0.802951\n",
            " 10468/50000: episode: 408, duration: 0.543s, episode steps:  64, steps per second: 118, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.406 [0.000, 1.000],  loss: 30.425086, mae: 59.837625, mean_q: 121.022364, mean_eps: 0.801725\n",
            " 10488/50000: episode: 409, duration: 0.185s, episode steps:  20, steps per second: 108, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 27.832426, mae: 59.163380, mean_q: 121.131744, mean_eps: 0.800927\n",
            " 10529/50000: episode: 410, duration: 0.453s, episode steps:  41, steps per second:  91, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.610 [0.000, 1.000],  loss: 37.281426, mae: 60.086054, mean_q: 121.251248, mean_eps: 0.800348\n",
            " 10548/50000: episode: 411, duration: 0.258s, episode steps:  19, steps per second:  74, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 40.359216, mae: 59.161219, mean_q: 118.779364, mean_eps: 0.799778\n",
            " 10566/50000: episode: 412, duration: 0.259s, episode steps:  18, steps per second:  69, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 21.567383, mae: 59.961424, mean_q: 121.512391, mean_eps: 0.799427\n",
            " 10583/50000: episode: 413, duration: 0.226s, episode steps:  17, steps per second:  75, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 30.006967, mae: 58.113388, mean_q: 118.567366, mean_eps: 0.799094\n",
            " 10628/50000: episode: 414, duration: 0.582s, episode steps:  45, steps per second:  77, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 31.665604, mae: 59.788478, mean_q: 121.473669, mean_eps: 0.798505\n",
            " 10697/50000: episode: 415, duration: 0.869s, episode steps:  69, steps per second:  79, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 28.986221, mae: 60.143707, mean_q: 121.985808, mean_eps: 0.797422\n",
            " 10711/50000: episode: 416, duration: 0.196s, episode steps:  14, steps per second:  71, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 41.220739, mae: 59.788911, mean_q: 120.900880, mean_eps: 0.796633\n",
            " 10805/50000: episode: 417, duration: 0.952s, episode steps:  94, steps per second:  99, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 37.014917, mae: 60.813381, mean_q: 123.110493, mean_eps: 0.795608\n",
            " 10828/50000: episode: 418, duration: 0.221s, episode steps:  23, steps per second: 104, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 37.669300, mae: 60.510530, mean_q: 122.131466, mean_eps: 0.794496\n",
            " 10852/50000: episode: 419, duration: 0.206s, episode steps:  24, steps per second: 117, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 28.541442, mae: 62.291894, mean_q: 125.648173, mean_eps: 0.794049\n",
            " 10870/50000: episode: 420, duration: 0.166s, episode steps:  18, steps per second: 109, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 27.629962, mae: 62.611428, mean_q: 127.717628, mean_eps: 0.793650\n",
            " 10885/50000: episode: 421, duration: 0.132s, episode steps:  15, steps per second: 113, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 28.959344, mae: 61.666267, mean_q: 125.818785, mean_eps: 0.793337\n",
            " 10902/50000: episode: 422, duration: 0.145s, episode steps:  17, steps per second: 117, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 42.650300, mae: 61.089837, mean_q: 122.793623, mean_eps: 0.793033\n",
            " 11029/50000: episode: 423, duration: 1.089s, episode steps: 127, steps per second: 117, episode reward: 127.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 34.814807, mae: 61.632777, mean_q: 124.807340, mean_eps: 0.791665\n",
            " 11059/50000: episode: 424, duration: 0.279s, episode steps:  30, steps per second: 107, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 32.080920, mae: 63.376985, mean_q: 128.445183, mean_eps: 0.790173\n",
            " 11102/50000: episode: 425, duration: 0.359s, episode steps:  43, steps per second: 120, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 33.209933, mae: 62.445897, mean_q: 126.270028, mean_eps: 0.789480\n",
            " 11157/50000: episode: 426, duration: 0.479s, episode steps:  55, steps per second: 115, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 37.213570, mae: 62.306727, mean_q: 126.034288, mean_eps: 0.788549\n",
            " 11185/50000: episode: 427, duration: 0.261s, episode steps:  28, steps per second: 107, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 44.438997, mae: 63.547720, mean_q: 128.017618, mean_eps: 0.787760\n",
            " 11230/50000: episode: 428, duration: 0.390s, episode steps:  45, steps per second: 115, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 37.876994, mae: 63.960355, mean_q: 128.725588, mean_eps: 0.787067\n",
            " 11265/50000: episode: 429, duration: 0.306s, episode steps:  35, steps per second: 114, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 24.377934, mae: 62.955345, mean_q: 128.965091, mean_eps: 0.786307\n",
            " 11295/50000: episode: 430, duration: 0.283s, episode steps:  30, steps per second: 106, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 33.780138, mae: 62.308223, mean_q: 126.474821, mean_eps: 0.785690\n",
            " 11309/50000: episode: 431, duration: 0.124s, episode steps:  14, steps per second: 113, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.786 [0.000, 1.000],  loss: 55.422218, mae: 61.250165, mean_q: 123.863478, mean_eps: 0.785272\n",
            " 11365/50000: episode: 432, duration: 0.493s, episode steps:  56, steps per second: 114, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 31.300685, mae: 63.061403, mean_q: 127.843637, mean_eps: 0.784606\n",
            " 11381/50000: episode: 433, duration: 0.162s, episode steps:  16, steps per second:  99, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 51.726925, mae: 63.170375, mean_q: 126.931503, mean_eps: 0.783923\n",
            " 11394/50000: episode: 434, duration: 0.135s, episode steps:  13, steps per second:  96, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 38.553705, mae: 64.011318, mean_q: 128.572408, mean_eps: 0.783647\n",
            " 11412/50000: episode: 435, duration: 0.162s, episode steps:  18, steps per second: 111, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 37.318990, mae: 61.973200, mean_q: 127.261108, mean_eps: 0.783353\n",
            " 11432/50000: episode: 436, duration: 0.175s, episode steps:  20, steps per second: 114, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 32.554899, mae: 63.715656, mean_q: 128.374658, mean_eps: 0.782992\n",
            " 11467/50000: episode: 437, duration: 0.309s, episode steps:  35, steps per second: 113, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 32.414504, mae: 63.246266, mean_q: 128.818375, mean_eps: 0.782469\n",
            " 11546/50000: episode: 438, duration: 0.686s, episode steps:  79, steps per second: 115, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.544 [0.000, 1.000],  loss: 37.061899, mae: 63.617494, mean_q: 129.607946, mean_eps: 0.781386\n",
            " 11594/50000: episode: 439, duration: 0.419s, episode steps:  48, steps per second: 114, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 29.741811, mae: 64.638606, mean_q: 132.161767, mean_eps: 0.780180\n",
            " 11615/50000: episode: 440, duration: 0.221s, episode steps:  21, steps per second:  95, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 34.479604, mae: 63.133517, mean_q: 129.125562, mean_eps: 0.779524\n",
            " 11681/50000: episode: 441, duration: 0.587s, episode steps:  66, steps per second: 112, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 33.604863, mae: 65.370580, mean_q: 132.382719, mean_eps: 0.778698\n",
            " 11740/50000: episode: 442, duration: 0.535s, episode steps:  59, steps per second: 110, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 35.001409, mae: 65.375673, mean_q: 132.341838, mean_eps: 0.777510\n",
            " 11825/50000: episode: 443, duration: 0.763s, episode steps:  85, steps per second: 111, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 46.156392, mae: 64.762161, mean_q: 131.488738, mean_eps: 0.776142\n",
            " 11847/50000: episode: 444, duration: 0.211s, episode steps:  22, steps per second: 105, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 29.035861, mae: 66.279111, mean_q: 134.226864, mean_eps: 0.775126\n",
            " 11890/50000: episode: 445, duration: 0.537s, episode steps:  43, steps per second:  80, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 37.412305, mae: 67.511314, mean_q: 137.171933, mean_eps: 0.774508\n",
            " 11909/50000: episode: 446, duration: 0.261s, episode steps:  19, steps per second:  73, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 33.897887, mae: 67.524330, mean_q: 138.749334, mean_eps: 0.773919\n",
            " 12040/50000: episode: 447, duration: 1.599s, episode steps: 131, steps per second:  82, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 43.150137, mae: 67.337862, mean_q: 136.778618, mean_eps: 0.772494\n",
            " 12066/50000: episode: 448, duration: 0.343s, episode steps:  26, steps per second:  76, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 34.191525, mae: 68.291589, mean_q: 139.745301, mean_eps: 0.771003\n",
            " 12116/50000: episode: 449, duration: 0.562s, episode steps:  50, steps per second:  89, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.580 [0.000, 1.000],  loss: 46.655095, mae: 68.872118, mean_q: 139.642058, mean_eps: 0.770281\n",
            " 12136/50000: episode: 450, duration: 0.177s, episode steps:  20, steps per second: 113, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 37.106093, mae: 68.061990, mean_q: 139.855795, mean_eps: 0.769615\n",
            " 12154/50000: episode: 451, duration: 0.164s, episode steps:  18, steps per second: 110, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 49.478568, mae: 69.015541, mean_q: 138.195706, mean_eps: 0.769254\n",
            " 12167/50000: episode: 452, duration: 0.127s, episode steps:  13, steps per second: 102, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 39.837846, mae: 68.191399, mean_q: 139.752813, mean_eps: 0.768960\n",
            " 12227/50000: episode: 453, duration: 0.547s, episode steps:  60, steps per second: 110, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 37.011247, mae: 68.694213, mean_q: 139.957365, mean_eps: 0.768267\n",
            " 12244/50000: episode: 454, duration: 0.155s, episode steps:  17, steps per second: 110, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.294 [0.000, 1.000],  loss: 57.589657, mae: 70.787900, mean_q: 142.058317, mean_eps: 0.767535\n",
            " 12265/50000: episode: 455, duration: 0.193s, episode steps:  21, steps per second: 109, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 28.737296, mae: 69.399212, mean_q: 142.194286, mean_eps: 0.767174\n",
            " 12279/50000: episode: 456, duration: 0.133s, episode steps:  14, steps per second: 106, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 38.263365, mae: 70.036847, mean_q: 142.731485, mean_eps: 0.766841\n",
            " 12306/50000: episode: 457, duration: 0.253s, episode steps:  27, steps per second: 107, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 49.938960, mae: 68.860462, mean_q: 140.239755, mean_eps: 0.766452\n",
            " 12340/50000: episode: 458, duration: 0.310s, episode steps:  34, steps per second: 110, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 41.773119, mae: 70.261528, mean_q: 143.539720, mean_eps: 0.765873\n",
            " 12420/50000: episode: 459, duration: 0.712s, episode steps:  80, steps per second: 112, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 38.336766, mae: 70.438558, mean_q: 143.397435, mean_eps: 0.764790\n",
            " 12508/50000: episode: 460, duration: 0.755s, episode steps:  88, steps per second: 117, episode reward: 88.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 40.776427, mae: 70.807664, mean_q: 144.111351, mean_eps: 0.763193\n",
            " 12559/50000: episode: 461, duration: 0.445s, episode steps:  51, steps per second: 115, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 33.988138, mae: 71.517262, mean_q: 146.563730, mean_eps: 0.761873\n",
            " 12579/50000: episode: 462, duration: 0.173s, episode steps:  20, steps per second: 115, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 33.608183, mae: 71.429500, mean_q: 146.694930, mean_eps: 0.761199\n",
            " 12610/50000: episode: 463, duration: 0.282s, episode steps:  31, steps per second: 110, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 46.740998, mae: 72.318403, mean_q: 146.775667, mean_eps: 0.760714\n",
            " 12671/50000: episode: 464, duration: 0.543s, episode steps:  61, steps per second: 112, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 40.122158, mae: 71.917587, mean_q: 147.300819, mean_eps: 0.759840\n",
            " 12704/50000: episode: 465, duration: 0.293s, episode steps:  33, steps per second: 113, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 45.108926, mae: 73.763441, mean_q: 149.440881, mean_eps: 0.758947\n",
            " 12764/50000: episode: 466, duration: 0.533s, episode steps:  60, steps per second: 113, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 43.715179, mae: 73.301392, mean_q: 149.002709, mean_eps: 0.758064\n",
            " 12804/50000: episode: 467, duration: 0.352s, episode steps:  40, steps per second: 114, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 48.904946, mae: 73.942585, mean_q: 150.104008, mean_eps: 0.757113\n",
            " 12884/50000: episode: 468, duration: 0.722s, episode steps:  80, steps per second: 111, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 47.003780, mae: 73.540566, mean_q: 149.662217, mean_eps: 0.755973\n",
            " 13018/50000: episode: 469, duration: 1.159s, episode steps: 134, steps per second: 116, episode reward: 134.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 51.887362, mae: 74.924991, mean_q: 152.836108, mean_eps: 0.753941\n",
            " 13104/50000: episode: 470, duration: 0.761s, episode steps:  86, steps per second: 113, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 42.724403, mae: 76.762318, mean_q: 156.757636, mean_eps: 0.751850\n",
            " 13136/50000: episode: 471, duration: 0.293s, episode steps:  32, steps per second: 109, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 39.631520, mae: 76.915226, mean_q: 157.597155, mean_eps: 0.750729\n",
            " 13162/50000: episode: 472, duration: 0.250s, episode steps:  26, steps per second: 104, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 37.536618, mae: 77.227188, mean_q: 157.966942, mean_eps: 0.750178\n",
            " 13180/50000: episode: 473, duration: 0.177s, episode steps:  18, steps per second: 102, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 56.242493, mae: 76.325097, mean_q: 155.893830, mean_eps: 0.749761\n",
            " 13205/50000: episode: 474, duration: 0.233s, episode steps:  25, steps per second: 107, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 61.903490, mae: 76.908212, mean_q: 156.161412, mean_eps: 0.749352\n",
            " 13223/50000: episode: 475, duration: 0.248s, episode steps:  18, steps per second:  72, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 43.116466, mae: 77.918016, mean_q: 158.390299, mean_eps: 0.748943\n",
            " 13376/50000: episode: 476, duration: 1.886s, episode steps: 153, steps per second:  81, episode reward: 153.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 50.564355, mae: 79.042711, mean_q: 160.928990, mean_eps: 0.747319\n",
            " 13409/50000: episode: 477, duration: 0.427s, episode steps:  33, steps per second:  77, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 56.658380, mae: 78.559186, mean_q: 159.413298, mean_eps: 0.745552\n",
            " 13423/50000: episode: 478, duration: 0.188s, episode steps:  14, steps per second:  74, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 50.457836, mae: 78.212963, mean_q: 158.334587, mean_eps: 0.745106\n",
            " 13457/50000: episode: 479, duration: 0.399s, episode steps:  34, steps per second:  85, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.441 [0.000, 1.000],  loss: 54.603126, mae: 78.708017, mean_q: 160.068764, mean_eps: 0.744650\n",
            " 13490/50000: episode: 480, duration: 0.304s, episode steps:  33, steps per second: 109, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 70.431600, mae: 78.555868, mean_q: 159.034950, mean_eps: 0.744013\n",
            " 13644/50000: episode: 481, duration: 1.346s, episode steps: 154, steps per second: 114, episode reward: 154.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 54.030999, mae: 80.220627, mean_q: 164.063575, mean_eps: 0.742237\n",
            " 13669/50000: episode: 482, duration: 0.227s, episode steps:  25, steps per second: 110, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 59.138498, mae: 80.836918, mean_q: 164.890607, mean_eps: 0.740536\n",
            " 13690/50000: episode: 483, duration: 0.190s, episode steps:  21, steps per second: 110, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 103.119085, mae: 80.755172, mean_q: 163.417563, mean_eps: 0.740099\n",
            " 13708/50000: episode: 484, duration: 0.172s, episode steps:  18, steps per second: 105, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 49.122741, mae: 80.587494, mean_q: 165.008202, mean_eps: 0.739729\n",
            " 13754/50000: episode: 485, duration: 0.427s, episode steps:  46, steps per second: 108, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 64.661339, mae: 82.350904, mean_q: 167.196070, mean_eps: 0.739120\n",
            " 13825/50000: episode: 486, duration: 0.637s, episode steps:  71, steps per second: 111, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 55.538820, mae: 82.912572, mean_q: 168.031254, mean_eps: 0.738009\n",
            " 13861/50000: episode: 487, duration: 0.325s, episode steps:  36, steps per second: 111, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 52.454856, mae: 81.582609, mean_q: 166.727910, mean_eps: 0.736992\n",
            " 13872/50000: episode: 488, duration: 0.105s, episode steps:  11, steps per second: 105, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 46.339554, mae: 85.171220, mean_q: 172.779660, mean_eps: 0.736546\n",
            " 14072/50000: episode: 489, duration: 1.707s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 60.643649, mae: 83.453462, mean_q: 169.950554, mean_eps: 0.734542\n",
            " 14088/50000: episode: 490, duration: 0.146s, episode steps:  16, steps per second: 110, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 61.193177, mae: 86.566926, mean_q: 175.919797, mean_eps: 0.732490\n",
            " 14157/50000: episode: 491, duration: 0.608s, episode steps:  69, steps per second: 113, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.551 [0.000, 1.000],  loss: 48.276950, mae: 85.269066, mean_q: 173.820054, mean_eps: 0.731682\n",
            " 14172/50000: episode: 492, duration: 0.142s, episode steps:  15, steps per second: 106, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 53.172172, mae: 84.492446, mean_q: 172.319539, mean_eps: 0.730884\n",
            " 14219/50000: episode: 493, duration: 0.415s, episode steps:  47, steps per second: 113, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 64.801671, mae: 84.979271, mean_q: 173.057268, mean_eps: 0.730295\n",
            " 14241/50000: episode: 494, duration: 0.198s, episode steps:  22, steps per second: 111, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 53.191675, mae: 86.785176, mean_q: 175.375780, mean_eps: 0.729639\n",
            " 14299/50000: episode: 495, duration: 0.500s, episode steps:  58, steps per second: 116, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.586 [0.000, 1.000],  loss: 87.919010, mae: 86.534932, mean_q: 175.651190, mean_eps: 0.728880\n",
            " 14320/50000: episode: 496, duration: 0.192s, episode steps:  21, steps per second: 109, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 65.347427, mae: 85.400952, mean_q: 174.123626, mean_eps: 0.728129\n",
            " 14352/50000: episode: 497, duration: 0.290s, episode steps:  32, steps per second: 110, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 81.844583, mae: 86.773329, mean_q: 175.259368, mean_eps: 0.727626\n",
            " 14378/50000: episode: 498, duration: 0.225s, episode steps:  26, steps per second: 116, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.423 [0.000, 1.000],  loss: 62.497582, mae: 88.417966, mean_q: 178.919546, mean_eps: 0.727075\n",
            " 14433/50000: episode: 499, duration: 0.485s, episode steps:  55, steps per second: 113, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 54.754374, mae: 87.174640, mean_q: 177.165342, mean_eps: 0.726305\n",
            " 14465/50000: episode: 500, duration: 0.285s, episode steps:  32, steps per second: 112, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 57.371862, mae: 89.470042, mean_q: 181.409392, mean_eps: 0.725479\n",
            " 14523/50000: episode: 501, duration: 0.515s, episode steps:  58, steps per second: 113, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 60.142752, mae: 87.805769, mean_q: 179.681818, mean_eps: 0.724623\n",
            " 14665/50000: episode: 502, duration: 1.587s, episode steps: 142, steps per second:  89, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 70.215934, mae: 88.796522, mean_q: 181.086236, mean_eps: 0.722724\n",
            " 14681/50000: episode: 503, duration: 0.202s, episode steps:  16, steps per second:  79, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 117.621227, mae: 88.989723, mean_q: 180.038773, mean_eps: 0.721223\n",
            " 14711/50000: episode: 504, duration: 0.385s, episode steps:  30, steps per second:  78, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 68.415333, mae: 91.187120, mean_q: 185.035038, mean_eps: 0.720786\n",
            " 14739/50000: episode: 505, duration: 0.346s, episode steps:  28, steps per second:  81, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 64.860343, mae: 90.400830, mean_q: 183.671734, mean_eps: 0.720235\n",
            " 14788/50000: episode: 506, duration: 0.645s, episode steps:  49, steps per second:  76, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 55.001392, mae: 91.041778, mean_q: 184.994639, mean_eps: 0.719503\n",
            " 14803/50000: episode: 507, duration: 0.202s, episode steps:  15, steps per second:  74, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 50.582360, mae: 89.708659, mean_q: 184.927121, mean_eps: 0.718895\n",
            " 14840/50000: episode: 508, duration: 0.352s, episode steps:  37, steps per second: 105, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 46.028868, mae: 90.861172, mean_q: 185.916087, mean_eps: 0.718401\n",
            " 14878/50000: episode: 509, duration: 0.345s, episode steps:  38, steps per second: 110, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 75.100398, mae: 92.335268, mean_q: 189.147817, mean_eps: 0.717688\n",
            " 14900/50000: episode: 510, duration: 0.193s, episode steps:  22, steps per second: 114, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 73.351560, mae: 91.291703, mean_q: 186.826472, mean_eps: 0.717119\n",
            " 14939/50000: episode: 511, duration: 0.333s, episode steps:  39, steps per second: 117, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.590 [0.000, 1.000],  loss: 51.975246, mae: 92.097361, mean_q: 187.761224, mean_eps: 0.716539\n",
            " 14969/50000: episode: 512, duration: 0.273s, episode steps:  30, steps per second: 110, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 65.700626, mae: 93.331502, mean_q: 188.749663, mean_eps: 0.715884\n",
            " 15044/50000: episode: 513, duration: 0.665s, episode steps:  75, steps per second: 113, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 57.374092, mae: 92.479054, mean_q: 188.935098, mean_eps: 0.714886\n",
            " 15073/50000: episode: 514, duration: 0.258s, episode steps:  29, steps per second: 112, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 53.024486, mae: 92.206123, mean_q: 188.793618, mean_eps: 0.713898\n",
            " 15189/50000: episode: 515, duration: 1.007s, episode steps: 116, steps per second: 115, episode reward: 116.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 58.629105, mae: 94.103159, mean_q: 192.504784, mean_eps: 0.712521\n",
            " 15237/50000: episode: 516, duration: 0.423s, episode steps:  48, steps per second: 114, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 61.583210, mae: 94.484809, mean_q: 192.822057, mean_eps: 0.710962\n",
            " 15287/50000: episode: 517, duration: 0.446s, episode steps:  50, steps per second: 112, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 84.546935, mae: 95.551966, mean_q: 193.643386, mean_eps: 0.710032\n",
            " 15321/50000: episode: 518, duration: 0.306s, episode steps:  34, steps per second: 111, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.441 [0.000, 1.000],  loss: 77.671380, mae: 96.628519, mean_q: 196.002037, mean_eps: 0.709234\n",
            " 15427/50000: episode: 519, duration: 0.937s, episode steps: 106, steps per second: 113, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.547 [0.000, 1.000],  loss: 72.071704, mae: 95.596578, mean_q: 195.868671, mean_eps: 0.707903\n",
            " 15478/50000: episode: 520, duration: 0.459s, episode steps:  51, steps per second: 111, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.549 [0.000, 1.000],  loss: 69.132058, mae: 95.928436, mean_q: 196.987081, mean_eps: 0.706412\n",
            " 15547/50000: episode: 521, duration: 0.605s, episode steps:  69, steps per second: 114, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 68.569744, mae: 98.600574, mean_q: 201.187741, mean_eps: 0.705272\n",
            " 15563/50000: episode: 522, duration: 0.158s, episode steps:  16, steps per second: 101, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 59.237386, mae: 98.530965, mean_q: 199.653687, mean_eps: 0.704465\n",
            " 15583/50000: episode: 523, duration: 0.190s, episode steps:  20, steps per second: 105, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 69.625634, mae: 98.551516, mean_q: 201.721684, mean_eps: 0.704122\n",
            " 15675/50000: episode: 524, duration: 0.805s, episode steps:  92, steps per second: 114, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.554 [0.000, 1.000],  loss: 70.084359, mae: 99.519394, mean_q: 202.872327, mean_eps: 0.703059\n",
            " 15824/50000: episode: 525, duration: 1.294s, episode steps: 149, steps per second: 115, episode reward: 149.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 79.535807, mae: 100.102197, mean_q: 203.623968, mean_eps: 0.700769\n",
            " 15868/50000: episode: 526, duration: 0.380s, episode steps:  44, steps per second: 116, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 63.727014, mae: 100.819876, mean_q: 206.507351, mean_eps: 0.698936\n",
            " 15890/50000: episode: 527, duration: 0.205s, episode steps:  22, steps per second: 107, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 82.704278, mae: 100.584725, mean_q: 204.641820, mean_eps: 0.698309\n",
            " 15965/50000: episode: 528, duration: 0.773s, episode steps:  75, steps per second:  97, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 76.148357, mae: 101.165550, mean_q: 207.186465, mean_eps: 0.697387\n",
            " 16002/50000: episode: 529, duration: 0.494s, episode steps:  37, steps per second:  75, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.432 [0.000, 1.000],  loss: 61.808528, mae: 101.939028, mean_q: 208.462125, mean_eps: 0.696323\n",
            " 16014/50000: episode: 530, duration: 0.151s, episode steps:  12, steps per second:  80, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 88.465864, mae: 102.725403, mean_q: 209.133500, mean_eps: 0.695857\n",
            " 16030/50000: episode: 531, duration: 0.215s, episode steps:  16, steps per second:  75, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 72.439103, mae: 102.844958, mean_q: 209.294834, mean_eps: 0.695592\n",
            " 16081/50000: episode: 532, duration: 0.624s, episode steps:  51, steps per second:  82, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 61.050344, mae: 103.677540, mean_q: 211.707235, mean_eps: 0.694955\n",
            " 16104/50000: episode: 533, duration: 0.295s, episode steps:  23, steps per second:  78, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 82.818509, mae: 102.143015, mean_q: 207.753711, mean_eps: 0.694252\n",
            " 16118/50000: episode: 534, duration: 0.186s, episode steps:  14, steps per second:  75, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 95.785583, mae: 104.899664, mean_q: 213.160863, mean_eps: 0.693901\n",
            " 16193/50000: episode: 535, duration: 0.863s, episode steps:  75, steps per second:  87, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 87.291193, mae: 104.337243, mean_q: 212.380109, mean_eps: 0.693055\n",
            " 16343/50000: episode: 536, duration: 1.273s, episode steps: 150, steps per second: 118, episode reward: 150.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 88.084416, mae: 104.504280, mean_q: 212.959326, mean_eps: 0.690917\n",
            " 16366/50000: episode: 537, duration: 0.205s, episode steps:  23, steps per second: 112, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 80.358403, mae: 105.814438, mean_q: 216.538242, mean_eps: 0.689274\n",
            " 16435/50000: episode: 538, duration: 0.617s, episode steps:  69, steps per second: 112, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 71.933814, mae: 107.574711, mean_q: 219.259999, mean_eps: 0.688400\n",
            " 16460/50000: episode: 539, duration: 0.216s, episode steps:  25, steps per second: 116, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 73.359689, mae: 107.315133, mean_q: 218.373438, mean_eps: 0.687507\n",
            " 16477/50000: episode: 540, duration: 0.154s, episode steps:  17, steps per second: 110, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 70.300008, mae: 107.337572, mean_q: 218.976791, mean_eps: 0.687108\n",
            " 16566/50000: episode: 541, duration: 0.779s, episode steps:  89, steps per second: 114, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 85.251917, mae: 106.985540, mean_q: 219.620267, mean_eps: 0.686101\n",
            " 16575/50000: episode: 542, duration: 0.086s, episode steps:   9, steps per second: 105, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 85.579382, mae: 107.755847, mean_q: 219.629142, mean_eps: 0.685170\n",
            " 16608/50000: episode: 543, duration: 0.306s, episode steps:  33, steps per second: 108, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 99.098778, mae: 108.374347, mean_q: 221.163664, mean_eps: 0.684771\n",
            " 16629/50000: episode: 544, duration: 0.192s, episode steps:  21, steps per second: 109, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 184.905212, mae: 106.660996, mean_q: 216.742297, mean_eps: 0.684258\n",
            " 16712/50000: episode: 545, duration: 0.711s, episode steps:  83, steps per second: 117, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 110.167626, mae: 108.189837, mean_q: 220.284261, mean_eps: 0.683270\n",
            " 16726/50000: episode: 546, duration: 0.121s, episode steps:  14, steps per second: 116, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 58.842884, mae: 110.662970, mean_q: 224.569160, mean_eps: 0.682349\n",
            " 16739/50000: episode: 547, duration: 0.117s, episode steps:  13, steps per second: 111, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 83.314405, mae: 108.101830, mean_q: 221.273173, mean_eps: 0.682092\n",
            " 16780/50000: episode: 548, duration: 0.360s, episode steps:  41, steps per second: 114, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.585 [0.000, 1.000],  loss: 77.358441, mae: 108.348479, mean_q: 221.866534, mean_eps: 0.681579\n",
            " 16832/50000: episode: 549, duration: 0.471s, episode steps:  52, steps per second: 110, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 86.824577, mae: 110.036549, mean_q: 223.528245, mean_eps: 0.680696\n",
            " 16880/50000: episode: 550, duration: 0.423s, episode steps:  48, steps per second: 113, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 117.744488, mae: 110.604075, mean_q: 225.488679, mean_eps: 0.679746\n",
            " 16894/50000: episode: 551, duration: 0.125s, episode steps:  14, steps per second: 112, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 80.937923, mae: 107.552801, mean_q: 221.554662, mean_eps: 0.679157\n",
            " 16911/50000: episode: 552, duration: 0.155s, episode steps:  17, steps per second: 109, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 80.877740, mae: 110.991982, mean_q: 229.009669, mean_eps: 0.678862\n",
            " 16964/50000: episode: 553, duration: 0.477s, episode steps:  53, steps per second: 111, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 78.935948, mae: 111.374463, mean_q: 227.027632, mean_eps: 0.678197\n",
            " 16976/50000: episode: 554, duration: 0.117s, episode steps:  12, steps per second: 102, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 55.796907, mae: 108.935175, mean_q: 222.442862, mean_eps: 0.677580\n",
            " 17102/50000: episode: 555, duration: 1.093s, episode steps: 126, steps per second: 115, episode reward: 126.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 84.988412, mae: 110.416289, mean_q: 226.193836, mean_eps: 0.676268\n",
            " 17140/50000: episode: 556, duration: 0.332s, episode steps:  38, steps per second: 115, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 101.384506, mae: 111.377306, mean_q: 228.760485, mean_eps: 0.674710\n",
            " 17165/50000: episode: 557, duration: 0.238s, episode steps:  25, steps per second: 105, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 82.147531, mae: 112.227725, mean_q: 229.251747, mean_eps: 0.674112\n",
            " 17265/50000: episode: 558, duration: 0.871s, episode steps: 100, steps per second: 115, episode reward: 100.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 82.759969, mae: 112.649585, mean_q: 231.040833, mean_eps: 0.672925\n",
            " 17348/50000: episode: 559, duration: 0.882s, episode steps:  83, steps per second:  94, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 102.412957, mae: 113.834685, mean_q: 232.197763, mean_eps: 0.671186\n",
            " 17383/50000: episode: 560, duration: 0.444s, episode steps:  35, steps per second:  79, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 93.959770, mae: 115.132166, mean_q: 234.994450, mean_eps: 0.670065\n",
            " 17410/50000: episode: 561, duration: 0.356s, episode steps:  27, steps per second:  76, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 60.888343, mae: 114.532947, mean_q: 234.146523, mean_eps: 0.669476\n",
            " 17421/50000: episode: 562, duration: 0.143s, episode steps:  11, steps per second:  77, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.091 [0.000, 1.000],  loss: 55.238018, mae: 113.357629, mean_q: 234.039333, mean_eps: 0.669115\n",
            " 17516/50000: episode: 563, duration: 1.139s, episode steps:  95, steps per second:  83, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 84.906938, mae: 114.878190, mean_q: 235.287672, mean_eps: 0.668108\n",
            " 17555/50000: episode: 564, duration: 0.496s, episode steps:  39, steps per second:  79, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 84.328918, mae: 114.927502, mean_q: 235.468804, mean_eps: 0.666835\n",
            " 17679/50000: episode: 565, duration: 1.078s, episode steps: 124, steps per second: 115, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 79.193399, mae: 116.593849, mean_q: 237.546177, mean_eps: 0.665287\n",
            " 17734/50000: episode: 566, duration: 0.478s, episode steps:  55, steps per second: 115, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 87.817594, mae: 117.245785, mean_q: 239.987338, mean_eps: 0.663586\n",
            " 17758/50000: episode: 567, duration: 0.222s, episode steps:  24, steps per second: 108, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 104.156293, mae: 117.427086, mean_q: 240.860612, mean_eps: 0.662836\n",
            " 17846/50000: episode: 568, duration: 0.761s, episode steps:  88, steps per second: 116, episode reward: 88.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 86.882393, mae: 117.486200, mean_q: 239.772633, mean_eps: 0.661771\n",
            " 17873/50000: episode: 569, duration: 0.247s, episode steps:  27, steps per second: 109, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 117.501382, mae: 118.889659, mean_q: 241.746479, mean_eps: 0.660679\n",
            " 17902/50000: episode: 570, duration: 0.259s, episode steps:  29, steps per second: 112, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 107.719856, mae: 117.738049, mean_q: 240.103829, mean_eps: 0.660147\n",
            " 17999/50000: episode: 571, duration: 0.837s, episode steps:  97, steps per second: 116, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 103.105270, mae: 118.908428, mean_q: 242.783027, mean_eps: 0.658950\n",
            " 18128/50000: episode: 572, duration: 1.103s, episode steps: 129, steps per second: 117, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 111.472732, mae: 119.376201, mean_q: 243.851741, mean_eps: 0.656803\n",
            " 18254/50000: episode: 573, duration: 1.070s, episode steps: 126, steps per second: 118, episode reward: 126.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 75.197863, mae: 121.979836, mean_q: 249.032034, mean_eps: 0.654381\n",
            " 18295/50000: episode: 574, duration: 0.363s, episode steps:  41, steps per second: 113, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 116.258335, mae: 122.180322, mean_q: 249.139309, mean_eps: 0.652794\n",
            " 18337/50000: episode: 575, duration: 0.370s, episode steps:  42, steps per second: 113, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 107.599742, mae: 122.756185, mean_q: 249.814806, mean_eps: 0.652006\n",
            " 18386/50000: episode: 576, duration: 0.429s, episode steps:  49, steps per second: 114, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 106.544507, mae: 123.007371, mean_q: 251.004713, mean_eps: 0.651141\n",
            " 18401/50000: episode: 577, duration: 0.151s, episode steps:  15, steps per second:  99, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 57.118873, mae: 120.307545, mean_q: 245.586103, mean_eps: 0.650533\n",
            " 18532/50000: episode: 578, duration: 1.135s, episode steps: 131, steps per second: 115, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 141.956542, mae: 123.521795, mean_q: 251.168534, mean_eps: 0.649146\n",
            " 18611/50000: episode: 579, duration: 0.699s, episode steps:  79, steps per second: 113, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 73.318174, mae: 124.703881, mean_q: 254.657806, mean_eps: 0.647151\n",
            " 18680/50000: episode: 580, duration: 0.611s, episode steps:  69, steps per second: 113, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 102.874622, mae: 126.032363, mean_q: 255.933009, mean_eps: 0.645745\n",
            " 18718/50000: episode: 581, duration: 0.431s, episode steps:  38, steps per second:  88, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 94.673401, mae: 125.640526, mean_q: 257.076922, mean_eps: 0.644728\n",
            " 18766/50000: episode: 582, duration: 0.631s, episode steps:  48, steps per second:  76, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 140.427425, mae: 125.793910, mean_q: 255.657097, mean_eps: 0.643912\n",
            " 18823/50000: episode: 583, duration: 0.711s, episode steps:  57, steps per second:  80, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 114.400356, mae: 124.483526, mean_q: 254.480253, mean_eps: 0.642914\n",
            " 18917/50000: episode: 584, duration: 1.164s, episode steps:  94, steps per second:  81, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 82.834221, mae: 125.965239, mean_q: 256.959491, mean_eps: 0.641480\n",
            " 18945/50000: episode: 585, duration: 0.313s, episode steps:  28, steps per second:  89, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.321 [0.000, 1.000],  loss: 119.473024, mae: 124.718588, mean_q: 254.934971, mean_eps: 0.640320\n",
            " 18969/50000: episode: 586, duration: 0.223s, episode steps:  24, steps per second: 108, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 71.029042, mae: 125.108191, mean_q: 256.175655, mean_eps: 0.639826\n",
            " 19002/50000: episode: 587, duration: 0.306s, episode steps:  33, steps per second: 108, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 95.491220, mae: 127.958527, mean_q: 260.852835, mean_eps: 0.639285\n",
            " 19138/50000: episode: 588, duration: 1.178s, episode steps: 136, steps per second: 115, episode reward: 136.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 125.203052, mae: 127.311378, mean_q: 259.847141, mean_eps: 0.637680\n",
            " 19171/50000: episode: 589, duration: 0.293s, episode steps:  33, steps per second: 113, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 95.472100, mae: 126.964930, mean_q: 260.846834, mean_eps: 0.636074\n",
            " 19230/50000: episode: 590, duration: 0.527s, episode steps:  59, steps per second: 112, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 111.277257, mae: 126.609116, mean_q: 258.697191, mean_eps: 0.635200\n",
            " 19263/50000: episode: 591, duration: 0.287s, episode steps:  33, steps per second: 115, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.394 [0.000, 1.000],  loss: 108.254948, mae: 127.685677, mean_q: 259.418055, mean_eps: 0.634326\n",
            " 19287/50000: episode: 592, duration: 0.216s, episode steps:  24, steps per second: 111, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 140.302541, mae: 128.599030, mean_q: 258.802191, mean_eps: 0.633785\n",
            " 19298/50000: episode: 593, duration: 0.099s, episode steps:  11, steps per second: 111, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 91.091765, mae: 129.147825, mean_q: 263.028381, mean_eps: 0.633452\n",
            " 19327/50000: episode: 594, duration: 0.251s, episode steps:  29, steps per second: 116, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 86.242422, mae: 128.371475, mean_q: 260.983311, mean_eps: 0.633072\n",
            " 19363/50000: episode: 595, duration: 0.319s, episode steps:  36, steps per second: 113, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 166.022791, mae: 128.331428, mean_q: 262.085981, mean_eps: 0.632455\n",
            " 19374/50000: episode: 596, duration: 0.102s, episode steps:  11, steps per second: 107, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 134.505908, mae: 126.533220, mean_q: 258.614363, mean_eps: 0.632008\n",
            " 19431/50000: episode: 597, duration: 0.512s, episode steps:  57, steps per second: 111, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 98.552998, mae: 127.967420, mean_q: 261.790825, mean_eps: 0.631362\n",
            " 19496/50000: episode: 598, duration: 0.576s, episode steps:  65, steps per second: 113, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 141.238920, mae: 129.215463, mean_q: 261.498642, mean_eps: 0.630203\n",
            " 19535/50000: episode: 599, duration: 0.345s, episode steps:  39, steps per second: 113, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.590 [0.000, 1.000],  loss: 173.296222, mae: 126.942165, mean_q: 258.125783, mean_eps: 0.629215\n",
            " 19578/50000: episode: 600, duration: 0.393s, episode steps:  43, steps per second: 109, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.442 [0.000, 1.000],  loss: 100.342491, mae: 129.548353, mean_q: 263.217530, mean_eps: 0.628436\n",
            " 19666/50000: episode: 601, duration: 0.756s, episode steps:  88, steps per second: 116, episode reward: 88.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 76.374779, mae: 129.162723, mean_q: 264.335689, mean_eps: 0.627192\n",
            " 19766/50000: episode: 602, duration: 0.866s, episode steps: 100, steps per second: 115, episode reward: 100.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 100.175164, mae: 129.745579, mean_q: 264.657901, mean_eps: 0.625406\n",
            " 19777/50000: episode: 603, duration: 0.103s, episode steps:  11, steps per second: 107, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 131.021973, mae: 129.018523, mean_q: 262.105312, mean_eps: 0.624351\n",
            " 19832/50000: episode: 604, duration: 0.500s, episode steps:  55, steps per second: 110, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 91.086211, mae: 131.239033, mean_q: 267.453974, mean_eps: 0.623724\n",
            " 19889/50000: episode: 605, duration: 0.519s, episode steps:  57, steps per second: 110, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 110.759021, mae: 130.392939, mean_q: 265.822590, mean_eps: 0.622660\n",
            " 19982/50000: episode: 606, duration: 0.819s, episode steps:  93, steps per second: 114, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 110.668402, mae: 130.949350, mean_q: 267.212401, mean_eps: 0.621235\n",
            " 20128/50000: episode: 607, duration: 1.603s, episode steps: 146, steps per second:  91, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 96.825375, mae: 131.852286, mean_q: 268.845059, mean_eps: 0.618965\n",
            " 20143/50000: episode: 608, duration: 0.224s, episode steps:  15, steps per second:  67, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 170.122147, mae: 129.448316, mean_q: 264.170449, mean_eps: 0.617435\n",
            " 20163/50000: episode: 609, duration: 0.270s, episode steps:  20, steps per second:  74, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 64.798751, mae: 132.518991, mean_q: 271.100481, mean_eps: 0.617103\n",
            " 20239/50000: episode: 610, duration: 0.992s, episode steps:  76, steps per second:  77, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.539 [0.000, 1.000],  loss: 72.620490, mae: 132.600677, mean_q: 270.088532, mean_eps: 0.616191\n",
            " 20252/50000: episode: 611, duration: 0.179s, episode steps:  13, steps per second:  73, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 104.862998, mae: 133.992230, mean_q: 274.298098, mean_eps: 0.615345\n",
            " 20272/50000: episode: 612, duration: 0.277s, episode steps:  20, steps per second:  72, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.350 [0.000, 1.000],  loss: 63.300944, mae: 131.852800, mean_q: 270.029488, mean_eps: 0.615031\n",
            " 20295/50000: episode: 613, duration: 0.234s, episode steps:  23, steps per second:  98, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 109.380539, mae: 132.090232, mean_q: 269.029166, mean_eps: 0.614623\n",
            " 20454/50000: episode: 614, duration: 1.361s, episode steps: 159, steps per second: 117, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 107.666162, mae: 133.076948, mean_q: 271.464871, mean_eps: 0.612894\n",
            " 20548/50000: episode: 615, duration: 0.830s, episode steps:  94, steps per second: 113, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 107.939587, mae: 133.781473, mean_q: 273.905918, mean_eps: 0.610491\n",
            " 20582/50000: episode: 616, duration: 0.308s, episode steps:  34, steps per second: 110, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 106.898449, mae: 133.516131, mean_q: 272.555776, mean_eps: 0.609275\n",
            " 20591/50000: episode: 617, duration: 0.087s, episode steps:   9, steps per second: 103, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 148.130520, mae: 133.670600, mean_q: 272.162754, mean_eps: 0.608866\n",
            " 20650/50000: episode: 618, duration: 0.531s, episode steps:  59, steps per second: 111, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.593 [0.000, 1.000],  loss: 162.175285, mae: 134.403488, mean_q: 273.853307, mean_eps: 0.608220\n",
            " 20826/50000: episode: 619, duration: 1.515s, episode steps: 176, steps per second: 116, episode reward: 176.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 144.445176, mae: 133.588034, mean_q: 272.087263, mean_eps: 0.605988\n",
            " 20918/50000: episode: 620, duration: 0.808s, episode steps:  92, steps per second: 114, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 90.525404, mae: 135.105202, mean_q: 276.603647, mean_eps: 0.603441\n",
            " 21114/50000: episode: 621, duration: 1.701s, episode steps: 196, steps per second: 115, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 114.956104, mae: 134.852349, mean_q: 274.800073, mean_eps: 0.600706\n",
            " 21228/50000: episode: 622, duration: 0.989s, episode steps: 114, steps per second: 115, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 105.339289, mae: 135.549867, mean_q: 276.979792, mean_eps: 0.597760\n",
            " 21309/50000: episode: 623, duration: 0.686s, episode steps:  81, steps per second: 118, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 94.192822, mae: 136.169387, mean_q: 277.732879, mean_eps: 0.595908\n",
            " 21462/50000: episode: 624, duration: 1.501s, episode steps: 153, steps per second: 102, episode reward: 153.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 119.319385, mae: 135.371397, mean_q: 276.613855, mean_eps: 0.593685\n",
            " 21518/50000: episode: 625, duration: 0.712s, episode steps:  56, steps per second:  79, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 89.754104, mae: 136.635317, mean_q: 278.558876, mean_eps: 0.591700\n",
            " 21536/50000: episode: 626, duration: 0.250s, episode steps:  18, steps per second:  72, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 78.109607, mae: 138.166060, mean_q: 281.087714, mean_eps: 0.590997\n",
            " 21567/50000: episode: 627, duration: 0.400s, episode steps:  31, steps per second:  77, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 127.722744, mae: 137.511178, mean_q: 280.764234, mean_eps: 0.590531\n",
            " 21616/50000: episode: 628, duration: 0.646s, episode steps:  49, steps per second:  76, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 114.420394, mae: 135.784568, mean_q: 276.623164, mean_eps: 0.589771\n",
            " 21631/50000: episode: 629, duration: 0.201s, episode steps:  15, steps per second:  75, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 119.897477, mae: 137.399961, mean_q: 279.013922, mean_eps: 0.589163\n",
            " 21700/50000: episode: 630, duration: 0.686s, episode steps:  69, steps per second: 101, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 85.155448, mae: 135.069151, mean_q: 276.460566, mean_eps: 0.588365\n",
            " 21759/50000: episode: 631, duration: 0.515s, episode steps:  59, steps per second: 115, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 102.488991, mae: 137.061085, mean_q: 280.232735, mean_eps: 0.587149\n",
            " 21817/50000: episode: 632, duration: 0.519s, episode steps:  58, steps per second: 112, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 83.395454, mae: 136.873434, mean_q: 279.944286, mean_eps: 0.586037\n",
            " 21864/50000: episode: 633, duration: 0.423s, episode steps:  47, steps per second: 111, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.553 [0.000, 1.000],  loss: 91.673100, mae: 137.057136, mean_q: 280.544945, mean_eps: 0.585040\n",
            " 21952/50000: episode: 634, duration: 0.756s, episode steps:  88, steps per second: 116, episode reward: 88.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 110.461427, mae: 137.230463, mean_q: 279.594851, mean_eps: 0.583758\n",
            " 22090/50000: episode: 635, duration: 1.197s, episode steps: 138, steps per second: 115, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 99.633359, mae: 137.068747, mean_q: 279.548559, mean_eps: 0.581611\n",
            " 22137/50000: episode: 636, duration: 0.416s, episode steps:  47, steps per second: 113, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 131.043715, mae: 136.326188, mean_q: 277.597363, mean_eps: 0.579853\n",
            " 22337/50000: episode: 637, duration: 1.757s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 98.157399, mae: 136.911213, mean_q: 279.810206, mean_eps: 0.577507\n",
            " 22459/50000: episode: 638, duration: 1.082s, episode steps: 122, steps per second: 113, episode reward: 122.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.549 [0.000, 1.000],  loss: 106.560210, mae: 136.880108, mean_q: 278.780422, mean_eps: 0.574447\n",
            " 22560/50000: episode: 639, duration: 0.882s, episode steps: 101, steps per second: 115, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 89.053666, mae: 137.193376, mean_q: 279.347867, mean_eps: 0.572329\n",
            " 22577/50000: episode: 640, duration: 0.149s, episode steps:  17, steps per second: 114, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 73.658307, mae: 136.932872, mean_q: 279.291396, mean_eps: 0.571208\n",
            " 22614/50000: episode: 641, duration: 0.326s, episode steps:  37, steps per second: 114, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 85.228899, mae: 137.915738, mean_q: 280.146538, mean_eps: 0.570695\n",
            " 22637/50000: episode: 642, duration: 0.222s, episode steps:  23, steps per second: 103, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 47.860600, mae: 136.071385, mean_q: 277.342848, mean_eps: 0.570125\n",
            " 22788/50000: episode: 643, duration: 1.360s, episode steps: 151, steps per second: 111, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 115.130006, mae: 136.986755, mean_q: 278.423494, mean_eps: 0.568472\n",
            " 22960/50000: episode: 644, duration: 2.156s, episode steps: 172, steps per second:  80, episode reward: 172.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 97.517102, mae: 136.559376, mean_q: 278.515693, mean_eps: 0.565404\n",
            " 23001/50000: episode: 645, duration: 0.556s, episode steps:  41, steps per second:  74, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 135.668462, mae: 135.640800, mean_q: 275.375437, mean_eps: 0.563380\n",
            " 23092/50000: episode: 646, duration: 0.845s, episode steps:  91, steps per second: 108, episode reward: 91.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 85.100839, mae: 135.892634, mean_q: 277.180948, mean_eps: 0.562126\n",
            " 23242/50000: episode: 647, duration: 1.311s, episode steps: 150, steps per second: 114, episode reward: 150.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 94.677146, mae: 135.360593, mean_q: 276.087103, mean_eps: 0.559837\n",
            " 23370/50000: episode: 648, duration: 1.121s, episode steps: 128, steps per second: 114, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.539 [0.000, 1.000],  loss: 85.114323, mae: 134.138655, mean_q: 273.845312, mean_eps: 0.557195\n",
            " 23479/50000: episode: 649, duration: 0.953s, episode steps: 109, steps per second: 114, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 105.846914, mae: 134.099456, mean_q: 273.431443, mean_eps: 0.554944\n",
            " 23498/50000: episode: 650, duration: 0.177s, episode steps:  19, steps per second: 107, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 67.816699, mae: 134.676863, mean_q: 274.339616, mean_eps: 0.553728\n",
            " 23590/50000: episode: 651, duration: 0.830s, episode steps:  92, steps per second: 111, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 73.946649, mae: 133.102843, mean_q: 271.697839, mean_eps: 0.552674\n",
            " 23614/50000: episode: 652, duration: 0.209s, episode steps:  24, steps per second: 115, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 81.632234, mae: 133.158321, mean_q: 271.768552, mean_eps: 0.551572\n",
            " 23693/50000: episode: 653, duration: 0.704s, episode steps:  79, steps per second: 112, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.544 [0.000, 1.000],  loss: 72.984955, mae: 132.542720, mean_q: 269.524227, mean_eps: 0.550593\n",
            " 23776/50000: episode: 654, duration: 0.711s, episode steps:  83, steps per second: 117, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 107.373989, mae: 132.696609, mean_q: 270.097162, mean_eps: 0.549054\n",
            " 23976/50000: episode: 655, duration: 1.681s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 88.294125, mae: 132.925242, mean_q: 271.040329, mean_eps: 0.546365\n",
            " 24080/50000: episode: 656, duration: 0.888s, episode steps: 104, steps per second: 117, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 92.002921, mae: 132.392292, mean_q: 269.523633, mean_eps: 0.543478\n",
            " 24200/50000: episode: 657, duration: 1.157s, episode steps: 120, steps per second: 104, episode reward: 120.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 66.653766, mae: 132.640379, mean_q: 270.628334, mean_eps: 0.541350\n",
            " 24285/50000: episode: 658, duration: 1.055s, episode steps:  85, steps per second:  81, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 71.989868, mae: 131.514397, mean_q: 268.676285, mean_eps: 0.539402\n",
            " 24423/50000: episode: 659, duration: 1.646s, episode steps: 138, steps per second:  84, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 80.762285, mae: 131.330790, mean_q: 267.997478, mean_eps: 0.537283\n",
            " 24456/50000: episode: 660, duration: 0.284s, episode steps:  33, steps per second: 116, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 73.454088, mae: 130.983388, mean_q: 266.405341, mean_eps: 0.535659\n",
            " 24498/50000: episode: 661, duration: 0.371s, episode steps:  42, steps per second: 113, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 86.945535, mae: 130.538595, mean_q: 265.650688, mean_eps: 0.534947\n",
            " 24514/50000: episode: 662, duration: 0.142s, episode steps:  16, steps per second: 112, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 56.439131, mae: 132.048546, mean_q: 268.484764, mean_eps: 0.534396\n",
            " 24684/50000: episode: 663, duration: 1.480s, episode steps: 170, steps per second: 115, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 81.278099, mae: 131.521550, mean_q: 267.448872, mean_eps: 0.532629\n",
            " 24777/50000: episode: 664, duration: 0.838s, episode steps:  93, steps per second: 111, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 63.441864, mae: 131.266078, mean_q: 267.969319, mean_eps: 0.530130\n",
            " 24889/50000: episode: 665, duration: 0.969s, episode steps: 112, steps per second: 116, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 80.009214, mae: 129.756434, mean_q: 264.193763, mean_eps: 0.528182\n",
            " 24920/50000: episode: 666, duration: 0.270s, episode steps:  31, steps per second: 115, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 90.544724, mae: 128.629583, mean_q: 261.120693, mean_eps: 0.526824\n",
            " 25086/50000: episode: 667, duration: 1.409s, episode steps: 166, steps per second: 118, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 60.717095, mae: 129.282783, mean_q: 263.792623, mean_eps: 0.524953\n",
            " 25221/50000: episode: 668, duration: 1.155s, episode steps: 135, steps per second: 117, episode reward: 135.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 68.539029, mae: 128.258135, mean_q: 261.877225, mean_eps: 0.522093\n",
            " 25351/50000: episode: 669, duration: 1.123s, episode steps: 130, steps per second: 116, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 77.534329, mae: 128.432830, mean_q: 261.188257, mean_eps: 0.519575\n",
            " 25467/50000: episode: 670, duration: 1.021s, episode steps: 116, steps per second: 114, episode reward: 116.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 62.421202, mae: 127.642859, mean_q: 260.182139, mean_eps: 0.517239\n",
            " 25587/50000: episode: 671, duration: 1.209s, episode steps: 120, steps per second:  99, episode reward: 120.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 46.524408, mae: 125.979063, mean_q: 257.420579, mean_eps: 0.514997\n",
            " 25600/50000: episode: 672, duration: 0.172s, episode steps:  13, steps per second:  76, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 28.148538, mae: 125.324628, mean_q: 255.193119, mean_eps: 0.513733\n",
            " 25616/50000: episode: 673, duration: 0.224s, episode steps:  16, steps per second:  72, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 42.491637, mae: 126.566845, mean_q: 258.507570, mean_eps: 0.513458\n",
            " 25680/50000: episode: 674, duration: 0.804s, episode steps:  64, steps per second:  80, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 74.190278, mae: 125.895353, mean_q: 255.891939, mean_eps: 0.512698\n",
            " 25835/50000: episode: 675, duration: 1.717s, episode steps: 155, steps per second:  90, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 61.432566, mae: 126.054083, mean_q: 256.416137, mean_eps: 0.510617\n",
            " 26011/50000: episode: 676, duration: 1.519s, episode steps: 176, steps per second: 116, episode reward: 176.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 64.540514, mae: 124.765795, mean_q: 253.781697, mean_eps: 0.507473\n",
            " 26173/50000: episode: 677, duration: 1.366s, episode steps: 162, steps per second: 119, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 62.613302, mae: 123.536126, mean_q: 251.166532, mean_eps: 0.504262\n",
            " 26216/50000: episode: 678, duration: 0.374s, episode steps:  43, steps per second: 115, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 63.328625, mae: 123.305718, mean_q: 250.619916, mean_eps: 0.502314\n",
            " 26274/50000: episode: 679, duration: 0.515s, episode steps:  58, steps per second: 113, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 43.540961, mae: 122.579947, mean_q: 249.229352, mean_eps: 0.501355\n",
            " 26316/50000: episode: 680, duration: 0.373s, episode steps:  42, steps per second: 113, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 59.297005, mae: 120.635053, mean_q: 246.652687, mean_eps: 0.500405\n",
            " 26512/50000: episode: 681, duration: 1.693s, episode steps: 196, steps per second: 116, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 53.850520, mae: 121.984431, mean_q: 248.465069, mean_eps: 0.498144\n",
            " 26547/50000: episode: 682, duration: 0.306s, episode steps:  35, steps per second: 114, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 46.089441, mae: 120.440362, mean_q: 245.026886, mean_eps: 0.495949\n",
            " 26587/50000: episode: 683, duration: 0.362s, episode steps:  40, steps per second: 111, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 48.176884, mae: 120.099031, mean_q: 244.767098, mean_eps: 0.495237\n",
            " 26751/50000: episode: 684, duration: 1.401s, episode steps: 164, steps per second: 117, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 51.938270, mae: 119.931028, mean_q: 244.242567, mean_eps: 0.493299\n",
            " 26856/50000: episode: 685, duration: 0.915s, episode steps: 105, steps per second: 115, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 52.443928, mae: 119.154485, mean_q: 242.596422, mean_eps: 0.490743\n",
            " 27044/50000: episode: 686, duration: 2.009s, episode steps: 188, steps per second:  94, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 47.682916, mae: 118.454287, mean_q: 240.791860, mean_eps: 0.487960\n",
            " 27244/50000: episode: 687, duration: 2.206s, episode steps: 200, steps per second:  91, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 45.179999, mae: 117.648236, mean_q: 238.477577, mean_eps: 0.484274\n",
            " 27309/50000: episode: 688, duration: 0.562s, episode steps:  65, steps per second: 116, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 49.930934, mae: 116.510921, mean_q: 236.307128, mean_eps: 0.481756\n",
            " 27385/50000: episode: 689, duration: 0.656s, episode steps:  76, steps per second: 116, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 31.464714, mae: 115.430375, mean_q: 235.051905, mean_eps: 0.480417\n",
            " 27469/50000: episode: 690, duration: 0.712s, episode steps:  84, steps per second: 118, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 37.564249, mae: 114.466535, mean_q: 231.936989, mean_eps: 0.478897\n",
            " 27663/50000: episode: 691, duration: 1.671s, episode steps: 194, steps per second: 116, episode reward: 194.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 55.701253, mae: 114.400139, mean_q: 232.119896, mean_eps: 0.476256\n",
            " 27772/50000: episode: 692, duration: 0.937s, episode steps: 109, steps per second: 116, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 53.497520, mae: 112.135178, mean_q: 227.015854, mean_eps: 0.473377\n",
            " 27829/50000: episode: 693, duration: 0.483s, episode steps:  57, steps per second: 118, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 38.367505, mae: 112.380604, mean_q: 227.834002, mean_eps: 0.471800\n",
            " 27851/50000: episode: 694, duration: 0.212s, episode steps:  22, steps per second: 104, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 36.181821, mae: 111.238277, mean_q: 226.171564, mean_eps: 0.471050\n",
            " 27954/50000: episode: 695, duration: 0.903s, episode steps: 103, steps per second: 114, episode reward: 103.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 42.060517, mae: 112.296549, mean_q: 227.861096, mean_eps: 0.469862\n",
            " 28120/50000: episode: 696, duration: 1.444s, episode steps: 166, steps per second: 115, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 48.111081, mae: 110.773929, mean_q: 225.217156, mean_eps: 0.467307\n",
            " 28200/50000: episode: 697, duration: 0.695s, episode steps:  80, steps per second: 115, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 35.137650, mae: 109.201476, mean_q: 221.569090, mean_eps: 0.464970\n",
            " 28331/50000: episode: 698, duration: 1.137s, episode steps: 131, steps per second: 115, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 36.027275, mae: 108.911206, mean_q: 220.947014, mean_eps: 0.462965\n",
            " 28424/50000: episode: 699, duration: 1.128s, episode steps:  93, steps per second:  82, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 45.232799, mae: 107.163572, mean_q: 217.424020, mean_eps: 0.460837\n",
            " 28526/50000: episode: 700, duration: 1.277s, episode steps: 102, steps per second:  80, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 39.651630, mae: 107.854173, mean_q: 219.360374, mean_eps: 0.458985\n",
            " 28630/50000: episode: 701, duration: 1.119s, episode steps: 104, steps per second:  93, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 28.026107, mae: 106.136613, mean_q: 215.958718, mean_eps: 0.457028\n",
            " 28696/50000: episode: 702, duration: 0.577s, episode steps:  66, steps per second: 114, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 58.442206, mae: 106.209269, mean_q: 214.819029, mean_eps: 0.455413\n",
            " 28896/50000: episode: 703, duration: 1.707s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 32.217290, mae: 105.241598, mean_q: 213.428992, mean_eps: 0.452885\n",
            " 29090/50000: episode: 704, duration: 1.685s, episode steps: 194, steps per second: 115, episode reward: 194.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 43.459877, mae: 104.817370, mean_q: 211.996912, mean_eps: 0.449143\n",
            " 29240/50000: episode: 705, duration: 1.302s, episode steps: 150, steps per second: 115, episode reward: 150.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 46.545865, mae: 102.711322, mean_q: 208.426717, mean_eps: 0.445875\n",
            " 29422/50000: episode: 706, duration: 1.594s, episode steps: 182, steps per second: 114, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 36.226255, mae: 102.479150, mean_q: 207.475743, mean_eps: 0.442721\n",
            " 29588/50000: episode: 707, duration: 1.442s, episode steps: 166, steps per second: 115, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 28.115165, mae: 101.047941, mean_q: 204.165865, mean_eps: 0.439415\n",
            " 29607/50000: episode: 708, duration: 0.179s, episode steps:  19, steps per second: 106, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 60.901169, mae: 102.414425, mean_q: 205.957467, mean_eps: 0.437657\n",
            " 29704/50000: episode: 709, duration: 0.840s, episode steps:  97, steps per second: 115, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 31.150233, mae: 100.267150, mean_q: 202.997988, mean_eps: 0.436555\n",
            " 29904/50000: episode: 710, duration: 2.408s, episode steps: 200, steps per second:  83, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 23.023629, mae: 99.874715, mean_q: 202.418552, mean_eps: 0.433734\n",
            " 30036/50000: episode: 711, duration: 1.404s, episode steps: 132, steps per second:  94, episode reward: 132.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 41.253962, mae: 99.338700, mean_q: 200.707313, mean_eps: 0.430580\n",
            " 30133/50000: episode: 712, duration: 0.839s, episode steps:  97, steps per second: 116, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 38.374065, mae: 99.912270, mean_q: 200.988850, mean_eps: 0.428404\n",
            " 30165/50000: episode: 713, duration: 0.298s, episode steps:  32, steps per second: 107, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 20.185256, mae: 99.810065, mean_q: 200.838810, mean_eps: 0.427179\n",
            " 30313/50000: episode: 714, duration: 1.262s, episode steps: 148, steps per second: 117, episode reward: 148.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 45.326604, mae: 99.523000, mean_q: 200.498233, mean_eps: 0.425469\n",
            " 30399/50000: episode: 715, duration: 0.766s, episode steps:  86, steps per second: 112, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 29.833070, mae: 99.917924, mean_q: 201.610009, mean_eps: 0.423246\n",
            " 30599/50000: episode: 716, duration: 1.729s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 42.108427, mae: 98.885966, mean_q: 199.639010, mean_eps: 0.420529\n",
            " 30658/50000: episode: 717, duration: 0.516s, episode steps:  59, steps per second: 114, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 31.412264, mae: 97.696702, mean_q: 197.929805, mean_eps: 0.418068\n",
            " 30857/50000: episode: 718, duration: 1.693s, episode steps: 199, steps per second: 118, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 31.538033, mae: 97.859326, mean_q: 198.219781, mean_eps: 0.415617\n",
            " 30872/50000: episode: 719, duration: 0.146s, episode steps:  15, steps per second: 103, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 17.984618, mae: 91.328747, mean_q: 186.085303, mean_eps: 0.413584\n",
            " 30990/50000: episode: 720, duration: 0.996s, episode steps: 118, steps per second: 118, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 20.048987, mae: 96.214611, mean_q: 194.498454, mean_eps: 0.412321\n",
            " 31190/50000: episode: 721, duration: 2.033s, episode steps: 200, steps per second:  98, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 51.242096, mae: 96.132394, mean_q: 194.584655, mean_eps: 0.409300\n",
            " 31378/50000: episode: 722, duration: 2.226s, episode steps: 188, steps per second:  84, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 37.119855, mae: 94.925015, mean_q: 191.428368, mean_eps: 0.405614\n",
            " 31517/50000: episode: 723, duration: 1.214s, episode steps: 139, steps per second: 115, episode reward: 139.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 49.747484, mae: 94.389215, mean_q: 190.548797, mean_eps: 0.402507\n",
            " 31699/50000: episode: 724, duration: 1.553s, episode steps: 182, steps per second: 117, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 38.684538, mae: 94.004807, mean_q: 189.992796, mean_eps: 0.399458\n",
            " 31899/50000: episode: 725, duration: 1.690s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 37.991709, mae: 91.626897, mean_q: 185.167437, mean_eps: 0.395829\n",
            " 32099/50000: episode: 726, duration: 1.722s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 31.226416, mae: 91.930783, mean_q: 185.574684, mean_eps: 0.392029\n",
            " 32203/50000: episode: 727, duration: 0.905s, episode steps: 104, steps per second: 115, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 58.044022, mae: 91.965927, mean_q: 184.880660, mean_eps: 0.389141\n",
            " 32403/50000: episode: 728, duration: 1.719s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 30.528565, mae: 91.303977, mean_q: 184.230003, mean_eps: 0.386253\n",
            " 32603/50000: episode: 729, duration: 2.100s, episode steps: 200, steps per second:  95, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 39.538004, mae: 91.093209, mean_q: 183.664985, mean_eps: 0.382453\n",
            " 32803/50000: episode: 730, duration: 2.295s, episode steps: 200, steps per second:  87, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 25.902182, mae: 90.325806, mean_q: 182.303797, mean_eps: 0.378653\n",
            " 32969/50000: episode: 731, duration: 1.426s, episode steps: 166, steps per second: 116, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 54.658124, mae: 91.391458, mean_q: 183.705204, mean_eps: 0.375176\n",
            " 33056/50000: episode: 732, duration: 0.754s, episode steps:  87, steps per second: 115, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 33.767360, mae: 90.366067, mean_q: 182.349120, mean_eps: 0.372772\n",
            " 33256/50000: episode: 733, duration: 1.707s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 47.254526, mae: 90.126229, mean_q: 181.887509, mean_eps: 0.370046\n",
            " 33421/50000: episode: 734, duration: 1.405s, episode steps: 165, steps per second: 117, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 38.910149, mae: 90.344979, mean_q: 182.108029, mean_eps: 0.366578\n",
            " 33480/50000: episode: 735, duration: 0.506s, episode steps:  59, steps per second: 117, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 29.864323, mae: 90.230594, mean_q: 181.256444, mean_eps: 0.364450\n",
            " 33680/50000: episode: 736, duration: 1.695s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 48.513641, mae: 90.562837, mean_q: 182.302573, mean_eps: 0.361990\n",
            " 33872/50000: episode: 737, duration: 1.611s, episode steps: 192, steps per second: 119, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 53.173475, mae: 90.848560, mean_q: 182.565928, mean_eps: 0.358266\n",
            " 33994/50000: episode: 738, duration: 1.340s, episode steps: 122, steps per second:  91, episode reward: 122.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 56.316740, mae: 90.207234, mean_q: 181.702913, mean_eps: 0.355283\n",
            " 34066/50000: episode: 739, duration: 0.919s, episode steps:  72, steps per second:  78, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 93.590992, mae: 91.008062, mean_q: 183.404606, mean_eps: 0.353440\n",
            " 34266/50000: episode: 740, duration: 2.068s, episode steps: 200, steps per second:  97, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 29.015795, mae: 90.528580, mean_q: 182.876479, mean_eps: 0.350856\n",
            " 34466/50000: episode: 741, duration: 1.711s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 59.136297, mae: 89.536989, mean_q: 180.247776, mean_eps: 0.347056\n",
            " 34563/50000: episode: 742, duration: 0.855s, episode steps:  97, steps per second: 113, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 45.475863, mae: 88.790520, mean_q: 178.932323, mean_eps: 0.344234\n",
            " 34763/50000: episode: 743, duration: 1.703s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 38.386664, mae: 88.994634, mean_q: 179.387625, mean_eps: 0.341413\n",
            " 34956/50000: episode: 744, duration: 1.649s, episode steps: 193, steps per second: 117, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 46.523214, mae: 88.602804, mean_q: 178.435596, mean_eps: 0.337679\n",
            " 35087/50000: episode: 745, duration: 1.129s, episode steps: 131, steps per second: 116, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 36.903538, mae: 88.398441, mean_q: 178.407947, mean_eps: 0.334601\n",
            " 35188/50000: episode: 746, duration: 0.871s, episode steps: 101, steps per second: 116, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 37.428941, mae: 88.483134, mean_q: 178.667011, mean_eps: 0.332397\n",
            " 35388/50000: episode: 747, duration: 2.050s, episode steps: 200, steps per second:  98, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 58.933462, mae: 88.985010, mean_q: 179.234691, mean_eps: 0.329538\n",
            " 35588/50000: episode: 748, duration: 2.318s, episode steps: 200, steps per second:  86, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 71.133512, mae: 87.719849, mean_q: 176.359944, mean_eps: 0.325738\n",
            " 35788/50000: episode: 749, duration: 1.792s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 57.085643, mae: 87.117887, mean_q: 175.481517, mean_eps: 0.321938\n",
            " 35988/50000: episode: 750, duration: 1.745s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 56.343029, mae: 86.408293, mean_q: 173.363953, mean_eps: 0.318138\n",
            " 36032/50000: episode: 751, duration: 0.408s, episode steps:  44, steps per second: 108, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 70.609211, mae: 86.614059, mean_q: 173.709817, mean_eps: 0.315820\n",
            " 36228/50000: episode: 752, duration: 1.738s, episode steps: 196, steps per second: 113, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 39.855605, mae: 87.056160, mean_q: 175.165938, mean_eps: 0.313540\n",
            " 36428/50000: episode: 753, duration: 1.751s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 58.994661, mae: 87.076846, mean_q: 175.205538, mean_eps: 0.309778\n",
            " 36628/50000: episode: 754, duration: 1.756s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 47.293214, mae: 86.950338, mean_q: 174.588907, mean_eps: 0.305978\n",
            " 36828/50000: episode: 755, duration: 2.206s, episode steps: 200, steps per second:  91, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 33.321117, mae: 87.073155, mean_q: 175.449267, mean_eps: 0.302178\n",
            " 37028/50000: episode: 756, duration: 2.080s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 69.341333, mae: 87.227575, mean_q: 175.418791, mean_eps: 0.298378\n",
            " 37038/50000: episode: 757, duration: 0.095s, episode steps:  10, steps per second: 106, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 70.167053, mae: 88.683961, mean_q: 175.916000, mean_eps: 0.296383\n",
            " 37231/50000: episode: 758, duration: 1.664s, episode steps: 193, steps per second: 116, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 73.209584, mae: 87.363115, mean_q: 175.964274, mean_eps: 0.294454\n",
            " 37431/50000: episode: 759, duration: 1.718s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 59.785292, mae: 87.859637, mean_q: 176.659684, mean_eps: 0.290721\n",
            " 37522/50000: episode: 760, duration: 0.774s, episode steps:  91, steps per second: 118, episode reward: 91.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 50.799481, mae: 86.344970, mean_q: 175.196898, mean_eps: 0.287956\n",
            " 37657/50000: episode: 761, duration: 1.167s, episode steps: 135, steps per second: 116, episode reward: 135.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.496 [0.000, 1.000],  loss: 59.871447, mae: 88.005510, mean_q: 177.125949, mean_eps: 0.285809\n",
            " 37846/50000: episode: 762, duration: 1.607s, episode steps: 189, steps per second: 118, episode reward: 189.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 53.081493, mae: 89.225094, mean_q: 179.632719, mean_eps: 0.282731\n",
            " 37948/50000: episode: 763, duration: 0.868s, episode steps: 102, steps per second: 118, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 63.377806, mae: 88.451728, mean_q: 177.678372, mean_eps: 0.279967\n",
            " 38148/50000: episode: 764, duration: 1.884s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 33.083374, mae: 88.884259, mean_q: 179.474384, mean_eps: 0.277098\n",
            " 38348/50000: episode: 765, duration: 2.452s, episode steps: 200, steps per second:  82, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 78.668486, mae: 89.067199, mean_q: 179.126177, mean_eps: 0.273298\n",
            " 38404/50000: episode: 766, duration: 0.488s, episode steps:  56, steps per second: 115, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 124.258232, mae: 90.091686, mean_q: 179.995235, mean_eps: 0.270866\n",
            " 38604/50000: episode: 767, duration: 1.720s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 46.554264, mae: 88.521196, mean_q: 178.010069, mean_eps: 0.268434\n",
            " 38804/50000: episode: 768, duration: 1.679s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 38.363661, mae: 87.936057, mean_q: 177.672025, mean_eps: 0.264634\n",
            " 38942/50000: episode: 769, duration: 1.185s, episode steps: 138, steps per second: 116, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 53.276623, mae: 87.896890, mean_q: 176.903172, mean_eps: 0.261423\n",
            " 38964/50000: episode: 770, duration: 0.192s, episode steps:  22, steps per second: 115, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 62.058830, mae: 88.731108, mean_q: 176.901781, mean_eps: 0.259903\n",
            " 39164/50000: episode: 771, duration: 1.677s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 56.548443, mae: 88.093405, mean_q: 177.041411, mean_eps: 0.257794\n",
            " 39328/50000: episode: 772, duration: 1.436s, episode steps: 164, steps per second: 114, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 66.821076, mae: 87.564463, mean_q: 176.136672, mean_eps: 0.254336\n",
            " 39528/50000: episode: 773, duration: 1.885s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 70.769427, mae: 87.865626, mean_q: 176.457497, mean_eps: 0.250878\n",
            " 39687/50000: episode: 774, duration: 1.926s, episode steps: 159, steps per second:  83, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 50.332342, mae: 87.612222, mean_q: 176.750343, mean_eps: 0.247467\n",
            " 39887/50000: episode: 775, duration: 1.920s, episode steps: 200, steps per second: 104, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 64.891200, mae: 87.583591, mean_q: 176.118537, mean_eps: 0.244057\n",
            " 40087/50000: episode: 776, duration: 1.696s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 59.977555, mae: 87.262336, mean_q: 175.641976, mean_eps: 0.240257\n",
            " 40156/50000: episode: 777, duration: 0.605s, episode steps:  69, steps per second: 114, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 51.383446, mae: 87.810393, mean_q: 176.309880, mean_eps: 0.237701\n",
            " 40356/50000: episode: 778, duration: 1.693s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 57.373368, mae: 87.166713, mean_q: 175.327384, mean_eps: 0.235146\n",
            " 40556/50000: episode: 779, duration: 1.707s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 50.810344, mae: 86.894611, mean_q: 175.124263, mean_eps: 0.231346\n",
            " 40756/50000: episode: 780, duration: 1.725s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 52.751663, mae: 87.241896, mean_q: 175.398833, mean_eps: 0.227546\n",
            " 40956/50000: episode: 781, duration: 1.931s, episode steps: 200, steps per second: 104, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 86.191995, mae: 87.804405, mean_q: 175.873258, mean_eps: 0.223746\n",
            " 41156/50000: episode: 782, duration: 2.386s, episode steps: 200, steps per second:  84, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 66.462398, mae: 86.981483, mean_q: 174.680685, mean_eps: 0.219946\n",
            " 41219/50000: episode: 783, duration: 0.549s, episode steps:  63, steps per second: 115, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 70.289425, mae: 87.696052, mean_q: 175.289584, mean_eps: 0.217447\n",
            " 41272/50000: episode: 784, duration: 0.477s, episode steps:  53, steps per second: 111, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 107.603455, mae: 88.310318, mean_q: 176.334916, mean_eps: 0.216345\n",
            " 41472/50000: episode: 785, duration: 1.729s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 57.106180, mae: 87.009711, mean_q: 174.787547, mean_eps: 0.213942\n",
            " 41657/50000: episode: 786, duration: 1.593s, episode steps: 185, steps per second: 116, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 76.266635, mae: 86.834341, mean_q: 173.964413, mean_eps: 0.210284\n",
            " 41824/50000: episode: 787, duration: 1.440s, episode steps: 167, steps per second: 116, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 76.311478, mae: 86.715452, mean_q: 173.573784, mean_eps: 0.206940\n",
            " 42024/50000: episode: 788, duration: 1.711s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 52.556225, mae: 86.658564, mean_q: 173.672285, mean_eps: 0.203454\n",
            " 42212/50000: episode: 789, duration: 1.671s, episode steps: 188, steps per second: 112, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 66.744297, mae: 85.831506, mean_q: 172.390435, mean_eps: 0.199768\n",
            " 42412/50000: episode: 790, duration: 2.210s, episode steps: 200, steps per second:  90, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 59.245310, mae: 86.038105, mean_q: 172.994320, mean_eps: 0.196082\n",
            " 42612/50000: episode: 791, duration: 2.171s, episode steps: 200, steps per second:  92, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 73.701043, mae: 85.966558, mean_q: 172.288749, mean_eps: 0.192282\n",
            " 42812/50000: episode: 792, duration: 1.731s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 89.076418, mae: 86.163641, mean_q: 172.251672, mean_eps: 0.188482\n",
            " 43012/50000: episode: 793, duration: 1.694s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 56.585451, mae: 84.900341, mean_q: 170.635308, mean_eps: 0.184682\n",
            " 43212/50000: episode: 794, duration: 1.726s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 52.678434, mae: 84.511385, mean_q: 169.715845, mean_eps: 0.180882\n",
            " 43412/50000: episode: 795, duration: 1.699s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 65.100030, mae: 84.144947, mean_q: 168.663660, mean_eps: 0.177082\n",
            " 43457/50000: episode: 796, duration: 0.387s, episode steps:  45, steps per second: 116, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 43.513078, mae: 84.692258, mean_q: 169.265040, mean_eps: 0.174754\n",
            " 43619/50000: episode: 797, duration: 1.397s, episode steps: 162, steps per second: 116, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 70.090245, mae: 83.707674, mean_q: 167.488155, mean_eps: 0.172788\n",
            " 43819/50000: episode: 798, duration: 2.257s, episode steps: 200, steps per second:  89, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 53.930421, mae: 83.154224, mean_q: 167.198575, mean_eps: 0.169349\n",
            " 44012/50000: episode: 799, duration: 2.043s, episode steps: 193, steps per second:  94, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 40.143486, mae: 82.336179, mean_q: 165.760083, mean_eps: 0.165615\n",
            " 44198/50000: episode: 800, duration: 1.589s, episode steps: 186, steps per second: 117, episode reward: 186.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 57.723898, mae: 82.510387, mean_q: 165.513465, mean_eps: 0.162015\n",
            " 44398/50000: episode: 801, duration: 1.705s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 54.900542, mae: 82.410814, mean_q: 165.315587, mean_eps: 0.158348\n",
            " 44546/50000: episode: 802, duration: 1.256s, episode steps: 148, steps per second: 118, episode reward: 148.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 49.428039, mae: 82.041543, mean_q: 164.361964, mean_eps: 0.155042\n",
            " 44746/50000: episode: 803, duration: 1.734s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 62.523937, mae: 81.255722, mean_q: 163.022178, mean_eps: 0.151736\n",
            " 44931/50000: episode: 804, duration: 1.586s, episode steps: 185, steps per second: 117, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 57.009416, mae: 80.726294, mean_q: 161.731431, mean_eps: 0.148078\n",
            " 45131/50000: episode: 805, duration: 1.909s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 51.220611, mae: 79.892149, mean_q: 159.879843, mean_eps: 0.144421\n",
            " 45311/50000: episode: 806, duration: 2.246s, episode steps: 180, steps per second:  80, episode reward: 180.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 52.696554, mae: 79.296518, mean_q: 158.962136, mean_eps: 0.140811\n",
            " 45460/50000: episode: 807, duration: 1.483s, episode steps: 149, steps per second: 101, episode reward: 149.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 53.923703, mae: 78.629553, mean_q: 157.441827, mean_eps: 0.137685\n",
            " 45513/50000: episode: 808, duration: 0.484s, episode steps:  53, steps per second: 110, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.547 [0.000, 1.000],  loss: 50.438331, mae: 78.326770, mean_q: 156.507649, mean_eps: 0.135766\n",
            " 45676/50000: episode: 809, duration: 1.400s, episode steps: 163, steps per second: 116, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 41.312782, mae: 77.938239, mean_q: 156.244070, mean_eps: 0.133714\n",
            " 45876/50000: episode: 810, duration: 1.759s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 37.289831, mae: 77.198541, mean_q: 154.713480, mean_eps: 0.130266\n",
            " 45961/50000: episode: 811, duration: 0.756s, episode steps:  85, steps per second: 112, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 48.243216, mae: 76.806598, mean_q: 153.360077, mean_eps: 0.127558\n",
            " 46152/50000: episode: 812, duration: 1.678s, episode steps: 191, steps per second: 114, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 26.020191, mae: 75.821742, mean_q: 152.174753, mean_eps: 0.124936\n",
            " 46352/50000: episode: 813, duration: 1.764s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 26.364389, mae: 75.550977, mean_q: 151.691841, mean_eps: 0.121222\n",
            " 46365/50000: episode: 814, duration: 0.120s, episode steps:  13, steps per second: 108, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 48.020013, mae: 75.123525, mean_q: 149.903918, mean_eps: 0.119198\n",
            " 46395/50000: episode: 815, duration: 0.269s, episode steps:  30, steps per second: 112, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 63.692897, mae: 75.153493, mean_q: 149.327340, mean_eps: 0.118790\n",
            " 46460/50000: episode: 816, duration: 0.687s, episode steps:  65, steps per second:  95, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 43.560488, mae: 74.901141, mean_q: 149.734254, mean_eps: 0.117887\n",
            " 46589/50000: episode: 817, duration: 1.572s, episode steps: 129, steps per second:  82, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.442 [0.000, 1.000],  loss: 42.824363, mae: 74.150416, mean_q: 148.195445, mean_eps: 0.116044\n",
            " 46770/50000: episode: 818, duration: 1.854s, episode steps: 181, steps per second:  98, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 33.242646, mae: 73.968321, mean_q: 148.167226, mean_eps: 0.113099\n",
            " 46837/50000: episode: 819, duration: 0.561s, episode steps:  67, steps per second: 119, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 25.323846, mae: 73.222883, mean_q: 147.081144, mean_eps: 0.110743\n",
            " 46846/50000: episode: 820, duration: 0.089s, episode steps:   9, steps per second: 101, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 18.774259, mae: 73.979956, mean_q: 148.239092, mean_eps: 0.110021\n",
            " 46982/50000: episode: 821, duration: 1.160s, episode steps: 136, steps per second: 117, episode reward: 136.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 23.658835, mae: 72.882808, mean_q: 146.155805, mean_eps: 0.108644\n",
            " 47116/50000: episode: 822, duration: 1.141s, episode steps: 134, steps per second: 117, episode reward: 134.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 40.192196, mae: 73.272414, mean_q: 146.429730, mean_eps: 0.106079\n",
            " 47232/50000: episode: 823, duration: 0.996s, episode steps: 116, steps per second: 117, episode reward: 116.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 22.069565, mae: 72.741582, mean_q: 145.882639, mean_eps: 0.103704\n",
            " 47432/50000: episode: 824, duration: 1.724s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 38.344695, mae: 72.746297, mean_q: 144.939677, mean_eps: 0.100702\n",
            " 47632/50000: episode: 825, duration: 1.701s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 32.410054, mae: 71.548649, mean_q: 142.969445, mean_eps: 0.096902\n",
            " 47774/50000: episode: 826, duration: 1.215s, episode steps: 142, steps per second: 117, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 35.549187, mae: 70.214932, mean_q: 140.175083, mean_eps: 0.093653\n",
            " 47823/50000: episode: 827, duration: 0.429s, episode steps:  49, steps per second: 114, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 36.137997, mae: 70.786430, mean_q: 140.853931, mean_eps: 0.091838\n",
            " 47959/50000: episode: 828, duration: 1.634s, episode steps: 136, steps per second:  83, episode reward: 136.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 40.963740, mae: 69.392105, mean_q: 138.422024, mean_eps: 0.090081\n",
            " 48064/50000: episode: 829, duration: 1.292s, episode steps: 105, steps per second:  81, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 37.916942, mae: 68.953402, mean_q: 137.521320, mean_eps: 0.087791\n",
            " 48264/50000: episode: 830, duration: 1.758s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 34.228515, mae: 68.420477, mean_q: 136.857560, mean_eps: 0.084894\n",
            " 48456/50000: episode: 831, duration: 1.648s, episode steps: 192, steps per second: 117, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 25.893212, mae: 67.751611, mean_q: 135.681526, mean_eps: 0.081170\n",
            " 48629/50000: episode: 832, duration: 1.502s, episode steps: 173, steps per second: 115, episode reward: 173.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 19.711790, mae: 66.667886, mean_q: 133.587200, mean_eps: 0.077702\n",
            " 48801/50000: episode: 833, duration: 1.463s, episode steps: 172, steps per second: 118, episode reward: 172.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 24.443599, mae: 66.205938, mean_q: 132.222589, mean_eps: 0.074425\n",
            " 48913/50000: episode: 834, duration: 1.000s, episode steps: 112, steps per second: 112, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 28.918741, mae: 65.757013, mean_q: 131.369163, mean_eps: 0.071727\n",
            " 49077/50000: episode: 835, duration: 1.444s, episode steps: 164, steps per second: 114, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 19.336448, mae: 64.907624, mean_q: 129.823627, mean_eps: 0.069105\n",
            " 49250/50000: episode: 836, duration: 1.539s, episode steps: 173, steps per second: 112, episode reward: 173.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 28.866304, mae: 64.692429, mean_q: 128.976704, mean_eps: 0.065903\n",
            " 49287/50000: episode: 837, duration: 0.478s, episode steps:  37, steps per second:  77, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 20.601416, mae: 64.124451, mean_q: 127.765017, mean_eps: 0.063908\n",
            " 49438/50000: episode: 838, duration: 1.856s, episode steps: 151, steps per second:  81, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 22.212428, mae: 63.317024, mean_q: 126.338248, mean_eps: 0.062122\n",
            " 49627/50000: episode: 839, duration: 1.781s, episode steps: 189, steps per second: 106, episode reward: 189.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 15.561229, mae: 62.712819, mean_q: 125.420733, mean_eps: 0.058892\n",
            " 49751/50000: episode: 840, duration: 1.074s, episode steps: 124, steps per second: 115, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 20.946192, mae: 61.781224, mean_q: 123.065666, mean_eps: 0.055919\n",
            " 49847/50000: episode: 841, duration: 0.829s, episode steps:  96, steps per second: 116, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 25.259543, mae: 61.850187, mean_q: 123.289886, mean_eps: 0.053829\n",
            "done, took 481.706 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 5 episodes ...\n",
            "Episode 1: reward: 129.000, steps: 129\n",
            "Episode 2: reward: 135.000, steps: 135\n",
            "Episode 3: reward: 130.000, steps: 130\n",
            "Episode 4: reward: 129.000, steps: 129\n",
            "Episode 5: reward: 129.000, steps: 129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd751430040>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS9UlEQVR4nO3dcYxd5Z3e8e8z4wGcwMYYZqljmzUhriK2akw0JUTJHyxRdgmq6qyURtBqgyIqbyUSJVLUFrZSk0hF2pW6oY26RWUFG1KlAboJwkK0LEuQVtEqEJM4BEPYmECELYOBYAiNYLH59Y95TW6JPXNnxsO978z3Ix3dc97znnt/r7g8HN45555UFZKkfkyMugBJ0sIY3JLUGYNbkjpjcEtSZwxuSeqMwS1JnVm24E5ySZLHkuxNcvVyfY4krTZZjuu4k0wCfwd8BNgHfA+4vKoeOeEfJkmrzHKdcV8A7K2qn1bV3wO3ANuX6bMkaVVZs0zvuxF4amB7H/D+43U+88wza8uWLctUiiT158knn+S5557LsfYtV3DPK8kOYAfA2Wefza5du0ZViiSNnZmZmePuW66pkv3A5oHtTa3tDVV1Q1XNVNXM9PT0MpUhSSvPcgX394CtSc5JchJwGbBzmT5LklaVZZkqqarDST4N3A1MAjdV1Z7l+CxJWm2WbY67qu4C7lqu95ek1co7JyWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdWZJjy5L8iTwC+AIcLiqZpKsB24FtgBPAp+oqheWVqYk6agTccb9O1W1rapm2vbVwL1VtRW4t21Lkk6Q5Zgq2Q7c3NZvBj62DJ8hSavWUoO7gL9K8mCSHa3trKo60NafBs5a4mdIkgYsaY4b+FBV7U/ym8A9SX48uLOqKkkd68AW9DsAzj777CWWIUmrx5LOuKtqf3s9CNwOXAA8k2QDQHs9eJxjb6iqmaqamZ6eXkoZkrSqLDq4k7w9yWlH14HfBR4GdgJXtG5XAHcstUhJ0q8sZarkLOD2JEff539W1f9J8j3gtiRXAj8DPrH0MiVJRy06uKvqp8B7j9H+PPDhpRQlSTo+75yUpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOjNvcCe5KcnBJA8PtK1Pck+Sn7TX01t7knwlyd4kDyV533IWL0mr0TBn3F8FLnlT29XAvVW1Fbi3bQN8FNjalh3A9SemTEnSUfMGd1X9DfDzNzVvB25u6zcDHxto/1rN+i6wLsmGE1SrJInFz3GfVVUH2vrTwFltfSPw1EC/fa3t1yTZkWRXkl3PPvvsIsuQpNVnyX+crKoCahHH3VBVM1U1Mz09vdQyJGnVWGxwP3N0CqS9Hmzt+4HNA/02tTZJ0gmy2ODeCVzR1q8A7hho/2S7uuRC4MWBKRVJ0gmwZr4OSb4BXAScmWQf8AXgj4HbklwJ/Az4ROt+F3ApsBf4JfCpZahZkla1eYO7qi4/zq4PH6NvAVcttShJ0vF556QkdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM7MG9xJbkpyMMnDA21fTLI/ye62XDqw75oke5M8luT3lqtwSVqthjnj/ipwyTHar6uqbW25CyDJecBlwG+3Y/5bkskTVawkaYjgrqq/AX4+5PttB26pqler6glmn/Z+wRLqkyS9yVLmuD+d5KE2lXJ6a9sIPDXQZ19r+zVJdiTZlWTXs88+u4QyJGl1WWxwXw+cC2wDDgB/utA3qKobqmqmqmamp6cXWYYkrT6LCu6qeqaqjlTV68Cf86vpkP3A5oGum1qbJOkEWVRwJ9kwsPn7wNErTnYClyU5Ock5wFbggaWVKEkatGa+Dkm+AVwEnJlkH/AF4KIk24ACngT+EKCq9iS5DXgEOAxcVVVHlqVySVql5g3uqrr8GM03ztH/WuDapRQlSTo+75yUpM4Y3JLUGYNbkjpjcEtSZwxuSerMvFeVvBWOvPYKL+3/8Rvba09/J1Nv+40RViRJ42ssgvuVQ8/w2J1ffmP7XR/+V5zxbn+bSpKOxakSSeqMwS1JnTG4JakzBrckdWbsgjsTa5icOnnUZUjS2Bq74F6z9jROfsdZoy5DksbW2AV3JiaYmJwadRmSNLbGMLgnDW5JmsP4BXcmicEtScc1fsE9McHEmrG4oVOSxtL4BXcmyITBLUnHM29wJ9mc5L4kjyTZk+SzrX19knuS/KS9nt7ak+QrSfYmeSjJ+xZUUbKogUjSajHMGfdh4PNVdR5wIXBVkvOAq4F7q2orcG/bBvgos0933wrsAK4/4VVL0io2b3BX1YGq+n5b/wXwKLAR2A7c3LrdDHysrW8HvlazvgusS7LhRBcuSavVgua4k2wBzgfuB86qqgNt19PA0btmNgJPDRy2r7W9+b12JNmVZNehl19ZaN2StGoNHdxJTgW+CXyuql4a3FdVBdRCPriqbqiqmaqaWXfqKQs5VJJWtaGCO8kUs6H99ar6Vmt+5ugUSHs92Nr3A5sHDt/U2oZy6j/YOmxXSVqVhrmqJMCNwKNV9eWBXTuBK9r6FcAdA+2fbFeXXAi8ODClMq+T3vaOYbtK0qo0zAXTHwT+APhRkt2t7Y+APwZuS3Il8DPgE23fXcClwF7gl8CnFlLQhL8MKElzmje4q+o7wPEurv7wMfoXcNViC5qccr5bkuYydndOesYtSXMbu+D2IQqSNLexC24S4m3vknRc4xfckqQ5GdyS1BmDW5I6Y3BLUmfGKrgnpk5hcmrtqMuQpLE2VsF90ttP56S3rxt1GZI01sYquDO5hkz62DJJmstYBffExCSZmBx1GZI01sYquD3jlqT5jVdwT6xhwjNuSZrTmAX3BGSsSpKksTN2KenvlEjS3MYuuCVJczO4JakzBrckdWaYhwVvTnJfkkeS7Eny2db+xST7k+xuy6UDx1yTZG+Sx5L83rDFnHzaGYsbhSStIsNcNH0Y+HxVfT/JacCDSe5p+66rqv802DnJecBlwG8D7wT+Osk/rKoj833Q2vWbFla9JK1C855xV9WBqvp+W/8F8CiwcY5DtgO3VNWrVfUEs097v2CYYnxsmSTNb0Fz3Em2AOcD97emTyd5KMlNSU5vbRuBpwYO28fcQf+rYgxuSZrX0MGd5FTgm8Dnquol4HrgXGAbcAD404V8cJIdSXYl2XXo5VcAmJw6ZSFvIUmr0lDBnWSK2dD+elV9C6CqnqmqI1X1OvDn/Go6ZD+weeDwTa3t/1NVN1TVTFXNrDt1NrA945ak+Q1zVUmAG4FHq+rLA+0bBrr9PvBwW98JXJbk5CTnAFuBB4YqZs1Jw9YtSavWMFeVfBD4A+BHSXa3tj8CLk+yDSjgSeAPAapqT5LbgEeYvSLlqmGuKJEkDWfe4K6q7wDH+gGRu+Y45lrg2iXUJUk6Du+clKTOGNyS1JnxCe5MEH+LW5LmNTZJuXb9O5lae9qoy5CksTc2wT2x5iQy4fMmJWk+4xPck1Ozjy6TJM1pbJJyYnIN+KBgSZrX2AR3Jqf846QkDWFsknJ2qsQzbkmaz9gEN4lPeJekIYxPcEuShmJwS1JnxubC6eeee45n/vZv5+03NTXF+eefz5o1Y1O6JL2lxib97r77br7wF9fM22/9+vU8/vjjrFu3bvmLkqQxNBZTJUV44sChUZchSV0Yi+D+5ZHf4ImDr426DEnqwlgE9+Ga4vTf2j7qMiSpC2MR3CFMTvqEd0kaxjAPCz4lyQNJfphkT5IvtfZzktyfZG+SW5Oc1NpPbtt72/4t831GUbz00jNLHowkrQbDnHG/ClxcVe8FtgGXJLkQ+BPguqp6N/ACcGXrfyXwQmu/rvWb01ReYc8PvrGI8iVp9RnmYcEFvNw2p9pSwMXAv2jtNwNfBK4Htrd1gL8E/muStPc5phcPPc3fHz48VMGvv/46Bw8e5JVXXhmqvyT16LXXjn/BxlDXcSeZBB4E3g38GfA4cKiqjqbtPmBjW98IPAVQVYeTvAicATx3vPd/8f8OH8Kvvvoqt956K6ec4py4pJXr+eefP+6+oYK7qo4A25KsA24H3rPUopLsAHYs9Li1a9fymc98xhtwJK1ot95663H3Leiqkqo6BNwHfABYl+Ro8G8C9rf1/cBmgLb/HcCv/aejqm6oqpmqmllIDZK02g1zVcl0O9MmyVrgI8CjzAb4x1u3K4A72vrOtk3b/+255rclSQszzFTJBuDmNs89AdxWVXcmeQS4Jcl/BH4A3Nj63wj8jyR7gZ8Dly1D3ZK0ag1zVclDwPnHaP8pcMEx2l8B/vkJqU6S9GvG4s5JSdLwDG5J6sxY/B73unXruOiii4bqe+qppzI1NbW8BUnSGBuL4D733HO5/fbbR12GJHXBqRJJ6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTOGNyS1JlhHhZ8SpIHkvwwyZ4kX2rtX03yRJLdbdnW2pPkK0n2JnkoyfuWeQyStKoM83vcrwIXV9XLSaaA7yT5323fv6mqv3xT/48CW9vyfuD69ipJOgHmPeOuWS+3zam21ByHbAe+1o77LrAuyYallypJgiHnuJNMJtkNHATuqar7265r23TIdUlObm0bgacGDt/X2iRJJ8BQwV1VR6pqG7AJuCDJPwKuAd4D/BNgPfDvFvLBSXYk2ZVk17PPPruwqiVpFVvQVSVVdQi4D7ikqg606ZBXgb8ALmjd9gObBw7b1Nre/F43VNVMVc1MT08vqnhJWo2GuapkOsm6tr4W+Ajw46Pz1kkCfAx4uB2yE/hku7rkQuDFqjqwDLVL0qo0zFUlG4Cbk0wyG/S3VdWdSb6dZBoIsBv4163/XcClwF7gl8CnTnjVkrSKzRvcVfUQcP4x2i8+Tv8Crlp6aZKkY/HOSUnqjMEtSZ0xuCWpMwa3JHXG4JakzhjcktQZg1uSOmNwS1JnDG5J6ozBLUmdMbglqTMGtyR1xuCWpM4Y3JLUGYNbkjpjcEtSZwxuSeqMwS1JnTG4JakzBrckdcbglqTOGNyS1JlU1ahrIMkvgMdGXccyORN4btRFLIOVOi5YuWNzXH35raqaPtaONW91JcfxWFXNjLqI5ZBk10oc20odF6zcsTmulcOpEknqjMEtSZ0Zl+C+YdQFLKOVOraVOi5YuWNzXCvEWPxxUpI0vHE545YkDWnkwZ3kkiSPJdmb5OpR17NQSW5KcjDJwwNt65Pck+Qn7fX01p4kX2ljfSjJ+0ZX+dySbE5yX5JHkuxJ8tnW3vXYkpyS5IEkP2zj+lJrPyfJ/a3+W5Oc1NpPbtt72/4tIx3APJJMJvlBkjvb9koZ15NJfpRkd5Jdra3r7+JSjDS4k0wCfwZ8FDgPuDzJeaOsaRG+ClzyprargXuraitwb9uG2XFubcsO4Pq3qMbFOAx8vqrOAy4Ermr/bHof26vAxVX1XmAbcEmSC4E/Aa6rqncDLwBXtv5XAi+09utav3H2WeDRge2VMi6A36mqbQOX/vX+XVy8qhrZAnwAuHtg+xrgmlHWtMhxbAEeHth+DNjQ1jcwe506wH8HLj9Wv3FfgDuAj6yksQFvA74PvJ/ZGzjWtPY3vpfA3cAH2vqa1i+jrv0449nEbIBdDNwJZCWMq9X4JHDmm9pWzHdxocuop0o2Ak8NbO9rbb07q6oOtPWngbPaepfjbf8bfT5wPytgbG06YTdwELgHeBw4VFWHW5fB2t8YV9v/InDGW1rw8P4z8G+B19v2GayMcQEU8FdJHkyyo7V1/11crHG5c3LFqqpK0u2lO0lOBb4JfK6qXkryxr5ex1ZVR4BtSdYBtwPvGW1FS5fknwIHq+rBJBeNuJzl8KGq2p/kN4F7kvx4cGev38XFGvUZ935g88D2ptbWu2eSbABorwdbe1fjTTLFbGh/vaq+1ZpXxNgAquoQcB+zUwjrkhw9kRms/Y1xtf3vAJ5/aysdygeBf5bkSeAWZqdL/gv9jwuAqtrfXg8y+x/bC1hB38WFGnVwfw/Y2v7yfRJwGbBzxDWdCDuBK9r6FczODx9t/2T7q/eFwIsD/6s3VjJ7an0j8GhVfXlgV9djSzLdzrRJspbZeftHmQ3wj7dubx7X0fF+HPh2tYnTcVJV11TVpqrawuy/R9+uqn9J5+MCSPL2JKcdXQd+F3iYzr+LSzLqSXbgUuDvmJ1n/PejrmcR9X8DOAC8xuxc2pXMzhXeC/wE+GtgfesbZq+ieRz4ETAz6vrnGNeHmJ1XfAjY3ZZLex8b8I+BH7RxPQz8h9b+LuABYC/wv4CTW/spbXtv2/+uUY9hiDFeBNy5UsbVxvDDtuw5mhO9fxeXsnjnpCR1ZtRTJZKkBTK4JakzBrckdcbglqTOGNyS1BmDW5I6Y3BLUmcMbknqzP8DSiMfy1fk/vAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 0.5\n",
        "\n",
        "# value_min = 0.01\n",
        "\n",
        "#value_test = 0.05\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "# target_model_update=1e-2\n",
        "\n",
        "nb_steps=50000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "0GMfAK_bkFpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=0.5,\n",
        "                               value_min=0.01, \n",
        "                               value_test=0.05,\n",
        "                               nb_steps=50000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qNQqIxxxjuFP",
        "outputId": "453219c2-0073-4ec7-9d7d-61eb8b25204b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   170/50000: episode: 1, duration: 5.575s, episode steps: 170, steps per second:  30, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 9.751393, mae: 27.911642, mean_q: 55.224113, mean_eps: 0.499118\n",
            "   210/50000: episode: 2, duration: 0.361s, episode steps:  40, steps per second: 111, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.683141, mae: 28.165603, mean_q: 55.739946, mean_eps: 0.498143\n",
            "   406/50000: episode: 3, duration: 2.176s, episode steps: 196, steps per second:  90, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 11.227803, mae: 28.335392, mean_q: 56.093776, mean_eps: 0.496986\n",
            "   606/50000: episode: 4, duration: 2.032s, episode steps: 200, steps per second:  98, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.038761, mae: 28.896393, mean_q: 57.491890, mean_eps: 0.495046\n",
            "   732/50000: episode: 5, duration: 1.046s, episode steps: 126, steps per second: 120, episode reward: 126.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 8.861438, mae: 29.240648, mean_q: 58.430772, mean_eps: 0.493449\n",
            "   898/50000: episode: 6, duration: 1.368s, episode steps: 166, steps per second: 121, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 12.404434, mae: 29.846009, mean_q: 59.535682, mean_eps: 0.492018\n",
            "  1098/50000: episode: 7, duration: 1.674s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 10.356246, mae: 30.790751, mean_q: 61.609655, mean_eps: 0.490225\n",
            "  1272/50000: episode: 8, duration: 1.445s, episode steps: 174, steps per second: 120, episode reward: 174.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 10.181444, mae: 31.486939, mean_q: 62.990138, mean_eps: 0.488392\n",
            "  1325/50000: episode: 9, duration: 0.465s, episode steps:  53, steps per second: 114, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 8.194987, mae: 32.187181, mean_q: 64.573153, mean_eps: 0.487280\n",
            "  1484/50000: episode: 10, duration: 1.338s, episode steps: 159, steps per second: 119, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 9.475263, mae: 32.737725, mean_q: 65.604102, mean_eps: 0.486241\n",
            "  1625/50000: episode: 11, duration: 1.220s, episode steps: 141, steps per second: 116, episode reward: 141.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.496 [0.000, 1.000],  loss: 10.242714, mae: 33.460093, mean_q: 66.968793, mean_eps: 0.484771\n",
            "  1750/50000: episode: 12, duration: 1.245s, episode steps: 125, steps per second: 100, episode reward: 125.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 10.967564, mae: 34.174633, mean_q: 68.376981, mean_eps: 0.483467\n",
            "  1931/50000: episode: 13, duration: 2.146s, episode steps: 181, steps per second:  84, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 13.735780, mae: 34.547938, mean_q: 69.059578, mean_eps: 0.481968\n",
            "  2086/50000: episode: 14, duration: 1.319s, episode steps: 155, steps per second: 117, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 15.020757, mae: 35.103412, mean_q: 70.085371, mean_eps: 0.480322\n",
            "  2142/50000: episode: 15, duration: 0.484s, episode steps:  56, steps per second: 116, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 17.176755, mae: 35.674162, mean_q: 70.876724, mean_eps: 0.479288\n",
            "  2333/50000: episode: 16, duration: 1.587s, episode steps: 191, steps per second: 120, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 13.888998, mae: 36.063366, mean_q: 72.017887, mean_eps: 0.478077\n",
            "  2427/50000: episode: 17, duration: 0.804s, episode steps:  94, steps per second: 117, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 18.329710, mae: 36.320467, mean_q: 72.420661, mean_eps: 0.476681\n",
            "  2568/50000: episode: 18, duration: 1.217s, episode steps: 141, steps per second: 116, episode reward: 141.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 9.533656, mae: 36.829293, mean_q: 73.938252, mean_eps: 0.475529\n",
            "  2691/50000: episode: 19, duration: 1.051s, episode steps: 123, steps per second: 117, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 18.996254, mae: 37.387902, mean_q: 74.710403, mean_eps: 0.474236\n",
            "  2712/50000: episode: 20, duration: 0.222s, episode steps:  21, steps per second:  95, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 12.336423, mae: 37.175121, mean_q: 74.314627, mean_eps: 0.473530\n",
            "  2832/50000: episode: 21, duration: 1.015s, episode steps: 120, steps per second: 118, episode reward: 120.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 16.669093, mae: 37.772850, mean_q: 75.471391, mean_eps: 0.472839\n",
            "  3032/50000: episode: 22, duration: 1.660s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 13.542247, mae: 38.098865, mean_q: 76.206973, mean_eps: 0.471271\n",
            "  3048/50000: episode: 23, duration: 0.135s, episode steps:  16, steps per second: 119, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 13.448402, mae: 38.072121, mean_q: 76.165385, mean_eps: 0.470213\n",
            "  3110/50000: episode: 24, duration: 0.528s, episode steps:  62, steps per second: 118, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 12.408688, mae: 38.751623, mean_q: 77.588082, mean_eps: 0.469831\n",
            "  3274/50000: episode: 25, duration: 1.923s, episode steps: 164, steps per second:  85, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 18.734592, mae: 38.935127, mean_q: 77.699829, mean_eps: 0.468723\n",
            "  3465/50000: episode: 26, duration: 1.925s, episode steps: 191, steps per second:  99, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 18.768546, mae: 39.325696, mean_q: 78.542055, mean_eps: 0.466984\n",
            "  3665/50000: episode: 27, duration: 1.634s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 20.265701, mae: 39.826123, mean_q: 79.436569, mean_eps: 0.465068\n",
            "  3691/50000: episode: 28, duration: 0.246s, episode steps:  26, steps per second: 106, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.245896, mae: 39.916601, mean_q: 79.492615, mean_eps: 0.463960\n",
            "  3891/50000: episode: 29, duration: 1.661s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 16.999800, mae: 40.216410, mean_q: 80.393696, mean_eps: 0.462853\n",
            "  3922/50000: episode: 30, duration: 0.266s, episode steps:  31, steps per second: 116, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 16.885668, mae: 40.771153, mean_q: 81.110794, mean_eps: 0.461721\n",
            "  4061/50000: episode: 31, duration: 1.178s, episode steps: 139, steps per second: 118, episode reward: 139.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 16.067256, mae: 40.611219, mean_q: 81.175502, mean_eps: 0.460888\n",
            "  4147/50000: episode: 32, duration: 0.704s, episode steps:  86, steps per second: 122, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 12.978567, mae: 40.946961, mean_q: 81.766850, mean_eps: 0.459786\n",
            "  4277/50000: episode: 33, duration: 1.065s, episode steps: 130, steps per second: 122, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 17.479582, mae: 41.131170, mean_q: 81.903099, mean_eps: 0.458727\n",
            "  4401/50000: episode: 34, duration: 1.024s, episode steps: 124, steps per second: 121, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 21.957906, mae: 41.268222, mean_q: 82.241055, mean_eps: 0.457483\n",
            "  4512/50000: episode: 35, duration: 0.938s, episode steps: 111, steps per second: 118, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 11.717334, mae: 41.422100, mean_q: 82.862994, mean_eps: 0.456331\n",
            "  4659/50000: episode: 36, duration: 1.592s, episode steps: 147, steps per second:  92, episode reward: 147.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 19.309966, mae: 41.641772, mean_q: 83.040616, mean_eps: 0.455067\n",
            "  4859/50000: episode: 37, duration: 2.226s, episode steps: 200, steps per second:  90, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 17.272232, mae: 41.807158, mean_q: 83.443874, mean_eps: 0.453367\n",
            "  5059/50000: episode: 38, duration: 1.715s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 17.117635, mae: 42.075654, mean_q: 84.116848, mean_eps: 0.451407\n",
            "  5259/50000: episode: 39, duration: 1.711s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 18.261258, mae: 42.368867, mean_q: 84.512538, mean_eps: 0.449447\n",
            "  5459/50000: episode: 40, duration: 1.667s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 20.434506, mae: 42.515287, mean_q: 84.762855, mean_eps: 0.447487\n",
            "  5511/50000: episode: 41, duration: 0.446s, episode steps:  52, steps per second: 117, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 12.280617, mae: 42.498164, mean_q: 84.958846, mean_eps: 0.446252\n",
            "  5705/50000: episode: 42, duration: 1.602s, episode steps: 194, steps per second: 121, episode reward: 194.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 19.819446, mae: 42.723373, mean_q: 85.096139, mean_eps: 0.445047\n",
            "  5782/50000: episode: 43, duration: 0.664s, episode steps:  77, steps per second: 116, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 24.933259, mae: 42.778428, mean_q: 85.252058, mean_eps: 0.443719\n",
            "  5814/50000: episode: 44, duration: 0.264s, episode steps:  32, steps per second: 121, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 18.720098, mae: 42.752543, mean_q: 85.463998, mean_eps: 0.443184\n",
            "  6010/50000: episode: 45, duration: 1.715s, episode steps: 196, steps per second: 114, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 16.137566, mae: 43.031584, mean_q: 85.930945, mean_eps: 0.442067\n",
            "  6170/50000: episode: 46, duration: 1.914s, episode steps: 160, steps per second:  84, episode reward: 160.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 13.407822, mae: 43.468537, mean_q: 86.935313, mean_eps: 0.440323\n",
            "  6370/50000: episode: 47, duration: 1.910s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 16.015476, mae: 43.673512, mean_q: 87.286490, mean_eps: 0.438559\n",
            "  6452/50000: episode: 48, duration: 0.703s, episode steps:  82, steps per second: 117, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 23.527072, mae: 43.814585, mean_q: 87.289908, mean_eps: 0.437177\n",
            "  6652/50000: episode: 49, duration: 1.632s, episode steps: 200, steps per second: 123, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 17.166432, mae: 44.005442, mean_q: 87.880823, mean_eps: 0.435795\n",
            "  6718/50000: episode: 50, duration: 0.562s, episode steps:  66, steps per second: 117, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 10.811217, mae: 44.290513, mean_q: 88.427302, mean_eps: 0.434492\n",
            "  6759/50000: episode: 51, duration: 0.340s, episode steps:  41, steps per second: 121, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 27.564682, mae: 44.449868, mean_q: 87.896233, mean_eps: 0.433968\n",
            "  6959/50000: episode: 52, duration: 1.632s, episode steps: 200, steps per second: 123, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 21.338357, mae: 44.298871, mean_q: 88.044051, mean_eps: 0.432787\n",
            "  7071/50000: episode: 53, duration: 0.929s, episode steps: 112, steps per second: 121, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 20.097935, mae: 44.502222, mean_q: 88.576522, mean_eps: 0.431258\n",
            "  7271/50000: episode: 54, duration: 1.634s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 14.951375, mae: 44.392306, mean_q: 88.640139, mean_eps: 0.429729\n",
            "  7321/50000: episode: 55, duration: 0.434s, episode steps:  50, steps per second: 115, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 24.434156, mae: 44.752516, mean_q: 89.072742, mean_eps: 0.428504\n",
            "  7521/50000: episode: 56, duration: 1.986s, episode steps: 200, steps per second: 101, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 19.444072, mae: 44.809361, mean_q: 89.472114, mean_eps: 0.427279\n",
            "  7721/50000: episode: 57, duration: 2.337s, episode steps: 200, steps per second:  86, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 16.521819, mae: 45.108584, mean_q: 89.987600, mean_eps: 0.425319\n",
            "  7921/50000: episode: 58, duration: 1.696s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 25.101224, mae: 45.403740, mean_q: 90.281596, mean_eps: 0.423359\n",
            "  8121/50000: episode: 59, duration: 1.731s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 20.951806, mae: 45.423165, mean_q: 90.588029, mean_eps: 0.421399\n",
            "  8321/50000: episode: 60, duration: 1.674s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 26.287057, mae: 45.524403, mean_q: 90.665654, mean_eps: 0.419439\n",
            "  8505/50000: episode: 61, duration: 1.550s, episode steps: 184, steps per second: 119, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 21.919482, mae: 45.602765, mean_q: 90.963743, mean_eps: 0.417558\n",
            "  8561/50000: episode: 62, duration: 0.451s, episode steps:  56, steps per second: 124, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 25.700928, mae: 45.651889, mean_q: 91.019839, mean_eps: 0.416381\n",
            "  8761/50000: episode: 63, duration: 2.488s, episode steps: 200, steps per second:  80, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 20.080810, mae: 45.783259, mean_q: 91.419565, mean_eps: 0.415127\n",
            "  8961/50000: episode: 64, duration: 3.164s, episode steps: 200, steps per second:  63, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 15.952766, mae: 45.991089, mean_q: 91.866247, mean_eps: 0.413167\n",
            "  9161/50000: episode: 65, duration: 1.670s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 24.557883, mae: 46.181968, mean_q: 92.015923, mean_eps: 0.411207\n",
            "  9361/50000: episode: 66, duration: 1.688s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 22.394170, mae: 46.197464, mean_q: 92.217812, mean_eps: 0.409247\n",
            "  9561/50000: episode: 67, duration: 1.667s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 14.706506, mae: 46.407748, mean_q: 92.775738, mean_eps: 0.407287\n",
            "  9761/50000: episode: 68, duration: 1.635s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 22.468172, mae: 46.720630, mean_q: 93.268837, mean_eps: 0.405327\n",
            "  9961/50000: episode: 69, duration: 1.647s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 18.453234, mae: 46.794930, mean_q: 93.399387, mean_eps: 0.403367\n",
            " 10161/50000: episode: 70, duration: 1.687s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 22.735564, mae: 46.984388, mean_q: 93.715352, mean_eps: 0.401407\n",
            " 10277/50000: episode: 71, duration: 1.360s, episode steps: 116, steps per second:  85, episode reward: 116.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 25.668575, mae: 47.239086, mean_q: 93.983957, mean_eps: 0.399859\n",
            " 10371/50000: episode: 72, duration: 1.134s, episode steps:  94, steps per second:  83, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 26.639815, mae: 47.438412, mean_q: 94.246120, mean_eps: 0.398830\n",
            " 10571/50000: episode: 73, duration: 1.797s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 15.917752, mae: 47.154316, mean_q: 94.066262, mean_eps: 0.397389\n",
            " 10771/50000: episode: 74, duration: 1.635s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 27.984897, mae: 47.135958, mean_q: 93.927171, mean_eps: 0.395429\n",
            " 10893/50000: episode: 75, duration: 1.021s, episode steps: 122, steps per second: 119, episode reward: 122.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 25.948646, mae: 47.014954, mean_q: 93.689685, mean_eps: 0.393851\n",
            " 10929/50000: episode: 76, duration: 0.304s, episode steps:  36, steps per second: 118, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 20.216647, mae: 47.293742, mean_q: 94.498822, mean_eps: 0.393077\n",
            " 11009/50000: episode: 77, duration: 0.682s, episode steps:  80, steps per second: 117, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 12.267971, mae: 47.226874, mean_q: 94.411123, mean_eps: 0.392509\n",
            " 11057/50000: episode: 78, duration: 0.400s, episode steps:  48, steps per second: 120, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 16.146947, mae: 47.379343, mean_q: 94.710564, mean_eps: 0.391881\n",
            " 11257/50000: episode: 79, duration: 1.685s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 23.573275, mae: 47.428380, mean_q: 94.487991, mean_eps: 0.390666\n",
            " 11416/50000: episode: 80, duration: 1.313s, episode steps: 159, steps per second: 121, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 17.142118, mae: 47.535649, mean_q: 94.928212, mean_eps: 0.388907\n",
            " 11545/50000: episode: 81, duration: 1.068s, episode steps: 129, steps per second: 121, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 27.634223, mae: 47.532950, mean_q: 94.777441, mean_eps: 0.387496\n",
            " 11745/50000: episode: 82, duration: 2.167s, episode steps: 200, steps per second:  92, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 20.871377, mae: 47.547438, mean_q: 94.832703, mean_eps: 0.385884\n",
            " 11859/50000: episode: 83, duration: 1.355s, episode steps: 114, steps per second:  84, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 28.796196, mae: 47.562203, mean_q: 94.607755, mean_eps: 0.384345\n",
            " 12059/50000: episode: 84, duration: 1.650s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 24.304263, mae: 47.422863, mean_q: 94.547592, mean_eps: 0.382807\n",
            " 12112/50000: episode: 85, duration: 0.458s, episode steps:  53, steps per second: 116, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 27.249622, mae: 47.573294, mean_q: 94.724421, mean_eps: 0.381567\n",
            " 12312/50000: episode: 86, duration: 1.646s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 17.944720, mae: 47.473093, mean_q: 94.983445, mean_eps: 0.380327\n",
            " 12512/50000: episode: 87, duration: 1.669s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 17.612232, mae: 47.664382, mean_q: 95.254311, mean_eps: 0.378367\n",
            " 12697/50000: episode: 88, duration: 1.564s, episode steps: 185, steps per second: 118, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 26.105724, mae: 47.765460, mean_q: 95.003572, mean_eps: 0.376481\n",
            " 12779/50000: episode: 89, duration: 0.685s, episode steps:  82, steps per second: 120, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 21.305831, mae: 47.873975, mean_q: 95.513725, mean_eps: 0.375172\n",
            " 12979/50000: episode: 90, duration: 1.657s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 20.454616, mae: 47.719284, mean_q: 95.350140, mean_eps: 0.373791\n",
            " 13012/50000: episode: 91, duration: 0.290s, episode steps:  33, steps per second: 114, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 15.470994, mae: 47.763467, mean_q: 95.468873, mean_eps: 0.372649\n",
            " 13027/50000: episode: 92, duration: 0.132s, episode steps:  15, steps per second: 113, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 20.144016, mae: 47.893010, mean_q: 95.403844, mean_eps: 0.372414\n",
            " 13136/50000: episode: 93, duration: 1.239s, episode steps: 109, steps per second:  88, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 26.029537, mae: 47.784663, mean_q: 95.043064, mean_eps: 0.371806\n",
            " 13336/50000: episode: 94, duration: 2.264s, episode steps: 200, steps per second:  88, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 18.822486, mae: 47.799795, mean_q: 95.427660, mean_eps: 0.370292\n",
            " 13536/50000: episode: 95, duration: 1.639s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 21.070715, mae: 47.873329, mean_q: 95.543357, mean_eps: 0.368332\n",
            " 13736/50000: episode: 96, duration: 1.651s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 16.682401, mae: 47.836222, mean_q: 95.463556, mean_eps: 0.366372\n",
            " 13778/50000: episode: 97, duration: 0.367s, episode steps:  42, steps per second: 114, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 22.240819, mae: 47.948527, mean_q: 95.633366, mean_eps: 0.365186\n",
            " 13978/50000: episode: 98, duration: 1.633s, episode steps: 200, steps per second: 123, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 22.863857, mae: 47.841081, mean_q: 95.371061, mean_eps: 0.364001\n",
            " 14124/50000: episode: 99, duration: 1.214s, episode steps: 146, steps per second: 120, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 29.560045, mae: 47.800522, mean_q: 95.069062, mean_eps: 0.362305\n",
            " 14324/50000: episode: 100, duration: 1.659s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 20.576949, mae: 47.669716, mean_q: 95.116609, mean_eps: 0.360610\n",
            " 14524/50000: episode: 101, duration: 1.775s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 20.818527, mae: 47.709657, mean_q: 95.284952, mean_eps: 0.358650\n",
            " 14667/50000: episode: 102, duration: 1.683s, episode steps: 143, steps per second:  85, episode reward: 143.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 16.548291, mae: 47.890970, mean_q: 95.768900, mean_eps: 0.356969\n",
            " 14867/50000: episode: 103, duration: 1.921s, episode steps: 200, steps per second: 104, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 16.753226, mae: 47.889976, mean_q: 95.739494, mean_eps: 0.355288\n",
            " 15067/50000: episode: 104, duration: 1.615s, episode steps: 200, steps per second: 124, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 19.455023, mae: 47.933690, mean_q: 95.680272, mean_eps: 0.353328\n",
            " 15230/50000: episode: 105, duration: 1.346s, episode steps: 163, steps per second: 121, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 23.457069, mae: 47.967081, mean_q: 95.687082, mean_eps: 0.351550\n",
            " 15430/50000: episode: 106, duration: 1.622s, episode steps: 200, steps per second: 123, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 22.339259, mae: 47.969092, mean_q: 95.711347, mean_eps: 0.349771\n",
            " 15503/50000: episode: 107, duration: 0.610s, episode steps:  73, steps per second: 120, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 34.559537, mae: 47.823728, mean_q: 95.070963, mean_eps: 0.348433\n",
            " 15703/50000: episode: 108, duration: 1.650s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 25.643154, mae: 47.805129, mean_q: 95.152250, mean_eps: 0.347096\n",
            " 15903/50000: episode: 109, duration: 1.647s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 22.565602, mae: 47.585228, mean_q: 94.955824, mean_eps: 0.345136\n",
            " 16103/50000: episode: 110, duration: 2.278s, episode steps: 200, steps per second:  88, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 18.759416, mae: 47.810691, mean_q: 95.416654, mean_eps: 0.343176\n",
            " 16303/50000: episode: 111, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 18.507775, mae: 47.763861, mean_q: 95.413912, mean_eps: 0.341216\n",
            " 16503/50000: episode: 112, duration: 1.642s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 20.377715, mae: 47.704791, mean_q: 95.143848, mean_eps: 0.339255\n",
            " 16616/50000: episode: 113, duration: 0.938s, episode steps: 113, steps per second: 120, episode reward: 113.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 20.305438, mae: 47.790107, mean_q: 95.347095, mean_eps: 0.337722\n",
            " 16816/50000: episode: 114, duration: 1.638s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 20.314462, mae: 47.582634, mean_q: 94.876575, mean_eps: 0.336188\n",
            " 16989/50000: episode: 115, duration: 1.419s, episode steps: 173, steps per second: 122, episode reward: 173.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 19.295490, mae: 47.562619, mean_q: 94.878869, mean_eps: 0.334360\n",
            " 17189/50000: episode: 116, duration: 1.648s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 23.996392, mae: 47.549422, mean_q: 94.541540, mean_eps: 0.332533\n",
            " 17389/50000: episode: 117, duration: 1.651s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 22.113413, mae: 47.401832, mean_q: 94.354421, mean_eps: 0.330573\n",
            " 17589/50000: episode: 118, duration: 2.356s, episode steps: 200, steps per second:  85, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 19.322921, mae: 47.207640, mean_q: 94.158834, mean_eps: 0.328613\n",
            " 17789/50000: episode: 119, duration: 1.907s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 22.731686, mae: 47.030590, mean_q: 93.430953, mean_eps: 0.326653\n",
            " 17989/50000: episode: 120, duration: 1.669s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.162766, mae: 46.876618, mean_q: 93.417528, mean_eps: 0.324693\n",
            " 18102/50000: episode: 121, duration: 0.939s, episode steps: 113, steps per second: 120, episode reward: 113.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.496 [0.000, 1.000],  loss: 16.793552, mae: 46.974398, mean_q: 93.704173, mean_eps: 0.323159\n",
            " 18302/50000: episode: 122, duration: 1.639s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 24.026774, mae: 46.692155, mean_q: 92.790574, mean_eps: 0.321625\n",
            " 18502/50000: episode: 123, duration: 1.636s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 21.437000, mae: 46.373724, mean_q: 92.149054, mean_eps: 0.319665\n",
            " 18702/50000: episode: 124, duration: 1.646s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 18.619636, mae: 46.245009, mean_q: 92.107725, mean_eps: 0.317705\n",
            " 18902/50000: episode: 125, duration: 1.801s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 19.544616, mae: 46.144025, mean_q: 91.778062, mean_eps: 0.315745\n",
            " 19102/50000: episode: 126, duration: 2.372s, episode steps: 200, steps per second:  84, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 17.714320, mae: 45.805547, mean_q: 91.189223, mean_eps: 0.313785\n",
            " 19302/50000: episode: 127, duration: 1.668s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 16.361936, mae: 45.810828, mean_q: 91.406336, mean_eps: 0.311825\n",
            " 19502/50000: episode: 128, duration: 1.660s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 15.696272, mae: 45.925074, mean_q: 91.470472, mean_eps: 0.309865\n",
            " 19702/50000: episode: 129, duration: 1.683s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 14.367454, mae: 45.888996, mean_q: 91.636979, mean_eps: 0.307905\n",
            " 19902/50000: episode: 130, duration: 1.654s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 20.330834, mae: 45.878688, mean_q: 91.208369, mean_eps: 0.305945\n",
            " 20102/50000: episode: 131, duration: 1.659s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 14.596457, mae: 45.859612, mean_q: 91.368945, mean_eps: 0.303985\n",
            " 20302/50000: episode: 132, duration: 1.636s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 17.653624, mae: 45.491382, mean_q: 90.527572, mean_eps: 0.302025\n",
            " 20502/50000: episode: 133, duration: 2.369s, episode steps: 200, steps per second:  84, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 20.817848, mae: 45.143231, mean_q: 89.615118, mean_eps: 0.300065\n",
            " 20702/50000: episode: 134, duration: 1.841s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 14.310580, mae: 44.871512, mean_q: 89.353644, mean_eps: 0.298105\n",
            " 20808/50000: episode: 135, duration: 0.879s, episode steps: 106, steps per second: 121, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 17.104608, mae: 44.815247, mean_q: 89.323309, mean_eps: 0.296606\n",
            " 21008/50000: episode: 136, duration: 1.682s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.183436, mae: 44.664137, mean_q: 88.937110, mean_eps: 0.295106\n",
            " 21208/50000: episode: 137, duration: 1.689s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.324096, mae: 44.374477, mean_q: 88.572721, mean_eps: 0.293146\n",
            " 21331/50000: episode: 138, duration: 1.024s, episode steps: 123, steps per second: 120, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.496 [0.000, 1.000],  loss: 17.578087, mae: 44.497393, mean_q: 88.456642, mean_eps: 0.291564\n",
            " 21531/50000: episode: 139, duration: 1.654s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 11.350450, mae: 44.319860, mean_q: 88.442154, mean_eps: 0.289981\n",
            " 21731/50000: episode: 140, duration: 1.658s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 16.675950, mae: 44.524456, mean_q: 88.581379, mean_eps: 0.288021\n",
            " 21931/50000: episode: 141, duration: 2.290s, episode steps: 200, steps per second:  87, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 16.738514, mae: 44.246640, mean_q: 87.922136, mean_eps: 0.286061\n",
            " 22131/50000: episode: 142, duration: 1.905s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 8.481729, mae: 44.045243, mean_q: 87.938709, mean_eps: 0.284101\n",
            " 22331/50000: episode: 143, duration: 1.638s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 10.646166, mae: 44.198884, mean_q: 88.220271, mean_eps: 0.282141\n",
            " 22409/50000: episode: 144, duration: 0.662s, episode steps:  78, steps per second: 118, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 18.695102, mae: 44.105724, mean_q: 87.683437, mean_eps: 0.280779\n",
            " 22424/50000: episode: 145, duration: 0.134s, episode steps:  15, steps per second: 112, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 24.040712, mae: 43.962391, mean_q: 87.227108, mean_eps: 0.280323\n",
            " 22624/50000: episode: 146, duration: 1.696s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 14.184459, mae: 43.722261, mean_q: 86.943100, mean_eps: 0.279270\n",
            " 22670/50000: episode: 147, duration: 0.395s, episode steps:  46, steps per second: 116, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 15.080980, mae: 43.528857, mean_q: 86.421058, mean_eps: 0.278064\n",
            " 22870/50000: episode: 148, duration: 1.712s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 12.890547, mae: 43.536346, mean_q: 86.637494, mean_eps: 0.276859\n",
            " 23070/50000: episode: 149, duration: 1.644s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.497758, mae: 43.349698, mean_q: 86.193805, mean_eps: 0.274899\n",
            " 23270/50000: episode: 150, duration: 1.908s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 11.138021, mae: 42.810897, mean_q: 85.164262, mean_eps: 0.272939\n",
            " 23470/50000: episode: 151, duration: 2.295s, episode steps: 200, steps per second:  87, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 8.875228, mae: 42.605446, mean_q: 84.880003, mean_eps: 0.270979\n",
            " 23632/50000: episode: 152, duration: 1.337s, episode steps: 162, steps per second: 121, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 11.755739, mae: 42.450482, mean_q: 84.533880, mean_eps: 0.269205\n",
            " 23789/50000: episode: 153, duration: 1.268s, episode steps: 157, steps per second: 124, episode reward: 157.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 10.237243, mae: 42.400227, mean_q: 84.460549, mean_eps: 0.267642\n",
            " 23982/50000: episode: 154, duration: 1.560s, episode steps: 193, steps per second: 124, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 13.155738, mae: 42.242513, mean_q: 84.011262, mean_eps: 0.265927\n",
            " 24013/50000: episode: 155, duration: 0.267s, episode steps:  31, steps per second: 116, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 12.557894, mae: 41.471551, mean_q: 82.592174, mean_eps: 0.264829\n",
            " 24213/50000: episode: 156, duration: 1.611s, episode steps: 200, steps per second: 124, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 6.093420, mae: 41.811632, mean_q: 83.460581, mean_eps: 0.263698\n",
            " 24413/50000: episode: 157, duration: 1.654s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 10.621904, mae: 41.408560, mean_q: 82.461728, mean_eps: 0.261737\n",
            " 24606/50000: episode: 158, duration: 1.595s, episode steps: 193, steps per second: 121, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 10.662423, mae: 41.466797, mean_q: 82.678278, mean_eps: 0.259812\n",
            " 24663/50000: episode: 159, duration: 0.495s, episode steps:  57, steps per second: 115, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 18.961480, mae: 41.175791, mean_q: 81.701865, mean_eps: 0.258587\n",
            " 24863/50000: episode: 160, duration: 2.373s, episode steps: 200, steps per second:  84, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 8.115860, mae: 41.155335, mean_q: 81.975394, mean_eps: 0.257327\n",
            " 25063/50000: episode: 161, duration: 1.844s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 7.207454, mae: 40.782407, mean_q: 81.403813, mean_eps: 0.255367\n",
            " 25263/50000: episode: 162, duration: 1.665s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 11.197605, mae: 40.654626, mean_q: 80.943748, mean_eps: 0.253408\n",
            " 25297/50000: episode: 163, duration: 0.285s, episode steps:  34, steps per second: 119, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 6.312211, mae: 40.275656, mean_q: 80.042840, mean_eps: 0.252261\n",
            " 25350/50000: episode: 164, duration: 0.454s, episode steps:  53, steps per second: 117, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 6.429722, mae: 40.576261, mean_q: 80.959099, mean_eps: 0.251835\n",
            " 25550/50000: episode: 165, duration: 1.654s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 10.077383, mae: 40.229093, mean_q: 80.189795, mean_eps: 0.250595\n",
            " 25600/50000: episode: 166, duration: 0.424s, episode steps:  50, steps per second: 118, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 11.159029, mae: 39.639088, mean_q: 78.996255, mean_eps: 0.249370\n",
            " 25800/50000: episode: 167, duration: 1.659s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 8.758888, mae: 40.075836, mean_q: 79.875798, mean_eps: 0.248145\n",
            " 25840/50000: episode: 168, duration: 0.343s, episode steps:  40, steps per second: 116, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.391817, mae: 39.715486, mean_q: 78.996847, mean_eps: 0.246969\n",
            " 26040/50000: episode: 169, duration: 1.673s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 7.851400, mae: 39.720252, mean_q: 79.406692, mean_eps: 0.245793\n",
            " 26240/50000: episode: 170, duration: 2.182s, episode steps: 200, steps per second:  92, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 9.918190, mae: 39.549380, mean_q: 78.816917, mean_eps: 0.243833\n",
            " 26440/50000: episode: 171, duration: 2.058s, episode steps: 200, steps per second:  97, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 10.287095, mae: 39.114409, mean_q: 78.020290, mean_eps: 0.241873\n",
            " 26640/50000: episode: 172, duration: 1.652s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 8.361245, mae: 39.031098, mean_q: 77.934755, mean_eps: 0.239913\n",
            " 26840/50000: episode: 173, duration: 1.653s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.614804, mae: 38.679127, mean_q: 77.177280, mean_eps: 0.237953\n",
            " 27040/50000: episode: 174, duration: 1.649s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.653853, mae: 39.149319, mean_q: 78.099029, mean_eps: 0.235993\n",
            " 27240/50000: episode: 175, duration: 1.660s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 6.445557, mae: 38.352377, mean_q: 76.584506, mean_eps: 0.234033\n",
            " 27440/50000: episode: 176, duration: 1.635s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.333505, mae: 38.235127, mean_q: 76.287239, mean_eps: 0.232073\n",
            " 27606/50000: episode: 177, duration: 1.594s, episode steps: 166, steps per second: 104, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 8.376131, mae: 37.895816, mean_q: 75.542203, mean_eps: 0.230279\n",
            " 27806/50000: episode: 178, duration: 2.377s, episode steps: 200, steps per second:  84, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 4.541422, mae: 37.840605, mean_q: 75.612543, mean_eps: 0.228486\n",
            " 28006/50000: episode: 179, duration: 1.657s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 8.829011, mae: 37.891900, mean_q: 75.561009, mean_eps: 0.226526\n",
            " 28030/50000: episode: 180, duration: 0.203s, episode steps:  24, steps per second: 118, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.135058, mae: 38.704299, mean_q: 77.260379, mean_eps: 0.225429\n",
            " 28183/50000: episode: 181, duration: 1.270s, episode steps: 153, steps per second: 120, episode reward: 153.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 9.175807, mae: 37.836439, mean_q: 75.392572, mean_eps: 0.224561\n",
            " 28267/50000: episode: 182, duration: 0.710s, episode steps:  84, steps per second: 118, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 6.319113, mae: 38.318042, mean_q: 76.517061, mean_eps: 0.223400\n",
            " 28467/50000: episode: 183, duration: 1.652s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 4.964813, mae: 37.600052, mean_q: 75.070338, mean_eps: 0.222008\n",
            " 28600/50000: episode: 184, duration: 1.093s, episode steps: 133, steps per second: 122, episode reward: 133.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.496 [0.000, 1.000],  loss: 10.401341, mae: 37.589562, mean_q: 74.983913, mean_eps: 0.220377\n",
            " 28800/50000: episode: 185, duration: 1.644s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 7.531704, mae: 37.378712, mean_q: 74.493969, mean_eps: 0.218745\n",
            " 28973/50000: episode: 186, duration: 1.439s, episode steps: 173, steps per second: 120, episode reward: 173.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 10.924612, mae: 37.320955, mean_q: 74.253679, mean_eps: 0.216917\n",
            " 29158/50000: episode: 187, duration: 2.065s, episode steps: 185, steps per second:  90, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 4.843784, mae: 37.068034, mean_q: 74.061926, mean_eps: 0.215163\n",
            " 29343/50000: episode: 188, duration: 1.979s, episode steps: 185, steps per second:  93, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 5.488026, mae: 36.760230, mean_q: 73.351414, mean_eps: 0.213350\n",
            " 29543/50000: episode: 189, duration: 1.710s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.261806, mae: 36.823961, mean_q: 73.508108, mean_eps: 0.211464\n",
            " 29743/50000: episode: 190, duration: 1.680s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 5.864445, mae: 37.015616, mean_q: 73.622910, mean_eps: 0.209504\n",
            " 29908/50000: episode: 191, duration: 1.362s, episode steps: 165, steps per second: 121, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 7.415299, mae: 36.530436, mean_q: 72.663883, mean_eps: 0.207715\n",
            " 30108/50000: episode: 192, duration: 1.694s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 6.467455, mae: 37.001462, mean_q: 73.779531, mean_eps: 0.205927\n",
            " 30308/50000: episode: 193, duration: 1.680s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 8.553602, mae: 36.668630, mean_q: 73.281421, mean_eps: 0.203967\n",
            " 30508/50000: episode: 194, duration: 1.963s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.542264, mae: 37.073663, mean_q: 74.036998, mean_eps: 0.202007\n",
            " 30705/50000: episode: 195, duration: 2.263s, episode steps: 197, steps per second:  87, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 12.629527, mae: 36.794307, mean_q: 73.440565, mean_eps: 0.200061\n",
            " 30905/50000: episode: 196, duration: 1.687s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 6.166984, mae: 36.309379, mean_q: 72.474708, mean_eps: 0.198116\n",
            " 31072/50000: episode: 197, duration: 1.400s, episode steps: 167, steps per second: 119, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 9.009922, mae: 36.267919, mean_q: 72.472748, mean_eps: 0.196318\n",
            " 31272/50000: episode: 198, duration: 1.710s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 5.327421, mae: 36.173086, mean_q: 72.260275, mean_eps: 0.194519\n",
            " 31472/50000: episode: 199, duration: 1.673s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 4.809935, mae: 35.632605, mean_q: 71.274078, mean_eps: 0.192559\n",
            " 31672/50000: episode: 200, duration: 1.662s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 4.705546, mae: 35.502421, mean_q: 70.966502, mean_eps: 0.190599\n",
            " 31872/50000: episode: 201, duration: 1.681s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.082392, mae: 35.961295, mean_q: 71.726069, mean_eps: 0.188639\n",
            " 32072/50000: episode: 202, duration: 2.356s, episode steps: 200, steps per second:  85, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.297198, mae: 35.130212, mean_q: 70.170161, mean_eps: 0.186679\n",
            " 32272/50000: episode: 203, duration: 1.863s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 5.929268, mae: 35.360245, mean_q: 70.744366, mean_eps: 0.184719\n",
            " 32472/50000: episode: 204, duration: 1.723s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 7.606137, mae: 35.584475, mean_q: 71.115612, mean_eps: 0.182759\n",
            " 32672/50000: episode: 205, duration: 1.719s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 4.214631, mae: 35.428972, mean_q: 70.991979, mean_eps: 0.180799\n",
            " 32872/50000: episode: 206, duration: 1.725s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.097001, mae: 35.376006, mean_q: 70.653815, mean_eps: 0.178839\n",
            " 33072/50000: episode: 207, duration: 1.709s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 6.411950, mae: 35.626315, mean_q: 71.151057, mean_eps: 0.176879\n",
            " 33272/50000: episode: 208, duration: 1.681s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 5.867771, mae: 35.445848, mean_q: 70.809427, mean_eps: 0.174919\n",
            " 33374/50000: episode: 209, duration: 1.204s, episode steps: 102, steps per second:  85, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.441 [0.000, 1.000],  loss: 7.709020, mae: 35.274952, mean_q: 70.437752, mean_eps: 0.173440\n",
            " 33574/50000: episode: 210, duration: 2.249s, episode steps: 200, steps per second:  89, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.469173, mae: 35.670722, mean_q: 71.187633, mean_eps: 0.171960\n",
            " 33774/50000: episode: 211, duration: 1.692s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.429595, mae: 36.044021, mean_q: 71.962616, mean_eps: 0.170000\n",
            " 33974/50000: episode: 212, duration: 1.650s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 9.090690, mae: 36.316993, mean_q: 72.452664, mean_eps: 0.168040\n",
            " 34174/50000: episode: 213, duration: 1.652s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 6.847609, mae: 36.909571, mean_q: 73.711177, mean_eps: 0.166080\n",
            " 34374/50000: episode: 214, duration: 1.672s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 5.650880, mae: 37.245327, mean_q: 74.364437, mean_eps: 0.164120\n",
            " 34574/50000: episode: 215, duration: 1.663s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 11.708298, mae: 37.372789, mean_q: 74.416144, mean_eps: 0.162160\n",
            " 34774/50000: episode: 216, duration: 1.862s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.534335, mae: 37.681000, mean_q: 75.043747, mean_eps: 0.160200\n",
            " 34974/50000: episode: 217, duration: 2.370s, episode steps: 200, steps per second:  84, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.434351, mae: 37.813184, mean_q: 75.433317, mean_eps: 0.158240\n",
            " 35174/50000: episode: 218, duration: 1.663s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 8.403922, mae: 38.320761, mean_q: 76.462561, mean_eps: 0.156280\n",
            " 35374/50000: episode: 219, duration: 1.640s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 10.419295, mae: 38.404588, mean_q: 76.614063, mean_eps: 0.154320\n",
            " 35544/50000: episode: 220, duration: 1.414s, episode steps: 170, steps per second: 120, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 13.030763, mae: 39.307032, mean_q: 78.244773, mean_eps: 0.152507\n",
            " 35696/50000: episode: 221, duration: 1.258s, episode steps: 152, steps per second: 121, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 11.788230, mae: 38.816626, mean_q: 77.333899, mean_eps: 0.150929\n",
            " 35896/50000: episode: 222, duration: 1.641s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 7.138421, mae: 39.322014, mean_q: 78.469330, mean_eps: 0.149204\n",
            " 36096/50000: episode: 223, duration: 1.695s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.736431, mae: 39.794574, mean_q: 79.404576, mean_eps: 0.147244\n",
            " 36296/50000: episode: 224, duration: 2.182s, episode steps: 200, steps per second:  92, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 7.330769, mae: 39.954703, mean_q: 79.792375, mean_eps: 0.145284\n",
            " 36496/50000: episode: 225, duration: 2.139s, episode steps: 200, steps per second:  94, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 14.769720, mae: 40.513412, mean_q: 80.693852, mean_eps: 0.143324\n",
            " 36696/50000: episode: 226, duration: 1.662s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 18.535019, mae: 40.570110, mean_q: 80.584325, mean_eps: 0.141364\n",
            " 36896/50000: episode: 227, duration: 1.670s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 13.919710, mae: 40.748591, mean_q: 81.180324, mean_eps: 0.139404\n",
            " 37096/50000: episode: 228, duration: 1.630s, episode steps: 200, steps per second: 123, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 16.839339, mae: 40.966190, mean_q: 81.391205, mean_eps: 0.137444\n",
            " 37296/50000: episode: 229, duration: 1.646s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 15.719365, mae: 41.096913, mean_q: 81.903488, mean_eps: 0.135484\n",
            " 37496/50000: episode: 230, duration: 1.655s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 12.031046, mae: 41.078573, mean_q: 81.885481, mean_eps: 0.133524\n",
            " 37696/50000: episode: 231, duration: 2.019s, episode steps: 200, steps per second:  99, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 12.982438, mae: 41.501401, mean_q: 82.657239, mean_eps: 0.131564\n",
            " 37821/50000: episode: 232, duration: 1.530s, episode steps: 125, steps per second:  82, episode reward: 125.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 24.680608, mae: 41.610262, mean_q: 82.619451, mean_eps: 0.129972\n",
            " 38021/50000: episode: 233, duration: 1.756s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 19.081021, mae: 41.522699, mean_q: 82.627330, mean_eps: 0.128379\n",
            " 38221/50000: episode: 234, duration: 1.641s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.594657, mae: 41.500076, mean_q: 82.884044, mean_eps: 0.126419\n",
            " 38421/50000: episode: 235, duration: 1.679s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.344696, mae: 42.090870, mean_q: 83.897542, mean_eps: 0.124459\n",
            " 38621/50000: episode: 236, duration: 1.668s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 8.326020, mae: 41.853287, mean_q: 83.672818, mean_eps: 0.122499\n",
            " 38821/50000: episode: 237, duration: 1.669s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 14.466843, mae: 42.551948, mean_q: 84.747285, mean_eps: 0.120539\n",
            " 39021/50000: episode: 238, duration: 1.686s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 23.951021, mae: 42.951591, mean_q: 85.226794, mean_eps: 0.118579\n",
            " 39221/50000: episode: 239, duration: 2.330s, episode steps: 200, steps per second:  86, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 13.922101, mae: 43.102839, mean_q: 85.934849, mean_eps: 0.116619\n",
            " 39421/50000: episode: 240, duration: 1.964s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 15.541782, mae: 42.866258, mean_q: 85.366797, mean_eps: 0.114659\n",
            " 39621/50000: episode: 241, duration: 1.670s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 15.569110, mae: 42.806248, mean_q: 85.209147, mean_eps: 0.112699\n",
            " 39821/50000: episode: 242, duration: 1.681s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 13.834820, mae: 43.306698, mean_q: 86.373821, mean_eps: 0.110739\n",
            " 39997/50000: episode: 243, duration: 1.456s, episode steps: 176, steps per second: 121, episode reward: 176.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 15.612353, mae: 43.380400, mean_q: 86.447073, mean_eps: 0.108897\n",
            " 40167/50000: episode: 244, duration: 1.435s, episode steps: 170, steps per second: 118, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 20.599970, mae: 43.685023, mean_q: 86.782209, mean_eps: 0.107201\n",
            " 40342/50000: episode: 245, duration: 1.482s, episode steps: 175, steps per second: 118, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 15.761595, mae: 43.833326, mean_q: 87.252052, mean_eps: 0.105511\n",
            " 40537/50000: episode: 246, duration: 1.812s, episode steps: 195, steps per second: 108, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 16.217818, mae: 44.446257, mean_q: 88.393127, mean_eps: 0.103698\n",
            " 40737/50000: episode: 247, duration: 2.320s, episode steps: 200, steps per second:  86, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 13.236142, mae: 44.495446, mean_q: 88.815809, mean_eps: 0.101762\n",
            " 40865/50000: episode: 248, duration: 1.074s, episode steps: 128, steps per second: 119, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.982786, mae: 44.973023, mean_q: 89.535534, mean_eps: 0.100155\n",
            " 41065/50000: episode: 249, duration: 1.694s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 16.339785, mae: 45.309869, mean_q: 90.224775, mean_eps: 0.098548\n",
            " 41265/50000: episode: 250, duration: 1.686s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 16.131447, mae: 45.455998, mean_q: 90.536945, mean_eps: 0.096588\n",
            " 41432/50000: episode: 251, duration: 1.380s, episode steps: 167, steps per second: 121, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 14.273722, mae: 45.718134, mean_q: 91.062569, mean_eps: 0.094790\n",
            " 41632/50000: episode: 252, duration: 1.664s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 12.997524, mae: 46.190198, mean_q: 91.895220, mean_eps: 0.092991\n",
            " 41829/50000: episode: 253, duration: 1.617s, episode steps: 197, steps per second: 122, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 13.811359, mae: 46.171412, mean_q: 92.010224, mean_eps: 0.091046\n",
            " 41983/50000: episode: 254, duration: 1.511s, episode steps: 154, steps per second: 102, episode reward: 154.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 16.364208, mae: 46.746677, mean_q: 93.252253, mean_eps: 0.089326\n",
            " 41993/50000: episode: 255, duration: 0.126s, episode steps:  10, steps per second:  79, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 23.191341, mae: 47.465860, mean_q: 94.287853, mean_eps: 0.088523\n",
            " 42175/50000: episode: 256, duration: 2.197s, episode steps: 182, steps per second:  83, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 17.209458, mae: 47.035953, mean_q: 93.809917, mean_eps: 0.087582\n",
            " 42375/50000: episode: 257, duration: 1.690s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 13.163751, mae: 47.584411, mean_q: 94.875965, mean_eps: 0.085710\n",
            " 42532/50000: episode: 258, duration: 1.325s, episode steps: 157, steps per second: 119, episode reward: 157.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 19.714460, mae: 47.575461, mean_q: 94.696459, mean_eps: 0.083961\n",
            " 42732/50000: episode: 259, duration: 1.698s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 22.753846, mae: 47.712656, mean_q: 94.897137, mean_eps: 0.082211\n",
            " 42932/50000: episode: 260, duration: 1.721s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 14.131412, mae: 47.884944, mean_q: 95.495843, mean_eps: 0.080251\n",
            " 42992/50000: episode: 261, duration: 0.535s, episode steps:  60, steps per second: 112, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 20.375064, mae: 47.820400, mean_q: 95.211857, mean_eps: 0.078977\n",
            " 43088/50000: episode: 262, duration: 0.821s, episode steps:  96, steps per second: 117, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 24.780472, mae: 47.939207, mean_q: 95.372734, mean_eps: 0.078213\n",
            " 43244/50000: episode: 263, duration: 1.311s, episode steps: 156, steps per second: 119, episode reward: 156.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 26.879165, mae: 47.788786, mean_q: 94.909510, mean_eps: 0.076978\n",
            " 43443/50000: episode: 264, duration: 2.094s, episode steps: 199, steps per second:  95, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 23.857533, mae: 47.749350, mean_q: 95.046283, mean_eps: 0.075239\n",
            " 43628/50000: episode: 265, duration: 2.228s, episode steps: 185, steps per second:  83, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 23.268023, mae: 47.671332, mean_q: 95.116658, mean_eps: 0.073357\n",
            " 43773/50000: episode: 266, duration: 1.217s, episode steps: 145, steps per second: 119, episode reward: 145.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 13.693711, mae: 47.656293, mean_q: 95.368497, mean_eps: 0.071740\n",
            " 43912/50000: episode: 267, duration: 1.173s, episode steps: 139, steps per second: 119, episode reward: 139.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 16.200275, mae: 48.133309, mean_q: 96.217526, mean_eps: 0.070348\n",
            " 44091/50000: episode: 268, duration: 1.462s, episode steps: 179, steps per second: 122, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 18.450806, mae: 48.187781, mean_q: 96.155045, mean_eps: 0.068790\n",
            " 44266/50000: episode: 269, duration: 1.459s, episode steps: 175, steps per second: 120, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 17.016717, mae: 48.318739, mean_q: 96.591279, mean_eps: 0.067056\n",
            " 44435/50000: episode: 270, duration: 1.453s, episode steps: 169, steps per second: 116, episode reward: 169.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 12.735521, mae: 48.405468, mean_q: 96.760414, mean_eps: 0.065370\n",
            " 44581/50000: episode: 271, duration: 1.251s, episode steps: 146, steps per second: 117, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 20.772459, mae: 48.667439, mean_q: 96.906347, mean_eps: 0.063827\n",
            " 44778/50000: episode: 272, duration: 1.758s, episode steps: 197, steps per second: 112, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 14.169521, mae: 48.678982, mean_q: 97.159733, mean_eps: 0.062146\n",
            " 44930/50000: episode: 273, duration: 1.782s, episode steps: 152, steps per second:  85, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 20.332857, mae: 48.571466, mean_q: 96.859071, mean_eps: 0.060436\n",
            " 45089/50000: episode: 274, duration: 1.590s, episode steps: 159, steps per second: 100, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 17.612644, mae: 48.880017, mean_q: 97.628120, mean_eps: 0.058912\n",
            " 45235/50000: episode: 275, duration: 1.222s, episode steps: 146, steps per second: 120, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 12.787391, mae: 48.473119, mean_q: 96.887475, mean_eps: 0.057417\n",
            " 45435/50000: episode: 276, duration: 1.690s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 16.297425, mae: 48.656716, mean_q: 96.981923, mean_eps: 0.055722\n",
            " 45610/50000: episode: 277, duration: 1.471s, episode steps: 175, steps per second: 119, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 16.167157, mae: 48.485002, mean_q: 96.840355, mean_eps: 0.053884\n",
            " 45791/50000: episode: 278, duration: 1.534s, episode steps: 181, steps per second: 118, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 13.975408, mae: 48.560372, mean_q: 97.025252, mean_eps: 0.052140\n",
            " 45991/50000: episode: 279, duration: 1.728s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 11.861177, mae: 48.777726, mean_q: 97.650467, mean_eps: 0.050273\n",
            " 46141/50000: episode: 280, duration: 1.295s, episode steps: 150, steps per second: 116, episode reward: 150.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 11.091301, mae: 48.938878, mean_q: 98.127841, mean_eps: 0.048558\n",
            " 46306/50000: episode: 281, duration: 1.887s, episode steps: 165, steps per second:  87, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 16.236565, mae: 49.059782, mean_q: 98.136507, mean_eps: 0.047015\n",
            " 46506/50000: episode: 282, duration: 2.082s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 11.935395, mae: 49.168802, mean_q: 98.436649, mean_eps: 0.045226\n",
            " 46706/50000: episode: 283, duration: 1.667s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 16.437255, mae: 49.066234, mean_q: 98.126199, mean_eps: 0.043266\n",
            " 46906/50000: episode: 284, duration: 1.704s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 14.501498, mae: 49.204170, mean_q: 98.334326, mean_eps: 0.041306\n",
            " 47106/50000: episode: 285, duration: 1.676s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.499221, mae: 48.991227, mean_q: 97.997534, mean_eps: 0.039346\n",
            " 47277/50000: episode: 286, duration: 1.424s, episode steps: 171, steps per second: 120, episode reward: 171.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 6.467088, mae: 48.865227, mean_q: 97.625267, mean_eps: 0.037528\n",
            " 47432/50000: episode: 287, duration: 1.297s, episode steps: 155, steps per second: 120, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 11.839072, mae: 48.908250, mean_q: 97.565894, mean_eps: 0.035931\n",
            " 47589/50000: episode: 288, duration: 1.292s, episode steps: 157, steps per second: 122, episode reward: 157.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 8.461853, mae: 48.768470, mean_q: 97.464042, mean_eps: 0.034402\n",
            " 47789/50000: episode: 289, duration: 2.310s, episode steps: 200, steps per second:  87, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 16.683088, mae: 48.890180, mean_q: 97.298621, mean_eps: 0.032653\n",
            " 47989/50000: episode: 290, duration: 1.936s, episode steps: 200, steps per second: 103, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 12.469085, mae: 49.086726, mean_q: 97.839128, mean_eps: 0.030693\n",
            " 48189/50000: episode: 291, duration: 1.661s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 12.541961, mae: 48.787739, mean_q: 97.144408, mean_eps: 0.028733\n",
            " 48389/50000: episode: 292, duration: 1.674s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 9.013231, mae: 48.883657, mean_q: 97.539456, mean_eps: 0.026773\n",
            " 48568/50000: episode: 293, duration: 1.469s, episode steps: 179, steps per second: 122, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 7.129283, mae: 48.906631, mean_q: 97.680435, mean_eps: 0.024916\n",
            " 48768/50000: episode: 294, duration: 1.658s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.959848, mae: 48.676611, mean_q: 97.193245, mean_eps: 0.023059\n",
            " 48968/50000: episode: 295, duration: 1.657s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 12.891716, mae: 48.679288, mean_q: 97.065987, mean_eps: 0.021099\n",
            " 49163/50000: episode: 296, duration: 1.981s, episode steps: 195, steps per second:  98, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 7.809132, mae: 48.435639, mean_q: 96.644694, mean_eps: 0.019163\n",
            " 49344/50000: episode: 297, duration: 2.058s, episode steps: 181, steps per second:  88, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 6.039053, mae: 48.469354, mean_q: 96.879714, mean_eps: 0.017321\n",
            " 49512/50000: episode: 298, duration: 1.440s, episode steps: 168, steps per second: 117, episode reward: 168.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 10.103540, mae: 48.790842, mean_q: 97.184236, mean_eps: 0.015611\n",
            " 49699/50000: episode: 299, duration: 1.527s, episode steps: 187, steps per second: 122, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 12.083501, mae: 48.224194, mean_q: 96.075873, mean_eps: 0.013871\n",
            " 49868/50000: episode: 300, duration: 1.396s, episode steps: 169, steps per second: 121, episode reward: 169.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 5.234251, mae: 48.065096, mean_q: 95.821923, mean_eps: 0.012127\n",
            "done, took 455.226 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 157.000, steps: 157\n",
            "Episode 2: reward: 162.000, steps: 162\n",
            "Episode 3: reward: 159.000, steps: 159\n",
            "Episode 4: reward: 153.000, steps: 153\n",
            "Episode 5: reward: 153.000, steps: 153\n",
            "Episode 6: reward: 170.000, steps: 170\n",
            "Episode 7: reward: 158.000, steps: 158\n",
            "Episode 8: reward: 158.000, steps: 158\n",
            "Episode 9: reward: 154.000, steps: 154\n",
            "Episode 10: reward: 160.000, steps: 160\n",
            "Episode 11: reward: 162.000, steps: 162\n",
            "Episode 12: reward: 167.000, steps: 167\n",
            "Episode 13: reward: 163.000, steps: 163\n",
            "Episode 14: reward: 165.000, steps: 165\n",
            "Episode 15: reward: 165.000, steps: 165\n",
            "Episode 16: reward: 163.000, steps: 163\n",
            "Episode 17: reward: 174.000, steps: 174\n",
            "Episode 18: reward: 166.000, steps: 166\n",
            "Episode 19: reward: 172.000, steps: 172\n",
            "Episode 20: reward: 173.000, steps: 173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd7516f8fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 0.5\n",
        "\n",
        "# value_min = 0.01\n",
        "\n",
        "#value_test = 0.05\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "# target_model_update=1e-4\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "rbumxnKuiHu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=0.5,\n",
        "                               value_min=0.01, \n",
        "                               value_test=0.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-4, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FBgHvmbgiFL6",
        "outputId": "2a8eba7b-5afd-40de-a274-d43cc8fcda27"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   18/10000: episode: 1, duration: 3.697s, episode steps:  18, steps per second:   5, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 1.284858, mae: 18.656778, mean_q: 37.301461, mean_eps: 0.499314\n",
            "   82/10000: episode: 2, duration: 0.540s, episode steps:  64, steps per second: 119, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.504567, mae: 19.238596, mean_q: 38.555629, mean_eps: 0.497574\n",
            "  164/10000: episode: 3, duration: 0.676s, episode steps:  82, steps per second: 121, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.062835, mae: 19.268979, mean_q: 38.566923, mean_eps: 0.493997\n",
            "  324/10000: episode: 4, duration: 1.339s, episode steps: 160, steps per second: 119, episode reward: 160.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 1.986157, mae: 19.352337, mean_q: 38.639301, mean_eps: 0.488068\n",
            "  357/10000: episode: 5, duration: 0.284s, episode steps:  33, steps per second: 116, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 0.966189, mae: 19.363580, mean_q: 38.792196, mean_eps: 0.483340\n",
            "  455/10000: episode: 6, duration: 0.817s, episode steps:  98, steps per second: 120, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 2.430573, mae: 19.407717, mean_q: 38.725913, mean_eps: 0.480130\n",
            "  480/10000: episode: 7, duration: 0.238s, episode steps:  25, steps per second: 105, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 1.316895, mae: 19.908741, mean_q: 39.764739, mean_eps: 0.477117\n",
            "  510/10000: episode: 8, duration: 0.253s, episode steps:  30, steps per second: 118, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.966915, mae: 19.704205, mean_q: 39.386140, mean_eps: 0.475770\n",
            "  544/10000: episode: 9, duration: 0.301s, episode steps:  34, steps per second: 113, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.302819, mae: 19.619099, mean_q: 39.025311, mean_eps: 0.474201\n",
            "  609/10000: episode: 10, duration: 0.629s, episode steps:  65, steps per second: 103, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.569 [0.000, 1.000],  loss: 0.736409, mae: 19.508853, mean_q: 39.043226, mean_eps: 0.471776\n",
            "  632/10000: episode: 11, duration: 0.293s, episode steps:  23, steps per second:  78, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.391 [0.000, 1.000],  loss: 5.576437, mae: 19.703866, mean_q: 39.341286, mean_eps: 0.469620\n",
            "  670/10000: episode: 12, duration: 0.457s, episode steps:  38, steps per second:  83, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 2.017955, mae: 19.487132, mean_q: 38.839662, mean_eps: 0.468126\n",
            "  681/10000: episode: 13, duration: 0.134s, episode steps:  11, steps per second:  82, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 1.817122, mae: 19.414172, mean_q: 38.771179, mean_eps: 0.466925\n",
            "  720/10000: episode: 14, duration: 0.485s, episode steps:  39, steps per second:  80, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 2.884803, mae: 19.448861, mean_q: 38.677179, mean_eps: 0.465700\n",
            "  743/10000: episode: 15, duration: 0.293s, episode steps:  23, steps per second:  79, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 4.211176, mae: 19.394334, mean_q: 38.414119, mean_eps: 0.464181\n",
            "  788/10000: episode: 16, duration: 0.548s, episode steps:  45, steps per second:  82, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 1.233073, mae: 19.431769, mean_q: 38.571678, mean_eps: 0.462515\n",
            "  806/10000: episode: 17, duration: 0.245s, episode steps:  18, steps per second:  74, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 1.741993, mae: 19.604194, mean_q: 39.003177, mean_eps: 0.460972\n",
            "  827/10000: episode: 18, duration: 0.270s, episode steps:  21, steps per second:  78, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 0.856230, mae: 19.753740, mean_q: 39.405045, mean_eps: 0.460016\n",
            "  838/10000: episode: 19, duration: 0.099s, episode steps:  11, steps per second: 111, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 4.781800, mae: 19.855475, mean_q: 39.407571, mean_eps: 0.459232\n",
            "  879/10000: episode: 20, duration: 0.333s, episode steps:  41, steps per second: 123, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 2.632925, mae: 19.769722, mean_q: 39.361417, mean_eps: 0.457958\n",
            "  891/10000: episode: 21, duration: 0.102s, episode steps:  12, steps per second: 118, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.930034, mae: 19.575519, mean_q: 39.021622, mean_eps: 0.456659\n",
            "  921/10000: episode: 22, duration: 0.271s, episode steps:  30, steps per second: 111, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.018538, mae: 20.169965, mean_q: 39.888673, mean_eps: 0.455630\n",
            "  933/10000: episode: 23, duration: 0.107s, episode steps:  12, steps per second: 112, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 4.055180, mae: 20.111022, mean_q: 40.101721, mean_eps: 0.454602\n",
            "  957/10000: episode: 24, duration: 0.201s, episode steps:  24, steps per second: 119, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 4.047637, mae: 20.072405, mean_q: 39.828952, mean_eps: 0.453720\n",
            "  976/10000: episode: 25, duration: 0.168s, episode steps:  19, steps per second: 113, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 1.326844, mae: 20.082197, mean_q: 39.999929, mean_eps: 0.452666\n",
            "  991/10000: episode: 26, duration: 0.138s, episode steps:  15, steps per second: 109, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 4.522535, mae: 19.699426, mean_q: 39.004243, mean_eps: 0.451833\n",
            " 1003/10000: episode: 27, duration: 0.105s, episode steps:  12, steps per second: 114, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 2.921550, mae: 19.690607, mean_q: 38.966185, mean_eps: 0.451172\n",
            " 1033/10000: episode: 28, duration: 0.263s, episode steps:  30, steps per second: 114, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 3.390499, mae: 20.266875, mean_q: 40.030793, mean_eps: 0.450143\n",
            " 1047/10000: episode: 29, duration: 0.125s, episode steps:  14, steps per second: 112, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 4.080246, mae: 20.204810, mean_q: 40.022007, mean_eps: 0.449064\n",
            " 1057/10000: episode: 30, duration: 0.093s, episode steps:  10, steps per second: 108, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 6.084168, mae: 19.917466, mean_q: 39.295151, mean_eps: 0.448477\n",
            " 1068/10000: episode: 31, duration: 0.094s, episode steps:  11, steps per second: 117, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 5.111720, mae: 19.834552, mean_q: 39.056299, mean_eps: 0.447962\n",
            " 1091/10000: episode: 32, duration: 0.195s, episode steps:  23, steps per second: 118, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 5.719090, mae: 20.156322, mean_q: 39.685918, mean_eps: 0.447129\n",
            " 1142/10000: episode: 33, duration: 0.446s, episode steps:  51, steps per second: 114, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.431 [0.000, 1.000],  loss: 2.903791, mae: 19.725053, mean_q: 39.176427, mean_eps: 0.445316\n",
            " 1166/10000: episode: 34, duration: 0.202s, episode steps:  24, steps per second: 119, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 2.772784, mae: 19.893843, mean_q: 39.528526, mean_eps: 0.443478\n",
            " 1187/10000: episode: 35, duration: 0.177s, episode steps:  21, steps per second: 118, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 9.094435, mae: 19.981937, mean_q: 39.372770, mean_eps: 0.442376\n",
            " 1233/10000: episode: 36, duration: 0.387s, episode steps:  46, steps per second: 119, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 6.642874, mae: 19.896124, mean_q: 39.148316, mean_eps: 0.440735\n",
            " 1344/10000: episode: 37, duration: 0.942s, episode steps: 111, steps per second: 118, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 4.600907, mae: 20.036004, mean_q: 39.609959, mean_eps: 0.436888\n",
            " 1404/10000: episode: 38, duration: 0.539s, episode steps:  60, steps per second: 111, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 6.638298, mae: 19.886500, mean_q: 39.100583, mean_eps: 0.432698\n",
            " 1414/10000: episode: 39, duration: 0.092s, episode steps:  10, steps per second: 109, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 8.426983, mae: 20.593932, mean_q: 39.955473, mean_eps: 0.430984\n",
            " 1464/10000: episode: 40, duration: 0.436s, episode steps:  50, steps per second: 115, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.420 [0.000, 1.000],  loss: 7.891392, mae: 20.151309, mean_q: 39.456390, mean_eps: 0.429513\n",
            " 1505/10000: episode: 41, duration: 0.363s, episode steps:  41, steps per second: 113, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.390 [0.000, 1.000],  loss: 4.991446, mae: 20.331951, mean_q: 40.102925, mean_eps: 0.427284\n",
            " 1516/10000: episode: 42, duration: 0.103s, episode steps:  11, steps per second: 107, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 5.718049, mae: 19.919939, mean_q: 39.192377, mean_eps: 0.426010\n",
            " 1551/10000: episode: 43, duration: 0.323s, episode steps:  35, steps per second: 108, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 7.382831, mae: 20.181129, mean_q: 39.510291, mean_eps: 0.424883\n",
            " 1705/10000: episode: 44, duration: 1.288s, episode steps: 154, steps per second: 120, episode reward: 154.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 6.066851, mae: 20.159242, mean_q: 39.708527, mean_eps: 0.420253\n",
            " 1716/10000: episode: 45, duration: 0.096s, episode steps:  11, steps per second: 114, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 0.521709, mae: 20.410952, mean_q: 40.566837, mean_eps: 0.416210\n",
            " 1749/10000: episode: 46, duration: 0.300s, episode steps:  33, steps per second: 110, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.303 [0.000, 1.000],  loss: 10.904362, mae: 20.324495, mean_q: 40.005197, mean_eps: 0.415132\n",
            " 1767/10000: episode: 47, duration: 0.152s, episode steps:  18, steps per second: 118, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 2.830627, mae: 20.212206, mean_q: 39.917222, mean_eps: 0.413882\n",
            " 1778/10000: episode: 48, duration: 0.101s, episode steps:  11, steps per second: 109, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 10.679893, mae: 19.937399, mean_q: 38.964275, mean_eps: 0.413172\n",
            " 1789/10000: episode: 49, duration: 0.102s, episode steps:  11, steps per second: 108, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 5.089762, mae: 19.925664, mean_q: 39.001434, mean_eps: 0.412633\n",
            " 1808/10000: episode: 50, duration: 0.166s, episode steps:  19, steps per second: 114, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 6.373173, mae: 20.089557, mean_q: 39.324561, mean_eps: 0.411898\n",
            " 1850/10000: episode: 51, duration: 0.376s, episode steps:  42, steps per second: 112, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 4.755674, mae: 20.149297, mean_q: 39.851199, mean_eps: 0.410404\n",
            " 1864/10000: episode: 52, duration: 0.118s, episode steps:  14, steps per second: 119, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.143 [0.000, 1.000],  loss: 9.053711, mae: 19.834588, mean_q: 39.188133, mean_eps: 0.409032\n",
            " 1874/10000: episode: 53, duration: 0.098s, episode steps:  10, steps per second: 102, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 2.097765, mae: 20.576336, mean_q: 40.590794, mean_eps: 0.408444\n",
            " 1886/10000: episode: 54, duration: 0.109s, episode steps:  12, steps per second: 110, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 11.222873, mae: 20.308070, mean_q: 39.753973, mean_eps: 0.407905\n",
            " 1896/10000: episode: 55, duration: 0.091s, episode steps:  10, steps per second: 110, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 1.450996, mae: 20.018033, mean_q: 39.373882, mean_eps: 0.407366\n",
            " 2007/10000: episode: 56, duration: 1.069s, episode steps: 111, steps per second: 104, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.414 [0.000, 1.000],  loss: 7.667746, mae: 20.379043, mean_q: 39.970390, mean_eps: 0.404401\n",
            " 2032/10000: episode: 57, duration: 0.333s, episode steps:  25, steps per second:  75, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 7.846973, mae: 20.367183, mean_q: 39.907466, mean_eps: 0.401069\n",
            " 2044/10000: episode: 58, duration: 0.176s, episode steps:  12, steps per second:  68, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.498484, mae: 19.923838, mean_q: 39.539316, mean_eps: 0.400162\n",
            " 2055/10000: episode: 59, duration: 0.142s, episode steps:  11, steps per second:  78, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 12.265477, mae: 20.633873, mean_q: 39.970903, mean_eps: 0.399599\n",
            " 2119/10000: episode: 60, duration: 0.797s, episode steps:  64, steps per second:  80, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.406 [0.000, 1.000],  loss: 6.441056, mae: 20.425482, mean_q: 40.149558, mean_eps: 0.397761\n",
            " 2153/10000: episode: 61, duration: 0.431s, episode steps:  34, steps per second:  79, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 6.203248, mae: 20.232823, mean_q: 39.768280, mean_eps: 0.395361\n",
            " 2171/10000: episode: 62, duration: 0.235s, episode steps:  18, steps per second:  77, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 12.636584, mae: 20.441705, mean_q: 39.739305, mean_eps: 0.394087\n",
            " 2180/10000: episode: 63, duration: 0.121s, episode steps:   9, steps per second:  74, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 14.571625, mae: 20.634459, mean_q: 39.699397, mean_eps: 0.393425\n",
            " 2226/10000: episode: 64, duration: 0.493s, episode steps:  46, steps per second:  93, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 3.796682, mae: 20.601871, mean_q: 40.580565, mean_eps: 0.392078\n",
            " 2237/10000: episode: 65, duration: 0.099s, episode steps:  11, steps per second: 111, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.091 [0.000, 1.000],  loss: 1.259589, mae: 20.329941, mean_q: 40.496283, mean_eps: 0.390681\n",
            " 2264/10000: episode: 66, duration: 0.229s, episode steps:  27, steps per second: 118, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.407 [0.000, 1.000],  loss: 8.293380, mae: 20.309273, mean_q: 40.022816, mean_eps: 0.389750\n",
            " 2278/10000: episode: 67, duration: 0.120s, episode steps:  14, steps per second: 117, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 3.584691, mae: 20.644618, mean_q: 40.870616, mean_eps: 0.388745\n",
            " 2288/10000: episode: 68, duration: 0.098s, episode steps:  10, steps per second: 102, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 5.376597, mae: 20.323450, mean_q: 40.216743, mean_eps: 0.388158\n",
            " 2334/10000: episode: 69, duration: 0.408s, episode steps:  46, steps per second: 113, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 7.348163, mae: 20.260206, mean_q: 39.889044, mean_eps: 0.386786\n",
            " 2383/10000: episode: 70, duration: 0.416s, episode steps:  49, steps per second: 118, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.408 [0.000, 1.000],  loss: 4.902554, mae: 20.636257, mean_q: 40.604092, mean_eps: 0.384458\n",
            " 2402/10000: episode: 71, duration: 0.157s, episode steps:  19, steps per second: 121, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.211 [0.000, 1.000],  loss: 2.630784, mae: 20.666368, mean_q: 40.843842, mean_eps: 0.382792\n",
            " 2437/10000: episode: 72, duration: 0.312s, episode steps:  35, steps per second: 112, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.371 [0.000, 1.000],  loss: 6.574279, mae: 20.415661, mean_q: 40.367605, mean_eps: 0.381469\n",
            " 2477/10000: episode: 73, duration: 0.337s, episode steps:  40, steps per second: 119, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.325 [0.000, 1.000],  loss: 7.364478, mae: 20.455111, mean_q: 40.312840, mean_eps: 0.379632\n",
            " 2536/10000: episode: 74, duration: 0.515s, episode steps:  59, steps per second: 115, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.373 [0.000, 1.000],  loss: 5.443179, mae: 20.506798, mean_q: 40.435972, mean_eps: 0.377206\n",
            " 2550/10000: episode: 75, duration: 0.136s, episode steps:  14, steps per second: 103, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 5.717208, mae: 20.616387, mean_q: 40.788726, mean_eps: 0.375418\n",
            " 2561/10000: episode: 76, duration: 0.112s, episode steps:  11, steps per second:  99, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 3.235228, mae: 20.304394, mean_q: 39.967454, mean_eps: 0.374805\n",
            " 2578/10000: episode: 77, duration: 0.158s, episode steps:  17, steps per second: 107, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 5.186818, mae: 20.390286, mean_q: 40.268017, mean_eps: 0.374119\n",
            " 2601/10000: episode: 78, duration: 0.198s, episode steps:  23, steps per second: 116, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 7.987338, mae: 20.512424, mean_q: 40.325446, mean_eps: 0.373139\n",
            " 2616/10000: episode: 79, duration: 0.136s, episode steps:  15, steps per second: 110, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 5.503765, mae: 20.237111, mean_q: 39.666616, mean_eps: 0.372208\n",
            " 2684/10000: episode: 80, duration: 0.613s, episode steps:  68, steps per second: 111, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.382 [0.000, 1.000],  loss: 9.808275, mae: 20.763722, mean_q: 40.478961, mean_eps: 0.370175\n",
            " 2696/10000: episode: 81, duration: 0.105s, episode steps:  12, steps per second: 115, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 17.379728, mae: 20.579349, mean_q: 39.971973, mean_eps: 0.368215\n",
            " 2783/10000: episode: 82, duration: 0.756s, episode steps:  87, steps per second: 115, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.414 [0.000, 1.000],  loss: 7.452908, mae: 20.568113, mean_q: 40.439634, mean_eps: 0.365789\n",
            " 2845/10000: episode: 83, duration: 0.528s, episode steps:  62, steps per second: 117, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 8.651045, mae: 20.538470, mean_q: 40.354458, mean_eps: 0.362138\n",
            " 2902/10000: episode: 84, duration: 0.514s, episode steps:  57, steps per second: 111, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 5.900557, mae: 20.694205, mean_q: 40.957984, mean_eps: 0.359223\n",
            " 2931/10000: episode: 85, duration: 0.247s, episode steps:  29, steps per second: 117, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.345 [0.000, 1.000],  loss: 6.900437, mae: 20.582218, mean_q: 40.556539, mean_eps: 0.357116\n",
            " 2996/10000: episode: 86, duration: 0.557s, episode steps:  65, steps per second: 117, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.431 [0.000, 1.000],  loss: 8.460400, mae: 20.542867, mean_q: 40.467804, mean_eps: 0.354813\n",
            " 3017/10000: episode: 87, duration: 0.194s, episode steps:  21, steps per second: 108, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.238 [0.000, 1.000],  loss: 8.189322, mae: 20.888593, mean_q: 41.110509, mean_eps: 0.352706\n",
            " 3053/10000: episode: 88, duration: 0.322s, episode steps:  36, steps per second: 112, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 4.452728, mae: 20.455329, mean_q: 40.483350, mean_eps: 0.351309\n",
            " 3071/10000: episode: 89, duration: 0.161s, episode steps:  18, steps per second: 111, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 10.421412, mae: 20.656075, mean_q: 40.589826, mean_eps: 0.349986\n",
            " 3115/10000: episode: 90, duration: 0.380s, episode steps:  44, steps per second: 116, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 8.469472, mae: 20.845774, mean_q: 40.577499, mean_eps: 0.348467\n",
            " 3170/10000: episode: 91, duration: 0.464s, episode steps:  55, steps per second: 119, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.418 [0.000, 1.000],  loss: 9.772462, mae: 20.863210, mean_q: 40.899962, mean_eps: 0.346042\n",
            " 3189/10000: episode: 92, duration: 0.167s, episode steps:  19, steps per second: 114, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.263 [0.000, 1.000],  loss: 9.944012, mae: 20.932772, mean_q: 40.980751, mean_eps: 0.344229\n",
            " 3231/10000: episode: 93, duration: 0.376s, episode steps:  42, steps per second: 112, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 8.439208, mae: 20.819801, mean_q: 41.013716, mean_eps: 0.342734\n",
            " 3270/10000: episode: 94, duration: 0.330s, episode steps:  39, steps per second: 118, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 10.358052, mae: 20.945808, mean_q: 40.846497, mean_eps: 0.340750\n",
            " 3280/10000: episode: 95, duration: 0.086s, episode steps:  10, steps per second: 116, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 2.121553, mae: 20.950671, mean_q: 41.620710, mean_eps: 0.339550\n",
            " 3289/10000: episode: 96, duration: 0.082s, episode steps:   9, steps per second: 110, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 14.519269, mae: 21.295030, mean_q: 41.669345, mean_eps: 0.339084\n",
            " 3331/10000: episode: 97, duration: 0.355s, episode steps:  42, steps per second: 118, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 9.727102, mae: 20.696838, mean_q: 40.530852, mean_eps: 0.337835\n",
            " 3344/10000: episode: 98, duration: 0.134s, episode steps:  13, steps per second:  97, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.154 [0.000, 1.000],  loss: 5.063869, mae: 21.223836, mean_q: 41.889361, mean_eps: 0.336487\n",
            " 3414/10000: episode: 99, duration: 0.862s, episode steps:  70, steps per second:  81, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 11.684996, mae: 21.256105, mean_q: 41.456140, mean_eps: 0.334454\n",
            " 3545/10000: episode: 100, duration: 1.560s, episode steps: 131, steps per second:  84, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 8.099210, mae: 20.959138, mean_q: 41.314414, mean_eps: 0.329529\n",
            " 3554/10000: episode: 101, duration: 0.116s, episode steps:   9, steps per second:  77, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 7.478224, mae: 21.381256, mean_q: 42.391955, mean_eps: 0.326099\n",
            " 3682/10000: episode: 102, duration: 1.219s, episode steps: 128, steps per second: 105, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.461 [0.000, 1.000],  loss: 10.108497, mae: 21.032449, mean_q: 41.096459, mean_eps: 0.322742\n",
            " 3692/10000: episode: 103, duration: 0.097s, episode steps:  10, steps per second: 103, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 13.602172, mae: 20.698055, mean_q: 40.769680, mean_eps: 0.319362\n",
            " 3706/10000: episode: 104, duration: 0.126s, episode steps:  14, steps per second: 111, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.143 [0.000, 1.000],  loss: 8.446069, mae: 20.719131, mean_q: 40.996644, mean_eps: 0.318773\n",
            " 3773/10000: episode: 105, duration: 0.581s, episode steps:  67, steps per second: 115, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 7.360195, mae: 21.276655, mean_q: 41.772294, mean_eps: 0.316789\n",
            " 3791/10000: episode: 106, duration: 0.161s, episode steps:  18, steps per second: 112, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.278 [0.000, 1.000],  loss: 10.020744, mae: 21.150320, mean_q: 41.622970, mean_eps: 0.314707\n",
            " 3829/10000: episode: 107, duration: 0.326s, episode steps:  38, steps per second: 116, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 5.748286, mae: 21.296198, mean_q: 41.759067, mean_eps: 0.313335\n",
            " 3862/10000: episode: 108, duration: 0.288s, episode steps:  33, steps per second: 115, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 7.687728, mae: 21.492566, mean_q: 42.134966, mean_eps: 0.311595\n",
            " 3908/10000: episode: 109, duration: 0.405s, episode steps:  46, steps per second: 114, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.370 [0.000, 1.000],  loss: 8.012316, mae: 21.089596, mean_q: 41.455621, mean_eps: 0.309659\n",
            " 3935/10000: episode: 110, duration: 0.230s, episode steps:  27, steps per second: 118, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.370 [0.000, 1.000],  loss: 11.983895, mae: 21.384925, mean_q: 41.773239, mean_eps: 0.307871\n",
            " 3964/10000: episode: 111, duration: 0.255s, episode steps:  29, steps per second: 114, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.379 [0.000, 1.000],  loss: 13.810411, mae: 21.475676, mean_q: 41.624971, mean_eps: 0.306499\n",
            " 4008/10000: episode: 112, duration: 0.379s, episode steps:  44, steps per second: 116, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.432 [0.000, 1.000],  loss: 7.275799, mae: 21.516785, mean_q: 41.948898, mean_eps: 0.304711\n",
            " 4017/10000: episode: 113, duration: 0.087s, episode steps:   9, steps per second: 103, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 11.261387, mae: 21.226763, mean_q: 41.833581, mean_eps: 0.303412\n",
            " 4052/10000: episode: 114, duration: 0.305s, episode steps:  35, steps per second: 115, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 11.010835, mae: 21.288856, mean_q: 41.590045, mean_eps: 0.302334\n",
            " 4066/10000: episode: 115, duration: 0.124s, episode steps:  14, steps per second: 113, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 8.816126, mae: 21.350276, mean_q: 41.811034, mean_eps: 0.301134\n",
            " 4077/10000: episode: 116, duration: 0.101s, episode steps:  11, steps per second: 109, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 6.712252, mae: 21.424686, mean_q: 42.344709, mean_eps: 0.300521\n",
            " 4118/10000: episode: 117, duration: 0.353s, episode steps:  41, steps per second: 116, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 9.282096, mae: 21.562171, mean_q: 42.055862, mean_eps: 0.299247\n",
            " 4141/10000: episode: 118, duration: 0.199s, episode steps:  23, steps per second: 116, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.261 [0.000, 1.000],  loss: 12.825171, mae: 22.055943, mean_q: 42.755432, mean_eps: 0.297679\n",
            " 4150/10000: episode: 119, duration: 0.087s, episode steps:   9, steps per second: 103, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.111 [0.000, 1.000],  loss: 10.318579, mae: 20.978395, mean_q: 41.026726, mean_eps: 0.296895\n",
            " 4163/10000: episode: 120, duration: 0.121s, episode steps:  13, steps per second: 107, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 7.798782, mae: 21.399000, mean_q: 41.682417, mean_eps: 0.296356\n",
            " 4179/10000: episode: 121, duration: 0.148s, episode steps:  16, steps per second: 108, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 10.530369, mae: 21.659321, mean_q: 41.958664, mean_eps: 0.295646\n",
            " 4202/10000: episode: 122, duration: 0.200s, episode steps:  23, steps per second: 115, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.391 [0.000, 1.000],  loss: 7.932729, mae: 21.573676, mean_q: 42.079007, mean_eps: 0.294690\n",
            " 4216/10000: episode: 123, duration: 0.139s, episode steps:  14, steps per second: 101, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 8.126241, mae: 21.309514, mean_q: 41.527558, mean_eps: 0.293784\n",
            " 4233/10000: episode: 124, duration: 0.154s, episode steps:  17, steps per second: 110, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 11.278135, mae: 21.839507, mean_q: 42.584767, mean_eps: 0.293024\n",
            " 4375/10000: episode: 125, duration: 1.193s, episode steps: 142, steps per second: 119, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.768716, mae: 21.794181, mean_q: 42.443522, mean_eps: 0.289129\n",
            " 4385/10000: episode: 126, duration: 0.100s, episode steps:  10, steps per second: 100, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 10.172110, mae: 21.640000, mean_q: 42.386013, mean_eps: 0.285405\n",
            " 4544/10000: episode: 127, duration: 1.353s, episode steps: 159, steps per second: 118, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 9.351421, mae: 21.741565, mean_q: 42.433837, mean_eps: 0.281264\n",
            " 4664/10000: episode: 128, duration: 1.026s, episode steps: 120, steps per second: 117, episode reward: 120.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 10.486712, mae: 21.879578, mean_q: 42.647525, mean_eps: 0.274429\n",
            " 4760/10000: episode: 129, duration: 0.906s, episode steps:  96, steps per second: 106, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 7.916445, mae: 22.018882, mean_q: 43.120419, mean_eps: 0.269137\n",
            " 4960/10000: episode: 130, duration: 2.359s, episode steps: 200, steps per second:  85, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 10.005917, mae: 22.152174, mean_q: 43.240691, mean_eps: 0.261885\n",
            " 4989/10000: episode: 131, duration: 0.367s, episode steps:  29, steps per second:  79, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 10.260338, mae: 22.241482, mean_q: 43.083537, mean_eps: 0.256274\n",
            " 5058/10000: episode: 132, duration: 0.595s, episode steps:  69, steps per second: 116, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 9.273001, mae: 22.269705, mean_q: 43.539277, mean_eps: 0.253873\n",
            " 5099/10000: episode: 133, duration: 0.375s, episode steps:  41, steps per second: 109, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 9.964030, mae: 22.336129, mean_q: 43.473429, mean_eps: 0.251178\n",
            " 5139/10000: episode: 134, duration: 0.355s, episode steps:  40, steps per second: 113, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 9.382074, mae: 22.343981, mean_q: 43.572631, mean_eps: 0.249194\n",
            " 5162/10000: episode: 135, duration: 0.197s, episode steps:  23, steps per second: 117, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 7.308733, mae: 22.526636, mean_q: 44.240474, mean_eps: 0.247650\n",
            " 5180/10000: episode: 136, duration: 0.169s, episode steps:  18, steps per second: 107, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 14.985188, mae: 21.977107, mean_q: 42.882580, mean_eps: 0.246646\n",
            " 5248/10000: episode: 137, duration: 0.608s, episode steps:  68, steps per second: 112, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.566267, mae: 22.434419, mean_q: 43.658636, mean_eps: 0.244538\n",
            " 5448/10000: episode: 138, duration: 1.674s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.118675, mae: 22.572254, mean_q: 44.211494, mean_eps: 0.237973\n",
            " 5587/10000: episode: 139, duration: 1.143s, episode steps: 139, steps per second: 122, episode reward: 139.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 9.440717, mae: 22.803055, mean_q: 44.645710, mean_eps: 0.229667\n",
            " 5634/10000: episode: 140, duration: 0.394s, episode steps:  47, steps per second: 119, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 9.496984, mae: 22.724820, mean_q: 44.413815, mean_eps: 0.225110\n",
            " 5729/10000: episode: 141, duration: 0.798s, episode steps:  95, steps per second: 119, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 9.108517, mae: 23.094791, mean_q: 45.043809, mean_eps: 0.221631\n",
            " 5904/10000: episode: 142, duration: 1.455s, episode steps: 175, steps per second: 120, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 9.266437, mae: 23.116793, mean_q: 45.227295, mean_eps: 0.215016\n",
            " 5990/10000: episode: 143, duration: 0.747s, episode steps:  86, steps per second: 115, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 8.885571, mae: 23.069262, mean_q: 45.101205, mean_eps: 0.208622\n",
            " 6190/10000: episode: 144, duration: 1.852s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 9.226230, mae: 23.244734, mean_q: 45.425093, mean_eps: 0.201615\n",
            " 6316/10000: episode: 145, duration: 1.512s, episode steps: 126, steps per second:  83, episode reward: 126.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 8.139784, mae: 23.316467, mean_q: 45.654068, mean_eps: 0.193628\n",
            " 6507/10000: episode: 146, duration: 1.884s, episode steps: 191, steps per second: 101, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 10.645341, mae: 23.601188, mean_q: 46.009736, mean_eps: 0.185861\n",
            " 6600/10000: episode: 147, duration: 0.782s, episode steps:  93, steps per second: 119, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.013107, mae: 24.085122, mean_q: 47.079963, mean_eps: 0.178903\n",
            " 6721/10000: episode: 148, duration: 1.022s, episode steps: 121, steps per second: 118, episode reward: 121.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 12.242014, mae: 24.243053, mean_q: 47.101805, mean_eps: 0.173660\n",
            " 6921/10000: episode: 149, duration: 1.668s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 9.306532, mae: 24.308540, mean_q: 47.483892, mean_eps: 0.165796\n",
            " 7121/10000: episode: 150, duration: 1.672s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 10.232951, mae: 24.536601, mean_q: 47.862752, mean_eps: 0.155996\n",
            " 7321/10000: episode: 151, duration: 1.960s, episode steps: 200, steps per second: 102, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 9.695115, mae: 24.735862, mean_q: 48.109576, mean_eps: 0.146196\n",
            " 7521/10000: episode: 152, duration: 1.751s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 10.732034, mae: 25.158201, mean_q: 49.009848, mean_eps: 0.136396\n",
            " 7721/10000: episode: 153, duration: 2.289s, episode steps: 200, steps per second:  87, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 10.051664, mae: 25.491533, mean_q: 49.775479, mean_eps: 0.126595\n",
            " 7921/10000: episode: 154, duration: 1.949s, episode steps: 200, steps per second: 103, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 10.476241, mae: 25.712857, mean_q: 50.248796, mean_eps: 0.116796\n",
            " 8121/10000: episode: 155, duration: 1.651s, episode steps: 200, steps per second: 121, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 9.456408, mae: 25.963925, mean_q: 50.732455, mean_eps: 0.106996\n",
            " 8321/10000: episode: 156, duration: 1.679s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 13.330957, mae: 26.207830, mean_q: 50.995652, mean_eps: 0.097196\n",
            " 8521/10000: episode: 157, duration: 1.675s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 12.140719, mae: 26.456835, mean_q: 51.571679, mean_eps: 0.087396\n",
            " 8721/10000: episode: 158, duration: 1.689s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 11.984542, mae: 26.760802, mean_q: 52.176791, mean_eps: 0.077596\n",
            " 8921/10000: episode: 159, duration: 1.712s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 10.509677, mae: 27.041086, mean_q: 52.751634, mean_eps: 0.067796\n",
            " 9121/10000: episode: 160, duration: 2.187s, episode steps: 200, steps per second:  91, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 11.082228, mae: 27.393128, mean_q: 53.512382, mean_eps: 0.057996\n",
            " 9321/10000: episode: 161, duration: 2.121s, episode steps: 200, steps per second:  94, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 12.993616, mae: 27.712668, mean_q: 54.081305, mean_eps: 0.048196\n",
            " 9521/10000: episode: 162, duration: 1.725s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 10.578244, mae: 27.776957, mean_q: 54.423259, mean_eps: 0.038396\n",
            " 9721/10000: episode: 163, duration: 1.695s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 11.238567, mae: 28.120425, mean_q: 55.086063, mean_eps: 0.028596\n",
            " 9921/10000: episode: 164, duration: 1.671s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 11.024695, mae: 28.372692, mean_q: 55.595682, mean_eps: 0.018796\n",
            "done, took 95.842 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABrjUlEQVR4nO19Z5gkV3nu+1V1nLxhNu9qd6WVhBahVUBIFsjCEiBkgsHY5IsBW4Ax4HDBYGwutvEFB8y1McHCZGNMlARCmCBAIBCSVmi1ytpdSavNMxsmd6hw7o8T6lR1daie7umenvM+zzzTXV1dfbq66nzn/d4vEGMMBgYGBgYGElanB2BgYGBg0F0whsHAwMDAIARjGAwMDAwMQjCGwcDAwMAgBGMYDAwMDAxCSHV6APPFypUr2ebNmzs9DAMDA4NFhbvvvvs4Y2w07rVFbxg2b96MnTt3dnoYBgYGBosKRLS/2mvGlWRgYGBgEIIxDAYGBgYGIRjDYGBgYGAQgjEMBgYGBgYhGMNgYGBgYBBCWw0DEW0koh8T0YNE9AARvUNsX05EPyCiPeL/MrGdiOhfiWgvEe0mogvaOT4DAwMDg0q0mzG4AP6MMXYOgEsAvJWIzgHwbgC3MMa2AbhFPAeA5wPYJv6uBfCJNo/PwMDAwCCCtuYxMMaOADgiHk8T0UMA1gN4MYArxG6fB/ATAH8utn+B8VrgvySiESJaK45jYGBgoDAxV8Zte4/jBU9bl/i9Y9NF3PPkBJ63fU3dfR3Px/X3HMLLLtgAy6Kq+9183xE8fGQq8Vjmg/M3LcOzz17V8uMuWIIbEW0GcD6AOwCs1ib7owBWi8frARzQ3nZQbAsZBiK6FpxRYNOmTe0btIGBQdfi2/cexl/d+ACedcYohvvSid77tZ0H8eHvP4KH//b5yKRqO05u33cC7/r6bpy5ehA7No5U3e9dX9+NmZILqm47Wo7X/9qWxWsYiGgAwDcA/DFjbIq0M8cYY0SUqFsQY+w6ANcBwEUXXWQ6DRkYLEGUXB8A4Ph+U+/1GVD2/LqGQX5OoezV2c/DW644HX9+9dmJx9NtaHtUEhGlwY3Clxhj3xSbjxHRWvH6WgBjYvshABu1t28Q2wwMDAxCcDy+JvT95GtDTxiTklN7stf3dbzqBogxBsdjSNu9EejZ7qgkAvBpAA8xxv5Ze+lbAF4nHr8OwI3a9v8lopMuATBp9AUDA4M4yAnba6I9sZzjJRuoBVcYnlqGQRqpjL2AfqQ2ot2upMsAvBbAfUS0S2z7CwAfAvBVInojgP0Afle8djOAawDsBTAH4PVtHp+BgcEihWIMTTiTpVEpN2AYvIYMA3+tVxhDu6OSbgNQzYReGbM/A/DWdo7JwMCgNyAn7OZcSfx/Q4xBGKCyV/1z5D69Yhh641sYGBgsOUjR2ZuHxpCEMdTatywZQx0he7GgN76FgYHBkoMnVulNaQziPSW3vvjcmMYgDEONPIfFBGMYDAwMFiXkhM2aEp/rs4Bg33BUkuP5mCo6oX16TWPojW9hYGCw5OAqV1Ly90rDkCQqSRqR//jZ4/jNf/1ZaB/HuJIMDAwMOg85uTejMbh+464kxS7E5H9ksoBjU6XQPmW3t8JVjWEwMDBYlAjCVZMbBr8JxuC4AXNwIzRFshfjSjIwMDDoIFS4ahOGwU1gGKJ5DGVRTkMPkzUag4GBgUEXQE7GzbiSpDFpRHyWOQry80riv6t9rnQlGcNgYGBg0EEEjCH5e+Vk3xhj8EP7SmPiasX7AsZgNAYDAwODjmFeGkMSxhDjStI/X3/NMAYDAwODDsKbR+ZzkqikaoZBF6CNYTAwMDDoArjzqpWUICpJaQxhY6IbJFlHKZMyriQDAwODjsGdV3XV5JnPMo9B/ne0D3YNYzAwMDDoPFSC2zxKYiRxJZWj4rNxJRkYGBh0F2R11fm4kprpxxBEJVW6koxhMDAwMOgg5pPgFlRXbT4qydWjklwTrmpgYGDQcUgxuLl+DE0wBlkSQ6uyGozFuJIaBhF9hojGiOh+bdtXiGiX+HtCtvwkos1EVNBe+2Q7x2ZgYLC4IUXhphhDE7WSZMZzKcaV1GuGod09nz8H4N8AfEFuYIy9XD4mog8DmNT238cY29HmMRkYGPQAXMUYkr83ifis+jFExGdPy3wONAbjSqoLxthPAZyMe42ICMDvAvhyO8dgYGDQm3DnozHUcSV99ueP4/Hjs/xztFpJjDHFGPTMZ9fzkbYJfFpb/Ogk73kWgGOMsT3ati1EdA8R3UpEz6r2RiK6loh2EtHO8fHx9o/UwMCg6zAv8bmGK6nkevjrbz+Ib997OLSv4/kRYxB2JfWKGwnorGF4JcJs4QiATYyx8wH8KYD/IqKhuDcyxq5jjF3EGLtodHR0AYZqYGDQbZhPdVWvRq0kJ1JNVc9jKGt+q3ARPYZUj/R7BjpkGIgoBeClAL4itzHGSoyxE+Lx3QD2ATizE+MzMDDofrSruqrrhV1FQQc3FjIkOmMoez4yPdLWE+gcY7gKwMOMsYNyAxGNEpEtHm8FsA3AYx0an4GBQZdDruibSXCrVV01Go4qmYHj+WHDoDMG17iSGgYRfRnA7QDOIqKDRPRG8dIrUCk6Xw5gtwhf/TqANzPGYoVrAwMDg/mUxKhVXVUyBTfiqqo0DL2rMbQ1XJUx9soq238vZts3AHyjneMxMDDoHTjzEJ9Vz2cnRmOQUUdiHz3zuewFhiQkPvusZ0JVAZP5bGBgsEihNIb59GOISYJQLqQKxsBQdPyK/QDjSjIwMDDoOBhjgSupGY1BizRiEcYRuJLC/wFgtuSqx1FXkhGfDQwMDDoIfVL2molK8sMRRTokEwhcScHrM1UNgwlXNTAwMOgodJYQXfE39H4WaALRkFVlGGJqIoUMg2ZQyj0mPvfONzEwMFgy0P37zVZXzadtAJUhq+VImKp+/NlSFfHZuJIMDAwMOgsv5EpKZhikPtGX4UGZUcYQ7fGsG4CZkhPs18Phqr3zTQwMDJYM9JpFST1Jcj7vy3DGUHLCuQzRxDbPZ8gKNjATYgzhLGgTrmpgYGDQQYQYQ0JXktw/LwxDVfFZMgafqX31qCQnImAbxtDDYIw1FRdtYGCwcJiPxiD375euJCeqMYSL6Hm+j750pWHQGYNxJfU4/urG+/Gm/7y708MwMDCoAd0YJM18lppEVcYQ6ens+gw5se+0Zhj0MTiucSX1NPafmMPBU4VOD8PAwEDA8xku+9CPcOOuQ2qbOx/DICb8QGOIiM9a0Tz5+X0RV1LKopDOYRhDj8PxfONKMjDoIpRcD4cmCtg7NqO26UlnSVt7VjKGsPhc1piC/C9DW2eKrnqv65s8hiUDx2OhH9zAwKCzkC6bajkESRmDvL+rMYbAlRQwhrzQI2ZKLmyLkE3ZIdbieszkMfQyXM9vKmHGwMCgPZDrtIITX44iKcOXx6uWx6BHJcmch3yaT5WzZRcZ20LKohjx2WgMPYuyx5qq725gYNAeyPtRZwye7kpqkjFUy3zWy2yr0FbNlZRNW0jZpFiL7zO4PjOupF6G4/lKnDKoDsYY/uALO/HTR8c7PRSDHoecnOfKWg6B1wrGIFxJkWY9Za1GkhvJeZgtecjYFtK2FRgQcUBjGHoYjueHaKpBPFyf4QcPHsPd+091eigGPQ4/ljHoGkOy41VoDFVdSTpj4G4n2ds5ZZEWvcT3Ma6kBkFEnyGiMSK6X9v2fiI6RES7xN812mvvIaK9RPQIET2vnWOrBsf1m+oItdQQNGI358qgvYhnDM27knwVlVRbY3A9nTEEU2UmZcHWwlWlWG0YQ+P4HICrY7Z/hDG2Q/zdDABEdA54L+jt4j0fJyK7zeOrQFm7GAyqQ54jI9QbtBsqKqlchTEkvAbdiG4Q1RiCUhiVGgOAwJXkhfMdjGFoEIyxnwI42eDuLwbw34yxEmPscQB7AVzctsFVgdEYGoM8R8YwGLQbcoU/V6VJTrMlMVI2IWNbNaOS5OSf0wxDNiXEZ6Ux8P8ZYxjmjT8iot3C1bRMbFsP4IC2z0GxrQJEdC0R7SSinePjrRU/Hc83UUkNIK5WvYFBO6BcSU61PIbmjpeyCNmUVSE+624qaTSk+Awg0BiirqSU0Rjmg08AOB3ADgBHAHw46QEYY9cxxi5ijF00Ojra0sEZ8bkxqH67xogatBkBY9AMgxaumrgkhrh2LYuQSVlVXUkAUBDGKGNzXQGQhsGqKJ1hXEnzAGPsGGPMY4z5AD6FwF10CMBGbdcNYttCjg2OZ6qrNgJpEMy5Mmg35EKt7PlBKKmYvC2ahytJMYb4Dm4AUBSGIWWTijrK2GFXktw/ZRnD0DSIaK329CUAZMTStwC8goiyRLQFwDYAdy7k2PT66830kV1KcCP1ZAwM2gV94i8IAVpuy6SsphmDTfGMwQ0ZBv7YtizFCDIpKT6HO71lesiVlGrnwYnoywCuALCSiA4C+D8AriCiHQAYgCcAvAkAGGMPENFXATwIwAXwVsaYF3PYtkH3LfoM6KGw5JbDhKsaLBT00mWzZRfDfWmVVJZN2c0bBlHzqFJjCI6nGINFSlzmn+mF8h2A3nIltdUwMMZeGbP50zX2/zsAf9e+EdVGtPmH9CkaVMKEqxosFHQdS+Yy6IwhsSuJaYYhHacxBM+lxmALPUJ+ph7K2ouGoeFvQkTvIKIh4vg0Ef2KiJ7bzsEtNPSVgpnwakOJz6YQrUGbod+Lc8KVpNw3tpX4GnQ1xhAXrqobCp0x6K4kLj6HXUlL0jAAeANjbArAcwEsA/BaAB9qy6g6BH2lYEpv10YQrmrOk0Hrcf+hSTx4eApA2F0py2J4ypVkJdYDfT/MGKKGQdfNSkpjiIjPFgWuJPH+pZrHIP0q1wD4ImPsAW1bTyCkMZj5riaCcNUOD8SgJ/G3Nz2ID373IQBRxsBdSa7uSkpcXTXMGGq5koquZAyB+KwS3CK9oVM9JEomMQx3E9H3wQ3D94hoEEBPTZ+GMTQOeXOZcFWDdqDk+molr19jsiyG6zWvMfh1xOey60PKi3q4albTGFJaddVyD2oMScTnN4InpT3GGJsjohUAXt+WUXUIZddoDI3CN+KzQRvh+Sw2iVKWxZCTctq2kDQwTr43VUN87sukMFNyUSj7al+lMdgW0jHVVXvJldSwYWCM+US0GcBriIgBuI0xdn3bRtYBzKdi41KDG3PTGhi0Cq7PYMcsPgLGwDum2UTJGQOTyXHVaiUx5DM2ZkquciXZEfHZtqwKV9KSLIlBRB8H8GYA94Enpb2JiD7WroF1AiFXknGe14RnGINBG+FrjMGPYQwynJyoiQ5uXuBKStlWKBqRv+6rXg1BVJKFdEpPcAsYg7vEXUm/AeApTIQAENHnwZPRegblUIKbmfBqweQxGLQTru/D9vkKXF+kyUJ6jseQsmRfhGR6oJ7HoE/wEmWPYbiPT41FLSopo4erauJzeYmHq+4FsEl7vhHAntYOp7PQVw6m1ENtyHBBY0AN2gGvLmPwkbIJtpXclaRnPqc0l5CEozGGkiY+y5IX2ZTNXUmidI40TEtSYwAwCOAhIroTvJzFxQB2EtG3AIAx9qI2jG9B4Wi+RrMSrg3X9GMwaCM8xtTKXicESmPwGVIWwSJKHDKtG4a0Xck4HM9XjXmqaQxpEbbk+kzNG70UrprEMLyvbaPoEkRLYhhUhzw/hlkZtAOex+BZ4QAHIi2PQbiSLEoeMq0X0dOrpEq4QnwGgqJ90aiklHjs+QFjSPVQCZ0kUUm3EtFpALYxxn5IRHkAKcbYdPuGt7AoG8PQMEweg0E74foMqcg1NphNqcxnV4jPtkVNF9FLWby0hSdcQkQExhjKIfFZ0xhSQYKbzIJ2PB9ljyFjWyDqHcOQJCrpDwB8HcC/i00bANzQhjF1DEZjaBymUY9BO+EzVhH5NphLa5nPPFzVaiJcNWjUA22CDzNgZRi0zOdMKFw1EMZl6GwvIYla8lYAlwGYAgDG2B4Aq9oxqE7BuJIah2cYQ9fju/cdwYV/+4OKzN7FADcmwW0wl1JF9CRjsKgJxsA0xiAm+2g3tnyaO1OkKylUKymlv4+7kmQoa68gybcpMcbK8gkRpcBF6J6BawxDwzAaQ/fj8ROzODFbVpPbYoLnsQp3ZcgweD7Sot1msz2fLSvQBSRjcNwwY5DJb3GZzwA3KGWP9VSoKpDMMNxKRH8BIE9EzwHwNQDfbs+wOoNyyJVkaiXVgslj6H7IyqCL0Xi7PlNMIGAMacxGEtwsi5oWn/XCeHJRKBsA5SMJbrYd7segu5Icz++pUFUgmWF4N4Bx8MznNwG4mTH23raMqkMw1VUbh8lj6H7IYAo5cX74+4/gL2+4r5NDahgeY2qyjmMMjseQsi3YzWQ+S8ZAQYhp0FuBf6ZkDIUq/RjSEVdSL4WqAskMw9sYY59ijP0OY+xljLFPEdE7ar2BiD5DRGNEdL+27R+J6GEi2k1E1xPRiNi+mYgKRLRL/H2yua/UPPQ8BsMYasMwhu5HlDHce3ASuw5MdHBEjcPzmXIRuZphmC27YEKYVnkMTVRX5eU0CGmLT4FBbwV+LJXHoHdwC4WrSsbgc41hCTOG18Vs+7067/kcgKsj234A4KmMsacBeBTAe7TX9jHGdoi/NycYW0vgmJIYDcPUSup+SNE5+K38RVEDTE78QTOowJXEGA8hdX1fuZKaqa5qi9DSYIIPl9DOV2gMFrJpPl3m0jZSyqAwlN3e0xjq5jEQ0SsBvArAFpnlLDAE4GSt9zLGfioqsurbvq89/SWAlzU82jYjpDEsghuokzDVVbsfspy0/K1cjy0KQy6HKEm7XKQNZPl0NVt24XoM2bTVdHVVqRFEo5Lk/4xtiazowO30/KeuBRFhdDCrRGvX50Yq02OupEYS3H4B4AiAlQA+rG2fBrB7np//BgBf0Z5vIaJ7wENi/5Ix9rO4NxHRtQCuBYBNmzbF7dIUTLhq4wjCVTs8EIOqkKtdT1t5L4brOjpJy9tyKBeEkLo+Q59lwbKaq64qDUO6SlRS2ubJb47nISXcTqODWbz2ktMAhLWJXnQl1TUMjLH9APYT0VUACqIvw5kAzgYXopsCEb0XgAvgS2LTEQCbGGMniOhCADcQ0XbRZzo6pusAXAcAF110UcuudNOPoXEYV1L3o+yGJ1bXZ4siQikonsfdSpIxDOXTAARj8H2khcaQuOdzHGOIuJJSNi+XAQdqXx1p7X1OD7qSknybnwLIEdF6AN8H8FpwDSExiOj3ALwAwKtlGW/GWIkxdkI8vhvAPgBnNnP8ZmEYQ+MwrqTuh9QY3EXGGPQx6mMeFIxhtuSpVX8z1VWlPgEEK38nkuDGXUl8eoyb9INwVR/lJR6VRIyxOQAvBfBxxtjvANie9AOJ6GoA7wLwInE8uX2UiGzxeCuAbQAeS3r8+UBv7Wk0htrwIsKgQfdBrn71ZMTFEG0XMgyMhcRngBfSc32+Sm+uJAY0V1KYMcj/aa0eUjxjCLuSlnIeAxHRpQBeDeA7Yptd5w1fBnA7gLOI6CARvRHAv4GX8P5BJCz1cgC7iWgXeE2mNzPGaorbrYaj1TwxK+HaMOGq3Y9ouKrn+4vi93IjjMFnDERAf0YyBjdIcKPkUUme78dEJYUZg9QYgPiqqfI11/dRKHvIZWpOhYsOScpuvwM8tPR6xtgDYlX/41pvYIy9Mmbzp6vs+w0A30gwnpbD8XzkUjYcz10UN1An4XmmVlK3Q4rPfogxdP/v5ce4kmwi5UqaKroqqcxuQnwOMQblSopoDFptpDjGkNKK700WHAwL/aNXkKTs9k/BdQb5/DEAb5fPieijjLG3tXZ4CwvH85HL2JguuYviBuokjMbQ/YiGq/o+Uwa9mxFlDB5jsCzCSB+ffCfmykGCW1Md3DSNQbmSIhqDViivJmPoUcPQSsfYZS08VkfgeExlPJqVcG2YInrdj2iC22JhDFHx2ReMYSCbQtomnJpzeL8GoTEkr64aTPapSNntsCtJMIYYYVm+b7rIxzKUM4ahZ+F4PnLpoAaKQXWYRj3djyhjWCxRSVHGIEtsExFG+jI4NVuG6/lIWQSbmqmu6sNSrqRo2W2ZxxAUzZPsQIcUrU/M8oLThjH0MPRer2bCqw0VlWRcSV2LaIKb67NF8XtFo5J8n0F6c5b1pXFqrhz0Y2jKlcQCxqBVSQXC4aqKMcS4kiSLODFjDEM9LPpA3rLHkBOGwTCG2pApH4wZI9qtiCa4ScaQNCFsoaFP9K7HjZn094/0ZbgryZPhqny/JNeg5zNYFGYMQRE9meBWW2OQGdMnZ0sAgKF8kjie7kdiw0BEfVVe+pd5jqXjcFxfGQZvEcR7dxL6+VkMq9CliArGEMlr6FbouRa8xSfURL5cuJJkuKoMO02iM3g+UxpBZdntwJVUOyrJuJIAAET0a0T0IICHxfPziOjj8nXG2OdaP7yFhe5K8oxdqImoH9igu+D7TIVeRnNOup0N62syV4rPYqZa1p/GqTkHjiyJYSXPO3I1xlARleQ3mMdgS8bADcNSFp8/AuB5AGTZinvBk9J6Bo7nI5u2QLT0GMOdj59M1AJSNwatLlE+Nl3Eg4crSmQZJEA5przLYklKDDEGoYtIZsBdSWUwBtiWpSb4JLerzwKNIR2NStKK6NVkDFbYMCxZxgAAjLEDkU2Lr5lsDTjCb2kTdf2qqpWYnHPw8utux/X3HGr4Pe1kDB/70V5c+8WdLT3mUkPJrTQMi4UxhDQGwRgkM1jWlw5ac4oENyAhY/CC40XLbjueD4u4MUjb1aOSUpGoJJl81ytI8m0OENGvAWBElAbPhH6oPcPqDMqiJIZt0ZLym/OuWMBkwWn4PSHG0GJyNVPyVG9fg+ZQDnUjDCcjdjtjqCiip1VDHenLqNdkBzcgGWv1GdMm/co8BvWa+F+LMZRdHwPZlNq3V5Dk27wZwFsBrAdwCMAO8bxnIC8K26JFkSHaKshJRLYxbARuaFXXWsvgLpJOY90MmdwGBElicu7s9kJ6cdVVbU18lkiJexVIFpUkQ12BcPlsgC8OZUG8tBUWqHVYFqmIqKEeYwtAspIYx8EL6PUsHDcwDN1Ot1sJ6Y8uukk0hvZFJbmacGrQHKKMYTEFC4TGKvoxKFdSf+DL10XhJN/J1wwDT5zTmgN5DGmZ2FZDY+CvWyi7vuoT0UtopLXnRwFUPeuMsbdXe22xQWoMKSt5mv1ihqzCKf83gna6klzPX1KGuR0IaQxeuKpqt7MxfaERZQwhV5IdZD0nuVz0ns8Az2IOu5LC+kNcVBJ/H6EM9KRhaMSVtBPA3QByAC4AsEf87QCQqf62xQXGmKCRtAQZA2cKSVxJ0ezUVkJOBiZxrnmEDAMLu4+6nTHoblx5LQTic1hjaDaPQWcBKZtUuGrZ85WwnKmhMfD38dd7LSIJaKy15+cBgIjeAuCZjDFXPP8kgNiezIsR8maRrqSlNCmV5qkxtFqPUas330fW6q069wuFcigqya+I9OlmVFRX1UpYDOfTIIIKV2UsedJehWHQFoKOx7QaSeFchyjk672WwwAkE5+XARjSng+IbT0BR+vclLKsrr95Wgk5iRS6hDHo/l6D5qCLz1GNodvdpJVRSVCMwbZIrdDTdpDglogxsLBhSNuWKonhxrmSqrTtlNuXJGPQ8CEA9xDRj8HrIl0O4P3tGFQnUNbK7VpW99PtViKISmpcLHAjdL+ViBY0M0iOEGPw2KLWGHjZ7eD1ZX0ZTMw54ZIYCS6VeFdSZbhqrQQ3IGASvVYnCUjAGBhjnwXwDADXg3dau1S6maqBiD5DRGNEdL+2bTkR/YCI9oj/y8R2IqJ/JaK9RLSbiC5o7is1h6CqIiFlWUvLMHjJXUntzHyO1q0xSI6wxrC4opK8iB4Snchlw56UxRdxQDLWWulKslQpjLLHNNG5tvjcy4whaVbGxQCeBc4Wnt7A/p8DcHVk27sB3MIY2wbgFvEcAJ4PYJv4uxbAJxKObV7QG3TYTZTyXcxQjMFNwBi0LlitXoHKSazb4+27GeVI5rMf0hi6+7zq15MsFW5pUUQyl0FPcEusMehRSTpjcHkACqCHqxqNoSqI6EPg2c4Pir+3E9H/rfUe0Q70ZGTziwFIpvF5AL+lbf8C4/glgBEiWtvo+OYLvUYKL4nR3TdPKyEnkVJCxiCjNlrOGFQJ5KVjnFuNWhpDty969OvJZyyUdwAEIaspEUEIIFEpcb26Kj+OFehafuBKytQLV13KUUkargGwg4kwACL6PIB7APxFws9czRg7Ih4fBbBaPF4PQK/FdFBsO4IIiOhacFaBTZs2Jfz4eCiNISUZQ0sOuyjQjCvJ9RmyaQsFx2v5RCOP5ywh49xqRGsl6e6Zbg+sCGfVswqxeJnmSpIr/6SuJJ2BpCxSbsuyx9CXaTTBTTCGHjQMSV1JI9rj4fl+OONmPvFVyhi7jjF2EWPsotHR0fkOA4DmSrJErSRxI73xc3fhpt2HW/IZ3QqZ2JZEfPY1xtDqqCTVNGUpWecWI5T57C0uxhBOnpQd3DTD0B8wBmrGlaRVVwX4yj9gqZW1kqoxBuli6kXGkMQwfBA8Kulzgi3cDeDvmvjMY9JFJP6Pie2HAGzU9tsgti0IohqDvJF+/MgYdj05sVDD6AgkY0gSrur6Qbx3q3M+VBVQIz43DckY8mkbPmMVfvtuRjTnopIxBBpD4EpKcHytuiogopJUwEMQriprJdlVwlXl60s9KunLAC4B8E0EUUlfaeIzvwXgdeLx6wDcqG3/XyI66RIAk5rLqe1wNFeSLInhej581vsr12YS3HSNodUTjWPCVecNZRgyNtxIglu39xqJMga9gxuguZJsKyi7PR/GYFkhltooYzBRSQCI6DIAU4yxb4Enur2LiE6r854vA7gdwFlEdJCI3gieD/EcItoD4CrxHABuBvAYgL0APgXgD5N+mfmgrMRnnjTjekEht14v6KbEZ9dvWMRrJ2MIauN398q2m1FyPWTEIseLiM/dzsQqNAbfD03Ol585indcuQ3b1w0FrqSkHdyq5jEEwnS6blQSP7+y62MvIQkH+gSA84joPAB/CuDTAL4A4NervYEx9soqL10Zsy9DB8t4B3kMlhCjfDVhlns8Okb3R5e0vte14PkM2VR7NIbAldTbBrmdKLs+ssIwuJEEt8WkMXisMo+hP5vCnzznTADQEtySVVdNhQyDhVnRvbDkeur6j/ZsiCJlkyjREf/6YkYSjcEVk/eLAXyMMfYxAIPtGdbCI05jkBNmr7s0ZBE9oHF3kuv7ijG0eqIJaiV19wTWzSgJw2CJplOLqVZSyDAId65VVQCWJTEaP360umpGK6JXdHzkUtwwSINQK/O5FyOSgGSMYZqI3gPgNQAuJyILQM+cFVUrSUtwKynG0OOGQft+jUYmeZorqW3hqj1+3tuJkuMjm7KVK6mdmeqtRrgfg0xIi983aYKbZBa6eyhlWcqVVHA85DOyJEZtxvCyCzfg+Eypoc9dbEhiGF4O4FUA3sgYO0pEmwD8Y3uGtfBQrqQUqZuptFQYQ8gwNMoYGLJiZdV6xhAkGxk0h7LHGZ1FMsEtHL7azQiXxPBDZbejkJsbNXauMgzBtpRNcHwfjuhbITWDenkMVz91TUOfuRiRpIPbUQD/rD1/Elxj6AnElcRQGkOvGwbt+zUSsirbRLYr81kamnKXT2DdjJLjIZuywFhlEb3u1xjCj30Wdv3oCFxJDTIGVskYeB4DU9d+oxpDL6OuxkBEt4n/00Q0Ff3f/iEuDGI1Bm9puJL0zm2NMAYpNgeupNaNhWkF34z43DzKHtcY5LUcjfTpZnh+kEsgGUO1VbtkEo0au1jGYHGNoViOGgaZx5A0D3jxo5FGPc8U/3tGaI5DOaQxWPCXlPicTGPQmxoBrXX5LKawym5GyeGuJJ/58FmUMXT39eyKHBnH8xRjqO5KSsYYvDiNwbbg+Exd+9Iw1Kuu2stIZAqJ6AIiejsRvY2Izm/XoDoBKXSmbYIt/LKBYejtCUpGsABA0a3PGOTkrfIYWuhK0iewxezC++pdBzA2VezY53PGYC9KxuD7DGnFRv2Kaqg6VK2kBi8VZRi0w6VtHp4uXUmNagy9jCQJbu8Dr4a6AsBKAJ8jor9s18AWGmFXEu/HIMM4e92VVHZ9FXbXSIVV2coz2wZXks7OFqsrabro4F3f2I1v/GrBKrpUIJzg5lf0OOhmuCLPIKWF2lZ3JfH/iRmDXRmVpAxDg1FJvYwkUUmvBnAeY6wIqDLcuwB8oA3jWnDohiEVEZ973pXk+hjKpTA+XWrIlSRdR9k2ZD4vpnj7apDRbKfmyp0bg6NpDN7iq5VkkahAENOoR4eVMMEtYAzhfgyO5yt9TeYxrBnO4YxVAzhzdU970WORxDAcBpADIPlxFgtY5K7dCDSG4IIsLaGoJMkYGhKfI66kVmY+6267xXre5UJiooOGQYar2hah7PqhFXW3MwZPYwx+TBE9HXJ7o9eg3C+c+czvdxWVlOGGYSiXxg//tGphh55GEsMwCeABIvoBeKns5wC4k4j+FQAYY29vw/gWDLKqIhGpInrlJZTgJrtQNWIYlMbQhiJ6i6k3cTXIBkOn5pyOjUFnDNHWnt1+Xj2fwbZJNMxi8CNF9HQE4nODxxbfPVQrSbiOC+WwxrCUkcQwXC/+JH7S2qF0FnoddluEry2lBDfJGAoJopKy6da7kvRzvVjPu2Q6kx00DFJ8jst8XgxRSTYRbFtnDPH7qjyGRl1JMYxBhqXOFF0AaKhWWK8jSYLb54koD2ATY+yRNo6pIyg4QfGsaIJbr0cllT0fgzl+KSRyJclGPS00DPrKdrGed2nQOqsxeMKVZC1KjcG2AsZQKypJzu+NXoPSKIarq/LreLrEDYNhDMmikl4ILjb/j3i+g4i+1aZxLTjGpksYHcgCgIqGWCoJbmWXFw7LpKxE4arptoSrLv6oJHm9TBQ6zRiseMbQ5bWSuMYQCOdA9SJ6yfMY+P+QxiAeTxf575VLL72EtiiSnIH3A7gYwAQAMMZ2Adja8hF1CGNTRawa4oYhriRGkmbjiw0ytDGXskJZ0NUQZQytXIHqLGGxupJ08bkT143nMzgeU+KzrjFYFPjZuxWyX4JtkVqctaokhoyos0JRSYIxGFeSQhLD4DDGJiPbFuedG4Ox6RJWDeYAoKLsNtD99LtZ+GISyaYs5NJ2g+KzCFdNt76Inn6sxVp2W05mjscwV268K17LPt+V4cS2WuR4frCt269l2ZhHNwz1GEOjawg/jjFoGgNREIa9lJFEfH6AiF4FwCaibQDeDuAXzXwoEZ0FQG8LuhXA+wCMAPgDAONi+18wxm5u5jOSwPcZxqZLWK0xBsb4SlqirInTvQR542USGIYoY2iX+LxYXUk66zk1V0Z/dmF7AkvDIBPcXN9XxiCbtro/XJXxe1CG2gLVs49lgluj7jG5qNGPl7akxuAgl7J7svFOUiSZ6d4GYDuAEoD/Ag9f/eNmPpQx9ghjbAdjbAeACwHMIYh4+oh8bSGMAgCcmC3D8xlWDwnGIC4MfbW3WN0a9SANA2cMVoMJbpHM5zaVxFi04rPGNCc6EJkkFzQqXFVUVyUSlUS73TBojEHed9Wyj+W92qjLLqiuWskYposu8hnjRgKSRSXNAXiv+KsAEX2UMfa2JsZwJYB9jLH9nbLUY9M8Z2/VoGAM4kLRS1Av1mSretBXl7m03VDZ7WgRvVauQHtJYwA6ZRgCYy+Tt/Sksa4PV/WExkABY6iXx9BwdVUvzjAEGoOJSOJopW/ksibf9woAX9ae/xER7SaizxDRshaMqy7GpngXplWCMcjVSaEcdiX1IpRhsBNoDNrNJaNeWgW9UutiNQz6ImKisPAhqyXN2FtEqrqqdM90O2PwGQs0hrqupGSGQbLbkPisRSVlTUQSgNYahsQgogyAFwH4mtj0CQCnA9gB4AiAD1d537VEtJOIdo6Pj8ftkgjHRBVMqTFYsa6k7r6ZmkWUMRQbMIA6HZc9hVuFxZShWw36IqIT2c+6+JzSqqumLKvlhrwdcDUjVk98lgaj0UtQfveUXckYZkqGMUh02jw+H8CvGGPHAIAxdowx5jHGfACfAg+PrQBj7DrG2EWMsYtGR0fnPYixac4YRgeDPAYgzBgW6+q1HkLic8pqqLpq0OyE0/1Wis/SGKQsWrRRSfoiYrIDSW5hjcFSGoNFWBSMQbKblM4Y6pXdTlhdVWcMusZgQlU5WmkYmhEIXgnNjUREa7XXXgLg/vkOqhEcmypiWV9a9TCWJXnnHFftY1xJAaSPWtL9VtpMeex82g6JuIsJ+iKiE4whTmNwfR8p2+J1gbqciUk9xNLzGKrMVHJ+bzzzOaYkhohKmit7hjEIJI6jI6IhAIwxNh156V8SHqcfvBDfm7TN/0BEO8CL9D0Rea1tODZVUhFJQLAKCWkMPcoY5OoykyQqSdMYLGpt7R252s5l7JZ2hltISMMwlEt1RHwuRzQGb5FpDDpjkOeymvicuFaSHyc+B48NY+Bo2DAQ0dMBfAbAIH9KEwDewBi7GwAYY59L8sGMsVnwpj/6ttcmOUarMD5dVG4kIOxKIuL+y8W6eq2HUoXG0HhUUsompGyrLeGq+bS9aHUduYhYNZTDZIfFZ6kpuB7TGF53X8tSY7CovvhsJ62uGmMY0iHD0GnvencgyVn4NIA/ZIxtZoydBuCtAD7bnmEtLCoYg7ho5hwPAxluO3uVMehCZS5th1hSNbgaHbeota4kuULkhmFxnnNZdnvlQKZDrqSgqb3MfNYF3W63t5wxcDeYExNeqkO5khjDv9+6D3/97QdqHzsuj0Hr/2xcSRxJDIPHGPuZfMIYuw2AW2P/RQHPZxifCbKegeCiKZQ9lbW6WCepeihr/uhc2kbJrV8XSm+oblutzXyWRieXsRdVVNI/f/8RfOqnjwEAyp4H2yKs6M92pFmPrHcli+gB/HdeLHkMSmNogDEQcXem7zPctvc4fvzwWN1jA/HiMwCT4CZQ1zAQ0QVEdAGAW4no34noCiL6dSL6OHqgJ8NJkfUs6yQBwUVYcn30Z/mFUnYXzySVBOGSGPxyKNVxm+mMQZZGbhVc5Uqy4HT5BKbjBw+N4dZHeei04zGkbcJIX7rDCW62StYsuX6gMWgGt+R6eMPn7sKDh6cWfJzVEIpKqlNED+D3q894XaqpYu21qi7MS+ilbozGwNGIxhDNJXif+E/gIvGiRjSHAQivTgZEZ7NedyVlbEv1ui1qvSnioNe0t21qadltd5G6kkqup1w4ZddHxra4YSg4YIwtaP2dULiq+Nyy5/M8BptCFXTHpkr40cNjuOKsUZyzbmjBxlgLru/zRj1auGq1PAaAswZPGIbJOudbhmPr17ceoWQMA0ddw8AYezYAEFEOwG8D2Ky9b9EbBlUOI0ZjAIABwRjixOe795/EDfccxt+8ePuiLbwVTXADUDcySa9pb1NrE6aU+LzIXEklx1fnzRH9lpf1ZeD5DNMlV7VOBYAfPzyGnftP4p3PO7s9Y5Gr4rQVsF/HE4zBgusHOpIMT24kTHmh4Pm8LI1+H9ZkDCKXZq7swvO5gahWuFD+RrrIHGYMRnwGkmkMNwB4IQAHwIz2t6ihymHERCUBQH+musbwgwfH8MVf7l/UbCLOlVRvkvC0CpWtznxW4aqpeMbgeD7+/Ou7ceDkXMs+sxUoOgFj4P3DLQyLdqnRFp/fvf8IvvCL/W0bS6Ax2Opalq6kaOaznCgL5e65hvUiehLVNAb5ms+CSgWTNRokFeIYg64xGMYAIFkewwbG2NVtG0mHIC+ikb6M2maFXEnVo5Jkx6dC2VPJcYsNsYyhTshqVGNoZcKUNDq5THy46pMn5/CVnQdw3sYRvOoZm1r2ufMFNwxBH4a0zRkDwEtvb1zep/adLXkNFStsFiXXQ1qsuGWyZsn1VbVVXROSv3UjYcoLBddnsIizG4lariSeS8MwJ1pzThUdrEM+dt+i4yFlUYglmKikSiRhDL8gonPbNpIOQd6g+So+x0FBSeMyn2fEhdiJZiytQimU+cwvh3ohq3osuN0mxpBP27H9GCSbmSp2rm1mHEqur8bGe3dw8RmozH6eKbkVjaBaPRa5UAmikrzYqKSSYgzdcw37IipJW8jXdCVZggXNifMfZWg6io5foSOkTYJbBZIYhmcCuJuIHhHVT+8jot3tGthCoaCapsfT1iBctXLyk60Ae8cwNKYxBIyBn7fWhqtyl0fatmLPuRzbdBcZBtfjjXDkuSwLV9Lmlf2wCLjz8ROh/WfFgqJdrKHkeirqRk6ooaikkCvJU+/pFrg+ExqDzhiq728TYa7sqUJ6tSKTiq5XoSOkTFRSBZK4kp7ftlF0EMWY+ij66qS/BmPQXUmLFXJ1a1nUsCupnYzBFavFtE2x4aoyqmS6TljiQkJWpC1FxOeVA1k8c9sobrjnMP7sOWcpd4hkmoWyp3SIlo7H8QPDoGkMKTtGY5CupAZKoSwUPJ+JqKRgWz3GMFMKFgq1NIZiuTLiLhyVZMRnIAFjYIztj/tr5+AWAgWn0jBExSi9k5SOgDF0zySVFGXN7SDDVetVWA3XSmpxPwbhn09ZFhirLI4mV+VTNW7+VuHrdx/E/hOzdffTV92MMW4YxKz20vPX49BEATv3n1L7S4bZPsbgq37c8lrmUUkWrGgeQxe6kjzVjyGYnmqJzxYFxhaofW1wxhB1JRmNIYolbx4Ljl+R7ahfkJmUxVevtQxDF4X6JUXZ4640AFpUUr1wVVnYDKrkQqsgk5vSKT4RRM97cYEYQ9Hx8L+/di++tvNg3X2lsfIZdzk6LlOTzXO3r0Zfxsb19wTHmS21d0FRcrwKxsDzGDhj0PNOuk189n0GxoKseomaUUlEoeuhJmNw/ApWYFukSmuYzGcOYxhiqKVOW7lhsGKzgad6xJUkV7eBxlDHlSRWdETUcsPAQz1JlUKuMAzuwojP46JHx2wDk7d+vkquxzUGMTH3ZVK4evsa3LT7iNpPrm7blTsgI5CAOI3BimgM3cUYlH5lUyhaqCZjsAgzmmGodW0UHU8xYx3yejMaA8eSNwxFx0M+ZgUhkU1ZyNhWxQTl+6wnopLKrq8xhsYMgyzIBojkohZXV7UtUi6QqABdUuJzexnD+Aw3DI1M3mHD4AtjG1xDV52zGtNFF3uOzcD1fLXIaNd1w8Vn0VtE63BmU1weg2QM3aEx6LWM9HpG1cpuA/w7TpcaYwwFx4tlBfJ6M64kjiVvGOIuFF1jyNgWMqlKwzBbdlUURGExawxeYBjkTVGo50oSJZyB1ruSHI+3oJSumGjIqgpXbbPGIBlDIytpnU2WXF8luEms6Of5DFNFB7Ol4Hi1ju37DN+970hTEV9cY+Cfr1/LMptYP6dy7MUuWdzIQIaUtjgA6mkMpAJBLAKmCjWikhw/NudIXs+GMXAYw1D2kE+Hg7OsGFdSNCpJX7EuesYgJjHpfkjCGKwWGwbeaYxUbHm0vadc2badMUjDkJAxFB2vwjAMi3yGyYKDGW0RUevYP90zjrd86Ve484mTicde0iY/XS8L8hh08bm7NAYvEtggUU98li6x0cFszUVDyakMVwUCAdpEJXEs+bNQjGMMIVeSLcTn8ATVK4ahpLmSLIuQSVkNhavK2O9U28JVhcbgxjOGmbLb0vyJKGQf8EZ+W70oXcnx4XhMnVMAqk7SVMFR2blAbcbwyFHeILGZ6qwl1wsYQyQ/x7bj8xi6pVaSq5Vb0cdez5UksWY4X19jiGEFkp0YxsDRMcNARE+IJLldRLRTbFtORD8goj3i/7J2j6NQR2PIpCxkUnZFSQw9brqd5Q3aDd0wAEAuZYUmujiEGEOLG/W4qgqocCVFchmk64MxhPzKrYZkDMk1Bk8luEmomkkFJxRWWcvo7BmbEfsk/466+BzqOxDHGNzuEp/1RjqW1bgrSWLtUK6+xhBnGCyrolTGUkanz8KzGWM7GGMXiefvBnALY2wbgFvE87Yi7kKpMAw2VbiSpkKMofs1hpmSiydPVBaeK2uTCMBXTI0U0ZPRLq1u1MPZCCFtxYvP+tjamf2cxJWkawxFxxd5DME11JfhuTCThYjGUOPY0jDMNmH8dD962E9vqagk2YypW8XnVIQx1ExwI50x5GrnMcSEqwK8LIYRngN02jBE8WIAnxePPw/gt9r9gYWyh1wNV1LGtkR5hsWtMVx36z689BM/r9iuawxA2DCUXC+2imkoKsmiilX9fOB43E2lXEkV4nPwvJbIOF+Mi3LsjaykKxiDG2YMRIThfBpTxTBjqHZsxhj2HuOupJlS8msrVBLDqmQMQNAjWZ7Psuu3VCtqFjL5zopUV61ZEkPslxWlzmfLXmzeEWMsNsEN4GUxovPAUkYnDQMD8H0iupuIrhXbVjPGjojHRwGsjnsjEV1LRDuJaOf4+HjTA/BFfZvoSsGqcCXFGQa+KhnOp7uGhtfC4ckijs+UK5hP2QsiWAAuvsnJ4st3PInnfuSnockMEEXObGkYrIYbsTcC2daxariq2zrG4PkMhyYKsa8liUqKhqs6Wh6DxFAuhcmCG2IA1RjDkckiZsXnNsMYQlFJUY1BPJfGXNeTuqFekq9FJVXryxyF3K0vY2M4zwNJ4oITyp4PxuJ1hJRFRnjW0Mkz8UzG2AXgNZjeSkSX6y8yznVjpxzG2HWMsYsYYxeNjo42PQB5U1SUxIjkMdSKSlo9lF0UjEHS66j/NcoY8mlbTVjHpksoOB4eODQZek84j6GybMV84IgM3WqMQdc/5huZ9Lc3PYgrP/yTCtcZY0zlMTQUlRRyJXmq7LaO4Xyai8/C7WhRdaYp3UgAKoxyPTDGQmVOooxBPpe/mX4+u2GBI4VxW5R0l6jFGORCri+TwlA+EPqjCJr0xCS42ZZxJWnomGFgjB0S/8cAXA/gYgDHiGgtAIj/tTt7zxPyxqwsiRETrloRleTAtgjL+zNdcUPVw2Qtw6CtbrOaK0l+r/sihkGu6oF2hKsKjUHlMVRqDP3i95pP9vP9hybxhdufQNHxK87JZMFRkUUNaQza5Con8myUMeTTQnzmx1sxkK2q5ewRbqR82k6sX0V7GkerBqcUYxAag8YSukFniBZolKjXwQ2QjCEQ+qOQ5zuOGaSMxhBCRwwDEfUT0aB8DOC5AO4H8C0ArxO7vQ7Aje0ch5z4KkpiRDSGbKwrycVgLoW+TApzTveLz1IsrzAMXiQqKW2rCUK6Me6PZQxByYWWGwbRmxhARYXVouthVHTbi2MMns9i+zjo8H2G9914v3KBRV1SMlR147I8io5fV1zXJ1dZmkGv8Q9ww8AT3FzYFmEkn6466e8dm8Hy/gzWjeRCYnUjiBqGaq4k+Z10zSbOUHk+W9De27r43GgHN8UYshpjiFk0KMMQk+A2nE9jWX+mYvtSRacYw2oAtxHRvQDuBPAdxtj/APgQgOcQ0R4AV4nnbYO8UOpFJaVjopKkYchn7IZdSayF8f5JIal1lGKXHA8ZO/j+PFyVf5+5BhhDym5xHoNwJWWq5DGUHF8Zhjh3wQe+8yBe99k7a37Gz/cdx6+enMBvnruWHydiYKS+cNqKfgD1k7+KjqeKsEnGEHUlDeW4K2mm5KIvY6MvY1fNMN8zNoMzVg2gP5tK7EqSOoFc7MQluAEBY+C/f/UGTR+8+SG84rpfJhrDfBAwBisiPtdOcAOAvnQ9xsDPd1xJjA++9Fx88KU914esaXTEMDDGHmOMnSf+tjPG/k5sP8EYu5Ixto0xdhVjLHnaZwLEdW8DwkKX1BjixOfBbBp9abshV9L9hyZx1l/9Dw6e6kyv4jiNwfF8zEZ6AuhRSXJF+9jx2dAEFc1jaEe4qmQMbuTYRdfDYC6NbMqKzWN4/PgsHh+vXSr76CSPOHrOOTy2IWpgpGHYJNpx1vt9i46vOv1NF+MNA9cYuPg8kOULirgyFIwx7Dk2jW2rBtCfSSUWn4N+z3GMwVKGQmkMrq86zcWJz/ccmMDDR6YSjWE+cKsxhgYS3PqztpZMWHnearmS1g7nsXY4vh3oUsSSluELVTQGeT1axMPY4qKSppQrqTHG8MjRaZRdH08cX3jD4PlMTaK6YQj6XeuGIYhKmi17sIgnk+kCtCe6rAFoQ2tPHynRj0E+1yHj0Ify6diopNmSW3eVLSfbtcM5AJUuqQrDUEdnKAljpR8rE2UM+RTKno8Ts2X0Z1NcP4hxQR6fKWOq6OL00WYZgzAMYrGjr7Rlox5A0xgcT/3+hXIlg9l/Yg6zZS9koMquj2f9w49w0+7DicbWCFRJ9ySuJGE08plUTcZQqOFKMghjaRsGJ15jkOWkpe89ruz2jHIlpRpiDCdnywBqV35sF/QJVC+xMDHHxxQ2DLZynRTKHravGwYQdie5XjTzucWMQXclxYSr5lI2BnOp2FXhbMnDbNmr6baToaByhRj1R49NF5FLW8plVe/3LQljlU1Z6lzLfhIScsI6PFFAf5ZrU3HHPTHLjdLqoRwGsnZDZb91yFVxPY1B1iQqOh5G8pnQeyVmSi6Oi+gs+R8AjkwWcOBkAY+Ksh2thFwHpKJRSQ0kuPVnbOTS3PVbS2PIGpG5Lpa0YaimMQCcusrJKTaPoeRgMJdGX4aXy6gneJ7ooGGIYwlAYCRG+gLRLa+5xmbLLjat6MPa4VzIMOgaQ9Lqqq/99B34yl1PVn1dVldVrqQYxpBNWxjMpWNv/tmyC89nNZsNzZZcpCzCigH+veMYw+hgFn0ZWW22vsaQS9vIpqyaGgPAcxQGsjbymXgXZPCbpNGfTWFOiM/X33MQV/+/n8ayJNfz8YKP/gw/evhYzagkPT9E5jGUXF8V+Yt+Tz1TXgryAHDoFM/9aCb5rh5CtZIarK4qX+vLpFQyYU2NwRiGuljShkFpDDFiFGcMfHsmpjH9tOZKAup3cTspVoLVDMN7r78Pn/jJvmRfoEHoK2v980+JSWiZxhiyaRsl1wdjDIWyh760jaeuHw5FJnksYAzR2ju14PkMt+09jru1NpdRuL4fSXCrLKKXTdkYyqVim77LKJ5aLpjZkitW7bxURYXGMFPC6EA2KENejzG4PnJpG7m0rT436krSXRx9mVQoX0SH/H2G82kMaK6kXU9O4OGj0/h/P9xT8Z6JgoP7D01h14FJpROokhjVGIOI3nJ9hhExtihj0NuajmuG4aBICqynf3z0lj14343319wnCj1cNdyPofp7LC1cFeDn7pePncB9B8NBE4Ewv6SnvYawpM+Q9KnGF9UitepK2xY8n6mLljEWikrix6pnGDhjmCiUY1//6Z5x3P7Yiea+SB1UZwzClZQPGIO8aUqurybQ9SN5HJ8Jxh3NY2i0Uc9kwQFjtUtZSPG5uiuJT8JDuXiNQQrmtSatmZKHgSxfXQ7lUhWM4chkEaODWVUioRHGkE1ZyKatQHyOyWOQGMhW16YmNcbQl0mh5HI2Khnn537xBB4+GhaDZYjsVMHRNIbaJTFcn6mwZOlKrDAMWjmU8VjGUNsw/GLfCdzyULJUJN0w6KyUarqS+P++LP+93vm8szAx5+CF/3Ybbtx1SO1XLTzdoBJL2zDUcCXJEtQAKvoPFxwPns+UKwmozGL1fYbf//xO/HzvcQCBK6laga+pgtu25jPS5bKsLx36DCU+92saQyro4iabGA3mUpguOspvzzWG5HkMjegsjidLYlRWV/V9por+DeUrJ3TfZ+p3qMcY5O82GDEw+8Zn8Nj4LC46bXngSqoXleRKV5JdVXzWI7/6s5xdlNzKHAm5cBjOp9EvJrrZkodTc2WcPtqPwVwKH7z54dB75HedKjoVUUnRkE89KkkaAulKjLrf9p+YxbK+NGyLMCZqRwFQZUTqGYapooPx6VKiMG09j0EK57UikgDNlSTu46ufuhY/eecVWDmQwc/2HFf7FatoigaVWNKGQV0omZhMSE0Alf9l6W158w/mUqrJz1zZxSdv3Yf/+NljAPhN8cOHjuHHD/MVU61JkTHeJrRdfYzlZ25c3hdxJZVhW6RCLYHgppkuunA8hn5hGHwWiLaVjKGxHI1TgqHU+p6y10M6plaSXA3n0jbXGCLnUnfn1WIMs2XOhAD+G+ouqRvvOQSLgBftWKd1tKsfrlohPldoDME5lm6suGNPzPGM+oFsCgNijDNlFydnHWxZ2Y/nnrNa9WqQmFaMwa1wJVWWxOCPXVEnDAiMVtHx8PDRKbzuM3diquhg/4k5bF7Zj5UDmVjGUM+VNF10Ufb8RD0lZLSURYH4XKscBn89SHCTGMqlsX5ZH45NBQZNMiSjMdTHkjYMhbLHtYSYGux6VJL8L5Pc5M2vM4ZC2cPXdh7ATbt5DUDpLjkiLsyTM9UNw1yZM5B2VQudqmIYJuYcjOTTIZouXUnSkOUzqVCjGYCv4m070BiAxuolNcYYRAe3mHBVPQ59KMfdLHrsvT5R1WMMctLVXVKMMVy/6xAuO2MlVg/lGjYMMlJKsgAgPvNZYiCjuSAjx54sBL+JNF5zJRenZstY3p9RVVp1yO86XXRiMp+Dazucx+Cr8zmQTSFlEQqOh9v3ncCtj47j5t1HuGFY0Y/RwWzIMByebIwxyPN6TGMb9SAZVMomdY3VZQwRjUFizVBW5awAlRFbBtWxpM+Q7MUQ57+MhqsCwSQ1pTEG3ZV0aKJQkUh2ZKKAkuvF5hFIyBu9nYwhZRHWDecqDMOwJjwDAWOQkzhnDOEYfc9nWj8GYRgaYQx13Gny2NKNYFG4VlKUMehjApIYBk+5afSw17v3n8KBkwX81o71ANCwfiQjpfQJJ8oY0ralrhWZxyCP/bEf71U5AROF4DdRjKHk4uRcGcv6MxjKpTEXKSstm0ZNFd3QOQLCom1IY/BYyNDyxEZfhaV+ZecBHJ4s4LQVfRgdyKqoJN9nODLBJ9taobSMMXWfjE2Vqu4XRSjBjQJWWgvy5f5MuEXvmqFcxDDw8i/1jmdgDENVf6Otic9BeQZ+0SpXUjZY+R2aKIQKsslJ/shkEadm48VfCXm8sutXCICtwFTRwVA+zUuEO55aZU8UyljWF64PIyesE4oxcFcSH6dkDJoriWTtnfrjOClcSdOl+LacjDFVKwlARca5vuILxqQbBi/2cRQzpcCVpCfK3bDrEPJpG1c/dQ2AYHKtbxh4pJRuGOJWpdJl0y/CVQF+Df7Hzx7DN+4+CICLz8F+fIxj0yWUXR/L+zKKeejfOyQ+q1h9/vlEYRFXN+R6MlxOREkdn+a/0T1PToAx4LQVfVg1mFOMYXymJDrUkTrHx2dKeOfX7g3VfpI6HICQO6ce9JIY+rhrQU700ejC1cM5TJeCUudFx0POsIWGsKTPUrHsIR+jLwBCY1Dis9QY+I0gV7zclcRv3j3HeKlkHnnDlAE4NlVUN9WaoZyKOtGhr6DbwRqmCi6GcpVZoadmHRWqKJFVriQ+5v5MZWGyuXLQJzvwWde3DJIxVGvLqa8WAWkYtP7EWh2gqHsLCK9g62kMA5rGICfZ+w5O4sLTlqkJOS20jrquJCcIV5WIaxEpx6xrDMdnSjg15+CYWFVPFMrqN5H7yGZJy/ozGBL9BvTvPa2LzxFXEhBMnDpj0MVn7gbjNbKOz5SwciCr3nuacCWdmC3D8xkOCn3h9NEBZZB++dgJfO3ug6HwUN0tqudA1IMyDJRAfFYJbmHGIDPbjwrDFNff3SAeS9owVOv/CoioJCU+8wuvLBjDDx86hoFsChuW5dXNu2eMC4KuiIyRN67PgIdEeOGWlf2xq2V99dcOnWGywFeh0Vr1kwUnlNwG6K4kvk9fiDHwsU/MBUxD+qwnCw7+9qYHa66uT2rMKc6dpCJSxHlP2RRiDCVVT9/CcpGcJjOFgbAxqNUPeraki89pTJd4UtyRySLWjeRC++aq5BtI+D7jzY5SEVdSTcaQUud5n6jrJCdP/TeRxktOxsv7MhjMVlYPlRP0TMlV51/XzeIYg+uzIIIpbam8ivGZEravG8JFpy0DAJy2vA+jg1l4PsPJ2bKKSDpz9SDKno+yG4jLkmUC4Wz7sWYYg1a+o74rqQpjGOK/5bHJwDCYiKTGYAxDlQvlt3asx3O3c5eCZA6O5+PwRAE37T6CVzx9Y+gG36s1V5koOCGXkawztGW0n6+WI2GW+k3eFsaguZIAjTHMlUPlMIAgXFUyhr5sWHyeKjrwWRD7LjXWn+89jk/f9jh++Xj1XAwZlaSPQYc0Ajpj0JlI4Eqy1Wrw8EQw6cyW60cllVxPRVsBQbTQqbkyxmdKFYXU+jK1e2DrPv1sSmcMlZOZXO0PiJIYALBPXDcnZktwRARP1JUkCy9yxlBZJE7qKYzx42RTVkg3U8mINik3nedFGQP/nsenOWP4o984A7+1Yx2W92ewSpQGGZ8u4bAyDAMA+HmWv+UJrWyGfh0fa1JjaJQxyP2kbiSxZijKGHxTJ6lBpOrv0rsolKuvIN5+5Tb1OK2Fq372548DAF7/zC0AArp/RBO5Juec0I1x/2HOGLau5GWcJwth0XcqxBhabxgmCw7WjeRDhqHkepgre6GsZ0CPSuLj6NcYw1TRVdnSy/slY+A3pXSXHa7SKpMfs4xsitedijOAnhaRAgBpiyKupIAxrBrMwbYIRyaDz5PGgKi6YZB+8X4tKgnghp0xVDAG3iynumHQBVy9RWpcpJuc1PszKXXeJNNkjLsdp4uuMrqSMRw4KRhDf0bpQ3GMAeC/Q1Tf0PWgEGPQzmcuzZsSHZ8pY+VgBlectQpXnLUKAFTNqPGZEg6dKmA4n8YqMenOlFyVKKknQcpruj9jJ4pKUkX0ItpILchT3RcVnyOuJK4pLum1cMNY0mepUZ+jNAwnZ8v47zsP4DfPXYv1I3n1WnR1OCkYg7xBHzw8BYt4uChQmf08HWIMLhhj+OIv94cKl9XC9x44igcPVy+NzDWGMGOQWsdwVVcS/+x8hq8mMzbP6pWrfulKkqs16QqRMe5xODVXxmkr+sSY4hhD2JWUTlUTn3kpi9WDWRUhAwTGYEV/pmpUktwnEJ/5/0dF17QoY8jVKauuM4ZGNYYBTWPQmaZs6Sl/p1zagkXAAcEYlvdlYrUV3W02PlOuKBIXlC8JalDpGoMUn8enubA8qmkMQGAYxqaKODRRwLqRvDJas2VXcyUF16tkxWesGkgUlRRKcKPGDEO0JIZEXyaFwVzKuJKawJI2DLVcSTqkK+n6Xx3CdMnFGwRbkJDHkJR7suBgquBi7XAO/Rnuu13Wl1GTadSNorsFpgoODp4q4K9uuB833HMIjeA937wPn7g1vs4SYwxTQmNQhmHOwUShsk4SEBeuGkygU0WnoiJrKsIYDtViDDNlbBbNb+K0FC8iPqcsqhKuyn+PtSP5EFOTbGB0MFedMQiBekDTGADgYZE0VsEYMrU1Bj1SSl+pZ2poDH3ZwIjobhbZ0lOeW5nLMCfybQZz8R3KZoquahR0PIYx2LEag6+5kni4qtQyVlYxDOMzJRw8NYf1umEIuZI0xiC2nb5qAGPTxYazn11dY7AbNwwZ24o1xmuGcuoaKYpyKgb1YQxDI4ZBXHA/fOgYTh/tx3kbhkOvSwr7lLVDAPhNIQXftYJZyOQkoNIwTBcd5fOeLrqq/EAj0Rwl18PJ2TKOVJmQS66PsudjKK9HJbkqQkivkwTEh6sCsnSEq1xM0pUkV2vjdRhD2fUxXXKxWXOnRRGnMVRjDACPOtFdSXNlF9mUheF89T4GUcYg3WSyhHRSjUGPlNIn5FTMZHbBacuwY+MIRvLp0Op2izgnjxzljEH/TaRhXtaXhmUR+jM2LKrUGHQdoNKVFIj5elSSznbyWnJe1DD0ZXgW9n/d8SQePTaD8zeNqPM3XXTVIkM3DDpjcDymXJD1oEclqTyGOmkHT9swjGduWxn72prhnAqXLRlXUsPoVM/njUT0YyJ6kIgeIKJ3iO3vJ6JDRLRL/F3TznEUyr4qlFYLqjG9z/CS89dXJMTJm/ycddwwTAqRdiifViJpLcMwVXQxOphFxrYwVQxCFxuJ/5YTsr5y1qFX60zZFgayKUwWAsYQFZ/lpDJddEO5HEO5FKYKOmOIaAwztTUG+b6Ny/J8YosrHx3VGCKGoeQEkzAgDUOwGpWlLgayaVUS+vZ9J0JjktsHslJ85t//kWPTGMql1IQnUV9jCFhMVqvGG5c0+etnjuKGt16GlG2FVq7nbRiGRYHeoOtPUlCVbJOIVP/o4Du5yqDxCKl4V1I0Kqmo1VXSJ8yVg5W9j0cHszh4qoCrnrIab7p8q8YYPOWWPD4bFp/TNuG05dzojTWoM8hESX2s9RjDSy/YgM/83tNjX1szlItoDIYxNIJOmU8XwJ8xxs4BcAmAtxLROeK1jzDGdoi/m9s5iGKDjEHXEF4ssmJ1yFX1WasHYVukNIahfBrrxA27YqA2YxjMpbm7puAog9CIYZBG5OhUMbYshaT0cgKUterjmvQA4eKBfVpWuCw2J+sryWgeedOOaeOIax4vk9tWDGQxmIuvly+FR32Fq7f2rHAlDedRcn3l9pIZzQNZG7MlrtX8/ufvwkd/tFcdQzIGyfL0UNy41o71wlVLGouR44qLSIpCN7qblvdhxUBW5cLouSVyAtYb1Q9F6kRNF12lefExx4vPertMz2coup4qWKhPmFHGAHDjdenWFfi3V52PlG1pBf5cpZmFGQO/plcP8WM1GpkkGwjpY63VpKce1gzz5DzX8xu+3w06FJXEGDsC4Ih4PE1EDwGonHHbO4bEGsPFm5crAVmHZAwbluUxlEspjWE4n1YUf3l/Brk0bxNaaRhcDOVTmC2lMVV0lQupEdFOxoh7PsP4dElFYkjojAHgkTGThbISDKOZzwD3OZddX5UxBvgEenSqiFOR+krypi04fJJxfYajk8WK8yQn72V9ot5PLfFZupIsS9WnAipdSVIPODJZxIqBLM9PyPBV/2yJi6KzZQ+PHw8EXuliimoMALA2oi8AnDHE9WZWY3IrGUNcDkMc8hnuvlm/LI/VQ0E9onAlVj7O5drvxPUe3ZXkhH73KGOwqjKGYAUt7wOL4q+Jj7x8BwCo310v1yGvpcmCg7LLy07IsvQql6DBXAalMSRgDLWweigHn/GIqaJjNIZG0XGHGxFtBnA+gDvEpj8iot1E9BkiWlblPdcS0U4i2jk+Pt7U5zoe76/QSFTSSF8GA9kUXn3JptjX82L1uX4ZDwmdKDiYKjgYygWMYXl/VnWXik6KUwUHg9k0BsVr8iaSBsLxfNz1xMnYzx6LKW4WOrZwOUjRcjjPDdepOU71o5EcQOCq0cP/ZLG5U7Pl0OpV96WftWYQQLwAfUrTJobEGKKIJrjlM+HWlkXHh0XBilyu8KWrKHAlcY1Bng+9E1lUY8hobpQ4xtCXsWs2YdKNVVYxhsZuK1kmet1IHqsHg4k9zjBUYwyO56Po+BgRjX0AhMJmAZ0xWFoegy96W1jiPXwsKwaysRMxUbgnghzXydkyN26CsagKuuL6H9W0j0bgMwaLgva6wPwMg57LUHS8inNjEI+OniUiGgDwDQB/zBibAvAJAKcD2AHOKD4c9z7G2HWMsYsYYxeNjo429dnV+j3HYSCbwj3ve06sGwngN3jKIqwazGE4n8axqSLKni/EZ35hrhA3dlzbQckYeFcyRzGFGdHY/qbdh/E7n7wdd++vNA76SkwP3ZSIMoZ1w3k8fHQaj43PYKQvE+sLDwxDmDHIcFU9kknPSj13PRfl43QG6Upa1p8WFUIrxeGo+LxxeV7F8ANBuKEcszy30oc8W/LQl7HRn+WVV2UpiSNiUgCCvhn9ITYkz00lY8hVacE5U3Lx6LHpUI3/aG2tepD61vqRvMoLGMymlGEEgpX5iqhhEAZfGrqBXEq59xqJSvJYUOMJCBhDnBspDmmbR2HJRcDWUa4lyBBryRhyaVvdE3HwfIbdByfUc71WVqtcSYAsZmkS3BpFxwwDEaXBjcKXGGPfBADG2DHGmMcY8wF8CsDF7fr8Wv2e41BrFbhhWR5nr+X6wlA+jYNiQhrKp3D66ADSNuH0UZ4pGmcYppTGwFeCY9NFFX44NlVU0Srf+FVl+OqxqZKaPI7EMAbp95V+67dccToKZQ/ff/BYRZ0kCbmK1A3DUJ5X9Tw+Uw6V0dCzUp8qDENcZNIpzZU0VFVjCIvPm1f0h/SQkmjSI7GyP4u0TSr7WZbTludD5ggwFmQPz5RcpG0KuVvkhLp2pJIxyGidaBmTf/reI3jRv92mVu68g5sQnxt0Jcnzu24kr1yO0Wq3cp8QY9CaFMn/A9kglDXqStITxYKoJB8lURUWCH7zlQOVbqRqGMim1HmV17e83qaKjtK19JDRKL668wBe9G8/x77xGTGuoG1stIJvM9iwjP+m94o6TqZWUmPoVFQSAfg0gIcYY/+sbV+r7fYSAMkaxiaAXAVWK6KXBO+6+mx85dpLAfCJX/ZgGM6nsW4kj7veexUuO2OF2jZZcFB0eJlu1/MxV/YwlEuLlaCLY1MllSV9bKqkfOTf2X0k1H8A4NEep4/2oy9jh8pDSDxxYhZDuZQSmbetHsQbRR5GnC8ZCIyl7kqSIu2Bk3MhxqDftOtGclg5kIl1JZ2cLWMol0LathrQGAJRFgD2C1dQNEHJsgirh4KQ1bmyp0IrgXDy2BPH+TH0OknBd6vOGOS5KGrnnTGGHzx4DEXHx11P8P7VOmNoRHyWx145kEUubStffDQYQH6X5VqXPd2VJDWTwVxQuqQaY0jFaQzCiMjzGk1uq4X+bEotAk5fJQzDbJgxAHxyPlgljPlne7greNeTEwDChiHKHJrBSF8Gz9iyHN/4Fa9ea6qrNoZOnaXLALwWwG9EQlP/gYjuI6LdAJ4N4E/aNYBabT2TIpOy1GQznE9D5vLIG1V32Qzn05iYc/D2L9+DF370tlBvh6FcCqdmy5gsOMotMzZdxGPjvMXiZMHBjx8OaypjUyWsHspVxPRLPDY+i62jAyGX0duu3Ia1w7mKZC4JufKNc7eUXD+0etVv2uX9WawfycdrDHNllfsQDbeUkHWRFGMQxvEJ0ZQ+LkFp3XBeudBmSi4Gsrb6LfaMzajudLJ/8YwQqHXIlXYcY4hr3frw0Wn1HX+xj9eGConPDbqSVg/lVM0hGb0zHGFxSmPQjPhgLo3ZsgfX8zUxPa2yuKN+dDuOMXgspDEoV9JgMsMg3XinC1eSZAzcMPDvsnF5Hw6enKtIcvN9htvF+btP1BPTDYPsMVSvVlI9vOT89UrjMOJzY+hUVNJtAOJ+7baGp+pQhiHT2lOg39jRm1xuOzRRUCsoWcpiMJdCwUmrqIynrh/GDbsO48hkEftPzOG1l56GG3cdwg33HFL9AgDeHevpW5ZhruzF0vXHj8/i0tNXhLYNZFO46W3PrBo9E0Sq6OJz8FifpHTDsKI/g/XL8iqLWMdJTbQezqdRdHj3Nd3tES27HWUMJcerWA2vHcnh7v181T5XdtGXTSmDtndsBk/bMIyHj05jvzAunDGEJwe5sl0bpzHE9GS45aFjALg/XvrUw4yhMcPwf196rnJRrRLiczThUEUlRVxJAJ98ZZ2k/qytMYZqJTEqGUNWMYZmXEk2pIdt47I+ZGwLx2d4ee6ZkqvGuWFZHtMiQ1p3Qz58dBqn5hwQBYbB9f2QWK6Pv1k8/9y1eN+3HkDZZD43jCXLq2QIYqvjmnVjMBRjGIYEo5CT0Z2iGulQPh2afM9YNYBc2sI9T55C2fNx5uoBvPC8dfjRw2Nq9VNyPUzMOVg9GM8Y5soujkwWlVtKx4qBrJpIopB0O44xAOEyGrowuLw/g3XDeRyeKFSsDsemSkpAld8zWhbDjbiScmkba4ZygSvJ9SvqAK0dzuOYEJcdj4U0hpLrY+1wHqet6MMTJ6QryatwJa0ezGHdcC520pA+aT37+YcPjeG8jSP49TNHxTngk658f6Pi81AurSZKxRgirqTRwSwsCkpIy/cB3I8/rbuS8vGuJH2CldE+Mo8hlw7ONdC4+AwgdB6H+9JYMZDBiZmSMlbymtmwjBt4PZAAAH6x7zgA4Orta/Dg4Sl4Po8UtCKMYb4d14bzaVz1FF4Q0BiGxrBkDUMrXUk6dB9xHGOQIuNHfncHiIA7HueRRvqNDfCJYNVgTr2+ZeUAXnPJaXB8H1+8/QkAQZ7D6qEc1o7kMTZdCiWXPX6cr5K3CmGwUSjGEIlKkohjDNkUb125cXkfio4fSmiaKbnYMzaN7eu4e0x+z6gA7UVcSQCwaUWfWu3HdeBaP5KD4zE8Jvoa9GVsDGhjXTuSw2kr+vGkOMaM1u9Z4h1XbcN/C40oCtXTW1wvY9NF7DowgavOXoULRc8CGSmlGEMq+US2YiCLfNoOha0CwDVPXYPvvP1ZYcOgld6eKWquJBWVVL2Innwu+zHI31r+putj3GnVIM+jbREGsyluGGbLyk0or5mNy/kxZTFAidv3ncCWlf14zjmrUXA87BufUa1dQ+Odn10AALz0/A0AKjUcg3gsWcOwfd0w/uUVO5S7olXQjYE+mUr89gUbcP0f/hquOmc1tqzox64DEwCgxGeJ1UM5rB7KquShraP9OH10AFeevRpf/OV+FMqeKjMwOpTFuuGcKt0sISfLLTGMoRbkKlL3xevfK05jWNHPdZTzN40AAO7Q+jLce2ACPuO1ggDEFoIDKhPcAGDzij6lD5RiXAFnreFlSHaKUN7+bCo07rVDOWxe0YeDp6TQX6kxDOfT2LQi/jqQnyc1hh8/PAYAuPIpq0OGAQh8+40yBh22Rbj+rb+G1z9zc2h7yrZUDS4JxbiKjur3PKAtLKKZz0pjsAOXkuf7gjHwsT9twzC+/uZLcfGW5Q2PeUDT1YgIK/qzODFTCnJnNI0BCDrRAYDr+bjj8ZO49PQVSk/bfXASRyaLKqpLXgbzdSUBwJVPWYWvvflSXLy58e+3lLFkDcOa4RxevGN9BXWfL+TN2ZexY33N+YyN8zfxCeXstYOqzMNQLhAP0zZhWV9Q834ol1JumGsv34pTcw6+/quDalW+ejCnhFNdZ5CMIblhiM9jkIiLSpId1bavG8ZgLqVERQC4e/8pEAE7No4ACIxMJWMIJ7gBvLXk+HQJsyU3VmPYvm4IRLy9JMCNmc4I1o7kcdryfrg+w+GJYqwrqRYko5SM4YcPjWHdcA5PWTuIbasGMJhNqTHJ89aoxhDF2WuGqrr3dOid+GRl1b603VBUEsDFXFkrSe5LRLho8/LYvJZqkOdRhj2vGMjg+ExZhdBKAyZLvuuM4ba9xzFTcnHp1hXYOjqAvoyNz9z2OH625zh+58INaky2Vn57PiAiPH3z8nm7pZYKlqxhaBfkpBfnRori7DXBSpAnuPH3rBrMgYiU22mLFlX09M3LcN7GEXzqp4+pGPJVgjEA4eSyx8ZnsH4kn9ivGheuqk+2cXkMy/v5WG2LcMnWFSpaB+CG4cxVg0FZjpieAkBlghsA1b/hyZNzsfX0+7M8V+SOxyRjsEMT/zqhMQA8uklGLjUKpTGUPRQdD7ftOY4rn7IaJHoSn3/asiDjONIjvF3QGdd0ycVAJgVLlOUGUKHD6I16AM4cvEhJjGYQ9LTg41k5kMWJ2VJQn0u7B/RkxbLr4wPfeQgbl+fxnHNWw7YI29cN4cEjU9iysh9/cPlW9T5by4A2WDgYw9BiRCe/WjhblJAAwglKq4QQKf3Kp2srfiLC/37umXjy5Bw+eetjSFmE5X0ZxRgkS5CPZUZqEmRjGEPKtlRpcD0xTgqEembur52+Ak+enMOBk3PwfYZ7njyl3EhAcI6i2bDR6qoAVHXO/SdmRa2bykv23PXDqkx4fzaFTMpS7py1IzkV9vrI0WnMlnjkUqOQbqejU0Xcvu8ECo6HK4WQCQB//aLt+IeXPQ0AtB7hbTYMmng/U3SVplJNfI4yhpRFmC15NTsYNgJpYKXffuVABkXHV02PdJa5cVmfYgyf/fnj2Ds2g/e/cLv6/HPXjwAA3v+i7SGNxLbIrPI7AGMYWowkjEH6jvsyNlK2pYyJFCBlpErUFfSsbaO45tw1ODlbxqrBLCyLMJBN4RlbluOrdx2A4/lgjAuySd1IQHzmM8CjTIZy4ZINypUUMgy8Nv7tj53AvvEZTBVdXCC0B4BPINvXDeGrOw+GMoqDcNXg+NL3v//EXEV4q4T0UQPBRD6Q4wZihehZfO76YXzxl/vh+qxCfK6F9SN5nLdxBB//yT7csOsQ+jI2LtkahP9uWdmvXINSgG40wa1Z9GdSqnS5LqbLay4aUJGyCEThYnrff+AoXJ/h8ip9DBoaR8SVdPX2tcikLHz8J7xplB7JtnE513nGp0v4l1v24KqnrMKVT1mtXr/28q342KsuUJFeEnruhcHCwRiGFmMgmxKlMepPPrITljQIuTRf6UqDIA1EXFTRX/7mOcinbaVDAPzmOjxZxM33HeG+3pIbG6paDzIbNtpDdyifCgnPQLAK1Q3DmasHsKI/g9v3nVA5BhdqjIGIcO3lW7F3bAY/eXQM373vCJ77kVtV9qs+EQzn01jen8G3dx/GbCm+0cq5WuMkGWLbn7Wxdjinir/9weVb8aQQP/sTlEWwLMLfvng7js+UcOOuw3jWtpU1V9l9GTvWeLUS3G3Es59nSgFj2L5uCB986bl49tmrKvbXz2nKsjBdcrF93VBFjksSSIMkXYubVvThLb9+uhLqw4whj7Lr459/8Cjmyh7e/fyzQ8daM5zDbz5tLaKwLZp3gptBcnQkwa2XISuoxuUwRGFZhLPWDKqez0SED//uearm0NO3LMdf/uZTQq4LiXUjeXzytRcird3wzz5rFbaO9uO6nz6GB4/wxLktCUNVAU18jvjih3LpUH8EIFjd64lRRIRLT1+Bb997GN974CiW9aUrmMs1567Fh777MD7wnYdw8GQBZc/Ho6IfQSqy4n7vNU/B+7/9AMqeHxtefM7aIVgE+CxYxQ5k0xjWjPM1T12DvxdZ2UnEZwB42oYRvPLiTfivO54MrXLj8MGXPg1nrEpujJNClt7WS08QEV55cWUFYD2xDQhY3h88a2sisTmKKFMBeC2ub95zECdmyiERfoOITPrvu57ElWevwhmrBtEIjCupMzCGoQ34mxdvV72N6+FdzztLRXEAwAvPW6cep20Lv/+srXFvA4AK2m1ZhN9/5lb8xfX34YHDU7h6+xpcujX5ilDWj4qGdf7Jc85EtHXvaSv68J7nn42rt4dXe394xRkYzqfhM+CSrZXRLmnbwusv24z/e/PD2LZqAH//sqfhjZ+7C6fmnJArCQB++8INePbZq/CVuw7gmnPXIAopQO8Zm1FjftfzzqrQSF5/2WZ84DsPJXIlSfz51Wdj1WAWL4hZ1erQs9LbiaFcGrsPTmC25GHdyEjNfW2t3DbADcXaKiv0JOiPMQy5tI2Pv+pCPHhkMrTvRpHkxhhC4nI9pIwrqSMwhqENeMHT1tXfSeAZTUzctfDbF67H4YkCnrVtZdPHfvZZq/DHV23DGavCbOOyMyr90USEN/366RXbz1k3hL97ybk1P+c1l5yGubKHlz99I9YO5/HFNz4Dtz46HlsBc3l/Bm+5ovJzJM5dP4x94zPK1RR1pwDAq56xCRNzjtJAkmA4n8YfX3Vm4ve1C9devhV/8c37MFv2Kgx4FFHG8I6rtmFFf7bpsFqJOMYAcNfeuZG+6LLK6bnrh/GMBLkS77nmbGxdmZz1GswPFC1dsNhw0UUXsZ07d3Z6GAYdxv2HJvHLx07UZFi9hvHpEr5w+xO44qxVIQ0ninsPTOC+Q5N4zSWntfTzHc/HP33/Ebz58tMrtKc4fPLWfXjGluVKrDfoLIjobsbYRbGvGcNgYGBgsPRQyzCYqCQDAwMDgxCMYTAwMDAwCMEYBgMDAwODEIxhMDAwMDAIoSsNAxFdTUSPENFeInp3p8djYGBgsJTQdYaBiGwAHwPwfADnAHglEZ3T2VEZGBgYLB10nWEAcDGAvYyxxxhjZQD/DeDFHR6TgYGBwZJBNxqG9QAOaM8Pim0KRHQtEe0kop3j4+MLOjgDAwODXseiLInBGLsOwHUAQETjRLS/yUOtBHC8ZQNrHbpxXGZMjaMbx9WNYwK6c1xLZUxVU+G70TAcArBRe75BbIsFY2y02mv1QEQ7q2X+dRLdOC4zpsbRjePqxjEB3TkuM6budCXdBWAbEW0hogyAVwD4VofHZGBgYLBk0HWMgTHmEtEfAfgeABvAZxhjD3R4WAYGBgZLBl1nGACAMXYzgJsX4KOuW4DPaAbdOC4zpsbRjePqxjEB3TmuJT+mRV9d1cDAwMCgtehGjcHAwMDAoIMwhsHAwMDAIIQlaxi6oR4TEW0koh8T0YNE9AARvUNsX05EPyCiPeL/gre8IiKbiO4hopvE8y1EdIc4X18REWMLPaYRIvo6ET1MRA8R0aWdPldE9Cfit7ufiL5MRLlOnCsi+gwRjRHR/dq22HNDHP8qxrebiC5YwDH9o/j9dhPR9UQ0or32HjGmR4joee0YU7Vxaa/9GRExIlopnnfsXIntbxPn6wEi+gdte3vPFWNsyf2BRzvtA7AVQAbAvQDO6cA41gK4QDweBPAoeH2ofwDwbrH93QD+vgNj+1MA/wXgJvH8qwBeIR5/EsBbOjCmzwP4ffE4A2Ckk+cKPCP/cQB57Rz9XifOFYDLAVwA4H5tW+y5AXANgO8CIACXALhjAcf0XAAp8fjvtTGdI+7DLIAt4v60F2pcYvtG8GjI/QBWdsG5ejaAHwLIiuerFupctfVi7dY/AJcC+J72/D0A3tMF47oRwHMAPAJgrdi2FsAjCzyODQBuAfAbAG4SN8Vx7YYOnb8FGtOwmIQpsr1j5wpB+Zbl4BF+NwF4XqfOFYDNkYkl9twA+HcAr4zbr91jirz2EgBfEo9D96CYoC9dqHMltn0dwHkAntAMQ8fOFfgC46qY/dp+rpaqK6luPaaFBhFtBnA+gDsArGaMHREvHQWweoGH8/8AvAuAL56vADDBGHPF806cry0AxgF8Vri4/oOI+tHBc8UYOwTgnwA8CeAIgEkAd6Pz50qi2rnpluv/DeCrcaDDYyKiFwM4xBi7N/JSJ8d1JoBnCbfkrUT09IUa01I1DF0FIhoA8A0Af8wYm9JfY3xJsGAxxUT0AgBjjLG7F+ozG0QKnGp/gjF2PoBZcPeIQgfO1TLwyr9bAKwD0A/g6oX6/CRY6HNTD0T0XgAugC91wVj6APwFgPd1eiwRpMDZ6CUA3gngq0REC/HBS9UwJKrH1E4QURrcKHyJMfZNsfkYEa0Vr68FMLaAQ7oMwIuI6Anwkue/AeBfAIwQkUyI7MT5OgjgIGPsDvH86+CGopPn6ioAjzPGxhljDoBvgp+/Tp8riWrnpqPXPxH9HoAXAHi1MFidHtPp4Mb9XnHdbwDwKyJa0+FxHQTwTcZxJziDX7kQY1qqhqEr6jEJ6/9pAA8xxv5Ze+lbAF4nHr8OXHtYEDDG3sMY28AY2wx+Xn7EGHs1gB8DeFknxiTGdRTAASI6S2y6EsCD6OC5AnchXUJEfeK3lGPq6LnSUO3cfAvA/xIRN5cAmNRcTm0FEV0N7qZ8EWNsLjLWVxBRloi2ANgG4M6FGBNj7D7G2CrG2GZx3R8EDwo5ig6eKwA3gAvQIKIzwQMujmMhzlW7xJ1u/wOPNngUXNF/b4fG8Exwer8bwC7xdw24T/8WAHvAoxKWd2h8VyCIStoqLr69AL4GESmxwOPZAWCnOF83AFjW6XMF4K8BPAzgfgBfBI8UWfBzBeDL4DqHAz6xvbHauQEPJviYuPbvA3DRAo5pL7h/XF7vn9T2f68Y0yMAnr+Q5yry+hMIxOdOnqsMgP8U19avAPzGQp0rUxLDwMDAwCCEpepKMjAwMDCoAmMYDAwMDAxCMIbBwMDAwCAEYxgMDAwMDEIwhsHAwMDAIARjGAwMmgAR/Q0RXdWC48y0YjwGBq2ECVc1MOggiGiGMTbQ6XEYGOgwjMHAQICIXkNEdxLRLiL6d+I9KWaI6COiHv4tRDQq9v0cEb1MPP4Q8Z4au4non8S2zUT0I7HtFiLaJLZvIaLbieg+IvpA5PPfSUR3iff8tdjWT0TfIaJ7ifd8ePnCnhWDpQhjGAwMABDRUwC8HMBljLEdADwArwYvjLeTMbYdwK0A/k/kfSvAy0dvZ4w9DYCc7D8K4PNi25cA/KvY/i/ghQDPBc90lcd5Lnhpg4vBM7wvJKLLwYvyHWaMnccYeyqA/2nxVzcwqIAxDAYGHFcCuBDAXUS0SzzfCl647Ctin/8EL2OiYxJAEcCnieilAGT9n0vBGx0BvFSGfN9l4OUP5HaJ54q/e8DLH5wNbijuA/AcIvp7InoWY2xyfl/TwKA+UvV3MTBYEiDwFf57QhuJ/iqyX0iUY4y5RHQxuCF5GYA/Aq9IWwtxwh4B+CBj7N8rXuDtJK8B8AEiuoUx9jd1jm9gMC8YxmBgwHELgJcR0SpA9Us+DfwekZVSXwXgNv1NopfGMGPsZgB/At4BDAB+AV6dFuAuqZ+Jxz+PbJf4HoA3iOOBiNYT0SoiWgdgjjH2nwD+EbzUuIFBW2EYg4EBAMbYg0T0lwC+T0QWeJXLt4I3BLpYvDYGrkPoGARwIxHlwFf9fyq2vw2829w7wTvPvV5sfweA/yKiP4dWjpsx9n2hc9wuerHMAHgNgDMA/CMR+WJMb2ntNzcwqIQJVzUwqAETTmqwFGFcSQYGBgYGIRjGYGBgYGAQgmEMBgYGBgYhGMNgYGBgYBCCMQwGBgYGBiEYw2BgYGBgEIIxDAYGBgYGIfx/X45kvf+yAvwAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 179.000, steps: 179\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 189.000, steps: 189\n",
            "Episode 7: reward: 199.000, steps: 199\n",
            "Episode 8: reward: 196.000, steps: 196\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 197.000, steps: 197\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 188.000, steps: 188\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 186.000, steps: 186\n",
            "Episode 18: reward: 188.000, steps: 188\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 195.000, steps: 195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd7518c9040>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 0.5\n",
        "\n",
        "# value_min = 0.01\n",
        "\n",
        "#value_test = 0.01\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "# target_model_update=1e-3\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "ED9pgMl-hKMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "#                                attr='eps',            \n",
        "#                                value_max=0.5,\n",
        "#                                value_min=0.01, \n",
        "#                                value_test=0.01,\n",
        "#                                nb_steps=10000)\n",
        "\n",
        "# # define the agent\n",
        "# dqn = DQNAgent(model=model, \n",
        "#                nb_actions=env.action_space.n,\n",
        "#                memory=memory,\n",
        "#                nb_steps_warmup=10,\n",
        "#                target_model_update=1e-3, \n",
        "#                policy=policy_outer) \n",
        "\n",
        "# dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "# history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# # summarize the history for number  of episode steps\n",
        "# plt.plot(history.history['nb_episode_steps'])\n",
        "# plt.ylabel('nb_episode_steps')\n",
        "# plt.xlabel('episodes')\n",
        "# plt.show()\n",
        "\n",
        "# dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "# plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xf3lsmqKg93b",
        "outputId": "e6dd457f-fc2a-41d3-e2f8-a11e74899ca7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   17/10000: episode: 1, duration: 3.429s, episode steps:  17, steps per second:   5, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 14.927475, mae: 18.110921, mean_q: 34.485975, mean_eps: 0.499339\n",
            "   46/10000: episode: 2, duration: 0.352s, episode steps:  29, steps per second:  82, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 9.331665, mae: 18.212118, mean_q: 35.537562, mean_eps: 0.498481\n",
            "   89/10000: episode: 3, duration: 0.507s, episode steps:  43, steps per second:  85, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.442 [0.000, 1.000],  loss: 8.382703, mae: 18.073512, mean_q: 35.352976, mean_eps: 0.496717\n",
            "  130/10000: episode: 4, duration: 0.493s, episode steps:  41, steps per second:  83, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 6.123927, mae: 18.139156, mean_q: 35.488250, mean_eps: 0.494659\n",
            "  156/10000: episode: 5, duration: 0.310s, episode steps:  26, steps per second:  84, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 9.100330, mae: 17.984144, mean_q: 35.035910, mean_eps: 0.493017\n",
            "  212/10000: episode: 6, duration: 0.690s, episode steps:  56, steps per second:  81, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 9.079283, mae: 18.124755, mean_q: 35.442119, mean_eps: 0.491009\n",
            "  282/10000: episode: 7, duration: 0.725s, episode steps:  70, steps per second:  96, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 9.773970, mae: 18.079696, mean_q: 35.111057, mean_eps: 0.487922\n",
            "  306/10000: episode: 8, duration: 0.209s, episode steps:  24, steps per second: 115, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.227670, mae: 17.902631, mean_q: 34.954458, mean_eps: 0.485619\n",
            "  325/10000: episode: 9, duration: 0.156s, episode steps:  19, steps per second: 122, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 8.943479, mae: 18.382249, mean_q: 35.828175, mean_eps: 0.484565\n",
            "  374/10000: episode: 10, duration: 0.418s, episode steps:  49, steps per second: 117, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 7.789400, mae: 18.255382, mean_q: 35.486838, mean_eps: 0.482899\n",
            "  468/10000: episode: 11, duration: 0.764s, episode steps:  94, steps per second: 123, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 8.259544, mae: 18.041936, mean_q: 35.395649, mean_eps: 0.479396\n",
            "  523/10000: episode: 12, duration: 0.444s, episode steps:  55, steps per second: 124, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 8.562955, mae: 17.942306, mean_q: 35.344036, mean_eps: 0.475745\n",
            "  537/10000: episode: 13, duration: 0.122s, episode steps:  14, steps per second: 115, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 5.519403, mae: 18.217819, mean_q: 36.035914, mean_eps: 0.474054\n",
            "  581/10000: episode: 14, duration: 0.357s, episode steps:  44, steps per second: 123, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 8.798317, mae: 18.233346, mean_q: 35.738313, mean_eps: 0.472634\n",
            "  601/10000: episode: 15, duration: 0.167s, episode steps:  20, steps per second: 120, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.482419, mae: 18.110839, mean_q: 35.559970, mean_eps: 0.471066\n",
            "  652/10000: episode: 16, duration: 0.411s, episode steps:  51, steps per second: 124, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 6.546811, mae: 18.131038, mean_q: 35.681725, mean_eps: 0.469326\n",
            "  679/10000: episode: 17, duration: 0.216s, episode steps:  27, steps per second: 125, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 8.270122, mae: 18.036893, mean_q: 35.600860, mean_eps: 0.467415\n",
            "  695/10000: episode: 18, duration: 0.129s, episode steps:  16, steps per second: 124, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.268532, mae: 18.034511, mean_q: 35.441629, mean_eps: 0.466361\n",
            "  760/10000: episode: 19, duration: 0.542s, episode steps:  65, steps per second: 120, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 8.779398, mae: 18.016222, mean_q: 35.413774, mean_eps: 0.464377\n",
            "  844/10000: episode: 20, duration: 0.673s, episode steps:  84, steps per second: 125, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 9.047855, mae: 17.970602, mean_q: 35.480575, mean_eps: 0.460726\n",
            "  859/10000: episode: 21, duration: 0.128s, episode steps:  15, steps per second: 117, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 11.355223, mae: 18.473940, mean_q: 35.821655, mean_eps: 0.458301\n",
            " 1034/10000: episode: 22, duration: 1.425s, episode steps: 175, steps per second: 123, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 8.245756, mae: 18.000444, mean_q: 35.479647, mean_eps: 0.453646\n",
            " 1176/10000: episode: 23, duration: 1.178s, episode steps: 142, steps per second: 121, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 7.595865, mae: 17.997028, mean_q: 35.664590, mean_eps: 0.445880\n",
            " 1339/10000: episode: 24, duration: 1.340s, episode steps: 163, steps per second: 122, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 6.961480, mae: 17.990212, mean_q: 35.790249, mean_eps: 0.438407\n",
            " 1485/10000: episode: 25, duration: 1.314s, episode steps: 146, steps per second: 111, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 6.309774, mae: 17.892756, mean_q: 35.702247, mean_eps: 0.430837\n",
            " 1620/10000: episode: 26, duration: 1.570s, episode steps: 135, steps per second:  86, episode reward: 135.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 6.053279, mae: 17.880370, mean_q: 35.565224, mean_eps: 0.423952\n",
            " 1797/10000: episode: 27, duration: 1.751s, episode steps: 177, steps per second: 101, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 6.358784, mae: 17.921128, mean_q: 35.613030, mean_eps: 0.416308\n",
            " 1972/10000: episode: 28, duration: 1.413s, episode steps: 175, steps per second: 124, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 5.083755, mae: 17.846366, mean_q: 35.738424, mean_eps: 0.407684\n",
            " 2126/10000: episode: 29, duration: 1.244s, episode steps: 154, steps per second: 124, episode reward: 154.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 5.456978, mae: 17.844373, mean_q: 35.783704, mean_eps: 0.399624\n",
            " 2306/10000: episode: 30, duration: 1.446s, episode steps: 180, steps per second: 125, episode reward: 180.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 4.932347, mae: 17.790636, mean_q: 35.823901, mean_eps: 0.391440\n",
            " 2468/10000: episode: 31, duration: 1.281s, episode steps: 162, steps per second: 126, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 4.046170, mae: 17.705162, mean_q: 35.719261, mean_eps: 0.383062\n",
            " 2640/10000: episode: 32, duration: 1.400s, episode steps: 172, steps per second: 123, episode reward: 172.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.644400, mae: 17.682422, mean_q: 35.897958, mean_eps: 0.374879\n",
            " 2697/10000: episode: 33, duration: 0.448s, episode steps:  57, steps per second: 127, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 3.000070, mae: 17.786842, mean_q: 36.080437, mean_eps: 0.369268\n",
            " 2871/10000: episode: 34, duration: 1.415s, episode steps: 174, steps per second: 123, episode reward: 174.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 4.094643, mae: 17.798433, mean_q: 35.971943, mean_eps: 0.363609\n",
            " 3022/10000: episode: 35, duration: 1.498s, episode steps: 151, steps per second: 101, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 3.253687, mae: 17.835915, mean_q: 36.037417, mean_eps: 0.355646\n",
            " 3184/10000: episode: 36, duration: 1.877s, episode steps: 162, steps per second:  86, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 3.707078, mae: 17.778323, mean_q: 35.953917, mean_eps: 0.347977\n",
            " 3334/10000: episode: 37, duration: 1.270s, episode steps: 150, steps per second: 118, episode reward: 150.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 3.316323, mae: 17.745105, mean_q: 35.891047, mean_eps: 0.340334\n",
            " 3534/10000: episode: 38, duration: 1.604s, episode steps: 200, steps per second: 125, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 3.382006, mae: 17.739039, mean_q: 35.912220, mean_eps: 0.331759\n",
            " 3668/10000: episode: 39, duration: 1.077s, episode steps: 134, steps per second: 124, episode reward: 134.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 3.777313, mae: 17.806867, mean_q: 35.944723, mean_eps: 0.323575\n",
            " 3861/10000: episode: 40, duration: 1.518s, episode steps: 193, steps per second: 127, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 3.530689, mae: 17.794644, mean_q: 36.041125, mean_eps: 0.315564\n",
            " 4054/10000: episode: 41, duration: 1.584s, episode steps: 193, steps per second: 122, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 3.342517, mae: 17.802995, mean_q: 36.137090, mean_eps: 0.306107\n",
            " 4228/10000: episode: 42, duration: 1.384s, episode steps: 174, steps per second: 126, episode reward: 174.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 2.426396, mae: 17.929029, mean_q: 36.474925, mean_eps: 0.297116\n",
            " 4420/10000: episode: 43, duration: 1.570s, episode steps: 192, steps per second: 122, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 2.631594, mae: 17.868253, mean_q: 36.388697, mean_eps: 0.288149\n",
            " 4619/10000: episode: 44, duration: 2.267s, episode steps: 199, steps per second:  88, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 3.179062, mae: 17.803774, mean_q: 36.194003, mean_eps: 0.278569\n",
            " 4796/10000: episode: 45, duration: 1.700s, episode steps: 177, steps per second: 104, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 3.102806, mae: 17.831317, mean_q: 36.074198, mean_eps: 0.269357\n",
            " 4984/10000: episode: 46, duration: 1.558s, episode steps: 188, steps per second: 121, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 2.788001, mae: 17.897029, mean_q: 36.307362, mean_eps: 0.260414\n",
            " 5130/10000: episode: 47, duration: 1.161s, episode steps: 146, steps per second: 126, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 2.488842, mae: 17.923779, mean_q: 36.488064, mean_eps: 0.252231\n",
            " 5292/10000: episode: 48, duration: 1.267s, episode steps: 162, steps per second: 128, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 1.865576, mae: 17.785609, mean_q: 36.378177, mean_eps: 0.244686\n",
            " 5454/10000: episode: 49, duration: 1.308s, episode steps: 162, steps per second: 124, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 2.377458, mae: 17.957499, mean_q: 36.609435, mean_eps: 0.236748\n",
            " 5601/10000: episode: 50, duration: 1.187s, episode steps: 147, steps per second: 124, episode reward: 147.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 1.937427, mae: 17.933390, mean_q: 36.678700, mean_eps: 0.229177\n",
            " 5764/10000: episode: 51, duration: 1.305s, episode steps: 163, steps per second: 125, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 2.540637, mae: 17.916008, mean_q: 36.544252, mean_eps: 0.221582\n",
            " 5930/10000: episode: 52, duration: 1.347s, episode steps: 166, steps per second: 123, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 2.212896, mae: 17.941017, mean_q: 36.557861, mean_eps: 0.213522\n",
            " 6083/10000: episode: 53, duration: 1.764s, episode steps: 153, steps per second:  87, episode reward: 153.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.291637, mae: 17.947665, mean_q: 36.602413, mean_eps: 0.205706\n",
            " 6257/10000: episode: 54, duration: 1.767s, episode steps: 174, steps per second:  98, episode reward: 174.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 2.398914, mae: 18.040474, mean_q: 36.694584, mean_eps: 0.197694\n",
            " 6431/10000: episode: 55, duration: 1.379s, episode steps: 174, steps per second: 126, episode reward: 174.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.081440, mae: 18.135237, mean_q: 36.927397, mean_eps: 0.189169\n",
            " 6591/10000: episode: 56, duration: 1.296s, episode steps: 160, steps per second: 123, episode reward: 160.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 2.354525, mae: 18.202974, mean_q: 37.051453, mean_eps: 0.180986\n",
            " 6733/10000: episode: 57, duration: 1.143s, episode steps: 142, steps per second: 124, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 1.505076, mae: 18.298192, mean_q: 37.385379, mean_eps: 0.173587\n",
            " 6897/10000: episode: 58, duration: 1.709s, episode steps: 164, steps per second:  96, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 2.235639, mae: 18.143782, mean_q: 36.942274, mean_eps: 0.166090\n",
            " 7051/10000: episode: 59, duration: 1.647s, episode steps: 154, steps per second:  93, episode reward: 154.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 1.960838, mae: 18.206728, mean_q: 37.044312, mean_eps: 0.158299\n",
            " 7203/10000: episode: 60, duration: 1.229s, episode steps: 152, steps per second: 124, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 1.914192, mae: 18.348393, mean_q: 37.262954, mean_eps: 0.150802\n",
            " 7372/10000: episode: 61, duration: 1.496s, episode steps: 169, steps per second: 113, episode reward: 169.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.480322, mae: 18.290928, mean_q: 37.213372, mean_eps: 0.142937\n",
            " 7534/10000: episode: 62, duration: 1.821s, episode steps: 162, steps per second:  89, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 1.656546, mae: 18.408262, mean_q: 37.284574, mean_eps: 0.134828\n",
            " 7699/10000: episode: 63, duration: 1.548s, episode steps: 165, steps per second: 107, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 1.919471, mae: 18.404214, mean_q: 37.235970, mean_eps: 0.126816\n",
            " 7861/10000: episode: 64, duration: 1.295s, episode steps: 162, steps per second: 125, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 1.571189, mae: 18.351036, mean_q: 37.172063, mean_eps: 0.118805\n",
            " 8023/10000: episode: 65, duration: 1.312s, episode steps: 162, steps per second: 123, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 1.669658, mae: 18.384802, mean_q: 37.132512, mean_eps: 0.110867\n",
            " 8184/10000: episode: 66, duration: 1.334s, episode steps: 161, steps per second: 121, episode reward: 161.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 2.111409, mae: 18.413047, mean_q: 37.041962, mean_eps: 0.102953\n",
            " 8367/10000: episode: 67, duration: 1.499s, episode steps: 183, steps per second: 122, episode reward: 183.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 1.901912, mae: 18.426614, mean_q: 37.041261, mean_eps: 0.094525\n",
            " 8556/10000: episode: 68, duration: 1.490s, episode steps: 189, steps per second: 127, episode reward: 189.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 1.535207, mae: 18.561579, mean_q: 37.333522, mean_eps: 0.085411\n",
            " 8729/10000: episode: 69, duration: 1.377s, episode steps: 173, steps per second: 126, episode reward: 173.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 1.461969, mae: 18.456495, mean_q: 37.181115, mean_eps: 0.076542\n",
            " 8904/10000: episode: 70, duration: 1.619s, episode steps: 175, steps per second: 108, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 1.752485, mae: 18.549334, mean_q: 37.201333, mean_eps: 0.068016\n",
            " 9071/10000: episode: 71, duration: 1.931s, episode steps: 167, steps per second:  86, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.187765, mae: 18.556533, mean_q: 37.276064, mean_eps: 0.059637\n",
            " 9262/10000: episode: 72, duration: 1.613s, episode steps: 191, steps per second: 118, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 1.394043, mae: 18.731727, mean_q: 37.580809, mean_eps: 0.050866\n",
            " 9432/10000: episode: 73, duration: 1.358s, episode steps: 170, steps per second: 125, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 1.407766, mae: 18.640980, mean_q: 37.255778, mean_eps: 0.042022\n",
            " 9621/10000: episode: 74, duration: 1.509s, episode steps: 189, steps per second: 125, episode reward: 189.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 1.481529, mae: 18.711309, mean_q: 37.403933, mean_eps: 0.033226\n",
            " 9821/10000: episode: 75, duration: 1.617s, episode steps: 200, steps per second: 124, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 1.309611, mae: 18.714673, mean_q: 37.434823, mean_eps: 0.023696\n",
            "done, took 91.281 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 115.000, steps: 115\n",
            "Episode 2: reward: 106.000, steps: 106\n",
            "Episode 3: reward: 109.000, steps: 109\n",
            "Episode 4: reward: 105.000, steps: 105\n",
            "Episode 5: reward: 113.000, steps: 113\n",
            "Episode 6: reward: 110.000, steps: 110\n",
            "Episode 7: reward: 108.000, steps: 108\n",
            "Episode 8: reward: 113.000, steps: 113\n",
            "Episode 9: reward: 110.000, steps: 110\n",
            "Episode 10: reward: 106.000, steps: 106\n",
            "Episode 11: reward: 111.000, steps: 111\n",
            "Episode 12: reward: 111.000, steps: 111\n",
            "Episode 13: reward: 110.000, steps: 110\n",
            "Episode 14: reward: 107.000, steps: 107\n",
            "Episode 15: reward: 113.000, steps: 113\n",
            "Episode 16: reward: 114.000, steps: 114\n",
            "Episode 17: reward: 111.000, steps: 111\n",
            "Episode 18: reward: 114.000, steps: 114\n",
            "Episode 19: reward: 106.000, steps: 106\n",
            "Episode 20: reward: 108.000, steps: 108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd751e064f0>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 0.5\n",
        "\n",
        "# value_min = 0.01\n",
        "\n",
        "#value_test = 0.05\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "# target_model_update=1e-3\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "UCEkxco_SqbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "#                                attr='eps',            \n",
        "#                                value_max=0.5,\n",
        "#                                value_min=0.01, \n",
        "#                                value_test=.05,\n",
        "#                                nb_steps=10000)\n",
        "\n",
        "# # define the agent\n",
        "# dqn = DQNAgent(model=model, \n",
        "#                nb_actions=env.action_space.n,\n",
        "#                memory=memory,\n",
        "#                nb_steps_warmup=10,\n",
        "#                target_model_update=1e-3, \n",
        "#                policy=policy_outer) \n",
        "\n",
        "# dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "# history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# # summarize the history for number  of episode steps\n",
        "# plt.plot(history.history['nb_episode_steps'])\n",
        "# plt.ylabel('nb_episode_steps')\n",
        "# plt.xlabel('episodes')\n",
        "# plt.show()\n",
        "\n",
        "# dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "# plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EhyLGSvySnTx",
        "outputId": "6bc7fa8b-83bd-40a7-ea8d-42e7fd251dda"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   78/10000: episode: 1, duration: 2.580s, episode steps:  78, steps per second:  30, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 6.250701, mae: 38.393078, mean_q: 77.922952, mean_eps: 0.497844\n",
            "   98/10000: episode: 2, duration: 0.162s, episode steps:  20, steps per second: 124, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 15.884942, mae: 38.455485, mean_q: 77.717164, mean_eps: 0.495712\n",
            "  110/10000: episode: 3, duration: 0.097s, episode steps:  12, steps per second: 123, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 5.063988, mae: 37.876823, mean_q: 77.795512, mean_eps: 0.494929\n",
            "  129/10000: episode: 4, duration: 0.152s, episode steps:  19, steps per second: 125, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 6.072230, mae: 38.375618, mean_q: 79.107656, mean_eps: 0.494169\n",
            "  163/10000: episode: 5, duration: 0.284s, episode steps:  34, steps per second: 120, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.397411, mae: 39.118011, mean_q: 79.242323, mean_eps: 0.492870\n",
            "  211/10000: episode: 6, duration: 0.526s, episode steps:  48, steps per second:  91, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.120346, mae: 38.630706, mean_q: 78.141652, mean_eps: 0.490862\n",
            "  411/10000: episode: 7, duration: 2.066s, episode steps: 200, steps per second:  97, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 7.988649, mae: 38.360103, mean_q: 78.153820, mean_eps: 0.484785\n",
            "  459/10000: episode: 8, duration: 0.435s, episode steps:  48, steps per second: 110, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.396 [0.000, 1.000],  loss: 12.290062, mae: 38.611254, mean_q: 77.528256, mean_eps: 0.478709\n",
            "  488/10000: episode: 9, duration: 0.230s, episode steps:  29, steps per second: 126, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.414 [0.000, 1.000],  loss: 10.408033, mae: 38.566077, mean_q: 77.720325, mean_eps: 0.476823\n",
            "  559/10000: episode: 10, duration: 0.530s, episode steps:  71, steps per second: 134, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.549 [0.000, 1.000],  loss: 5.324742, mae: 38.250224, mean_q: 77.881975, mean_eps: 0.474373\n",
            "  621/10000: episode: 11, duration: 0.457s, episode steps:  62, steps per second: 136, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.434570, mae: 38.018546, mean_q: 77.561407, mean_eps: 0.471115\n",
            "  699/10000: episode: 12, duration: 0.595s, episode steps:  78, steps per second: 131, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 8.162989, mae: 38.221393, mean_q: 77.898269, mean_eps: 0.467684\n",
            "  735/10000: episode: 13, duration: 0.262s, episode steps:  36, steps per second: 137, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 13.315243, mae: 37.981318, mean_q: 77.275916, mean_eps: 0.464892\n",
            "  748/10000: episode: 14, duration: 0.101s, episode steps:  13, steps per second: 128, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 7.981306, mae: 38.749994, mean_q: 78.084443, mean_eps: 0.463691\n",
            "  770/10000: episode: 15, duration: 0.171s, episode steps:  22, steps per second: 129, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 4.123790, mae: 38.625653, mean_q: 78.449345, mean_eps: 0.462834\n",
            "  780/10000: episode: 16, duration: 0.079s, episode steps:  10, steps per second: 127, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 4.526751, mae: 39.934581, mean_q: 81.089510, mean_eps: 0.462050\n",
            "  811/10000: episode: 17, duration: 0.243s, episode steps:  31, steps per second: 128, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 10.161380, mae: 38.524681, mean_q: 78.315622, mean_eps: 0.461045\n",
            "  822/10000: episode: 18, duration: 0.084s, episode steps:  11, steps per second: 130, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 8.241258, mae: 38.964878, mean_q: 79.487536, mean_eps: 0.460016\n",
            "  913/10000: episode: 19, duration: 0.651s, episode steps:  91, steps per second: 140, episode reward: 91.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 7.737541, mae: 38.602932, mean_q: 78.293573, mean_eps: 0.457517\n",
            "  925/10000: episode: 20, duration: 0.097s, episode steps:  12, steps per second: 123, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 1.790227, mae: 38.920665, mean_q: 79.452787, mean_eps: 0.454993\n",
            "  944/10000: episode: 21, duration: 0.175s, episode steps:  19, steps per second: 108, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 3.534761, mae: 38.992746, mean_q: 79.836847, mean_eps: 0.454234\n",
            " 1031/10000: episode: 22, duration: 0.668s, episode steps:  87, steps per second: 130, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 10.714788, mae: 38.386660, mean_q: 78.278408, mean_eps: 0.451637\n",
            " 1048/10000: episode: 23, duration: 0.133s, episode steps:  17, steps per second: 128, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 5.355390, mae: 38.804507, mean_q: 79.792104, mean_eps: 0.449089\n",
            " 1061/10000: episode: 24, duration: 0.115s, episode steps:  13, steps per second: 113, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 11.880651, mae: 39.307007, mean_q: 79.294125, mean_eps: 0.448354\n",
            " 1076/10000: episode: 25, duration: 0.130s, episode steps:  15, steps per second: 115, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 8.182141, mae: 38.369863, mean_q: 78.658233, mean_eps: 0.447668\n",
            " 1104/10000: episode: 26, duration: 0.209s, episode steps:  28, steps per second: 134, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 11.430280, mae: 38.420900, mean_q: 77.373274, mean_eps: 0.446614\n",
            " 1123/10000: episode: 27, duration: 0.147s, episode steps:  19, steps per second: 129, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 9.068949, mae: 38.464703, mean_q: 78.556705, mean_eps: 0.445463\n",
            " 1136/10000: episode: 28, duration: 0.107s, episode steps:  13, steps per second: 121, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 19.487325, mae: 39.096239, mean_q: 79.712571, mean_eps: 0.444679\n",
            " 1157/10000: episode: 29, duration: 0.159s, episode steps:  21, steps per second: 132, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 3.768764, mae: 38.284690, mean_q: 78.373575, mean_eps: 0.443846\n",
            " 1189/10000: episode: 30, duration: 0.258s, episode steps:  32, steps per second: 124, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.344 [0.000, 1.000],  loss: 11.773101, mae: 37.581943, mean_q: 76.761751, mean_eps: 0.442548\n",
            " 1216/10000: episode: 31, duration: 0.214s, episode steps:  27, steps per second: 126, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 7.979004, mae: 38.586718, mean_q: 78.677472, mean_eps: 0.441102\n",
            " 1256/10000: episode: 32, duration: 0.308s, episode steps:  40, steps per second: 130, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 6.351221, mae: 39.080016, mean_q: 79.519028, mean_eps: 0.439461\n",
            " 1275/10000: episode: 33, duration: 0.149s, episode steps:  19, steps per second: 128, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 17.168161, mae: 38.869441, mean_q: 78.436090, mean_eps: 0.438015\n",
            " 1286/10000: episode: 34, duration: 0.093s, episode steps:  11, steps per second: 118, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 13.830682, mae: 39.856583, mean_q: 80.630153, mean_eps: 0.437280\n",
            " 1297/10000: episode: 35, duration: 0.088s, episode steps:  11, steps per second: 125, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 21.117438, mae: 38.836617, mean_q: 77.788713, mean_eps: 0.436741\n",
            " 1311/10000: episode: 36, duration: 0.111s, episode steps:  14, steps per second: 126, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 8.385843, mae: 38.627491, mean_q: 78.224068, mean_eps: 0.436129\n",
            " 1338/10000: episode: 37, duration: 0.228s, episode steps:  27, steps per second: 118, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.593 [0.000, 1.000],  loss: 7.781258, mae: 38.971899, mean_q: 79.183872, mean_eps: 0.435124\n",
            " 1356/10000: episode: 38, duration: 0.142s, episode steps:  18, steps per second: 126, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 19.746020, mae: 39.280480, mean_q: 79.282857, mean_eps: 0.434022\n",
            " 1401/10000: episode: 39, duration: 0.342s, episode steps:  45, steps per second: 132, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 12.900214, mae: 38.782239, mean_q: 78.464881, mean_eps: 0.432478\n",
            " 1482/10000: episode: 40, duration: 0.615s, episode steps:  81, steps per second: 132, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.395 [0.000, 1.000],  loss: 10.729976, mae: 39.006668, mean_q: 79.304660, mean_eps: 0.429391\n",
            " 1549/10000: episode: 41, duration: 0.513s, episode steps:  67, steps per second: 131, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.433 [0.000, 1.000],  loss: 9.612819, mae: 38.577915, mean_q: 79.054617, mean_eps: 0.425765\n",
            " 1563/10000: episode: 42, duration: 0.120s, episode steps:  14, steps per second: 116, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 1.570937, mae: 39.154272, mean_q: 80.532464, mean_eps: 0.423781\n",
            " 1574/10000: episode: 43, duration: 0.101s, episode steps:  11, steps per second: 109, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 16.131069, mae: 37.959000, mean_q: 77.882784, mean_eps: 0.423168\n",
            " 1589/10000: episode: 44, duration: 0.129s, episode steps:  15, steps per second: 116, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 14.878847, mae: 39.771731, mean_q: 80.179085, mean_eps: 0.422531\n",
            " 1629/10000: episode: 45, duration: 0.295s, episode steps:  40, steps per second: 136, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.961119, mae: 38.783037, mean_q: 79.094901, mean_eps: 0.421184\n",
            " 1643/10000: episode: 46, duration: 0.106s, episode steps:  14, steps per second: 132, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.432777, mae: 39.188910, mean_q: 79.490726, mean_eps: 0.419860\n",
            " 1701/10000: episode: 47, duration: 0.439s, episode steps:  58, steps per second: 132, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 9.025946, mae: 39.490029, mean_q: 80.682427, mean_eps: 0.418096\n",
            " 1717/10000: episode: 48, duration: 0.133s, episode steps:  16, steps per second: 120, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.343894, mae: 39.113775, mean_q: 79.721685, mean_eps: 0.416284\n",
            " 1786/10000: episode: 49, duration: 0.714s, episode steps:  69, steps per second:  97, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 8.176863, mae: 39.069045, mean_q: 80.276787, mean_eps: 0.414201\n",
            " 1809/10000: episode: 50, duration: 0.259s, episode steps:  23, steps per second:  89, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 8.214044, mae: 38.991201, mean_q: 79.397249, mean_eps: 0.411947\n",
            " 1883/10000: episode: 51, duration: 0.797s, episode steps:  74, steps per second:  93, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 5.204471, mae: 38.864717, mean_q: 79.656213, mean_eps: 0.409571\n",
            " 1948/10000: episode: 52, duration: 0.676s, episode steps:  65, steps per second:  96, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 9.894009, mae: 38.822106, mean_q: 79.367099, mean_eps: 0.406165\n",
            " 2018/10000: episode: 53, duration: 0.728s, episode steps:  70, steps per second:  96, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 12.641791, mae: 38.743119, mean_q: 78.854441, mean_eps: 0.402857\n",
            " 2036/10000: episode: 54, duration: 0.138s, episode steps:  18, steps per second: 131, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 15.389087, mae: 38.797785, mean_q: 80.028371, mean_eps: 0.400702\n",
            " 2053/10000: episode: 55, duration: 0.130s, episode steps:  17, steps per second: 131, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 10.351461, mae: 39.173548, mean_q: 80.563518, mean_eps: 0.399844\n",
            " 2105/10000: episode: 56, duration: 0.401s, episode steps:  52, steps per second: 130, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 11.137879, mae: 39.027358, mean_q: 79.905012, mean_eps: 0.398153\n",
            " 2116/10000: episode: 57, duration: 0.092s, episode steps:  11, steps per second: 120, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 5.851212, mae: 39.357885, mean_q: 81.159513, mean_eps: 0.396610\n",
            " 2167/10000: episode: 58, duration: 0.425s, episode steps:  51, steps per second: 120, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 12.933030, mae: 38.693892, mean_q: 78.786189, mean_eps: 0.395091\n",
            " 2217/10000: episode: 59, duration: 0.390s, episode steps:  50, steps per second: 128, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 16.314424, mae: 38.495217, mean_q: 78.405109, mean_eps: 0.392616\n",
            " 2269/10000: episode: 60, duration: 0.400s, episode steps:  52, steps per second: 130, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.442 [0.000, 1.000],  loss: 10.725483, mae: 38.530138, mean_q: 78.950443, mean_eps: 0.390118\n",
            " 2302/10000: episode: 61, duration: 0.249s, episode steps:  33, steps per second: 133, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 17.579809, mae: 39.136981, mean_q: 79.178731, mean_eps: 0.388035\n",
            " 2367/10000: episode: 62, duration: 0.483s, episode steps:  65, steps per second: 135, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.415 [0.000, 1.000],  loss: 5.801345, mae: 38.377310, mean_q: 79.023343, mean_eps: 0.385634\n",
            " 2382/10000: episode: 63, duration: 0.115s, episode steps:  15, steps per second: 130, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 4.787184, mae: 37.725908, mean_q: 78.190775, mean_eps: 0.383674\n",
            " 2500/10000: episode: 64, duration: 0.875s, episode steps: 118, steps per second: 135, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 11.395606, mae: 38.648258, mean_q: 79.940121, mean_eps: 0.380416\n",
            " 2584/10000: episode: 65, duration: 0.627s, episode steps:  84, steps per second: 134, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 10.544269, mae: 38.314958, mean_q: 78.881801, mean_eps: 0.375467\n",
            " 2617/10000: episode: 66, duration: 0.248s, episode steps:  33, steps per second: 133, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 8.074660, mae: 38.547937, mean_q: 79.149260, mean_eps: 0.372600\n",
            " 2711/10000: episode: 67, duration: 0.690s, episode steps:  94, steps per second: 136, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 8.830624, mae: 38.948917, mean_q: 79.694689, mean_eps: 0.369488\n",
            " 2817/10000: episode: 68, duration: 0.782s, episode steps: 106, steps per second: 136, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 10.286484, mae: 38.617408, mean_q: 79.156430, mean_eps: 0.364588\n",
            " 2861/10000: episode: 69, duration: 0.323s, episode steps:  44, steps per second: 136, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.432 [0.000, 1.000],  loss: 17.503063, mae: 38.929285, mean_q: 79.601336, mean_eps: 0.360913\n",
            " 2907/10000: episode: 70, duration: 0.353s, episode steps:  46, steps per second: 130, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.132526, mae: 38.753573, mean_q: 79.884903, mean_eps: 0.358708\n",
            " 2992/10000: episode: 71, duration: 0.624s, episode steps:  85, steps per second: 136, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 13.080758, mae: 38.888352, mean_q: 79.229515, mean_eps: 0.355499\n",
            " 3014/10000: episode: 72, duration: 0.165s, episode steps:  22, steps per second: 133, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.659259, mae: 39.083827, mean_q: 79.783579, mean_eps: 0.352877\n",
            " 3093/10000: episode: 73, duration: 0.591s, episode steps:  79, steps per second: 134, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 13.129167, mae: 38.665015, mean_q: 79.214726, mean_eps: 0.350403\n",
            " 3259/10000: episode: 74, duration: 1.221s, episode steps: 166, steps per second: 136, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 10.470643, mae: 38.814645, mean_q: 79.612700, mean_eps: 0.344401\n",
            " 3313/10000: episode: 75, duration: 0.419s, episode steps:  54, steps per second: 129, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 14.373177, mae: 38.627302, mean_q: 78.879620, mean_eps: 0.339011\n",
            " 3387/10000: episode: 76, duration: 0.763s, episode steps:  74, steps per second:  97, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 8.812154, mae: 38.429814, mean_q: 79.170758, mean_eps: 0.335875\n",
            " 3461/10000: episode: 77, duration: 0.794s, episode steps:  74, steps per second:  93, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 13.577288, mae: 38.271508, mean_q: 78.704243, mean_eps: 0.332249\n",
            " 3485/10000: episode: 78, duration: 0.289s, episode steps:  24, steps per second:  83, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 10.485216, mae: 39.463031, mean_q: 80.808980, mean_eps: 0.329848\n",
            " 3520/10000: episode: 79, duration: 0.381s, episode steps:  35, steps per second:  92, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 11.556876, mae: 38.704955, mean_q: 78.988826, mean_eps: 0.328402\n",
            " 3552/10000: episode: 80, duration: 0.354s, episode steps:  32, steps per second:  90, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.267118, mae: 38.663547, mean_q: 78.564309, mean_eps: 0.326761\n",
            " 3663/10000: episode: 81, duration: 1.022s, episode steps: 111, steps per second: 109, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 10.348756, mae: 38.446430, mean_q: 79.252074, mean_eps: 0.323257\n",
            " 3750/10000: episode: 82, duration: 0.640s, episode steps:  87, steps per second: 136, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 7.444609, mae: 38.698348, mean_q: 79.988689, mean_eps: 0.318406\n",
            " 3771/10000: episode: 83, duration: 0.157s, episode steps:  21, steps per second: 134, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 7.051626, mae: 37.941809, mean_q: 78.334861, mean_eps: 0.315760\n",
            " 3798/10000: episode: 84, duration: 0.220s, episode steps:  27, steps per second: 123, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 7.341622, mae: 38.256231, mean_q: 79.496928, mean_eps: 0.314584\n",
            " 3868/10000: episode: 85, duration: 0.512s, episode steps:  70, steps per second: 137, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 12.511872, mae: 38.967048, mean_q: 80.049810, mean_eps: 0.312208\n",
            " 3966/10000: episode: 86, duration: 0.709s, episode steps:  98, steps per second: 138, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 14.444024, mae: 38.716322, mean_q: 79.729889, mean_eps: 0.308092\n",
            " 4057/10000: episode: 87, duration: 0.677s, episode steps:  91, steps per second: 134, episode reward: 91.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 8.445489, mae: 38.773086, mean_q: 80.239684, mean_eps: 0.303461\n",
            " 4074/10000: episode: 88, duration: 0.141s, episode steps:  17, steps per second: 121, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 6.912990, mae: 38.712175, mean_q: 79.573924, mean_eps: 0.300815\n",
            " 4090/10000: episode: 89, duration: 0.126s, episode steps:  16, steps per second: 127, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 15.746076, mae: 39.399814, mean_q: 80.403092, mean_eps: 0.300007\n",
            " 4177/10000: episode: 90, duration: 0.653s, episode steps:  87, steps per second: 133, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 9.085495, mae: 38.541257, mean_q: 79.300083, mean_eps: 0.297483\n",
            " 4220/10000: episode: 91, duration: 0.344s, episode steps:  43, steps per second: 125, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 16.715157, mae: 38.802492, mean_q: 79.620957, mean_eps: 0.294298\n",
            " 4297/10000: episode: 92, duration: 0.575s, episode steps:  77, steps per second: 134, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 7.381927, mae: 38.426960, mean_q: 79.800026, mean_eps: 0.291358\n",
            " 4352/10000: episode: 93, duration: 0.415s, episode steps:  55, steps per second: 132, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 9.598168, mae: 39.054293, mean_q: 80.551084, mean_eps: 0.288124\n",
            " 4398/10000: episode: 94, duration: 0.350s, episode steps:  46, steps per second: 131, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.825382, mae: 39.354977, mean_q: 81.310031, mean_eps: 0.285650\n",
            " 4429/10000: episode: 95, duration: 0.233s, episode steps:  31, steps per second: 133, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 8.808682, mae: 38.291055, mean_q: 78.911990, mean_eps: 0.283763\n",
            " 4494/10000: episode: 96, duration: 0.500s, episode steps:  65, steps per second: 130, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.446 [0.000, 1.000],  loss: 11.689911, mae: 38.954108, mean_q: 80.460681, mean_eps: 0.281411\n",
            " 4576/10000: episode: 97, duration: 0.612s, episode steps:  82, steps per second: 134, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.451 [0.000, 1.000],  loss: 9.592808, mae: 38.459792, mean_q: 79.704885, mean_eps: 0.277810\n",
            " 4730/10000: episode: 98, duration: 1.146s, episode steps: 154, steps per second: 134, episode reward: 154.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 9.229669, mae: 38.414584, mean_q: 79.589750, mean_eps: 0.272027\n",
            " 4835/10000: episode: 99, duration: 0.785s, episode steps: 105, steps per second: 134, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 11.156105, mae: 38.998301, mean_q: 80.462355, mean_eps: 0.265682\n",
            " 4927/10000: episode: 100, duration: 0.691s, episode steps:  92, steps per second: 133, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 10.314141, mae: 38.919007, mean_q: 80.688103, mean_eps: 0.260856\n",
            " 5125/10000: episode: 101, duration: 2.080s, episode steps: 198, steps per second:  95, episode reward: 198.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 12.286556, mae: 38.484110, mean_q: 79.124722, mean_eps: 0.253750\n",
            " 5138/10000: episode: 102, duration: 0.146s, episode steps:  13, steps per second:  89, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 13.222586, mae: 38.190481, mean_q: 78.431367, mean_eps: 0.248581\n",
            " 5338/10000: episode: 103, duration: 1.738s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 12.423961, mae: 38.612935, mean_q: 79.376579, mean_eps: 0.243363\n",
            " 5508/10000: episode: 104, duration: 1.221s, episode steps: 170, steps per second: 139, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 10.567999, mae: 38.472788, mean_q: 79.756488, mean_eps: 0.234297\n",
            " 5528/10000: episode: 105, duration: 0.150s, episode steps:  20, steps per second: 133, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 10.001014, mae: 38.501174, mean_q: 79.346535, mean_eps: 0.229643\n",
            " 5705/10000: episode: 106, duration: 1.289s, episode steps: 177, steps per second: 137, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 9.120167, mae: 38.076219, mean_q: 79.103797, mean_eps: 0.224816\n",
            " 5905/10000: episode: 107, duration: 1.463s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.664528, mae: 38.488729, mean_q: 79.728817, mean_eps: 0.215580\n",
            " 6105/10000: episode: 108, duration: 1.480s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.387894, mae: 38.019046, mean_q: 78.677274, mean_eps: 0.205780\n",
            " 6130/10000: episode: 109, duration: 0.186s, episode steps:  25, steps per second: 134, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 24.240106, mae: 38.227083, mean_q: 78.027258, mean_eps: 0.200267\n",
            " 6287/10000: episode: 110, duration: 1.146s, episode steps: 157, steps per second: 137, episode reward: 157.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 9.886358, mae: 37.936452, mean_q: 78.648566, mean_eps: 0.195808\n",
            " 6459/10000: episode: 111, duration: 1.215s, episode steps: 172, steps per second: 142, episode reward: 172.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 11.605759, mae: 38.251504, mean_q: 79.254254, mean_eps: 0.187747\n",
            " 6659/10000: episode: 112, duration: 1.693s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 10.635740, mae: 37.972806, mean_q: 78.354589, mean_eps: 0.178634\n",
            " 6859/10000: episode: 113, duration: 2.081s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 12.234556, mae: 37.873758, mean_q: 78.431436, mean_eps: 0.168833\n",
            " 7059/10000: episode: 114, duration: 1.510s, episode steps: 200, steps per second: 132, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 10.615828, mae: 37.797804, mean_q: 78.370148, mean_eps: 0.159034\n",
            " 7259/10000: episode: 115, duration: 1.467s, episode steps: 200, steps per second: 136, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 12.074736, mae: 37.573120, mean_q: 77.970220, mean_eps: 0.149234\n",
            " 7459/10000: episode: 116, duration: 1.482s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.135152, mae: 37.872594, mean_q: 78.508902, mean_eps: 0.139434\n",
            " 7659/10000: episode: 117, duration: 1.455s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 12.216277, mae: 37.596106, mean_q: 77.993408, mean_eps: 0.129634\n",
            " 7859/10000: episode: 118, duration: 1.448s, episode steps: 200, steps per second: 138, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.627958, mae: 37.822066, mean_q: 78.405445, mean_eps: 0.119834\n",
            " 7957/10000: episode: 119, duration: 0.698s, episode steps:  98, steps per second: 140, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.935818, mae: 37.908157, mean_q: 78.447056, mean_eps: 0.112533\n",
            " 8149/10000: episode: 120, duration: 1.405s, episode steps: 192, steps per second: 137, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 10.983815, mae: 38.025235, mean_q: 78.642396, mean_eps: 0.105428\n",
            " 8349/10000: episode: 121, duration: 1.801s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.651778, mae: 37.637903, mean_q: 78.173643, mean_eps: 0.095824\n",
            " 8460/10000: episode: 122, duration: 1.169s, episode steps: 111, steps per second:  95, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 11.121343, mae: 37.380082, mean_q: 77.889754, mean_eps: 0.088204\n",
            " 8660/10000: episode: 123, duration: 1.688s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 11.650810, mae: 37.664255, mean_q: 78.347206, mean_eps: 0.080585\n",
            " 8860/10000: episode: 124, duration: 1.474s, episode steps: 200, steps per second: 136, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.692860, mae: 37.460997, mean_q: 78.464738, mean_eps: 0.070785\n",
            " 9060/10000: episode: 125, duration: 1.488s, episode steps: 200, steps per second: 134, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 16.599720, mae: 37.775698, mean_q: 78.133302, mean_eps: 0.060985\n",
            " 9260/10000: episode: 126, duration: 1.460s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 13.243425, mae: 37.621824, mean_q: 77.914844, mean_eps: 0.051185\n",
            " 9363/10000: episode: 127, duration: 0.767s, episode steps: 103, steps per second: 134, episode reward: 103.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 13.486362, mae: 37.574302, mean_q: 77.632341, mean_eps: 0.043761\n",
            " 9563/10000: episode: 128, duration: 1.486s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 11.448246, mae: 37.619778, mean_q: 78.109109, mean_eps: 0.036338\n",
            " 9763/10000: episode: 129, duration: 1.464s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 9.414924, mae: 37.388813, mean_q: 77.829823, mean_eps: 0.026538\n",
            " 9963/10000: episode: 130, duration: 1.826s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 11.091827, mae: 37.776112, mean_q: 78.317042, mean_eps: 0.016738\n",
            "done, took 83.237 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd752337e20>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 0.5\n",
        "\n",
        "# value_min = 0.01\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "target_model_update=1e-2\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "bZthLuyWQt2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=0.5,\n",
        "                               value_min=0.01, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MLUlBG6DQphE",
        "outputId": "78cb324f-2ac7-4bb2-fe0c-77c46e6aae90"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   80/10000: episode: 1, duration: 2.426s, episode steps:  80, steps per second:  33, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 14.868063, mae: 45.011163, mean_q: 88.189117, mean_eps: 0.497795\n",
            "  105/10000: episode: 2, duration: 0.181s, episode steps:  25, steps per second: 138, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 11.367138, mae: 45.874433, mean_q: 90.632608, mean_eps: 0.495492\n",
            "  209/10000: episode: 3, duration: 0.770s, episode steps: 104, steps per second: 135, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 15.625989, mae: 44.978964, mean_q: 88.565751, mean_eps: 0.492332\n",
            "  333/10000: episode: 4, duration: 0.931s, episode steps: 124, steps per second: 133, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 8.374608, mae: 44.847735, mean_q: 88.544559, mean_eps: 0.486746\n",
            "  431/10000: episode: 5, duration: 0.699s, episode steps:  98, steps per second: 140, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 12.027946, mae: 45.480947, mean_q: 89.462008, mean_eps: 0.481307\n",
            "  561/10000: episode: 6, duration: 0.963s, episode steps: 130, steps per second: 135, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 10.593027, mae: 45.164131, mean_q: 89.635654, mean_eps: 0.475720\n",
            "  613/10000: episode: 7, duration: 0.562s, episode steps:  52, steps per second:  93, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 6.379580, mae: 44.634830, mean_q: 88.572961, mean_eps: 0.471262\n",
            "  679/10000: episode: 8, duration: 0.710s, episode steps:  66, steps per second:  93, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.264013, mae: 44.592598, mean_q: 88.284407, mean_eps: 0.468370\n",
            "  827/10000: episode: 9, duration: 1.589s, episode steps: 148, steps per second:  93, episode reward: 148.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 9.080075, mae: 44.371809, mean_q: 87.820219, mean_eps: 0.463127\n",
            "  850/10000: episode: 10, duration: 0.237s, episode steps:  23, steps per second:  97, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 14.188466, mae: 44.121325, mean_q: 86.954811, mean_eps: 0.458938\n",
            "  962/10000: episode: 11, duration: 0.840s, episode steps: 112, steps per second: 133, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 11.959068, mae: 43.803576, mean_q: 86.017088, mean_eps: 0.455630\n",
            "  987/10000: episode: 12, duration: 0.189s, episode steps:  25, steps per second: 132, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 10.770051, mae: 43.446976, mean_q: 86.148566, mean_eps: 0.452274\n",
            " 1052/10000: episode: 13, duration: 0.496s, episode steps:  65, steps per second: 131, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 4.336065, mae: 44.140251, mean_q: 87.348181, mean_eps: 0.450069\n",
            " 1101/10000: episode: 14, duration: 0.372s, episode steps:  49, steps per second: 132, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 12.245595, mae: 43.994598, mean_q: 86.821865, mean_eps: 0.447276\n",
            " 1216/10000: episode: 15, duration: 0.834s, episode steps: 115, steps per second: 138, episode reward: 115.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 10.581809, mae: 44.095484, mean_q: 86.959215, mean_eps: 0.443258\n",
            " 1326/10000: episode: 16, duration: 0.787s, episode steps: 110, steps per second: 140, episode reward: 110.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 10.629525, mae: 44.317441, mean_q: 87.275119, mean_eps: 0.437745\n",
            " 1457/10000: episode: 17, duration: 0.987s, episode steps: 131, steps per second: 133, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.557 [0.000, 1.000],  loss: 6.590264, mae: 44.044951, mean_q: 87.087080, mean_eps: 0.431841\n",
            " 1499/10000: episode: 18, duration: 0.335s, episode steps:  42, steps per second: 126, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 16.474591, mae: 43.896792, mean_q: 86.214137, mean_eps: 0.427602\n",
            " 1513/10000: episode: 19, duration: 0.111s, episode steps:  14, steps per second: 127, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 3.420720, mae: 44.002863, mean_q: 86.460674, mean_eps: 0.426231\n",
            " 1560/10000: episode: 20, duration: 0.359s, episode steps:  47, steps per second: 131, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.574 [0.000, 1.000],  loss: 11.656135, mae: 43.957682, mean_q: 86.552004, mean_eps: 0.424736\n",
            " 1582/10000: episode: 21, duration: 0.163s, episode steps:  22, steps per second: 135, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 12.469854, mae: 44.068758, mean_q: 87.124885, mean_eps: 0.423045\n",
            " 1641/10000: episode: 22, duration: 0.429s, episode steps:  59, steps per second: 138, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 7.118614, mae: 43.757293, mean_q: 86.406602, mean_eps: 0.421061\n",
            " 1691/10000: episode: 23, duration: 0.373s, episode steps:  50, steps per second: 134, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 8.431050, mae: 43.890212, mean_q: 86.983928, mean_eps: 0.418390\n",
            " 1797/10000: episode: 24, duration: 0.792s, episode steps: 106, steps per second: 134, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 10.080769, mae: 44.438742, mean_q: 87.825299, mean_eps: 0.414569\n",
            " 1811/10000: episode: 25, duration: 0.106s, episode steps:  14, steps per second: 133, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 23.200871, mae: 44.503866, mean_q: 87.454001, mean_eps: 0.411629\n",
            " 1844/10000: episode: 26, duration: 0.256s, episode steps:  33, steps per second: 129, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 13.580255, mae: 44.004425, mean_q: 86.330164, mean_eps: 0.410477\n",
            " 1923/10000: episode: 27, duration: 0.588s, episode steps:  79, steps per second: 134, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 11.915708, mae: 43.765334, mean_q: 85.604745, mean_eps: 0.407733\n",
            " 1954/10000: episode: 28, duration: 0.236s, episode steps:  31, steps per second: 131, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 12.247325, mae: 43.948372, mean_q: 85.625294, mean_eps: 0.405038\n",
            " 2084/10000: episode: 29, duration: 0.955s, episode steps: 130, steps per second: 136, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 8.862273, mae: 43.442237, mean_q: 85.576386, mean_eps: 0.401093\n",
            " 2119/10000: episode: 30, duration: 0.266s, episode steps:  35, steps per second: 131, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.371 [0.000, 1.000],  loss: 3.967903, mae: 43.109000, mean_q: 84.757320, mean_eps: 0.397051\n",
            " 2153/10000: episode: 31, duration: 0.261s, episode steps:  34, steps per second: 130, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.863156, mae: 43.930068, mean_q: 86.339739, mean_eps: 0.395361\n",
            " 2218/10000: episode: 32, duration: 0.668s, episode steps:  65, steps per second:  97, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 14.371418, mae: 43.579904, mean_q: 86.560809, mean_eps: 0.392935\n",
            " 2261/10000: episode: 33, duration: 0.462s, episode steps:  43, steps per second:  93, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 13.902476, mae: 43.848425, mean_q: 86.602190, mean_eps: 0.390289\n",
            " 2309/10000: episode: 34, duration: 0.504s, episode steps:  48, steps per second:  95, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 2.899984, mae: 43.443925, mean_q: 86.168612, mean_eps: 0.388060\n",
            " 2377/10000: episode: 35, duration: 0.704s, episode steps:  68, steps per second:  97, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 11.707786, mae: 44.023269, mean_q: 87.279834, mean_eps: 0.385217\n",
            " 2455/10000: episode: 36, duration: 0.856s, episode steps:  78, steps per second:  91, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 9.269020, mae: 43.095116, mean_q: 84.923788, mean_eps: 0.381640\n",
            " 2516/10000: episode: 37, duration: 0.446s, episode steps:  61, steps per second: 137, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 9.021022, mae: 44.315343, mean_q: 87.474313, mean_eps: 0.378235\n",
            " 2570/10000: episode: 38, duration: 0.403s, episode steps:  54, steps per second: 134, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 9.703354, mae: 43.262230, mean_q: 85.553111, mean_eps: 0.375418\n",
            " 2770/10000: episode: 39, duration: 1.498s, episode steps: 200, steps per second: 134, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 10.595737, mae: 43.235132, mean_q: 85.556459, mean_eps: 0.369194\n",
            " 2870/10000: episode: 40, duration: 0.766s, episode steps: 100, steps per second: 131, episode reward: 100.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 16.743637, mae: 43.442237, mean_q: 85.729332, mean_eps: 0.361844\n",
            " 2931/10000: episode: 41, duration: 0.460s, episode steps:  61, steps per second: 133, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 11.086278, mae: 43.526744, mean_q: 86.124661, mean_eps: 0.357900\n",
            " 2976/10000: episode: 42, duration: 0.342s, episode steps:  45, steps per second: 131, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 10.231373, mae: 43.294438, mean_q: 85.899866, mean_eps: 0.355303\n",
            " 3036/10000: episode: 43, duration: 0.427s, episode steps:  60, steps per second: 140, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 16.876339, mae: 43.448234, mean_q: 85.710465, mean_eps: 0.352730\n",
            " 3082/10000: episode: 44, duration: 0.352s, episode steps:  46, steps per second: 131, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 21.098440, mae: 43.273453, mean_q: 85.495895, mean_eps: 0.350134\n",
            " 3132/10000: episode: 45, duration: 0.389s, episode steps:  50, steps per second: 129, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.380 [0.000, 1.000],  loss: 24.344047, mae: 42.579307, mean_q: 84.013692, mean_eps: 0.347782\n",
            " 3181/10000: episode: 46, duration: 0.367s, episode steps:  49, steps per second: 134, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: 12.794826, mae: 42.615298, mean_q: 84.878460, mean_eps: 0.345356\n",
            " 3381/10000: episode: 47, duration: 1.484s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 10.249449, mae: 42.930174, mean_q: 85.460399, mean_eps: 0.339255\n",
            " 3454/10000: episode: 48, duration: 0.559s, episode steps:  73, steps per second: 130, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 15.304505, mae: 43.002291, mean_q: 84.972793, mean_eps: 0.332567\n",
            " 3563/10000: episode: 49, duration: 0.817s, episode steps: 109, steps per second: 133, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 11.436723, mae: 43.399524, mean_q: 85.924015, mean_eps: 0.328108\n",
            " 3763/10000: episode: 50, duration: 1.448s, episode steps: 200, steps per second: 138, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 13.932714, mae: 43.251727, mean_q: 85.756533, mean_eps: 0.320538\n",
            " 3816/10000: episode: 51, duration: 0.481s, episode steps:  53, steps per second: 110, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.547 [0.000, 1.000],  loss: 22.506806, mae: 43.529820, mean_q: 86.284537, mean_eps: 0.314339\n",
            " 3920/10000: episode: 52, duration: 1.098s, episode steps: 104, steps per second:  95, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 11.937704, mae: 43.228630, mean_q: 86.308220, mean_eps: 0.310492\n",
            " 4050/10000: episode: 53, duration: 1.361s, episode steps: 130, steps per second:  96, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 15.802697, mae: 43.380558, mean_q: 86.467942, mean_eps: 0.304760\n",
            " 4113/10000: episode: 54, duration: 0.552s, episode steps:  63, steps per second: 114, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 11.094247, mae: 42.760554, mean_q: 85.349945, mean_eps: 0.300031\n",
            " 4153/10000: episode: 55, duration: 0.292s, episode steps:  40, steps per second: 137, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.575 [0.000, 1.000],  loss: 11.800512, mae: 42.813740, mean_q: 85.154332, mean_eps: 0.297508\n",
            " 4304/10000: episode: 56, duration: 1.123s, episode steps: 151, steps per second: 134, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 10.288648, mae: 42.911834, mean_q: 85.657351, mean_eps: 0.292828\n",
            " 4444/10000: episode: 57, duration: 1.011s, episode steps: 140, steps per second: 138, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 15.140451, mae: 42.723221, mean_q: 85.215288, mean_eps: 0.285699\n",
            " 4572/10000: episode: 58, duration: 0.948s, episode steps: 128, steps per second: 135, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 15.300457, mae: 42.673348, mean_q: 85.065438, mean_eps: 0.279133\n",
            " 4666/10000: episode: 59, duration: 0.693s, episode steps:  94, steps per second: 136, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 8.504514, mae: 42.565058, mean_q: 85.300983, mean_eps: 0.273694\n",
            " 4698/10000: episode: 60, duration: 0.236s, episode steps:  32, steps per second: 136, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 10.753297, mae: 42.653565, mean_q: 85.705918, mean_eps: 0.270607\n",
            " 4898/10000: episode: 61, duration: 1.463s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.326276, mae: 42.074805, mean_q: 84.030773, mean_eps: 0.264923\n",
            " 5098/10000: episode: 62, duration: 1.498s, episode steps: 200, steps per second: 133, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 8.764069, mae: 42.361405, mean_q: 84.694139, mean_eps: 0.255123\n",
            " 5164/10000: episode: 63, duration: 0.489s, episode steps:  66, steps per second: 135, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.775579, mae: 42.526905, mean_q: 84.993257, mean_eps: 0.248606\n",
            " 5337/10000: episode: 64, duration: 1.283s, episode steps: 173, steps per second: 135, episode reward: 173.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 13.593009, mae: 42.296448, mean_q: 84.370978, mean_eps: 0.242750\n",
            " 5359/10000: episode: 65, duration: 0.165s, episode steps:  22, steps per second: 134, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.981138, mae: 42.353514, mean_q: 85.555062, mean_eps: 0.237972\n",
            " 5395/10000: episode: 66, duration: 0.263s, episode steps:  36, steps per second: 137, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 16.988646, mae: 41.472292, mean_q: 83.262450, mean_eps: 0.236551\n",
            " 5595/10000: episode: 67, duration: 1.987s, episode steps: 200, steps per second: 101, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 12.077049, mae: 41.806777, mean_q: 83.922739, mean_eps: 0.230770\n",
            " 5795/10000: episode: 68, duration: 1.835s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 16.144032, mae: 41.549812, mean_q: 83.227385, mean_eps: 0.220970\n",
            " 5995/10000: episode: 69, duration: 1.467s, episode steps: 200, steps per second: 136, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 11.696753, mae: 41.499901, mean_q: 83.537565, mean_eps: 0.211170\n",
            " 6195/10000: episode: 70, duration: 1.458s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 8.874202, mae: 41.653759, mean_q: 83.882431, mean_eps: 0.201370\n",
            " 6395/10000: episode: 71, duration: 1.473s, episode steps: 200, steps per second: 136, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 9.289469, mae: 41.365598, mean_q: 83.776725, mean_eps: 0.191570\n",
            " 6504/10000: episode: 72, duration: 0.819s, episode steps: 109, steps per second: 133, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 10.236751, mae: 41.108496, mean_q: 82.822746, mean_eps: 0.183999\n",
            " 6606/10000: episode: 73, duration: 0.778s, episode steps: 102, steps per second: 131, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 12.023975, mae: 41.680182, mean_q: 83.939865, mean_eps: 0.178830\n",
            " 6660/10000: episode: 74, duration: 0.415s, episode steps:  54, steps per second: 130, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 8.033795, mae: 41.578877, mean_q: 84.261533, mean_eps: 0.175008\n",
            " 6860/10000: episode: 75, duration: 1.523s, episode steps: 200, steps per second: 131, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 12.615612, mae: 41.704504, mean_q: 84.154861, mean_eps: 0.168785\n",
            " 7049/10000: episode: 76, duration: 1.372s, episode steps: 189, steps per second: 138, episode reward: 189.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 8.266435, mae: 41.709118, mean_q: 84.529625, mean_eps: 0.159254\n",
            " 7068/10000: episode: 77, duration: 0.190s, episode steps:  19, steps per second: 100, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 3.286202, mae: 41.468181, mean_q: 84.247339, mean_eps: 0.154158\n",
            " 7226/10000: episode: 78, duration: 1.659s, episode steps: 158, steps per second:  95, episode reward: 158.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 13.879434, mae: 41.687860, mean_q: 84.376546, mean_eps: 0.149821\n",
            " 7287/10000: episode: 79, duration: 0.650s, episode steps:  61, steps per second:  94, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 13.128900, mae: 42.114496, mean_q: 84.759287, mean_eps: 0.144456\n",
            " 7487/10000: episode: 80, duration: 1.623s, episode steps: 200, steps per second: 123, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 12.775253, mae: 41.853731, mean_q: 84.488483, mean_eps: 0.138062\n",
            " 7662/10000: episode: 81, duration: 1.263s, episode steps: 175, steps per second: 139, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 8.612374, mae: 41.300520, mean_q: 83.939971, mean_eps: 0.128874\n",
            " 7862/10000: episode: 82, duration: 2.220s, episode steps: 200, steps per second:  90, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 12.452717, mae: 40.887491, mean_q: 82.888256, mean_eps: 0.119687\n",
            " 8062/10000: episode: 83, duration: 1.840s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 8.012569, mae: 41.153461, mean_q: 83.632671, mean_eps: 0.109886\n",
            " 8262/10000: episode: 84, duration: 1.494s, episode steps: 200, steps per second: 134, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 11.469375, mae: 40.630762, mean_q: 82.553127, mean_eps: 0.100087\n",
            " 8410/10000: episode: 85, duration: 1.093s, episode steps: 148, steps per second: 135, episode reward: 148.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 8.360096, mae: 40.435476, mean_q: 82.292721, mean_eps: 0.091561\n",
            " 8610/10000: episode: 86, duration: 1.721s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.519181, mae: 40.356764, mean_q: 81.979185, mean_eps: 0.083035\n",
            " 8784/10000: episode: 87, duration: 1.764s, episode steps: 174, steps per second:  99, episode reward: 174.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 7.576948, mae: 40.207891, mean_q: 81.502839, mean_eps: 0.073872\n",
            " 8984/10000: episode: 88, duration: 1.593s, episode steps: 200, steps per second: 126, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 8.022120, mae: 39.702922, mean_q: 80.823261, mean_eps: 0.064709\n",
            " 9184/10000: episode: 89, duration: 1.414s, episode steps: 200, steps per second: 141, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 11.622433, mae: 39.772377, mean_q: 80.456215, mean_eps: 0.054909\n",
            " 9384/10000: episode: 90, duration: 1.418s, episode steps: 200, steps per second: 141, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 8.665518, mae: 39.634511, mean_q: 80.360574, mean_eps: 0.045109\n",
            " 9516/10000: episode: 91, duration: 0.951s, episode steps: 132, steps per second: 139, episode reward: 132.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 5.763415, mae: 39.052338, mean_q: 79.789636, mean_eps: 0.036975\n",
            " 9672/10000: episode: 92, duration: 1.148s, episode steps: 156, steps per second: 136, episode reward: 156.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 6.681459, mae: 39.272033, mean_q: 79.857962, mean_eps: 0.029919\n",
            " 9851/10000: episode: 93, duration: 1.304s, episode steps: 179, steps per second: 137, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 7.910736, mae: 38.835665, mean_q: 78.989845, mean_eps: 0.021711\n",
            " 9999/10000: episode: 94, duration: 1.115s, episode steps: 148, steps per second: 133, episode reward: 148.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 8.860651, mae: 38.955208, mean_q: 79.131383, mean_eps: 0.013700\n",
            "done, took 82.430 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 138.000, steps: 138\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 152.000, steps: 152\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 134.000, steps: 134\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd7524bd850>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_max = 0.1\n",
        "\n",
        "# value_min = 0.01\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "target_model_update=1e-2\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "s0DvOjd6NeNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=0.1,\n",
        "                               value_min=0.01, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cKd_3BtNNX3B",
        "outputId": "4d08873a-47e1-4ebe-ef6a-e447e4524c07"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  200/10000: episode: 1, duration: 3.000s, episode steps: 200, steps per second:  67, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 31.443744, mae: 69.685269, mean_q: 140.623246, mean_eps: 0.099055\n",
            "  400/10000: episode: 2, duration: 1.426s, episode steps: 200, steps per second: 140, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 38.006421, mae: 69.432146, mean_q: 139.975963, mean_eps: 0.097305\n",
            "  600/10000: episode: 3, duration: 1.424s, episode steps: 200, steps per second: 140, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 39.106716, mae: 69.309552, mean_q: 139.371017, mean_eps: 0.095504\n",
            "  800/10000: episode: 4, duration: 1.419s, episode steps: 200, steps per second: 141, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 32.530695, mae: 69.006197, mean_q: 139.017580, mean_eps: 0.093704\n",
            " 1000/10000: episode: 5, duration: 1.868s, episode steps: 200, steps per second: 107, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 33.366283, mae: 68.711885, mean_q: 138.458758, mean_eps: 0.091905\n",
            " 1200/10000: episode: 6, duration: 1.884s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 34.738969, mae: 68.450848, mean_q: 137.692859, mean_eps: 0.090105\n",
            " 1400/10000: episode: 7, duration: 1.403s, episode steps: 200, steps per second: 143, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 37.383432, mae: 67.952890, mean_q: 136.592229, mean_eps: 0.088304\n",
            " 1600/10000: episode: 8, duration: 1.388s, episode steps: 200, steps per second: 144, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 32.011258, mae: 67.412350, mean_q: 135.644556, mean_eps: 0.086504\n",
            " 1800/10000: episode: 9, duration: 1.384s, episode steps: 200, steps per second: 144, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 34.424219, mae: 66.736402, mean_q: 133.962951, mean_eps: 0.084705\n",
            " 2000/10000: episode: 10, duration: 1.362s, episode steps: 200, steps per second: 147, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 25.650107, mae: 66.708751, mean_q: 134.022856, mean_eps: 0.082904\n",
            " 2200/10000: episode: 11, duration: 1.433s, episode steps: 200, steps per second: 140, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 35.037010, mae: 65.957182, mean_q: 132.201518, mean_eps: 0.081104\n",
            " 2400/10000: episode: 12, duration: 1.370s, episode steps: 200, steps per second: 146, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 30.788153, mae: 65.339671, mean_q: 130.596405, mean_eps: 0.079304\n",
            " 2600/10000: episode: 13, duration: 1.467s, episode steps: 200, steps per second: 136, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 18.573701, mae: 64.338005, mean_q: 128.854402, mean_eps: 0.077505\n",
            " 2800/10000: episode: 14, duration: 2.019s, episode steps: 200, steps per second:  99, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 27.904756, mae: 63.955146, mean_q: 127.904837, mean_eps: 0.075705\n",
            " 3000/10000: episode: 15, duration: 1.634s, episode steps: 200, steps per second: 122, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 24.225045, mae: 63.618520, mean_q: 127.344926, mean_eps: 0.073905\n",
            " 3200/10000: episode: 16, duration: 1.371s, episode steps: 200, steps per second: 146, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 26.178395, mae: 62.776539, mean_q: 125.399985, mean_eps: 0.072105\n",
            " 3400/10000: episode: 17, duration: 1.415s, episode steps: 200, steps per second: 141, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 17.450273, mae: 62.258663, mean_q: 124.516623, mean_eps: 0.070305\n",
            " 3600/10000: episode: 18, duration: 1.404s, episode steps: 200, steps per second: 142, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 15.404477, mae: 61.910557, mean_q: 123.689509, mean_eps: 0.068505\n",
            " 3800/10000: episode: 19, duration: 1.414s, episode steps: 200, steps per second: 141, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 12.601581, mae: 60.596126, mean_q: 121.210518, mean_eps: 0.066704\n",
            " 4000/10000: episode: 20, duration: 1.369s, episode steps: 200, steps per second: 146, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 22.313737, mae: 59.735528, mean_q: 119.194104, mean_eps: 0.064905\n",
            " 4200/10000: episode: 21, duration: 1.397s, episode steps: 200, steps per second: 143, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 24.265903, mae: 59.196773, mean_q: 117.925561, mean_eps: 0.063105\n",
            " 4400/10000: episode: 22, duration: 1.747s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 23.008868, mae: 58.256316, mean_q: 115.815915, mean_eps: 0.061305\n",
            " 4600/10000: episode: 23, duration: 2.032s, episode steps: 200, steps per second:  98, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 27.099411, mae: 58.043531, mean_q: 115.194235, mean_eps: 0.059505\n",
            " 4800/10000: episode: 24, duration: 1.409s, episode steps: 200, steps per second: 142, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 17.801508, mae: 57.837829, mean_q: 114.915255, mean_eps: 0.057705\n",
            " 5000/10000: episode: 25, duration: 1.414s, episode steps: 200, steps per second: 141, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 19.854378, mae: 57.615326, mean_q: 114.405616, mean_eps: 0.055905\n",
            " 5200/10000: episode: 26, duration: 1.395s, episode steps: 200, steps per second: 143, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 17.744111, mae: 56.724272, mean_q: 112.623795, mean_eps: 0.054105\n",
            " 5400/10000: episode: 27, duration: 1.398s, episode steps: 200, steps per second: 143, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 14.121653, mae: 56.385487, mean_q: 111.902042, mean_eps: 0.052305\n",
            " 5600/10000: episode: 28, duration: 1.426s, episode steps: 200, steps per second: 140, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 18.016358, mae: 55.889910, mean_q: 110.716002, mean_eps: 0.050504\n",
            " 5800/10000: episode: 29, duration: 1.428s, episode steps: 200, steps per second: 140, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 9.921308, mae: 55.237888, mean_q: 109.787598, mean_eps: 0.048704\n",
            " 6000/10000: episode: 30, duration: 1.466s, episode steps: 200, steps per second: 136, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 20.477951, mae: 55.070920, mean_q: 109.195380, mean_eps: 0.046905\n",
            " 6200/10000: episode: 31, duration: 2.109s, episode steps: 200, steps per second:  95, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 16.228782, mae: 54.007314, mean_q: 106.877922, mean_eps: 0.045105\n",
            " 6400/10000: episode: 32, duration: 1.705s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 13.295412, mae: 53.824959, mean_q: 106.520264, mean_eps: 0.043305\n",
            " 6600/10000: episode: 33, duration: 1.462s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 12.490796, mae: 52.965230, mean_q: 104.692634, mean_eps: 0.041504\n",
            " 6800/10000: episode: 34, duration: 1.466s, episode steps: 200, steps per second: 136, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 20.182601, mae: 51.940488, mean_q: 102.483579, mean_eps: 0.039705\n",
            " 6991/10000: episode: 35, duration: 1.365s, episode steps: 191, steps per second: 140, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 11.132852, mae: 51.363629, mean_q: 101.380024, mean_eps: 0.037945\n",
            " 7191/10000: episode: 36, duration: 1.461s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 12.407102, mae: 50.648363, mean_q: 99.518881, mean_eps: 0.036186\n",
            " 7391/10000: episode: 37, duration: 1.414s, episode steps: 200, steps per second: 141, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 14.191709, mae: 49.883437, mean_q: 97.601282, mean_eps: 0.034385\n",
            " 7591/10000: episode: 38, duration: 2.035s, episode steps: 200, steps per second:  98, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 12.417411, mae: 49.454954, mean_q: 97.082224, mean_eps: 0.032586\n",
            " 7791/10000: episode: 39, duration: 3.277s, episode steps: 200, steps per second:  61, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 11.562595, mae: 48.538174, mean_q: 95.162347, mean_eps: 0.030786\n",
            " 7978/10000: episode: 40, duration: 1.375s, episode steps: 187, steps per second: 136, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 7.852322, mae: 48.442392, mean_q: 95.139617, mean_eps: 0.029044\n",
            " 8178/10000: episode: 41, duration: 1.453s, episode steps: 200, steps per second: 138, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.450857, mae: 48.169448, mean_q: 94.761408, mean_eps: 0.027303\n",
            " 8378/10000: episode: 42, duration: 1.447s, episode steps: 200, steps per second: 138, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 15.369381, mae: 47.889429, mean_q: 93.939747, mean_eps: 0.025503\n",
            " 8578/10000: episode: 43, duration: 1.397s, episode steps: 200, steps per second: 143, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 12.654867, mae: 47.593705, mean_q: 93.318910, mean_eps: 0.023703\n",
            " 8778/10000: episode: 44, duration: 1.386s, episode steps: 200, steps per second: 144, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 12.822685, mae: 46.877352, mean_q: 91.950467, mean_eps: 0.021903\n",
            " 8978/10000: episode: 45, duration: 1.363s, episode steps: 200, steps per second: 147, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.810637, mae: 46.468822, mean_q: 91.054894, mean_eps: 0.020103\n",
            " 9178/10000: episode: 46, duration: 1.413s, episode steps: 200, steps per second: 142, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.246873, mae: 46.307718, mean_q: 90.904855, mean_eps: 0.018302\n",
            " 9378/10000: episode: 47, duration: 1.999s, episode steps: 200, steps per second: 100, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 8.748571, mae: 46.167282, mean_q: 91.203575, mean_eps: 0.016503\n",
            " 9578/10000: episode: 48, duration: 1.710s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.667314, mae: 45.857523, mean_q: 90.456995, mean_eps: 0.014703\n",
            " 9778/10000: episode: 49, duration: 1.387s, episode steps: 200, steps per second: 144, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 15.097742, mae: 45.749902, mean_q: 90.125538, mean_eps: 0.012903\n",
            " 9978/10000: episode: 50, duration: 1.385s, episode steps: 200, steps per second: 144, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 12.140103, mae: 45.366729, mean_q: 89.159924, mean_eps: 0.011103\n",
            "done, took 79.393 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 126.000, steps: 126\n",
            "Episode 2: reward: 128.000, steps: 128\n",
            "Episode 3: reward: 127.000, steps: 127\n",
            "Episode 4: reward: 126.000, steps: 126\n",
            "Episode 5: reward: 129.000, steps: 129\n",
            "Episode 6: reward: 130.000, steps: 130\n",
            "Episode 7: reward: 132.000, steps: 132\n",
            "Episode 8: reward: 132.000, steps: 132\n",
            "Episode 9: reward: 122.000, steps: 122\n",
            "Episode 10: reward: 130.000, steps: 130\n",
            "Episode 11: reward: 124.000, steps: 124\n",
            "Episode 12: reward: 131.000, steps: 131\n",
            "Episode 13: reward: 124.000, steps: 124\n",
            "Episode 14: reward: 125.000, steps: 125\n",
            "Episode 15: reward: 128.000, steps: 128\n",
            "Episode 16: reward: 129.000, steps: 129\n",
            "Episode 17: reward: 124.000, steps: 124\n",
            "Episode 18: reward: 129.000, steps: 129\n",
            "Episode 19: reward: 121.000, steps: 121\n",
            "Episode 20: reward: 131.000, steps: 131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd7526c1460>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "value_max = 1.0\n",
        "\n",
        "value_min = 0.01\n",
        "\n",
        "value_test = 0.05\n",
        "\n",
        "nb_steps_warmup=10\n",
        "\n",
        "target_model_update=1e-2\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "ZpwwTZPaJ57u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.01, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy_outer) \n",
        "\n",
        "dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TBa4_jU9JzWt",
        "outputId": "710f4187-1ee0-48b3-8a2d-2eb6884960e6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   44/10000: episode: 1, duration: 1.836s, episode steps:  44, steps per second:  24, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 28.044643, mae: 57.917590, mean_q: 118.237616, mean_eps: 0.997327\n",
            "   65/10000: episode: 2, duration: 0.160s, episode steps:  21, steps per second: 131, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 34.251764, mae: 57.166277, mean_q: 116.348490, mean_eps: 0.994654\n",
            "   75/10000: episode: 3, duration: 0.082s, episode steps:  10, steps per second: 122, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 16.625178, mae: 59.078951, mean_q: 120.242591, mean_eps: 0.993119\n",
            "  100/10000: episode: 4, duration: 0.204s, episode steps:  25, steps per second: 123, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 22.496757, mae: 57.331595, mean_q: 117.131083, mean_eps: 0.991387\n",
            "  128/10000: episode: 5, duration: 0.191s, episode steps:  28, steps per second: 146, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 16.180772, mae: 57.779362, mean_q: 117.662860, mean_eps: 0.988764\n",
            "  165/10000: episode: 6, duration: 0.254s, episode steps:  37, steps per second: 146, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 15.990045, mae: 56.792261, mean_q: 116.722938, mean_eps: 0.985546\n",
            "  212/10000: episode: 7, duration: 0.331s, episode steps:  47, steps per second: 142, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.404 [0.000, 1.000],  loss: 18.677564, mae: 56.877578, mean_q: 116.384574, mean_eps: 0.981388\n",
            "  243/10000: episode: 8, duration: 0.234s, episode steps:  31, steps per second: 132, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 17.266956, mae: 56.819480, mean_q: 116.793495, mean_eps: 0.977527\n",
            "  279/10000: episode: 9, duration: 0.255s, episode steps:  36, steps per second: 141, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 25.763859, mae: 58.349563, mean_q: 118.834332, mean_eps: 0.974211\n",
            "  307/10000: episode: 10, duration: 0.205s, episode steps:  28, steps per second: 137, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 17.495359, mae: 58.005324, mean_q: 118.258896, mean_eps: 0.971042\n",
            "  324/10000: episode: 11, duration: 0.120s, episode steps:  17, steps per second: 142, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 14.662048, mae: 58.032589, mean_q: 119.162223, mean_eps: 0.968815\n",
            "  342/10000: episode: 12, duration: 0.140s, episode steps:  18, steps per second: 129, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 27.237667, mae: 58.203555, mean_q: 117.739613, mean_eps: 0.967083\n",
            "  359/10000: episode: 13, duration: 0.126s, episode steps:  17, steps per second: 135, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 12.055083, mae: 56.782621, mean_q: 116.193273, mean_eps: 0.965350\n",
            "  376/10000: episode: 14, duration: 0.137s, episode steps:  17, steps per second: 124, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 10.110429, mae: 58.157355, mean_q: 118.942599, mean_eps: 0.963667\n",
            "  409/10000: episode: 15, duration: 0.242s, episode steps:  33, steps per second: 137, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.576 [0.000, 1.000],  loss: 20.516321, mae: 57.587734, mean_q: 117.836754, mean_eps: 0.961192\n",
            "  426/10000: episode: 16, duration: 0.118s, episode steps:  17, steps per second: 144, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 13.276068, mae: 58.065409, mean_q: 119.431579, mean_eps: 0.958717\n",
            "  436/10000: episode: 17, duration: 0.074s, episode steps:  10, steps per second: 136, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 17.633040, mae: 58.651987, mean_q: 119.271128, mean_eps: 0.957380\n",
            "  450/10000: episode: 18, duration: 0.105s, episode steps:  14, steps per second: 134, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 27.171336, mae: 59.583615, mean_q: 120.718970, mean_eps: 0.956193\n",
            "  464/10000: episode: 19, duration: 0.108s, episode steps:  14, steps per second: 129, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.786 [0.000, 1.000],  loss: 16.119476, mae: 58.608926, mean_q: 119.037839, mean_eps: 0.954806\n",
            "  488/10000: episode: 20, duration: 0.181s, episode steps:  24, steps per second: 133, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 17.716223, mae: 57.557183, mean_q: 117.117141, mean_eps: 0.952925\n",
            "  543/10000: episode: 21, duration: 0.421s, episode steps:  55, steps per second: 131, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 22.408945, mae: 58.198462, mean_q: 118.680903, mean_eps: 0.949015\n",
            "  614/10000: episode: 22, duration: 0.489s, episode steps:  71, steps per second: 145, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 17.344526, mae: 58.329483, mean_q: 118.927547, mean_eps: 0.942778\n",
            "  644/10000: episode: 23, duration: 0.214s, episode steps:  30, steps per second: 140, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 24.783867, mae: 58.258959, mean_q: 119.309359, mean_eps: 0.937779\n",
            "  670/10000: episode: 24, duration: 0.195s, episode steps:  26, steps per second: 133, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 16.935364, mae: 57.772645, mean_q: 118.582552, mean_eps: 0.935007\n",
            "  721/10000: episode: 25, duration: 0.360s, episode steps:  51, steps per second: 142, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 26.397376, mae: 58.388745, mean_q: 118.329846, mean_eps: 0.931195\n",
            "  763/10000: episode: 26, duration: 0.292s, episode steps:  42, steps per second: 144, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 21.112610, mae: 57.857637, mean_q: 118.424808, mean_eps: 0.926592\n",
            "  777/10000: episode: 27, duration: 0.099s, episode steps:  14, steps per second: 141, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 19.653891, mae: 58.968546, mean_q: 121.338489, mean_eps: 0.923820\n",
            "  799/10000: episode: 28, duration: 0.158s, episode steps:  22, steps per second: 139, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 18.384851, mae: 58.436936, mean_q: 119.127090, mean_eps: 0.922038\n",
            "  822/10000: episode: 29, duration: 0.169s, episode steps:  23, steps per second: 136, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.696 [0.000, 1.000],  loss: 19.708715, mae: 58.194710, mean_q: 118.263151, mean_eps: 0.919810\n",
            "  835/10000: episode: 30, duration: 0.098s, episode steps:  13, steps per second: 133, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 27.452600, mae: 58.867354, mean_q: 120.322793, mean_eps: 0.918028\n",
            "  852/10000: episode: 31, duration: 0.127s, episode steps:  17, steps per second: 134, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 31.402925, mae: 60.102805, mean_q: 121.579963, mean_eps: 0.916543\n",
            "  890/10000: episode: 32, duration: 0.274s, episode steps:  38, steps per second: 139, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 24.749111, mae: 58.404459, mean_q: 118.259039, mean_eps: 0.913820\n",
            "  902/10000: episode: 33, duration: 0.089s, episode steps:  12, steps per second: 134, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 12.804659, mae: 59.614569, mean_q: 121.155472, mean_eps: 0.911345\n",
            "  913/10000: episode: 34, duration: 0.085s, episode steps:  11, steps per second: 129, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 37.465093, mae: 59.146664, mean_q: 119.277586, mean_eps: 0.910207\n",
            "  938/10000: episode: 35, duration: 0.182s, episode steps:  25, steps per second: 137, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 20.332719, mae: 58.356330, mean_q: 118.971248, mean_eps: 0.908425\n",
            "  964/10000: episode: 36, duration: 0.188s, episode steps:  26, steps per second: 138, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 18.067554, mae: 58.521542, mean_q: 119.657082, mean_eps: 0.905901\n",
            "  976/10000: episode: 37, duration: 0.093s, episode steps:  12, steps per second: 128, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 7.769490, mae: 59.603374, mean_q: 122.752168, mean_eps: 0.904020\n",
            " 1003/10000: episode: 38, duration: 0.187s, episode steps:  27, steps per second: 145, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 15.327741, mae: 59.480779, mean_q: 121.752705, mean_eps: 0.902089\n",
            " 1017/10000: episode: 39, duration: 0.101s, episode steps:  14, steps per second: 139, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 22.101793, mae: 59.657928, mean_q: 120.939175, mean_eps: 0.900060\n",
            " 1035/10000: episode: 40, duration: 0.136s, episode steps:  18, steps per second: 132, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 32.522331, mae: 58.892908, mean_q: 119.938686, mean_eps: 0.898475\n",
            " 1053/10000: episode: 41, duration: 0.129s, episode steps:  18, steps per second: 140, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 13.312702, mae: 59.964674, mean_q: 122.492313, mean_eps: 0.896694\n",
            " 1080/10000: episode: 42, duration: 0.192s, episode steps:  27, steps per second: 141, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 13.030939, mae: 58.770286, mean_q: 120.579181, mean_eps: 0.894466\n",
            " 1101/10000: episode: 43, duration: 0.154s, episode steps:  21, steps per second: 136, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 17.278384, mae: 58.886132, mean_q: 120.574916, mean_eps: 0.892090\n",
            " 1126/10000: episode: 44, duration: 0.177s, episode steps:  25, steps per second: 141, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 22.732756, mae: 59.943778, mean_q: 122.214069, mean_eps: 0.889813\n",
            " 1173/10000: episode: 45, duration: 0.331s, episode steps:  47, steps per second: 142, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 14.965272, mae: 59.115984, mean_q: 121.166237, mean_eps: 0.886249\n",
            " 1184/10000: episode: 46, duration: 0.084s, episode steps:  11, steps per second: 131, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 17.749515, mae: 58.762896, mean_q: 120.062155, mean_eps: 0.883378\n",
            " 1201/10000: episode: 47, duration: 0.181s, episode steps:  17, steps per second:  94, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 7.943413, mae: 58.940411, mean_q: 121.866394, mean_eps: 0.881992\n",
            " 1218/10000: episode: 48, duration: 0.175s, episode steps:  17, steps per second:  97, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 30.245041, mae: 58.600484, mean_q: 119.761145, mean_eps: 0.880309\n",
            " 1231/10000: episode: 49, duration: 0.143s, episode steps:  13, steps per second:  91, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 8.099070, mae: 59.728574, mean_q: 122.847584, mean_eps: 0.878824\n",
            " 1306/10000: episode: 50, duration: 0.730s, episode steps:  75, steps per second: 103, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 14.821834, mae: 59.371420, mean_q: 121.529738, mean_eps: 0.874468\n",
            " 1319/10000: episode: 51, duration: 0.147s, episode steps:  13, steps per second:  88, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 41.857374, mae: 59.188576, mean_q: 119.762968, mean_eps: 0.870112\n",
            " 1341/10000: episode: 52, duration: 0.237s, episode steps:  22, steps per second:  93, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.623454, mae: 60.383806, mean_q: 123.660559, mean_eps: 0.868379\n",
            " 1367/10000: episode: 53, duration: 0.278s, episode steps:  26, steps per second:  93, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 19.395656, mae: 59.648741, mean_q: 122.046391, mean_eps: 0.866003\n",
            " 1379/10000: episode: 54, duration: 0.129s, episode steps:  12, steps per second:  93, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 19.620305, mae: 59.383753, mean_q: 120.494068, mean_eps: 0.864123\n",
            " 1405/10000: episode: 55, duration: 0.283s, episode steps:  26, steps per second:  92, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 14.782937, mae: 60.390542, mean_q: 122.667716, mean_eps: 0.862242\n",
            " 1435/10000: episode: 56, duration: 0.316s, episode steps:  30, steps per second:  95, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 13.166656, mae: 59.747791, mean_q: 122.552455, mean_eps: 0.859469\n",
            " 1452/10000: episode: 57, duration: 0.181s, episode steps:  17, steps per second:  94, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 22.813741, mae: 58.257118, mean_q: 119.853823, mean_eps: 0.857143\n",
            " 1526/10000: episode: 58, duration: 0.593s, episode steps:  74, steps per second: 125, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 20.554893, mae: 59.658694, mean_q: 121.858557, mean_eps: 0.852638\n",
            " 1582/10000: episode: 59, duration: 0.394s, episode steps:  56, steps per second: 142, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 22.435633, mae: 60.379828, mean_q: 123.449743, mean_eps: 0.846203\n",
            " 1601/10000: episode: 60, duration: 0.143s, episode steps:  19, steps per second: 133, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 9.820201, mae: 60.135177, mean_q: 122.893511, mean_eps: 0.842491\n",
            " 1626/10000: episode: 61, duration: 0.180s, episode steps:  25, steps per second: 139, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 21.250148, mae: 59.767363, mean_q: 122.223948, mean_eps: 0.840313\n",
            " 1643/10000: episode: 62, duration: 0.131s, episode steps:  17, steps per second: 130, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 25.890171, mae: 60.713993, mean_q: 123.254634, mean_eps: 0.838234\n",
            " 1654/10000: episode: 63, duration: 0.086s, episode steps:  11, steps per second: 128, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 11.729069, mae: 59.539927, mean_q: 122.821746, mean_eps: 0.836848\n",
            " 1682/10000: episode: 64, duration: 0.213s, episode steps:  28, steps per second: 131, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 15.722651, mae: 60.547022, mean_q: 123.787362, mean_eps: 0.834917\n",
            " 1696/10000: episode: 65, duration: 0.104s, episode steps:  14, steps per second: 134, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 22.684674, mae: 59.442828, mean_q: 121.688434, mean_eps: 0.832839\n",
            " 1751/10000: episode: 66, duration: 0.401s, episode steps:  55, steps per second: 137, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 18.471268, mae: 60.643893, mean_q: 124.241070, mean_eps: 0.829423\n",
            " 1768/10000: episode: 67, duration: 0.126s, episode steps:  17, steps per second: 135, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.294 [0.000, 1.000],  loss: 51.699019, mae: 59.523853, mean_q: 120.806802, mean_eps: 0.825859\n",
            " 1796/10000: episode: 68, duration: 0.199s, episode steps:  28, steps per second: 141, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.393 [0.000, 1.000],  loss: 20.984642, mae: 59.716552, mean_q: 121.586733, mean_eps: 0.823632\n",
            " 1820/10000: episode: 69, duration: 0.183s, episode steps:  24, steps per second: 131, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 22.780427, mae: 60.593223, mean_q: 123.538515, mean_eps: 0.821058\n",
            " 1842/10000: episode: 70, duration: 0.160s, episode steps:  22, steps per second: 137, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 18.900116, mae: 62.222469, mean_q: 126.528910, mean_eps: 0.818781\n",
            " 1894/10000: episode: 71, duration: 0.368s, episode steps:  52, steps per second: 141, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 26.335791, mae: 60.162147, mean_q: 122.601289, mean_eps: 0.815118\n",
            " 1997/10000: episode: 72, duration: 0.722s, episode steps: 103, steps per second: 143, episode reward: 103.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 24.996876, mae: 60.223126, mean_q: 122.744382, mean_eps: 0.807445\n",
            " 2026/10000: episode: 73, duration: 0.214s, episode steps:  29, steps per second: 136, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 16.628192, mae: 60.251919, mean_q: 123.204473, mean_eps: 0.800911\n",
            " 2047/10000: episode: 74, duration: 0.146s, episode steps:  21, steps per second: 144, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 17.254781, mae: 59.943895, mean_q: 121.761715, mean_eps: 0.798436\n",
            " 2099/10000: episode: 75, duration: 0.368s, episode steps:  52, steps per second: 141, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 25.064327, mae: 60.484939, mean_q: 123.319621, mean_eps: 0.794822\n",
            " 2156/10000: episode: 76, duration: 0.397s, episode steps:  57, steps per second: 144, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.544 [0.000, 1.000],  loss: 21.867860, mae: 61.050395, mean_q: 124.068061, mean_eps: 0.789427\n",
            " 2177/10000: episode: 77, duration: 0.155s, episode steps:  21, steps per second: 135, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 27.310384, mae: 61.244348, mean_q: 124.719038, mean_eps: 0.785566\n",
            " 2218/10000: episode: 78, duration: 0.289s, episode steps:  41, steps per second: 142, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 17.894726, mae: 60.456181, mean_q: 123.322186, mean_eps: 0.782497\n",
            " 2291/10000: episode: 79, duration: 0.514s, episode steps:  73, steps per second: 142, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 24.598630, mae: 60.928043, mean_q: 123.947736, mean_eps: 0.776854\n",
            " 2310/10000: episode: 80, duration: 0.144s, episode steps:  19, steps per second: 132, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 22.654882, mae: 60.238747, mean_q: 122.804922, mean_eps: 0.772300\n",
            " 2362/10000: episode: 81, duration: 0.366s, episode steps:  52, steps per second: 142, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 23.850574, mae: 60.906703, mean_q: 124.003135, mean_eps: 0.768786\n",
            " 2375/10000: episode: 82, duration: 0.093s, episode steps:  13, steps per second: 140, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 13.089824, mae: 61.364629, mean_q: 124.998221, mean_eps: 0.765568\n",
            " 2428/10000: episode: 83, duration: 0.397s, episode steps:  53, steps per second: 134, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 16.422382, mae: 60.809681, mean_q: 124.787553, mean_eps: 0.762301\n",
            " 2483/10000: episode: 84, duration: 0.386s, episode steps:  55, steps per second: 143, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 22.357654, mae: 61.126631, mean_q: 124.424957, mean_eps: 0.756955\n",
            " 2612/10000: episode: 85, duration: 0.886s, episode steps: 129, steps per second: 146, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 20.283422, mae: 61.352178, mean_q: 125.655394, mean_eps: 0.747847\n",
            " 2679/10000: episode: 86, duration: 0.495s, episode steps:  67, steps per second: 135, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 24.179287, mae: 61.721628, mean_q: 125.798299, mean_eps: 0.738145\n",
            " 2711/10000: episode: 87, duration: 0.239s, episode steps:  32, steps per second: 134, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 17.548839, mae: 62.107602, mean_q: 126.803241, mean_eps: 0.733245\n",
            " 2747/10000: episode: 88, duration: 0.271s, episode steps:  36, steps per second: 133, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 15.022593, mae: 62.680243, mean_q: 127.900209, mean_eps: 0.729878\n",
            " 2788/10000: episode: 89, duration: 0.290s, episode steps:  41, steps per second: 141, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 23.807651, mae: 61.516589, mean_q: 126.309132, mean_eps: 0.726067\n",
            " 2804/10000: episode: 90, duration: 0.118s, episode steps:  16, steps per second: 136, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 24.857485, mae: 61.979750, mean_q: 126.597887, mean_eps: 0.723245\n",
            " 2839/10000: episode: 91, duration: 0.256s, episode steps:  35, steps per second: 137, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 15.780014, mae: 61.579137, mean_q: 125.550415, mean_eps: 0.720721\n",
            " 2870/10000: episode: 92, duration: 0.251s, episode steps:  31, steps per second: 124, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.548 [0.000, 1.000],  loss: 23.459567, mae: 62.200207, mean_q: 126.957628, mean_eps: 0.717454\n",
            " 2904/10000: episode: 93, duration: 0.346s, episode steps:  34, steps per second:  98, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 22.353091, mae: 62.373149, mean_q: 126.665914, mean_eps: 0.714237\n",
            " 2933/10000: episode: 94, duration: 0.314s, episode steps:  29, steps per second:  92, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.379 [0.000, 1.000],  loss: 29.257245, mae: 61.448559, mean_q: 124.288691, mean_eps: 0.711118\n",
            " 3060/10000: episode: 95, duration: 1.237s, episode steps: 127, steps per second: 103, episode reward: 127.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 26.130672, mae: 62.094531, mean_q: 126.473336, mean_eps: 0.703396\n",
            " 3114/10000: episode: 96, duration: 0.530s, episode steps:  54, steps per second: 102, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 17.244461, mae: 62.305823, mean_q: 127.363143, mean_eps: 0.694437\n",
            " 3148/10000: episode: 97, duration: 0.373s, episode steps:  34, steps per second:  91, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 12.516406, mae: 62.869128, mean_q: 128.677254, mean_eps: 0.690080\n",
            " 3211/10000: episode: 98, duration: 0.468s, episode steps:  63, steps per second: 135, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 33.104943, mae: 62.174895, mean_q: 126.348046, mean_eps: 0.685279\n",
            " 3271/10000: episode: 99, duration: 0.428s, episode steps:  60, steps per second: 140, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 20.942465, mae: 62.400327, mean_q: 127.352046, mean_eps: 0.679191\n",
            " 3285/10000: episode: 100, duration: 0.106s, episode steps:  14, steps per second: 132, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 25.365952, mae: 63.678836, mean_q: 129.337702, mean_eps: 0.675528\n",
            " 3312/10000: episode: 101, duration: 0.204s, episode steps:  27, steps per second: 133, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.593 [0.000, 1.000],  loss: 28.279769, mae: 62.328035, mean_q: 127.335153, mean_eps: 0.673498\n",
            " 3330/10000: episode: 102, duration: 0.129s, episode steps:  18, steps per second: 139, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 24.109316, mae: 62.248920, mean_q: 126.585314, mean_eps: 0.671270\n",
            " 3430/10000: episode: 103, duration: 0.725s, episode steps: 100, steps per second: 138, episode reward: 100.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 25.515900, mae: 62.709655, mean_q: 127.988502, mean_eps: 0.665429\n",
            " 3476/10000: episode: 104, duration: 0.321s, episode steps:  46, steps per second: 143, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 18.709558, mae: 62.638892, mean_q: 128.249099, mean_eps: 0.658203\n",
            " 3493/10000: episode: 105, duration: 0.120s, episode steps:  17, steps per second: 141, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 27.826724, mae: 63.463747, mean_q: 129.270965, mean_eps: 0.655084\n",
            " 3553/10000: episode: 106, duration: 0.419s, episode steps:  60, steps per second: 143, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 20.655396, mae: 62.607713, mean_q: 128.182296, mean_eps: 0.651273\n",
            " 3671/10000: episode: 107, duration: 0.813s, episode steps: 118, steps per second: 145, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 25.559152, mae: 62.311269, mean_q: 127.031313, mean_eps: 0.642462\n",
            " 3787/10000: episode: 108, duration: 0.831s, episode steps: 116, steps per second: 140, episode reward: 116.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 24.753653, mae: 63.013116, mean_q: 128.254466, mean_eps: 0.630879\n",
            " 3946/10000: episode: 109, duration: 1.124s, episode steps: 159, steps per second: 141, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 23.583472, mae: 63.105484, mean_q: 129.063186, mean_eps: 0.617266\n",
            " 4024/10000: episode: 110, duration: 0.559s, episode steps:  78, steps per second: 139, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: 21.123611, mae: 63.916769, mean_q: 130.661159, mean_eps: 0.605534\n",
            " 4203/10000: episode: 111, duration: 1.213s, episode steps: 179, steps per second: 148, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 21.357528, mae: 63.813161, mean_q: 130.516925, mean_eps: 0.592813\n",
            " 4247/10000: episode: 112, duration: 0.296s, episode steps:  44, steps per second: 149, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 33.396864, mae: 63.707012, mean_q: 130.152356, mean_eps: 0.581774\n",
            " 4391/10000: episode: 113, duration: 1.030s, episode steps: 144, steps per second: 140, episode reward: 144.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 27.231143, mae: 64.043699, mean_q: 130.515019, mean_eps: 0.572468\n",
            " 4591/10000: episode: 114, duration: 1.411s, episode steps: 200, steps per second: 142, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 24.760914, mae: 64.807824, mean_q: 132.056506, mean_eps: 0.555441\n",
            " 4791/10000: episode: 115, duration: 2.020s, episode steps: 200, steps per second:  99, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 25.626237, mae: 64.696940, mean_q: 131.631733, mean_eps: 0.535640\n",
            " 4847/10000: episode: 116, duration: 0.554s, episode steps:  56, steps per second: 101, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 14.281052, mae: 65.069486, mean_q: 133.080111, mean_eps: 0.522969\n",
            " 4884/10000: episode: 117, duration: 0.362s, episode steps:  37, steps per second: 102, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.405 [0.000, 1.000],  loss: 17.884576, mae: 65.189423, mean_q: 133.366243, mean_eps: 0.518365\n",
            " 4899/10000: episode: 118, duration: 0.114s, episode steps:  15, steps per second: 132, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 21.185215, mae: 64.623388, mean_q: 132.332610, mean_eps: 0.515791\n",
            " 4957/10000: episode: 119, duration: 0.409s, episode steps:  58, steps per second: 142, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 31.112685, mae: 65.301701, mean_q: 132.853847, mean_eps: 0.512177\n",
            " 5029/10000: episode: 120, duration: 0.506s, episode steps:  72, steps per second: 142, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 29.814667, mae: 65.909425, mean_q: 134.167090, mean_eps: 0.505742\n",
            " 5066/10000: episode: 121, duration: 0.268s, episode steps:  37, steps per second: 138, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 29.810628, mae: 65.282538, mean_q: 132.741935, mean_eps: 0.500347\n",
            " 5266/10000: episode: 122, duration: 1.358s, episode steps: 200, steps per second: 147, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 31.794504, mae: 65.534757, mean_q: 133.242346, mean_eps: 0.488616\n",
            " 5365/10000: episode: 123, duration: 0.681s, episode steps:  99, steps per second: 145, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 27.217861, mae: 65.948754, mean_q: 134.454822, mean_eps: 0.473815\n",
            " 5469/10000: episode: 124, duration: 0.698s, episode steps: 104, steps per second: 149, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 21.513563, mae: 65.758515, mean_q: 134.059576, mean_eps: 0.463767\n",
            " 5568/10000: episode: 125, duration: 0.669s, episode steps:  99, steps per second: 148, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 32.623808, mae: 66.314769, mean_q: 134.820347, mean_eps: 0.453718\n",
            " 5665/10000: episode: 126, duration: 0.660s, episode steps:  97, steps per second: 147, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 31.666239, mae: 66.461713, mean_q: 135.272187, mean_eps: 0.444016\n",
            " 5713/10000: episode: 127, duration: 0.317s, episode steps:  48, steps per second: 151, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 23.297292, mae: 66.367026, mean_q: 135.085366, mean_eps: 0.436839\n",
            " 5913/10000: episode: 128, duration: 1.383s, episode steps: 200, steps per second: 145, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 25.386053, mae: 67.034274, mean_q: 136.214936, mean_eps: 0.424563\n",
            " 6113/10000: episode: 129, duration: 1.359s, episode steps: 200, steps per second: 147, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 33.844239, mae: 66.974649, mean_q: 136.214014, mean_eps: 0.404763\n",
            " 6313/10000: episode: 130, duration: 1.340s, episode steps: 200, steps per second: 149, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 27.619721, mae: 67.383207, mean_q: 137.129940, mean_eps: 0.384963\n",
            " 6513/10000: episode: 131, duration: 1.945s, episode steps: 200, steps per second: 103, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 28.327148, mae: 67.399952, mean_q: 136.784782, mean_eps: 0.365163\n",
            " 6713/10000: episode: 132, duration: 1.747s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 27.998843, mae: 67.410742, mean_q: 137.422288, mean_eps: 0.345363\n",
            " 6913/10000: episode: 133, duration: 1.348s, episode steps: 200, steps per second: 148, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 32.582826, mae: 67.995902, mean_q: 138.270448, mean_eps: 0.325563\n",
            " 7113/10000: episode: 134, duration: 1.336s, episode steps: 200, steps per second: 150, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 29.957265, mae: 68.322289, mean_q: 138.450468, mean_eps: 0.305762\n",
            " 7313/10000: episode: 135, duration: 1.370s, episode steps: 200, steps per second: 146, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 35.721962, mae: 68.303002, mean_q: 138.624664, mean_eps: 0.285963\n",
            " 7513/10000: episode: 136, duration: 1.369s, episode steps: 200, steps per second: 146, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 28.243383, mae: 68.691340, mean_q: 139.413892, mean_eps: 0.266163\n",
            " 7713/10000: episode: 137, duration: 1.360s, episode steps: 200, steps per second: 147, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 28.897998, mae: 69.356639, mean_q: 140.813643, mean_eps: 0.246363\n",
            " 7913/10000: episode: 138, duration: 1.374s, episode steps: 200, steps per second: 146, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 28.048906, mae: 69.375593, mean_q: 141.033949, mean_eps: 0.226563\n",
            " 8113/10000: episode: 139, duration: 1.516s, episode steps: 200, steps per second: 132, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 32.213470, mae: 69.591363, mean_q: 140.847142, mean_eps: 0.206763\n",
            " 8313/10000: episode: 140, duration: 1.998s, episode steps: 200, steps per second: 100, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 37.559305, mae: 70.439264, mean_q: 142.443921, mean_eps: 0.186963\n",
            " 8513/10000: episode: 141, duration: 1.587s, episode steps: 200, steps per second: 126, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 41.141266, mae: 70.699527, mean_q: 142.787341, mean_eps: 0.167163\n",
            " 8713/10000: episode: 142, duration: 1.396s, episode steps: 200, steps per second: 143, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 34.256229, mae: 70.639842, mean_q: 143.013393, mean_eps: 0.147363\n",
            " 8913/10000: episode: 143, duration: 1.414s, episode steps: 200, steps per second: 141, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 41.587107, mae: 70.865953, mean_q: 142.952962, mean_eps: 0.127563\n",
            " 9113/10000: episode: 144, duration: 1.434s, episode steps: 200, steps per second: 139, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 35.674620, mae: 70.672899, mean_q: 142.394384, mean_eps: 0.107763\n",
            " 9313/10000: episode: 145, duration: 1.436s, episode steps: 200, steps per second: 139, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 46.544011, mae: 70.291214, mean_q: 141.559803, mean_eps: 0.087963\n",
            " 9513/10000: episode: 146, duration: 1.391s, episode steps: 200, steps per second: 144, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 34.294608, mae: 70.108663, mean_q: 141.362578, mean_eps: 0.068163\n",
            " 9713/10000: episode: 147, duration: 1.398s, episode steps: 200, steps per second: 143, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 30.780556, mae: 70.102140, mean_q: 141.562039, mean_eps: 0.048363\n",
            " 9913/10000: episode: 148, duration: 1.719s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 35.737834, mae: 70.208459, mean_q: 141.573776, mean_eps: 0.028563\n",
            "done, took 77.055 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd75282fb20>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_min = 0.5\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "target_model_update=1e-2\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "eyl_QYCPFrtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "#                                attr='eps',            \n",
        "#                                value_max=1.0,\n",
        "#                                value_min=0.5, \n",
        "#                                value_test=.05,\n",
        "#                                nb_steps=10000)\n",
        "\n",
        "# # define the agent\n",
        "# dqn = DQNAgent(model=model, \n",
        "#                nb_actions=env.action_space.n,\n",
        "#                memory=memory,\n",
        "#                nb_steps_warmup=10,\n",
        "#                target_model_update=1e-2, \n",
        "#                policy=policy_outer) \n",
        "\n",
        "# dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "# history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# # summarize the history for number  of episode steps\n",
        "# plt.plot(history.history['nb_episode_steps'])\n",
        "# plt.ylabel('nb_episode_steps')\n",
        "# plt.xlabel('episodes')\n",
        "# plt.show()\n",
        "\n",
        "# dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "# plt.imshow(env.render(mode='rgb_array'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wplz_AI_FnPb",
        "outputId": "bfbab55e-093d-494a-9c68-1958d47a754d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   23/10000: episode: 1, duration: 1.600s, episode steps:  23, steps per second:  14, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 3.070644, mae: 40.777772, mean_q: 82.875738, mean_eps: 0.999175\n",
            "   42/10000: episode: 2, duration: 0.133s, episode steps:  19, steps per second: 143, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 13.965445, mae: 39.990881, mean_q: 80.896786, mean_eps: 0.998400\n",
            "   59/10000: episode: 3, duration: 0.126s, episode steps:  17, steps per second: 135, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.978817, mae: 40.397267, mean_q: 82.217898, mean_eps: 0.997500\n",
            "   82/10000: episode: 4, duration: 0.158s, episode steps:  23, steps per second: 145, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.391 [0.000, 1.000],  loss: 17.077926, mae: 40.339962, mean_q: 81.372750, mean_eps: 0.996500\n",
            "  100/10000: episode: 5, duration: 0.133s, episode steps:  18, steps per second: 135, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 9.793843, mae: 41.264661, mean_q: 83.697646, mean_eps: 0.995475\n",
            "  123/10000: episode: 6, duration: 0.161s, episode steps:  23, steps per second: 143, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 9.774684, mae: 40.401107, mean_q: 82.432548, mean_eps: 0.994450\n",
            "  139/10000: episode: 7, duration: 0.112s, episode steps:  16, steps per second: 143, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 8.310834, mae: 40.419372, mean_q: 82.273673, mean_eps: 0.993475\n",
            "  149/10000: episode: 8, duration: 0.073s, episode steps:  10, steps per second: 137, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 3.329259, mae: 41.172540, mean_q: 84.291348, mean_eps: 0.992825\n",
            "  166/10000: episode: 9, duration: 0.136s, episode steps:  17, steps per second: 125, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 12.300383, mae: 40.883188, mean_q: 82.858792, mean_eps: 0.992150\n",
            "  177/10000: episode: 10, duration: 0.084s, episode steps:  11, steps per second: 130, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 14.205700, mae: 41.023744, mean_q: 82.924685, mean_eps: 0.991450\n",
            "  202/10000: episode: 11, duration: 0.188s, episode steps:  25, steps per second: 133, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 9.866706, mae: 41.171708, mean_q: 83.167376, mean_eps: 0.990550\n",
            "  219/10000: episode: 12, duration: 0.118s, episode steps:  17, steps per second: 144, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 11.213707, mae: 42.238766, mean_q: 85.399035, mean_eps: 0.989500\n",
            "  233/10000: episode: 13, duration: 0.110s, episode steps:  14, steps per second: 127, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 15.760017, mae: 40.898273, mean_q: 82.829438, mean_eps: 0.988725\n",
            "  267/10000: episode: 14, duration: 0.232s, episode steps:  34, steps per second: 146, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 12.234954, mae: 41.253830, mean_q: 83.537435, mean_eps: 0.987525\n",
            "  288/10000: episode: 15, duration: 0.152s, episode steps:  21, steps per second: 138, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 4.807903, mae: 41.278772, mean_q: 83.674896, mean_eps: 0.986150\n",
            "  308/10000: episode: 16, duration: 0.154s, episode steps:  20, steps per second: 130, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 19.459026, mae: 41.088554, mean_q: 83.274030, mean_eps: 0.985125\n",
            "  317/10000: episode: 17, duration: 0.065s, episode steps:   9, steps per second: 138, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 7.090712, mae: 40.864577, mean_q: 82.678070, mean_eps: 0.984400\n",
            "  333/10000: episode: 18, duration: 0.113s, episode steps:  16, steps per second: 142, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 11.647370, mae: 41.682251, mean_q: 84.353121, mean_eps: 0.983775\n",
            "  366/10000: episode: 19, duration: 0.234s, episode steps:  33, steps per second: 141, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 5.199347, mae: 41.335849, mean_q: 83.690348, mean_eps: 0.982550\n",
            "  380/10000: episode: 20, duration: 0.095s, episode steps:  14, steps per second: 147, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 7.352184, mae: 41.537369, mean_q: 83.962120, mean_eps: 0.981375\n",
            "  396/10000: episode: 21, duration: 0.118s, episode steps:  16, steps per second: 136, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 8.618781, mae: 41.496134, mean_q: 84.241442, mean_eps: 0.980625\n",
            "  413/10000: episode: 22, duration: 0.118s, episode steps:  17, steps per second: 144, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 11.600152, mae: 41.087878, mean_q: 83.213439, mean_eps: 0.979800\n",
            "  434/10000: episode: 23, duration: 0.154s, episode steps:  21, steps per second: 136, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 6.362677, mae: 41.229531, mean_q: 83.746609, mean_eps: 0.978850\n",
            "  450/10000: episode: 24, duration: 0.125s, episode steps:  16, steps per second: 128, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 17.461960, mae: 41.848551, mean_q: 84.228780, mean_eps: 0.977925\n",
            "  485/10000: episode: 25, duration: 0.254s, episode steps:  35, steps per second: 138, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 7.947314, mae: 41.467453, mean_q: 83.947764, mean_eps: 0.976650\n",
            "  494/10000: episode: 26, duration: 0.065s, episode steps:   9, steps per second: 139, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 8.100854, mae: 41.933031, mean_q: 84.152168, mean_eps: 0.975550\n",
            "  511/10000: episode: 27, duration: 0.118s, episode steps:  17, steps per second: 144, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 14.682350, mae: 41.876375, mean_q: 84.508365, mean_eps: 0.974900\n",
            "  532/10000: episode: 28, duration: 0.156s, episode steps:  21, steps per second: 134, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 6.960460, mae: 41.136083, mean_q: 83.814593, mean_eps: 0.973950\n",
            "  564/10000: episode: 29, duration: 0.224s, episode steps:  32, steps per second: 143, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 7.488153, mae: 41.627926, mean_q: 84.482243, mean_eps: 0.972625\n",
            "  595/10000: episode: 30, duration: 0.218s, episode steps:  31, steps per second: 142, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 10.690195, mae: 41.745316, mean_q: 84.865806, mean_eps: 0.971050\n",
            "  607/10000: episode: 31, duration: 0.098s, episode steps:  12, steps per second: 123, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 3.690816, mae: 41.891273, mean_q: 85.009176, mean_eps: 0.969975\n",
            "  616/10000: episode: 32, duration: 0.070s, episode steps:   9, steps per second: 129, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.111 [0.000, 1.000],  loss: 4.087737, mae: 41.744658, mean_q: 85.098423, mean_eps: 0.969450\n",
            "  640/10000: episode: 33, duration: 0.169s, episode steps:  24, steps per second: 142, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 8.964086, mae: 41.309423, mean_q: 83.464083, mean_eps: 0.968625\n",
            "  661/10000: episode: 34, duration: 0.149s, episode steps:  21, steps per second: 141, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 6.691870, mae: 42.563469, mean_q: 86.412922, mean_eps: 0.967500\n",
            "  674/10000: episode: 35, duration: 0.096s, episode steps:  13, steps per second: 135, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 8.863165, mae: 41.419457, mean_q: 84.204674, mean_eps: 0.966650\n",
            "  720/10000: episode: 36, duration: 0.326s, episode steps:  46, steps per second: 141, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 8.863164, mae: 42.173494, mean_q: 85.438800, mean_eps: 0.965175\n",
            "  753/10000: episode: 37, duration: 0.245s, episode steps:  33, steps per second: 135, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.576 [0.000, 1.000],  loss: 8.421014, mae: 41.980129, mean_q: 84.509885, mean_eps: 0.963200\n",
            "  783/10000: episode: 38, duration: 0.206s, episode steps:  30, steps per second: 146, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 7.582675, mae: 42.275731, mean_q: 85.457494, mean_eps: 0.961625\n",
            "  805/10000: episode: 39, duration: 0.145s, episode steps:  22, steps per second: 152, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 8.421139, mae: 42.535398, mean_q: 86.384865, mean_eps: 0.960325\n",
            "  821/10000: episode: 40, duration: 0.127s, episode steps:  16, steps per second: 126, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 4.921670, mae: 42.127795, mean_q: 85.853560, mean_eps: 0.959375\n",
            "  836/10000: episode: 41, duration: 0.105s, episode steps:  15, steps per second: 143, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 6.034925, mae: 42.681697, mean_q: 86.883144, mean_eps: 0.958600\n",
            "  863/10000: episode: 42, duration: 0.192s, episode steps:  27, steps per second: 141, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.407 [0.000, 1.000],  loss: 11.533586, mae: 42.097600, mean_q: 84.971035, mean_eps: 0.957550\n",
            "  896/10000: episode: 43, duration: 0.239s, episode steps:  33, steps per second: 138, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 9.952587, mae: 42.523254, mean_q: 86.043690, mean_eps: 0.956050\n",
            "  917/10000: episode: 44, duration: 0.156s, episode steps:  21, steps per second: 135, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.762 [0.000, 1.000],  loss: 12.501711, mae: 42.058306, mean_q: 85.011487, mean_eps: 0.954700\n",
            "  944/10000: episode: 45, duration: 0.192s, episode steps:  27, steps per second: 140, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 5.469681, mae: 42.410481, mean_q: 86.080093, mean_eps: 0.953500\n",
            "  958/10000: episode: 46, duration: 0.101s, episode steps:  14, steps per second: 139, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 6.386669, mae: 42.412546, mean_q: 85.673906, mean_eps: 0.952475\n",
            "  973/10000: episode: 47, duration: 0.113s, episode steps:  15, steps per second: 133, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 7.172346, mae: 42.122169, mean_q: 85.232910, mean_eps: 0.951750\n",
            " 1023/10000: episode: 48, duration: 0.360s, episode steps:  50, steps per second: 139, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 5.552754, mae: 42.572279, mean_q: 86.680933, mean_eps: 0.950125\n",
            " 1088/10000: episode: 49, duration: 0.469s, episode steps:  65, steps per second: 139, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 7.995196, mae: 42.621112, mean_q: 86.599052, mean_eps: 0.947250\n",
            " 1110/10000: episode: 50, duration: 0.160s, episode steps:  22, steps per second: 137, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.318 [0.000, 1.000],  loss: 15.486765, mae: 42.549590, mean_q: 85.643302, mean_eps: 0.945075\n",
            " 1124/10000: episode: 51, duration: 0.101s, episode steps:  14, steps per second: 139, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 16.351745, mae: 43.353217, mean_q: 87.298458, mean_eps: 0.944175\n",
            " 1137/10000: episode: 52, duration: 0.095s, episode steps:  13, steps per second: 137, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 6.936709, mae: 43.302745, mean_q: 87.401516, mean_eps: 0.943500\n",
            " 1148/10000: episode: 53, duration: 0.096s, episode steps:  11, steps per second: 115, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 10.896000, mae: 42.889334, mean_q: 86.733962, mean_eps: 0.942900\n",
            " 1169/10000: episode: 54, duration: 0.148s, episode steps:  21, steps per second: 142, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 8.122137, mae: 42.582582, mean_q: 86.222468, mean_eps: 0.942100\n",
            " 1191/10000: episode: 55, duration: 0.156s, episode steps:  22, steps per second: 141, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 9.866083, mae: 42.871271, mean_q: 86.804473, mean_eps: 0.941025\n",
            " 1228/10000: episode: 56, duration: 0.257s, episode steps:  37, steps per second: 144, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.432 [0.000, 1.000],  loss: 11.305589, mae: 43.459463, mean_q: 87.985511, mean_eps: 0.939550\n",
            " 1239/10000: episode: 57, duration: 0.081s, episode steps:  11, steps per second: 136, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 9.004731, mae: 41.765261, mean_q: 84.343655, mean_eps: 0.938350\n",
            " 1263/10000: episode: 58, duration: 0.212s, episode steps:  24, steps per second: 113, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 5.673656, mae: 42.923292, mean_q: 87.135365, mean_eps: 0.937475\n",
            " 1290/10000: episode: 59, duration: 0.279s, episode steps:  27, steps per second:  97, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.370 [0.000, 1.000],  loss: 8.616452, mae: 42.570722, mean_q: 86.590097, mean_eps: 0.936200\n",
            " 1349/10000: episode: 60, duration: 0.579s, episode steps:  59, steps per second: 102, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 9.340440, mae: 42.505290, mean_q: 86.140774, mean_eps: 0.934050\n",
            " 1368/10000: episode: 61, duration: 0.190s, episode steps:  19, steps per second: 100, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.684 [0.000, 1.000],  loss: 8.725286, mae: 43.751667, mean_q: 88.412177, mean_eps: 0.932100\n",
            " 1389/10000: episode: 62, duration: 0.220s, episode steps:  21, steps per second:  96, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 7.876823, mae: 43.083367, mean_q: 87.270808, mean_eps: 0.931100\n",
            " 1406/10000: episode: 63, duration: 0.178s, episode steps:  17, steps per second:  96, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 5.596854, mae: 43.335988, mean_q: 87.767107, mean_eps: 0.930150\n",
            " 1431/10000: episode: 64, duration: 0.251s, episode steps:  25, steps per second: 100, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 4.231113, mae: 43.200781, mean_q: 87.708627, mean_eps: 0.929100\n",
            " 1462/10000: episode: 65, duration: 0.319s, episode steps:  31, steps per second:  97, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.387 [0.000, 1.000],  loss: 13.039918, mae: 43.234515, mean_q: 87.601340, mean_eps: 0.927700\n",
            " 1476/10000: episode: 66, duration: 0.161s, episode steps:  14, steps per second:  87, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 5.011640, mae: 43.850516, mean_q: 89.252719, mean_eps: 0.926575\n",
            " 1494/10000: episode: 67, duration: 0.209s, episode steps:  18, steps per second:  86, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 8.588047, mae: 42.739602, mean_q: 87.167863, mean_eps: 0.925775\n",
            " 1517/10000: episode: 68, duration: 0.253s, episode steps:  23, steps per second:  91, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.652 [0.000, 1.000],  loss: 6.513198, mae: 43.388637, mean_q: 88.467076, mean_eps: 0.924750\n",
            " 1602/10000: episode: 69, duration: 0.684s, episode steps:  85, steps per second: 124, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 10.540351, mae: 43.491372, mean_q: 87.962417, mean_eps: 0.922050\n",
            " 1627/10000: episode: 70, duration: 0.176s, episode steps:  25, steps per second: 142, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 18.442073, mae: 43.490795, mean_q: 87.590509, mean_eps: 0.919300\n",
            " 1672/10000: episode: 71, duration: 0.298s, episode steps:  45, steps per second: 151, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 14.130309, mae: 43.229612, mean_q: 87.313928, mean_eps: 0.917550\n",
            " 1682/10000: episode: 72, duration: 0.083s, episode steps:  10, steps per second: 120, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 6.381286, mae: 43.809906, mean_q: 88.779433, mean_eps: 0.916175\n",
            " 1700/10000: episode: 73, duration: 0.131s, episode steps:  18, steps per second: 138, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 12.843752, mae: 44.291827, mean_q: 88.707699, mean_eps: 0.915475\n",
            " 1714/10000: episode: 74, duration: 0.104s, episode steps:  14, steps per second: 135, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 5.773304, mae: 44.241752, mean_q: 88.921876, mean_eps: 0.914675\n",
            " 1741/10000: episode: 75, duration: 0.203s, episode steps:  27, steps per second: 133, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 11.578003, mae: 44.168230, mean_q: 88.830763, mean_eps: 0.913650\n",
            " 1771/10000: episode: 76, duration: 0.217s, episode steps:  30, steps per second: 138, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 12.498706, mae: 43.497815, mean_q: 87.710533, mean_eps: 0.912225\n",
            " 1804/10000: episode: 77, duration: 0.233s, episode steps:  33, steps per second: 142, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 12.844681, mae: 43.559043, mean_q: 87.435603, mean_eps: 0.910650\n",
            " 1829/10000: episode: 78, duration: 0.173s, episode steps:  25, steps per second: 144, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 19.774391, mae: 44.294498, mean_q: 88.866973, mean_eps: 0.909200\n",
            " 1877/10000: episode: 79, duration: 0.324s, episode steps:  48, steps per second: 148, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.137178, mae: 43.212541, mean_q: 87.325881, mean_eps: 0.907375\n",
            " 1925/10000: episode: 80, duration: 0.327s, episode steps:  48, steps per second: 147, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 9.856800, mae: 43.518800, mean_q: 88.387932, mean_eps: 0.904975\n",
            " 1956/10000: episode: 81, duration: 0.223s, episode steps:  31, steps per second: 139, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 10.164093, mae: 44.336577, mean_q: 89.168651, mean_eps: 0.903000\n",
            " 1973/10000: episode: 82, duration: 0.115s, episode steps:  17, steps per second: 147, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 11.980460, mae: 44.626563, mean_q: 90.017502, mean_eps: 0.901800\n",
            " 2011/10000: episode: 83, duration: 0.266s, episode steps:  38, steps per second: 143, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.948621, mae: 44.152066, mean_q: 89.575259, mean_eps: 0.900425\n",
            " 2046/10000: episode: 84, duration: 0.248s, episode steps:  35, steps per second: 141, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 12.598618, mae: 43.470149, mean_q: 87.811618, mean_eps: 0.898600\n",
            " 2061/10000: episode: 85, duration: 0.103s, episode steps:  15, steps per second: 146, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 8.312171, mae: 43.946221, mean_q: 89.244530, mean_eps: 0.897350\n",
            " 2077/10000: episode: 86, duration: 0.109s, episode steps:  16, steps per second: 146, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 3.358697, mae: 43.677576, mean_q: 89.012384, mean_eps: 0.896575\n",
            " 2112/10000: episode: 87, duration: 0.241s, episode steps:  35, steps per second: 145, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 11.511001, mae: 44.175694, mean_q: 89.261813, mean_eps: 0.895300\n",
            " 2125/10000: episode: 88, duration: 0.092s, episode steps:  13, steps per second: 142, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 25.246713, mae: 45.082481, mean_q: 90.119581, mean_eps: 0.894100\n",
            " 2139/10000: episode: 89, duration: 0.099s, episode steps:  14, steps per second: 142, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 4.683707, mae: 44.120577, mean_q: 89.747112, mean_eps: 0.893425\n",
            " 2172/10000: episode: 90, duration: 0.240s, episode steps:  33, steps per second: 138, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 16.122497, mae: 44.391775, mean_q: 89.764649, mean_eps: 0.892250\n",
            " 2202/10000: episode: 91, duration: 0.217s, episode steps:  30, steps per second: 138, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 7.930887, mae: 44.067384, mean_q: 89.230022, mean_eps: 0.890675\n",
            " 2261/10000: episode: 92, duration: 0.413s, episode steps:  59, steps per second: 143, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 10.907190, mae: 44.288816, mean_q: 89.401936, mean_eps: 0.888450\n",
            " 2287/10000: episode: 93, duration: 0.184s, episode steps:  26, steps per second: 142, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 17.883009, mae: 44.409741, mean_q: 90.339557, mean_eps: 0.886325\n",
            " 2302/10000: episode: 94, duration: 0.114s, episode steps:  15, steps per second: 131, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 7.568724, mae: 43.695594, mean_q: 88.671242, mean_eps: 0.885300\n",
            " 2335/10000: episode: 95, duration: 0.240s, episode steps:  33, steps per second: 138, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 11.907192, mae: 44.075305, mean_q: 88.960914, mean_eps: 0.884100\n",
            " 2400/10000: episode: 96, duration: 0.474s, episode steps:  65, steps per second: 137, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 12.201937, mae: 45.032415, mean_q: 91.068485, mean_eps: 0.881650\n",
            " 2417/10000: episode: 97, duration: 0.122s, episode steps:  17, steps per second: 140, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 13.260163, mae: 44.121108, mean_q: 89.024957, mean_eps: 0.879600\n",
            " 2467/10000: episode: 98, duration: 0.351s, episode steps:  50, steps per second: 142, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 13.555272, mae: 44.628499, mean_q: 89.723823, mean_eps: 0.877925\n",
            " 2480/10000: episode: 99, duration: 0.093s, episode steps:  13, steps per second: 140, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 4.199206, mae: 45.661080, mean_q: 92.610052, mean_eps: 0.876350\n",
            " 2494/10000: episode: 100, duration: 0.098s, episode steps:  14, steps per second: 143, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 9.414127, mae: 43.128683, mean_q: 86.275475, mean_eps: 0.875675\n",
            " 2552/10000: episode: 101, duration: 0.416s, episode steps:  58, steps per second: 139, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.727624, mae: 44.447272, mean_q: 90.056216, mean_eps: 0.873875\n",
            " 2566/10000: episode: 102, duration: 0.101s, episode steps:  14, steps per second: 138, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 6.980375, mae: 43.525378, mean_q: 88.614252, mean_eps: 0.872075\n",
            " 2603/10000: episode: 103, duration: 0.281s, episode steps:  37, steps per second: 132, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 7.523213, mae: 44.565381, mean_q: 90.117822, mean_eps: 0.870800\n",
            " 2618/10000: episode: 104, duration: 0.103s, episode steps:  15, steps per second: 146, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 4.141141, mae: 45.987979, mean_q: 93.030363, mean_eps: 0.869500\n",
            " 2635/10000: episode: 105, duration: 0.128s, episode steps:  17, steps per second: 133, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 18.757718, mae: 45.190062, mean_q: 91.222658, mean_eps: 0.868700\n",
            " 2645/10000: episode: 106, duration: 0.074s, episode steps:  10, steps per second: 135, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 9.686062, mae: 44.607980, mean_q: 90.643829, mean_eps: 0.868025\n",
            " 2695/10000: episode: 107, duration: 0.352s, episode steps:  50, steps per second: 142, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 12.863355, mae: 44.963274, mean_q: 90.597522, mean_eps: 0.866525\n",
            " 2724/10000: episode: 108, duration: 0.216s, episode steps:  29, steps per second: 135, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 5.618858, mae: 44.858110, mean_q: 90.757941, mean_eps: 0.864550\n",
            " 2752/10000: episode: 109, duration: 0.217s, episode steps:  28, steps per second: 129, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 16.635069, mae: 44.595000, mean_q: 90.239638, mean_eps: 0.863125\n",
            " 2780/10000: episode: 110, duration: 0.199s, episode steps:  28, steps per second: 141, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.607 [0.000, 1.000],  loss: 12.250108, mae: 45.558564, mean_q: 91.718900, mean_eps: 0.861725\n",
            " 2807/10000: episode: 111, duration: 0.199s, episode steps:  27, steps per second: 136, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.593 [0.000, 1.000],  loss: 11.629410, mae: 44.699029, mean_q: 90.055387, mean_eps: 0.860350\n",
            " 2833/10000: episode: 112, duration: 0.191s, episode steps:  26, steps per second: 136, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 9.054720, mae: 44.912038, mean_q: 90.326847, mean_eps: 0.859025\n",
            " 2845/10000: episode: 113, duration: 0.096s, episode steps:  12, steps per second: 124, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 17.147410, mae: 43.747206, mean_q: 88.145385, mean_eps: 0.858075\n",
            " 2863/10000: episode: 114, duration: 0.132s, episode steps:  18, steps per second: 137, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 2.449630, mae: 44.914475, mean_q: 90.730472, mean_eps: 0.857325\n",
            " 2880/10000: episode: 115, duration: 0.141s, episode steps:  17, steps per second: 120, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 18.755975, mae: 44.920627, mean_q: 91.018083, mean_eps: 0.856450\n",
            " 2930/10000: episode: 116, duration: 0.365s, episode steps:  50, steps per second: 137, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 20.443250, mae: 45.024124, mean_q: 90.213027, mean_eps: 0.854775\n",
            " 2962/10000: episode: 117, duration: 0.327s, episode steps:  32, steps per second:  98, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 14.662920, mae: 45.025372, mean_q: 90.850001, mean_eps: 0.852725\n",
            " 2973/10000: episode: 118, duration: 0.120s, episode steps:  11, steps per second:  92, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 6.522045, mae: 45.898166, mean_q: 92.147360, mean_eps: 0.851650\n",
            " 3022/10000: episode: 119, duration: 0.496s, episode steps:  49, steps per second:  99, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 6.765938, mae: 45.114954, mean_q: 91.238014, mean_eps: 0.850150\n",
            " 3054/10000: episode: 120, duration: 0.310s, episode steps:  32, steps per second: 103, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 9.793212, mae: 45.013052, mean_q: 91.198184, mean_eps: 0.848125\n",
            " 3068/10000: episode: 121, duration: 0.141s, episode steps:  14, steps per second:  99, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 15.215968, mae: 45.629516, mean_q: 92.026682, mean_eps: 0.846975\n",
            " 3080/10000: episode: 122, duration: 0.133s, episode steps:  12, steps per second:  91, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 4.076041, mae: 43.389321, mean_q: 87.961450, mean_eps: 0.846325\n",
            " 3091/10000: episode: 123, duration: 0.118s, episode steps:  11, steps per second:  93, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 18.930307, mae: 46.588267, mean_q: 93.844450, mean_eps: 0.845750\n",
            " 3102/10000: episode: 124, duration: 0.121s, episode steps:  11, steps per second:  91, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 7.769500, mae: 44.588929, mean_q: 90.038973, mean_eps: 0.845200\n",
            " 3157/10000: episode: 125, duration: 0.552s, episode steps:  55, steps per second: 100, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.418 [0.000, 1.000],  loss: 10.738979, mae: 45.425720, mean_q: 91.683124, mean_eps: 0.843550\n",
            " 3173/10000: episode: 126, duration: 0.166s, episode steps:  16, steps per second:  97, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 11.726772, mae: 45.468936, mean_q: 92.047249, mean_eps: 0.841775\n",
            " 3184/10000: episode: 127, duration: 0.119s, episode steps:  11, steps per second:  92, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 8.920860, mae: 45.820017, mean_q: 92.800156, mean_eps: 0.841100\n",
            " 3232/10000: episode: 128, duration: 0.470s, episode steps:  48, steps per second: 102, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 11.078227, mae: 45.058810, mean_q: 90.916495, mean_eps: 0.839625\n",
            " 3255/10000: episode: 129, duration: 0.162s, episode steps:  23, steps per second: 142, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 5.384902, mae: 45.336043, mean_q: 91.558621, mean_eps: 0.837850\n",
            " 3271/10000: episode: 130, duration: 0.122s, episode steps:  16, steps per second: 131, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 14.970643, mae: 45.012109, mean_q: 90.954659, mean_eps: 0.836875\n",
            " 3294/10000: episode: 131, duration: 0.156s, episode steps:  23, steps per second: 147, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.609 [0.000, 1.000],  loss: 10.926016, mae: 44.727338, mean_q: 90.408974, mean_eps: 0.835900\n",
            " 3353/10000: episode: 132, duration: 0.395s, episode steps:  59, steps per second: 149, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 8.409910, mae: 45.291354, mean_q: 91.658900, mean_eps: 0.833850\n",
            " 3420/10000: episode: 133, duration: 0.446s, episode steps:  67, steps per second: 150, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 20.584501, mae: 45.072811, mean_q: 90.672303, mean_eps: 0.830700\n",
            " 3435/10000: episode: 134, duration: 0.107s, episode steps:  15, steps per second: 140, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 6.151296, mae: 44.976062, mean_q: 91.184290, mean_eps: 0.828650\n",
            " 3466/10000: episode: 135, duration: 0.206s, episode steps:  31, steps per second: 151, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 7.213914, mae: 45.692177, mean_q: 92.565658, mean_eps: 0.827500\n",
            " 3483/10000: episode: 136, duration: 0.135s, episode steps:  17, steps per second: 126, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 9.973461, mae: 44.933358, mean_q: 90.903308, mean_eps: 0.826300\n",
            " 3501/10000: episode: 137, duration: 0.128s, episode steps:  18, steps per second: 141, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 11.475287, mae: 46.543590, mean_q: 94.091578, mean_eps: 0.825425\n",
            " 3543/10000: episode: 138, duration: 0.289s, episode steps:  42, steps per second: 145, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 10.846158, mae: 46.741396, mean_q: 93.853362, mean_eps: 0.823925\n",
            " 3598/10000: episode: 139, duration: 0.390s, episode steps:  55, steps per second: 141, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 10.899335, mae: 45.916227, mean_q: 92.655938, mean_eps: 0.821500\n",
            " 3677/10000: episode: 140, duration: 0.534s, episode steps:  79, steps per second: 148, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 10.522096, mae: 45.725909, mean_q: 92.291003, mean_eps: 0.818150\n",
            " 3714/10000: episode: 141, duration: 0.292s, episode steps:  37, steps per second: 127, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 8.786219, mae: 45.519655, mean_q: 91.774634, mean_eps: 0.815250\n",
            " 3753/10000: episode: 142, duration: 0.273s, episode steps:  39, steps per second: 143, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 8.106976, mae: 46.149297, mean_q: 93.619333, mean_eps: 0.813350\n",
            " 3798/10000: episode: 143, duration: 0.318s, episode steps:  45, steps per second: 142, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 16.201585, mae: 45.878489, mean_q: 92.219937, mean_eps: 0.811250\n",
            " 3851/10000: episode: 144, duration: 0.359s, episode steps:  53, steps per second: 148, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.566 [0.000, 1.000],  loss: 8.774884, mae: 45.868155, mean_q: 92.870784, mean_eps: 0.808800\n",
            " 3870/10000: episode: 145, duration: 0.132s, episode steps:  19, steps per second: 143, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 7.168625, mae: 45.168052, mean_q: 91.677565, mean_eps: 0.807000\n",
            " 3923/10000: episode: 146, duration: 0.366s, episode steps:  53, steps per second: 145, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.396 [0.000, 1.000],  loss: 8.974080, mae: 45.917786, mean_q: 92.972300, mean_eps: 0.805200\n",
            " 3947/10000: episode: 147, duration: 0.160s, episode steps:  24, steps per second: 150, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 16.772359, mae: 45.850290, mean_q: 92.149356, mean_eps: 0.803275\n",
            " 3998/10000: episode: 148, duration: 0.358s, episode steps:  51, steps per second: 142, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.431 [0.000, 1.000],  loss: 21.565162, mae: 46.539166, mean_q: 93.651150, mean_eps: 0.801400\n",
            " 4018/10000: episode: 149, duration: 0.134s, episode steps:  20, steps per second: 149, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 6.824943, mae: 46.693349, mean_q: 94.194454, mean_eps: 0.799625\n",
            " 4028/10000: episode: 150, duration: 0.075s, episode steps:  10, steps per second: 133, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 6.989266, mae: 45.124426, mean_q: 91.401804, mean_eps: 0.798875\n",
            " 4049/10000: episode: 151, duration: 0.138s, episode steps:  21, steps per second: 152, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 11.252437, mae: 46.137682, mean_q: 93.319914, mean_eps: 0.798100\n",
            " 4072/10000: episode: 152, duration: 0.164s, episode steps:  23, steps per second: 140, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 7.745838, mae: 46.595433, mean_q: 94.688190, mean_eps: 0.797000\n",
            " 4107/10000: episode: 153, duration: 0.246s, episode steps:  35, steps per second: 142, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 8.817298, mae: 45.648164, mean_q: 93.183094, mean_eps: 0.795550\n",
            " 4132/10000: episode: 154, duration: 0.180s, episode steps:  25, steps per second: 139, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 18.150198, mae: 45.984426, mean_q: 92.826071, mean_eps: 0.794050\n",
            " 4159/10000: episode: 155, duration: 0.187s, episode steps:  27, steps per second: 144, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 11.983689, mae: 46.783768, mean_q: 95.026565, mean_eps: 0.792750\n",
            " 4198/10000: episode: 156, duration: 0.281s, episode steps:  39, steps per second: 139, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 14.606663, mae: 45.931416, mean_q: 93.612277, mean_eps: 0.791100\n",
            " 4236/10000: episode: 157, duration: 0.263s, episode steps:  38, steps per second: 144, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.446943, mae: 47.243644, mean_q: 95.764520, mean_eps: 0.789175\n",
            " 4299/10000: episode: 158, duration: 0.438s, episode steps:  63, steps per second: 144, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 14.128861, mae: 46.854986, mean_q: 95.106406, mean_eps: 0.786650\n",
            " 4334/10000: episode: 159, duration: 0.254s, episode steps:  35, steps per second: 138, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 16.412658, mae: 45.877024, mean_q: 92.466179, mean_eps: 0.784200\n",
            " 4414/10000: episode: 160, duration: 0.566s, episode steps:  80, steps per second: 141, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 11.761035, mae: 46.872076, mean_q: 94.611304, mean_eps: 0.781325\n",
            " 4438/10000: episode: 161, duration: 0.165s, episode steps:  24, steps per second: 145, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 18.929192, mae: 46.776538, mean_q: 93.704959, mean_eps: 0.778725\n",
            " 4453/10000: episode: 162, duration: 0.110s, episode steps:  15, steps per second: 137, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 13.472871, mae: 47.502411, mean_q: 95.347928, mean_eps: 0.777750\n",
            " 4474/10000: episode: 163, duration: 0.149s, episode steps:  21, steps per second: 141, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 17.193914, mae: 47.432395, mean_q: 95.471228, mean_eps: 0.776850\n",
            " 4515/10000: episode: 164, duration: 0.294s, episode steps:  41, steps per second: 140, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 8.949894, mae: 46.828616, mean_q: 94.462981, mean_eps: 0.775300\n",
            " 4550/10000: episode: 165, duration: 0.259s, episode steps:  35, steps per second: 135, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 10.867839, mae: 47.458878, mean_q: 95.575752, mean_eps: 0.773400\n",
            " 4614/10000: episode: 166, duration: 0.443s, episode steps:  64, steps per second: 144, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 20.619642, mae: 47.306858, mean_q: 95.384098, mean_eps: 0.770925\n",
            " 4644/10000: episode: 167, duration: 0.220s, episode steps:  30, steps per second: 136, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 22.609327, mae: 46.788007, mean_q: 94.289560, mean_eps: 0.768575\n",
            " 4658/10000: episode: 168, duration: 0.160s, episode steps:  14, steps per second:  88, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 15.702306, mae: 47.052734, mean_q: 93.877023, mean_eps: 0.767475\n",
            " 4738/10000: episode: 169, duration: 1.680s, episode steps:  80, steps per second:  48, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 12.598560, mae: 47.334117, mean_q: 95.471912, mean_eps: 0.765125\n",
            " 4755/10000: episode: 170, duration: 0.171s, episode steps:  17, steps per second:  99, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 22.983715, mae: 47.752547, mean_q: 95.670834, mean_eps: 0.762700\n",
            " 4785/10000: episode: 171, duration: 0.978s, episode steps:  30, steps per second:  31, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.852069, mae: 47.484614, mean_q: 95.004984, mean_eps: 0.761525\n",
            " 4803/10000: episode: 172, duration: 0.246s, episode steps:  18, steps per second:  73, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.364019, mae: 45.839589, mean_q: 92.593700, mean_eps: 0.760325\n",
            " 4843/10000: episode: 173, duration: 0.310s, episode steps:  40, steps per second: 129, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 6.264915, mae: 47.414161, mean_q: 96.077047, mean_eps: 0.758875\n",
            " 4881/10000: episode: 174, duration: 0.268s, episode steps:  38, steps per second: 142, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 12.226624, mae: 47.135845, mean_q: 95.640516, mean_eps: 0.756925\n",
            " 4922/10000: episode: 175, duration: 0.284s, episode steps:  41, steps per second: 144, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 9.596427, mae: 46.753196, mean_q: 94.914759, mean_eps: 0.754950\n",
            " 4972/10000: episode: 176, duration: 0.349s, episode steps:  50, steps per second: 143, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.670346, mae: 47.233375, mean_q: 95.292191, mean_eps: 0.752675\n",
            " 4987/10000: episode: 177, duration: 0.111s, episode steps:  15, steps per second: 135, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 10.763564, mae: 47.002717, mean_q: 95.354792, mean_eps: 0.751050\n",
            " 5014/10000: episode: 178, duration: 0.187s, episode steps:  27, steps per second: 145, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.407 [0.000, 1.000],  loss: 7.252592, mae: 47.716196, mean_q: 97.031582, mean_eps: 0.750000\n",
            " 5045/10000: episode: 179, duration: 0.218s, episode steps:  31, steps per second: 142, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.710 [0.000, 1.000],  loss: 12.810805, mae: 47.755101, mean_q: 96.665167, mean_eps: 0.748550\n",
            " 5056/10000: episode: 180, duration: 0.078s, episode steps:  11, steps per second: 141, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 22.081741, mae: 46.720947, mean_q: 93.592409, mean_eps: 0.747500\n",
            " 5087/10000: episode: 181, duration: 0.227s, episode steps:  31, steps per second: 137, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 18.911391, mae: 47.688386, mean_q: 96.166809, mean_eps: 0.746450\n",
            " 5102/10000: episode: 182, duration: 0.108s, episode steps:  15, steps per second: 139, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 22.812143, mae: 47.052864, mean_q: 95.135620, mean_eps: 0.745300\n",
            " 5149/10000: episode: 183, duration: 0.320s, episode steps:  47, steps per second: 147, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 16.797318, mae: 48.057439, mean_q: 96.773515, mean_eps: 0.743750\n",
            " 5171/10000: episode: 184, duration: 0.150s, episode steps:  22, steps per second: 147, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 24.939211, mae: 47.682544, mean_q: 95.341735, mean_eps: 0.742025\n",
            " 5183/10000: episode: 185, duration: 0.092s, episode steps:  12, steps per second: 131, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 10.051336, mae: 46.614609, mean_q: 93.903056, mean_eps: 0.741175\n",
            " 5217/10000: episode: 186, duration: 0.248s, episode steps:  34, steps per second: 137, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 16.755227, mae: 46.934515, mean_q: 95.040837, mean_eps: 0.740025\n",
            " 5291/10000: episode: 187, duration: 0.517s, episode steps:  74, steps per second: 143, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 17.246059, mae: 47.085367, mean_q: 95.101715, mean_eps: 0.737325\n",
            " 5334/10000: episode: 188, duration: 0.303s, episode steps:  43, steps per second: 142, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 10.262741, mae: 46.725180, mean_q: 94.626001, mean_eps: 0.734400\n",
            " 5425/10000: episode: 189, duration: 0.617s, episode steps:  91, steps per second: 148, episode reward: 91.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 16.636112, mae: 47.907854, mean_q: 96.521598, mean_eps: 0.731050\n",
            " 5469/10000: episode: 190, duration: 0.305s, episode steps:  44, steps per second: 144, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 20.618554, mae: 47.832263, mean_q: 96.383956, mean_eps: 0.727675\n",
            " 5512/10000: episode: 191, duration: 0.295s, episode steps:  43, steps per second: 146, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 13.596925, mae: 47.678950, mean_q: 96.255333, mean_eps: 0.725500\n",
            " 5536/10000: episode: 192, duration: 0.175s, episode steps:  24, steps per second: 137, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 10.413293, mae: 47.618121, mean_q: 97.047830, mean_eps: 0.723825\n",
            " 5577/10000: episode: 193, duration: 0.284s, episode steps:  41, steps per second: 144, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.415 [0.000, 1.000],  loss: 19.980235, mae: 47.573067, mean_q: 95.535851, mean_eps: 0.722200\n",
            " 5641/10000: episode: 194, duration: 0.429s, episode steps:  64, steps per second: 149, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.547 [0.000, 1.000],  loss: 19.352742, mae: 47.370170, mean_q: 95.862090, mean_eps: 0.719575\n",
            " 5697/10000: episode: 195, duration: 0.381s, episode steps:  56, steps per second: 147, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.446 [0.000, 1.000],  loss: 14.203183, mae: 47.903010, mean_q: 97.107654, mean_eps: 0.716575\n",
            " 5757/10000: episode: 196, duration: 0.408s, episode steps:  60, steps per second: 147, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 13.294490, mae: 47.743153, mean_q: 96.472123, mean_eps: 0.713675\n",
            " 5770/10000: episode: 197, duration: 0.091s, episode steps:  13, steps per second: 142, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 21.592044, mae: 49.257472, mean_q: 99.169303, mean_eps: 0.711850\n",
            " 5794/10000: episode: 198, duration: 0.180s, episode steps:  24, steps per second: 133, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.840801, mae: 48.806012, mean_q: 98.567989, mean_eps: 0.710925\n",
            " 5837/10000: episode: 199, duration: 0.301s, episode steps:  43, steps per second: 143, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 11.508004, mae: 47.991059, mean_q: 97.290673, mean_eps: 0.709250\n",
            " 5867/10000: episode: 200, duration: 0.215s, episode steps:  30, steps per second: 139, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 12.501146, mae: 48.011636, mean_q: 97.370054, mean_eps: 0.707425\n",
            " 5898/10000: episode: 201, duration: 0.213s, episode steps:  31, steps per second: 146, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 19.011837, mae: 48.264483, mean_q: 97.682798, mean_eps: 0.705900\n",
            " 5926/10000: episode: 202, duration: 0.189s, episode steps:  28, steps per second: 148, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.252335, mae: 48.048823, mean_q: 97.247582, mean_eps: 0.704425\n",
            " 6074/10000: episode: 203, duration: 0.989s, episode steps: 148, steps per second: 150, episode reward: 148.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 15.309678, mae: 48.951045, mean_q: 98.802574, mean_eps: 0.700025\n",
            " 6092/10000: episode: 204, duration: 0.130s, episode steps:  18, steps per second: 138, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 24.259556, mae: 49.242114, mean_q: 98.410369, mean_eps: 0.695875\n",
            " 6108/10000: episode: 205, duration: 0.118s, episode steps:  16, steps per second: 135, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 10.652631, mae: 48.548420, mean_q: 98.261088, mean_eps: 0.695025\n",
            " 6220/10000: episode: 206, duration: 0.757s, episode steps: 112, steps per second: 148, episode reward: 112.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 16.199952, mae: 48.951406, mean_q: 98.762533, mean_eps: 0.691825\n",
            " 6241/10000: episode: 207, duration: 0.158s, episode steps:  21, steps per second: 133, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 15.864235, mae: 48.879975, mean_q: 98.823521, mean_eps: 0.688500\n",
            " 6272/10000: episode: 208, duration: 0.287s, episode steps:  31, steps per second: 108, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.548 [0.000, 1.000],  loss: 17.881901, mae: 48.970103, mean_q: 98.637028, mean_eps: 0.687200\n",
            " 6285/10000: episode: 209, duration: 0.136s, episode steps:  13, steps per second:  96, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 31.163771, mae: 50.394727, mean_q: 101.831734, mean_eps: 0.686100\n",
            " 6325/10000: episode: 210, duration: 0.395s, episode steps:  40, steps per second: 101, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 15.685238, mae: 49.479601, mean_q: 99.577771, mean_eps: 0.684775\n",
            " 6400/10000: episode: 211, duration: 0.762s, episode steps:  75, steps per second:  98, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 20.506450, mae: 49.572861, mean_q: 100.072718, mean_eps: 0.681900\n",
            " 6441/10000: episode: 212, duration: 0.420s, episode steps:  41, steps per second:  98, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 10.335072, mae: 48.819203, mean_q: 99.031919, mean_eps: 0.679000\n",
            " 6458/10000: episode: 213, duration: 0.181s, episode steps:  17, steps per second:  94, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 7.910932, mae: 49.385374, mean_q: 100.147833, mean_eps: 0.677550\n",
            " 6592/10000: episode: 214, duration: 1.197s, episode steps: 134, steps per second: 112, episode reward: 134.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 14.855894, mae: 49.882670, mean_q: 100.785462, mean_eps: 0.673775\n",
            " 6710/10000: episode: 215, duration: 0.828s, episode steps: 118, steps per second: 143, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 10.013235, mae: 49.459045, mean_q: 100.556782, mean_eps: 0.667475\n",
            " 6753/10000: episode: 216, duration: 0.300s, episode steps:  43, steps per second: 143, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 14.389563, mae: 50.474414, mean_q: 102.575216, mean_eps: 0.663450\n",
            " 6819/10000: episode: 217, duration: 0.450s, episode steps:  66, steps per second: 147, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.576 [0.000, 1.000],  loss: 17.427047, mae: 50.221734, mean_q: 102.028750, mean_eps: 0.660725\n",
            " 6876/10000: episode: 218, duration: 0.404s, episode steps:  57, steps per second: 141, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 15.963196, mae: 49.730968, mean_q: 100.905457, mean_eps: 0.657650\n",
            " 6901/10000: episode: 219, duration: 0.182s, episode steps:  25, steps per second: 137, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 13.640235, mae: 50.255852, mean_q: 101.688457, mean_eps: 0.655600\n",
            " 6936/10000: episode: 220, duration: 0.248s, episode steps:  35, steps per second: 141, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 12.167053, mae: 50.186148, mean_q: 102.062781, mean_eps: 0.654100\n",
            " 7014/10000: episode: 221, duration: 0.547s, episode steps:  78, steps per second: 143, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 11.997554, mae: 50.255977, mean_q: 102.005913, mean_eps: 0.651275\n",
            " 7029/10000: episode: 222, duration: 0.111s, episode steps:  15, steps per second: 135, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 14.003172, mae: 51.126527, mean_q: 103.044834, mean_eps: 0.648950\n",
            " 7058/10000: episode: 223, duration: 0.219s, episode steps:  29, steps per second: 132, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.621 [0.000, 1.000],  loss: 11.447899, mae: 50.283414, mean_q: 102.468103, mean_eps: 0.647850\n",
            " 7162/10000: episode: 224, duration: 0.718s, episode steps: 104, steps per second: 145, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 14.520474, mae: 50.537297, mean_q: 102.909385, mean_eps: 0.644525\n",
            " 7220/10000: episode: 225, duration: 0.391s, episode steps:  58, steps per second: 148, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 14.144900, mae: 50.709993, mean_q: 103.945600, mean_eps: 0.640475\n",
            " 7290/10000: episode: 226, duration: 0.476s, episode steps:  70, steps per second: 147, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 18.427422, mae: 51.251516, mean_q: 103.666982, mean_eps: 0.637275\n",
            " 7366/10000: episode: 227, duration: 0.515s, episode steps:  76, steps per second: 148, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 16.998307, mae: 51.089834, mean_q: 103.761679, mean_eps: 0.633625\n",
            " 7385/10000: episode: 228, duration: 0.135s, episode steps:  19, steps per second: 141, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 32.277492, mae: 50.540777, mean_q: 102.485940, mean_eps: 0.631250\n",
            " 7585/10000: episode: 229, duration: 1.344s, episode steps: 200, steps per second: 149, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 15.773205, mae: 51.469303, mean_q: 104.356188, mean_eps: 0.625775\n",
            " 7649/10000: episode: 230, duration: 0.432s, episode steps:  64, steps per second: 148, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 16.928422, mae: 51.762867, mean_q: 104.739444, mean_eps: 0.619175\n",
            " 7664/10000: episode: 231, duration: 0.110s, episode steps:  15, steps per second: 136, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 28.539960, mae: 52.037858, mean_q: 104.145970, mean_eps: 0.617200\n",
            " 7730/10000: episode: 232, duration: 0.464s, episode steps:  66, steps per second: 142, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 11.938210, mae: 51.362097, mean_q: 104.609484, mean_eps: 0.615175\n",
            " 7749/10000: episode: 233, duration: 0.141s, episode steps:  19, steps per second: 135, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 28.004693, mae: 53.003802, mean_q: 107.527875, mean_eps: 0.613050\n",
            " 7817/10000: episode: 234, duration: 0.454s, episode steps:  68, steps per second: 150, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 16.299280, mae: 51.390562, mean_q: 103.795169, mean_eps: 0.610875\n",
            " 7852/10000: episode: 235, duration: 0.244s, episode steps:  35, steps per second: 144, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 14.573082, mae: 52.793437, mean_q: 107.251449, mean_eps: 0.608300\n",
            " 7908/10000: episode: 236, duration: 0.385s, episode steps:  56, steps per second: 146, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.554 [0.000, 1.000],  loss: 18.131267, mae: 51.697499, mean_q: 104.643046, mean_eps: 0.606025\n",
            " 7965/10000: episode: 237, duration: 0.390s, episode steps:  57, steps per second: 146, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 25.604255, mae: 51.510880, mean_q: 103.740665, mean_eps: 0.603200\n",
            " 8049/10000: episode: 238, duration: 0.775s, episode steps:  84, steps per second: 108, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 18.303915, mae: 52.456374, mean_q: 106.158341, mean_eps: 0.599675\n",
            " 8096/10000: episode: 239, duration: 0.465s, episode steps:  47, steps per second: 101, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 17.114760, mae: 52.448523, mean_q: 107.096644, mean_eps: 0.596400\n",
            " 8165/10000: episode: 240, duration: 0.666s, episode steps:  69, steps per second: 104, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 14.760188, mae: 52.293974, mean_q: 106.490907, mean_eps: 0.593500\n",
            " 8328/10000: episode: 241, duration: 1.469s, episode steps: 163, steps per second: 111, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 16.143860, mae: 52.590652, mean_q: 107.041499, mean_eps: 0.587700\n",
            " 8528/10000: episode: 242, duration: 1.320s, episode steps: 200, steps per second: 151, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 18.490746, mae: 52.527057, mean_q: 106.835182, mean_eps: 0.578625\n",
            " 8677/10000: episode: 243, duration: 1.027s, episode steps: 149, steps per second: 145, episode reward: 149.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 20.340100, mae: 52.587701, mean_q: 106.606000, mean_eps: 0.569900\n",
            " 8693/10000: episode: 244, duration: 0.116s, episode steps:  16, steps per second: 137, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 15.190660, mae: 54.323376, mean_q: 110.178299, mean_eps: 0.565775\n",
            " 8737/10000: episode: 245, duration: 0.303s, episode steps:  44, steps per second: 145, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 19.394389, mae: 52.988119, mean_q: 107.528041, mean_eps: 0.564275\n",
            " 8792/10000: episode: 246, duration: 0.390s, episode steps:  55, steps per second: 141, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 19.746309, mae: 53.743836, mean_q: 109.046580, mean_eps: 0.561800\n",
            " 8815/10000: episode: 247, duration: 0.177s, episode steps:  23, steps per second: 130, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 16.079055, mae: 53.207688, mean_q: 108.128554, mean_eps: 0.559850\n",
            " 9015/10000: episode: 248, duration: 1.356s, episode steps: 200, steps per second: 148, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 17.203655, mae: 53.737384, mean_q: 109.532981, mean_eps: 0.554275\n",
            " 9057/10000: episode: 249, duration: 0.296s, episode steps:  42, steps per second: 142, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 21.898376, mae: 53.905956, mean_q: 109.464933, mean_eps: 0.548225\n",
            " 9158/10000: episode: 250, duration: 0.690s, episode steps: 101, steps per second: 146, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 21.636205, mae: 54.370770, mean_q: 110.806784, mean_eps: 0.544650\n",
            " 9172/10000: episode: 251, duration: 0.104s, episode steps:  14, steps per second: 134, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 17.485285, mae: 53.855075, mean_q: 109.781554, mean_eps: 0.541775\n",
            " 9204/10000: episode: 252, duration: 0.216s, episode steps:  32, steps per second: 148, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 21.775739, mae: 54.649052, mean_q: 111.294326, mean_eps: 0.540625\n",
            " 9404/10000: episode: 253, duration: 1.316s, episode steps: 200, steps per second: 152, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 17.667187, mae: 54.737085, mean_q: 111.904935, mean_eps: 0.534825\n",
            " 9438/10000: episode: 254, duration: 0.234s, episode steps:  34, steps per second: 145, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 17.997987, mae: 55.137407, mean_q: 112.982310, mean_eps: 0.528975\n",
            " 9575/10000: episode: 255, duration: 0.917s, episode steps: 137, steps per second: 149, episode reward: 137.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 15.258785, mae: 55.801889, mean_q: 114.280566, mean_eps: 0.524700\n",
            " 9635/10000: episode: 256, duration: 0.406s, episode steps:  60, steps per second: 148, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 15.127276, mae: 55.877477, mean_q: 114.501478, mean_eps: 0.519775\n",
            " 9744/10000: episode: 257, duration: 0.739s, episode steps: 109, steps per second: 147, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 17.956424, mae: 56.481150, mean_q: 115.155466, mean_eps: 0.515550\n",
            " 9862/10000: episode: 258, duration: 1.083s, episode steps: 118, steps per second: 109, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 24.805937, mae: 56.168055, mean_q: 114.520456, mean_eps: 0.509875\n",
            "done, took 78.175 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 177.000, steps: 177\n",
            "Episode 4: reward: 183.000, steps: 183\n",
            "Episode 5: reward: 186.000, steps: 186\n",
            "Episode 6: reward: 179.000, steps: 179\n",
            "Episode 7: reward: 175.000, steps: 175\n",
            "Episode 8: reward: 190.000, steps: 190\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 185.000, steps: 185\n",
            "Episode 11: reward: 188.000, steps: 188\n",
            "Episode 12: reward: 186.000, steps: 186\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 180.000, steps: 180\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 180.000, steps: 180\n",
            "Episode 17: reward: 173.000, steps: 173\n",
            "Episode 18: reward: 185.000, steps: 185\n",
            "Episode 19: reward: 175.000, steps: 175\n",
            "Episode 20: reward: 168.000, steps: 168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd752a68fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run params\n",
        "\n",
        "# value_min = 0.1\n",
        "\n",
        "# nb_steps_warmup=10\n",
        "\n",
        "target_model_update=1e-2\n",
        "\n",
        "nb_steps=10000\n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "nb_episodes=20"
      ],
      "metadata": {
        "id": "e4jIXWElj9on"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ZiiRbxlH2D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b27a4688-f7e5-41a1-deb8-5ff74ceecda2"
      },
      "source": [
        "# policy_outer =  LinearAnnealedPolicy(inner_policy=policy_inner, \n",
        "#                                attr='eps',            \n",
        "#                                value_max=1.0,\n",
        "#                                value_min=0.1, \n",
        "#                                value_test=.05,\n",
        "#                                nb_steps=10000)\n",
        "\n",
        "# # define the agent\n",
        "# dqn = DQNAgent(model=model, \n",
        "#                nb_actions=env.action_space.n,\n",
        "#                memory=memory,\n",
        "#                nb_steps_warmup=10,\n",
        "#                target_model_update=1e-2, \n",
        "#                policy=policy_outer) \n",
        "\n",
        "# dqn.compile(Adam(lr=0.01), metrics=['mae'])\n",
        "\n",
        "# history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# # summarize the history for number  of episode steps\n",
        "# plt.plot(history.history['nb_episode_steps'])\n",
        "# plt.ylabel('nb_episode_steps')\n",
        "# plt.xlabel('episodes')\n",
        "# plt.show()\n",
        "\n",
        "# dqn.test(env, nb_episodes=20, visualize=False)\n",
        "\n",
        "# plt.imshow(env.render(mode='rgb_array'))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 10 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 11 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 12 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 13 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 14 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 15 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 16 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 17 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 18 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 19 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 20 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 21 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 22 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 23 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 24 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 25 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 26 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 27 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 28 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 29 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 30 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 31 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   16/10000: episode: 1, duration: 1.171s, episode steps:  16, steps per second:  14, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.800655, mae: 0.704553, mean_q: 0.219762, mean_eps: 0.998830\n",
            "   30/10000: episode: 2, duration: 0.106s, episode steps:  14, steps per second: 133, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.443065, mae: 0.682525, mean_q: 0.679667, mean_eps: 0.997975\n",
            "   53/10000: episode: 3, duration: 0.162s, episode steps:  23, steps per second: 142, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.304 [0.000, 1.000],  loss: 0.099335, mae: 0.741548, mean_q: 1.213493, mean_eps: 0.996310\n",
            "   68/10000: episode: 4, duration: 0.113s, episode steps:  15, steps per second: 132, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 0.064469, mae: 0.828117, mean_q: 1.535144, mean_eps: 0.994600\n",
            "   79/10000: episode: 5, duration: 0.075s, episode steps:  11, steps per second: 146, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 0.063754, mae: 0.892721, mean_q: 1.653038, mean_eps: 0.993430\n",
            "  104/10000: episode: 6, duration: 0.183s, episode steps:  25, steps per second: 137, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 0.062405, mae: 0.937899, mean_q: 1.781148, mean_eps: 0.991810\n",
            "  122/10000: episode: 7, duration: 0.127s, episode steps:  18, steps per second: 142, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 0.048320, mae: 0.997909, mean_q: 1.949731, mean_eps: 0.989875\n",
            "  144/10000: episode: 8, duration: 0.150s, episode steps:  22, steps per second: 147, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 0.052888, mae: 1.072604, mean_q: 2.096978, mean_eps: 0.988075\n",
            "  161/10000: episode: 9, duration: 0.114s, episode steps:  17, steps per second: 149, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 0.074304, mae: 1.168501, mean_q: 2.258962, mean_eps: 0.986320\n",
            "  175/10000: episode: 10, duration: 0.097s, episode steps:  14, steps per second: 145, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 0.086298, mae: 1.207332, mean_q: 2.366191, mean_eps: 0.984925\n",
            "  192/10000: episode: 11, duration: 0.117s, episode steps:  17, steps per second: 145, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 0.068252, mae: 1.305521, mean_q: 2.567563, mean_eps: 0.983530\n",
            "  239/10000: episode: 12, duration: 0.325s, episode steps:  47, steps per second: 145, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.553 [0.000, 1.000],  loss: 0.076732, mae: 1.416596, mean_q: 2.790816, mean_eps: 0.980650\n",
            "  256/10000: episode: 13, duration: 0.115s, episode steps:  17, steps per second: 148, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 0.086742, mae: 1.556841, mean_q: 2.997453, mean_eps: 0.977770\n",
            "  301/10000: episode: 14, duration: 0.292s, episode steps:  45, steps per second: 154, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.102004, mae: 1.696617, mean_q: 3.343720, mean_eps: 0.974980\n",
            "  318/10000: episode: 15, duration: 0.117s, episode steps:  17, steps per second: 146, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 0.126632, mae: 1.866692, mean_q: 3.637115, mean_eps: 0.972190\n",
            "  337/10000: episode: 16, duration: 0.127s, episode steps:  19, steps per second: 150, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 0.181062, mae: 1.934444, mean_q: 3.714789, mean_eps: 0.970570\n",
            "  365/10000: episode: 17, duration: 0.190s, episode steps:  28, steps per second: 147, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.112711, mae: 2.050053, mean_q: 4.048275, mean_eps: 0.968455\n",
            "  377/10000: episode: 18, duration: 0.087s, episode steps:  12, steps per second: 138, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.152933, mae: 2.128303, mean_q: 4.133943, mean_eps: 0.966655\n",
            "  396/10000: episode: 19, duration: 0.139s, episode steps:  19, steps per second: 137, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 0.153496, mae: 2.196078, mean_q: 4.311885, mean_eps: 0.965260\n",
            "  422/10000: episode: 20, duration: 0.178s, episode steps:  26, steps per second: 146, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.654 [0.000, 1.000],  loss: 0.169528, mae: 2.312120, mean_q: 4.558060, mean_eps: 0.963235\n",
            "  458/10000: episode: 21, duration: 0.240s, episode steps:  36, steps per second: 150, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 0.184276, mae: 2.443550, mean_q: 4.748635, mean_eps: 0.960445\n",
            "  487/10000: episode: 22, duration: 0.187s, episode steps:  29, steps per second: 155, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 0.177001, mae: 2.619321, mean_q: 5.122258, mean_eps: 0.957520\n",
            "  533/10000: episode: 23, duration: 0.295s, episode steps:  46, steps per second: 156, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.264590, mae: 2.782826, mean_q: 5.385759, mean_eps: 0.954145\n",
            "  543/10000: episode: 24, duration: 0.083s, episode steps:  10, steps per second: 120, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 0.206661, mae: 2.979455, mean_q: 5.789444, mean_eps: 0.951625\n",
            "  568/10000: episode: 25, duration: 0.168s, episode steps:  25, steps per second: 149, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 0.264333, mae: 2.962848, mean_q: 5.783006, mean_eps: 0.950050\n",
            "  592/10000: episode: 26, duration: 0.172s, episode steps:  24, steps per second: 140, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.244038, mae: 3.088610, mean_q: 5.996939, mean_eps: 0.947845\n",
            "  606/10000: episode: 27, duration: 0.098s, episode steps:  14, steps per second: 143, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 0.275032, mae: 3.160614, mean_q: 6.200976, mean_eps: 0.946135\n",
            "  645/10000: episode: 28, duration: 0.259s, episode steps:  39, steps per second: 151, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 0.352534, mae: 3.288105, mean_q: 6.380511, mean_eps: 0.943750\n",
            "  659/10000: episode: 29, duration: 0.131s, episode steps:  14, steps per second: 107, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.378372, mae: 3.390395, mean_q: 6.515549, mean_eps: 0.941365\n",
            "  678/10000: episode: 30, duration: 0.201s, episode steps:  19, steps per second:  95, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 0.338116, mae: 3.449251, mean_q: 6.735125, mean_eps: 0.939880\n",
            "  705/10000: episode: 31, duration: 0.263s, episode steps:  27, steps per second: 103, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 0.369713, mae: 3.589300, mean_q: 7.022605, mean_eps: 0.937810\n",
            "  718/10000: episode: 32, duration: 0.131s, episode steps:  13, steps per second:  99, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: 0.451108, mae: 3.615202, mean_q: 6.986349, mean_eps: 0.936010\n",
            "  742/10000: episode: 33, duration: 0.224s, episode steps:  24, steps per second: 107, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 0.333412, mae: 3.717585, mean_q: 7.332371, mean_eps: 0.934345\n",
            "  771/10000: episode: 34, duration: 0.273s, episode steps:  29, steps per second: 106, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 0.405708, mae: 3.860288, mean_q: 7.569574, mean_eps: 0.931960\n",
            "  787/10000: episode: 35, duration: 0.156s, episode steps:  16, steps per second: 102, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.402178, mae: 3.935387, mean_q: 7.654162, mean_eps: 0.929935\n",
            "  820/10000: episode: 36, duration: 0.320s, episode steps:  33, steps per second: 103, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.387169, mae: 4.017339, mean_q: 7.931750, mean_eps: 0.927730\n",
            "  837/10000: episode: 37, duration: 0.162s, episode steps:  17, steps per second: 105, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 0.369793, mae: 4.113872, mean_q: 8.101511, mean_eps: 0.925480\n",
            "  892/10000: episode: 38, duration: 0.524s, episode steps:  55, steps per second: 105, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.382 [0.000, 1.000],  loss: 0.359458, mae: 4.278473, mean_q: 8.410088, mean_eps: 0.922240\n",
            "  918/10000: episode: 39, duration: 0.256s, episode steps:  26, steps per second: 102, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.376323, mae: 4.442875, mean_q: 8.724207, mean_eps: 0.918595\n",
            "  932/10000: episode: 40, duration: 0.146s, episode steps:  14, steps per second:  96, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 0.329854, mae: 4.571974, mean_q: 9.092189, mean_eps: 0.916795\n",
            "  945/10000: episode: 41, duration: 0.139s, episode steps:  13, steps per second:  94, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.339106, mae: 4.611597, mean_q: 9.182326, mean_eps: 0.915580\n",
            "  965/10000: episode: 42, duration: 0.194s, episode steps:  20, steps per second: 103, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.350 [0.000, 1.000],  loss: 0.309082, mae: 4.660196, mean_q: 9.216455, mean_eps: 0.914095\n",
            " 1008/10000: episode: 43, duration: 0.296s, episode steps:  43, steps per second: 145, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.442 [0.000, 1.000],  loss: 0.362494, mae: 4.798198, mean_q: 9.528330, mean_eps: 0.911260\n",
            " 1024/10000: episode: 44, duration: 0.108s, episode steps:  16, steps per second: 149, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.580886, mae: 4.958518, mean_q: 9.779191, mean_eps: 0.908605\n",
            " 1060/10000: episode: 45, duration: 0.243s, episode steps:  36, steps per second: 148, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.456434, mae: 5.072971, mean_q: 9.923171, mean_eps: 0.906265\n",
            " 1076/10000: episode: 46, duration: 0.104s, episode steps:  16, steps per second: 154, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 0.438977, mae: 5.071905, mean_q: 10.020697, mean_eps: 0.903925\n",
            " 1106/10000: episode: 47, duration: 0.200s, episode steps:  30, steps per second: 150, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 0.347645, mae: 5.178175, mean_q: 10.262490, mean_eps: 0.901855\n",
            " 1137/10000: episode: 48, duration: 0.204s, episode steps:  31, steps per second: 152, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 0.475978, mae: 5.336808, mean_q: 10.538207, mean_eps: 0.899110\n",
            " 1169/10000: episode: 49, duration: 0.225s, episode steps:  32, steps per second: 142, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.527765, mae: 5.420638, mean_q: 10.686045, mean_eps: 0.896275\n",
            " 1189/10000: episode: 50, duration: 0.146s, episode steps:  20, steps per second: 137, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.473455, mae: 5.493793, mean_q: 10.912311, mean_eps: 0.893935\n",
            " 1206/10000: episode: 51, duration: 0.119s, episode steps:  17, steps per second: 143, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 0.349015, mae: 5.655984, mean_q: 11.366063, mean_eps: 0.892270\n",
            " 1229/10000: episode: 52, duration: 0.156s, episode steps:  23, steps per second: 147, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 0.406545, mae: 5.686854, mean_q: 11.457202, mean_eps: 0.890470\n",
            " 1242/10000: episode: 53, duration: 0.090s, episode steps:  13, steps per second: 144, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.551533, mae: 5.810276, mean_q: 11.619625, mean_eps: 0.888850\n",
            " 1254/10000: episode: 54, duration: 0.088s, episode steps:  12, steps per second: 137, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.879285, mae: 5.716388, mean_q: 11.399693, mean_eps: 0.887725\n",
            " 1284/10000: episode: 55, duration: 0.194s, episode steps:  30, steps per second: 155, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 0.432170, mae: 5.878213, mean_q: 11.759722, mean_eps: 0.885835\n",
            " 1312/10000: episode: 56, duration: 0.194s, episode steps:  28, steps per second: 145, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.607 [0.000, 1.000],  loss: 0.575409, mae: 5.994077, mean_q: 12.076800, mean_eps: 0.883225\n",
            " 1336/10000: episode: 57, duration: 0.165s, episode steps:  24, steps per second: 146, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.663627, mae: 6.075529, mean_q: 12.044984, mean_eps: 0.880885\n",
            " 1366/10000: episode: 58, duration: 0.189s, episode steps:  30, steps per second: 158, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 0.635260, mae: 6.215711, mean_q: 12.400140, mean_eps: 0.878455\n",
            " 1389/10000: episode: 59, duration: 0.154s, episode steps:  23, steps per second: 149, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.609 [0.000, 1.000],  loss: 0.524172, mae: 6.334120, mean_q: 12.671620, mean_eps: 0.876070\n",
            " 1402/10000: episode: 60, duration: 0.087s, episode steps:  13, steps per second: 150, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 0.964014, mae: 6.323730, mean_q: 12.567126, mean_eps: 0.874450\n",
            " 1444/10000: episode: 61, duration: 0.280s, episode steps:  42, steps per second: 150, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.522893, mae: 6.568549, mean_q: 13.153584, mean_eps: 0.871975\n",
            " 1485/10000: episode: 62, duration: 0.280s, episode steps:  41, steps per second: 147, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 0.467508, mae: 6.720551, mean_q: 13.603569, mean_eps: 0.868240\n",
            " 1510/10000: episode: 63, duration: 0.166s, episode steps:  25, steps per second: 150, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 0.702630, mae: 6.911798, mean_q: 13.860215, mean_eps: 0.865270\n",
            " 1528/10000: episode: 64, duration: 0.120s, episode steps:  18, steps per second: 150, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.688094, mae: 6.942527, mean_q: 13.952015, mean_eps: 0.863335\n",
            " 1560/10000: episode: 65, duration: 0.207s, episode steps:  32, steps per second: 155, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 0.783526, mae: 7.064030, mean_q: 14.194993, mean_eps: 0.861085\n",
            " 1606/10000: episode: 66, duration: 0.298s, episode steps:  46, steps per second: 154, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 0.625730, mae: 7.171068, mean_q: 14.586478, mean_eps: 0.857575\n",
            " 1630/10000: episode: 67, duration: 0.166s, episode steps:  24, steps per second: 145, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 0.547540, mae: 7.478915, mean_q: 15.032760, mean_eps: 0.854425\n",
            " 1641/10000: episode: 68, duration: 0.078s, episode steps:  11, steps per second: 142, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 0.467969, mae: 7.445644, mean_q: 15.124579, mean_eps: 0.852850\n",
            " 1682/10000: episode: 69, duration: 0.266s, episode steps:  41, steps per second: 154, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 0.589306, mae: 7.554164, mean_q: 15.277033, mean_eps: 0.850510\n",
            " 1695/10000: episode: 70, duration: 0.086s, episode steps:  13, steps per second: 151, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.549523, mae: 7.565528, mean_q: 15.292962, mean_eps: 0.848080\n",
            " 1715/10000: episode: 71, duration: 0.135s, episode steps:  20, steps per second: 148, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 0.621835, mae: 7.659639, mean_q: 15.502828, mean_eps: 0.846595\n",
            " 1733/10000: episode: 72, duration: 0.117s, episode steps:  18, steps per second: 153, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 0.657893, mae: 7.885885, mean_q: 15.953184, mean_eps: 0.844885\n",
            " 1778/10000: episode: 73, duration: 0.314s, episode steps:  45, steps per second: 144, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.578 [0.000, 1.000],  loss: 0.565336, mae: 7.922551, mean_q: 15.997151, mean_eps: 0.842050\n",
            " 1802/10000: episode: 74, duration: 0.159s, episode steps:  24, steps per second: 150, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.659942, mae: 8.119152, mean_q: 16.387889, mean_eps: 0.838945\n",
            " 1817/10000: episode: 75, duration: 0.102s, episode steps:  15, steps per second: 146, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 0.573964, mae: 8.158296, mean_q: 16.417536, mean_eps: 0.837190\n",
            " 1828/10000: episode: 76, duration: 0.074s, episode steps:  11, steps per second: 148, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 0.384064, mae: 8.317956, mean_q: 16.888059, mean_eps: 0.836020\n",
            " 1852/10000: episode: 77, duration: 0.165s, episode steps:  24, steps per second: 145, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 0.807997, mae: 8.322727, mean_q: 16.916243, mean_eps: 0.834445\n",
            " 1867/10000: episode: 78, duration: 0.101s, episode steps:  15, steps per second: 148, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.408302, mae: 8.227915, mean_q: 16.745638, mean_eps: 0.832690\n",
            " 1946/10000: episode: 79, duration: 0.535s, episode steps:  79, steps per second: 148, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.430 [0.000, 1.000],  loss: 0.674201, mae: 8.529504, mean_q: 17.361135, mean_eps: 0.828460\n",
            " 1999/10000: episode: 80, duration: 0.346s, episode steps:  53, steps per second: 153, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 0.932467, mae: 8.897227, mean_q: 17.981007, mean_eps: 0.822520\n",
            " 2023/10000: episode: 81, duration: 0.155s, episode steps:  24, steps per second: 155, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 0.815844, mae: 8.931634, mean_q: 18.077248, mean_eps: 0.819055\n",
            " 2061/10000: episode: 82, duration: 0.272s, episode steps:  38, steps per second: 140, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.605 [0.000, 1.000],  loss: 0.899146, mae: 9.194555, mean_q: 18.643547, mean_eps: 0.816265\n",
            " 2102/10000: episode: 83, duration: 0.299s, episode steps:  41, steps per second: 137, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 0.847601, mae: 9.456805, mean_q: 19.147171, mean_eps: 0.812710\n",
            " 2121/10000: episode: 84, duration: 0.125s, episode steps:  19, steps per second: 152, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 0.725007, mae: 9.475492, mean_q: 19.335647, mean_eps: 0.810010\n",
            " 2202/10000: episode: 85, duration: 0.517s, episode steps:  81, steps per second: 157, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 0.793522, mae: 9.789204, mean_q: 19.988278, mean_eps: 0.805510\n",
            " 2222/10000: episode: 86, duration: 0.141s, episode steps:  20, steps per second: 142, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 0.984831, mae: 10.151547, mean_q: 20.603525, mean_eps: 0.800965\n",
            " 2233/10000: episode: 87, duration: 0.080s, episode steps:  11, steps per second: 138, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 1.498696, mae: 10.278065, mean_q: 20.911942, mean_eps: 0.799570\n",
            " 2293/10000: episode: 88, duration: 0.375s, episode steps:  60, steps per second: 160, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 1.519986, mae: 10.214483, mean_q: 20.563810, mean_eps: 0.796375\n",
            " 2328/10000: episode: 89, duration: 0.232s, episode steps:  35, steps per second: 151, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.851757, mae: 10.600623, mean_q: 21.684104, mean_eps: 0.792100\n",
            " 2364/10000: episode: 90, duration: 0.242s, episode steps:  36, steps per second: 148, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 1.143950, mae: 10.542189, mean_q: 21.567316, mean_eps: 0.788905\n",
            " 2376/10000: episode: 91, duration: 0.095s, episode steps:  12, steps per second: 127, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.704701, mae: 10.506234, mean_q: 21.516048, mean_eps: 0.786745\n",
            " 2398/10000: episode: 92, duration: 0.145s, episode steps:  22, steps per second: 152, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 0.969448, mae: 10.918355, mean_q: 22.278342, mean_eps: 0.785215\n",
            " 2438/10000: episode: 93, duration: 0.261s, episode steps:  40, steps per second: 153, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.089813, mae: 11.024868, mean_q: 22.409186, mean_eps: 0.782425\n",
            " 2496/10000: episode: 94, duration: 0.544s, episode steps:  58, steps per second: 107, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 1.195918, mae: 11.162984, mean_q: 22.534829, mean_eps: 0.778015\n",
            " 2539/10000: episode: 95, duration: 0.407s, episode steps:  43, steps per second: 106, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 1.176515, mae: 11.230911, mean_q: 22.935354, mean_eps: 0.773470\n",
            " 2559/10000: episode: 96, duration: 0.186s, episode steps:  20, steps per second: 108, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 1.113896, mae: 11.479759, mean_q: 23.383163, mean_eps: 0.770635\n",
            " 2571/10000: episode: 97, duration: 0.124s, episode steps:  12, steps per second:  96, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 1.671042, mae: 11.710248, mean_q: 23.800700, mean_eps: 0.769195\n",
            " 2590/10000: episode: 98, duration: 0.186s, episode steps:  19, steps per second: 102, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 1.065866, mae: 11.635261, mean_q: 23.750895, mean_eps: 0.767800\n",
            " 2608/10000: episode: 99, duration: 0.191s, episode steps:  18, steps per second:  94, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.860057, mae: 11.744652, mean_q: 24.098168, mean_eps: 0.766135\n",
            " 2621/10000: episode: 100, duration: 0.129s, episode steps:  13, steps per second: 100, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 1.710809, mae: 11.817796, mean_q: 24.309845, mean_eps: 0.764740\n",
            " 2664/10000: episode: 101, duration: 0.409s, episode steps:  43, steps per second: 105, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 2.084890, mae: 11.962954, mean_q: 24.188234, mean_eps: 0.762220\n",
            " 2689/10000: episode: 102, duration: 0.251s, episode steps:  25, steps per second:  99, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 1.629347, mae: 12.168243, mean_q: 24.653581, mean_eps: 0.759160\n",
            " 2747/10000: episode: 103, duration: 0.558s, episode steps:  58, steps per second: 104, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 1.605357, mae: 12.261424, mean_q: 24.999088, mean_eps: 0.755425\n",
            " 2851/10000: episode: 104, duration: 0.749s, episode steps: 104, steps per second: 139, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 1.438161, mae: 12.808200, mean_q: 26.104288, mean_eps: 0.748135\n",
            " 2949/10000: episode: 105, duration: 0.621s, episode steps:  98, steps per second: 158, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 1.635456, mae: 13.078196, mean_q: 26.597221, mean_eps: 0.739045\n",
            " 3009/10000: episode: 106, duration: 0.388s, episode steps:  60, steps per second: 155, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 1.815645, mae: 13.469710, mean_q: 27.339150, mean_eps: 0.731935\n",
            " 3044/10000: episode: 107, duration: 0.232s, episode steps:  35, steps per second: 151, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 2.185396, mae: 13.415733, mean_q: 27.052785, mean_eps: 0.727660\n",
            " 3077/10000: episode: 108, duration: 0.219s, episode steps:  33, steps per second: 150, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 1.474341, mae: 13.992935, mean_q: 28.579406, mean_eps: 0.724600\n",
            " 3107/10000: episode: 109, duration: 0.193s, episode steps:  30, steps per second: 156, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 1.990700, mae: 14.171325, mean_q: 28.761728, mean_eps: 0.721765\n",
            " 3136/10000: episode: 110, duration: 0.199s, episode steps:  29, steps per second: 146, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 1.391143, mae: 14.160831, mean_q: 29.015925, mean_eps: 0.719110\n",
            " 3173/10000: episode: 111, duration: 0.243s, episode steps:  37, steps per second: 152, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 2.523043, mae: 14.497138, mean_q: 29.426863, mean_eps: 0.716140\n",
            " 3205/10000: episode: 112, duration: 0.198s, episode steps:  32, steps per second: 162, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.016014, mae: 14.582200, mean_q: 29.654855, mean_eps: 0.713035\n",
            " 3299/10000: episode: 113, duration: 0.603s, episode steps:  94, steps per second: 156, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 1.974504, mae: 14.873442, mean_q: 30.360553, mean_eps: 0.707365\n",
            " 3452/10000: episode: 114, duration: 0.974s, episode steps: 153, steps per second: 157, episode reward: 153.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 2.164137, mae: 15.533224, mean_q: 31.730957, mean_eps: 0.696250\n",
            " 3533/10000: episode: 115, duration: 0.527s, episode steps:  81, steps per second: 154, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 2.082663, mae: 16.082508, mean_q: 32.877840, mean_eps: 0.685720\n",
            " 3669/10000: episode: 116, duration: 0.910s, episode steps: 136, steps per second: 150, episode reward: 136.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 2.350822, mae: 16.739156, mean_q: 34.160931, mean_eps: 0.675955\n",
            " 3705/10000: episode: 117, duration: 0.245s, episode steps:  36, steps per second: 147, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 2.763185, mae: 16.974025, mean_q: 34.742341, mean_eps: 0.668215\n",
            " 3724/10000: episode: 118, duration: 0.131s, episode steps:  19, steps per second: 144, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 2.032700, mae: 17.088110, mean_q: 35.094710, mean_eps: 0.665740\n",
            " 3752/10000: episode: 119, duration: 0.197s, episode steps:  28, steps per second: 142, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 3.277645, mae: 17.392531, mean_q: 35.493463, mean_eps: 0.663625\n",
            " 3826/10000: episode: 120, duration: 0.484s, episode steps:  74, steps per second: 153, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.446 [0.000, 1.000],  loss: 2.672736, mae: 17.641547, mean_q: 36.022876, mean_eps: 0.659035\n",
            " 3866/10000: episode: 121, duration: 0.278s, episode steps:  40, steps per second: 144, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.125314, mae: 17.989921, mean_q: 36.490458, mean_eps: 0.653905\n",
            " 3923/10000: episode: 122, duration: 0.405s, episode steps:  57, steps per second: 141, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 2.718887, mae: 18.197776, mean_q: 37.102789, mean_eps: 0.649540\n",
            " 3993/10000: episode: 123, duration: 0.461s, episode steps:  70, steps per second: 152, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.557 [0.000, 1.000],  loss: 3.002005, mae: 18.421158, mean_q: 37.536326, mean_eps: 0.643825\n",
            " 4087/10000: episode: 124, duration: 0.630s, episode steps:  94, steps per second: 149, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.142596, mae: 18.699162, mean_q: 38.250253, mean_eps: 0.636445\n",
            " 4108/10000: episode: 125, duration: 0.139s, episode steps:  21, steps per second: 151, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 2.697647, mae: 19.161806, mean_q: 38.884637, mean_eps: 0.631270\n",
            " 4153/10000: episode: 126, duration: 0.300s, episode steps:  45, steps per second: 150, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 3.811484, mae: 19.261550, mean_q: 39.423624, mean_eps: 0.628300\n",
            " 4299/10000: episode: 127, duration: 1.046s, episode steps: 146, steps per second: 140, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 2.935686, mae: 19.812929, mean_q: 40.625080, mean_eps: 0.619705\n",
            " 4409/10000: episode: 128, duration: 1.043s, episode steps: 110, steps per second: 105, episode reward: 110.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 3.806148, mae: 20.452887, mean_q: 41.822279, mean_eps: 0.608185\n",
            " 4459/10000: episode: 129, duration: 0.490s, episode steps:  50, steps per second: 102, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.733508, mae: 20.762234, mean_q: 42.386184, mean_eps: 0.600985\n",
            " 4531/10000: episode: 130, duration: 0.700s, episode steps:  72, steps per second: 103, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.119896, mae: 21.359422, mean_q: 43.589506, mean_eps: 0.595495\n",
            " 4631/10000: episode: 131, duration: 0.821s, episode steps: 100, steps per second: 122, episode reward: 100.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 3.112283, mae: 21.717360, mean_q: 44.582320, mean_eps: 0.587755\n",
            " 4685/10000: episode: 132, duration: 0.362s, episode steps:  54, steps per second: 149, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.426 [0.000, 1.000],  loss: 3.230943, mae: 22.224451, mean_q: 45.427501, mean_eps: 0.580825\n",
            " 4849/10000: episode: 133, duration: 1.048s, episode steps: 164, steps per second: 156, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 3.656306, mae: 22.746221, mean_q: 46.339327, mean_eps: 0.571015\n",
            " 4967/10000: episode: 134, duration: 0.774s, episode steps: 118, steps per second: 152, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 4.440911, mae: 23.267524, mean_q: 47.531430, mean_eps: 0.558325\n",
            " 5066/10000: episode: 135, duration: 0.632s, episode steps:  99, steps per second: 157, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 4.781358, mae: 23.784918, mean_q: 48.364719, mean_eps: 0.548560\n",
            " 5217/10000: episode: 136, duration: 0.971s, episode steps: 151, steps per second: 155, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 3.935704, mae: 24.404163, mean_q: 49.973821, mean_eps: 0.537310\n",
            " 5294/10000: episode: 137, duration: 0.510s, episode steps:  77, steps per second: 151, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 4.188704, mae: 24.999991, mean_q: 51.198286, mean_eps: 0.527050\n",
            " 5494/10000: episode: 138, duration: 1.315s, episode steps: 200, steps per second: 152, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 4.581333, mae: 25.664693, mean_q: 52.272676, mean_eps: 0.514585\n",
            " 5691/10000: episode: 139, duration: 1.283s, episode steps: 197, steps per second: 153, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 5.354759, mae: 26.428088, mean_q: 53.836005, mean_eps: 0.496720\n",
            " 5718/10000: episode: 140, duration: 0.189s, episode steps:  27, steps per second: 143, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 3.155898, mae: 27.282181, mean_q: 55.862239, mean_eps: 0.486640\n",
            " 5739/10000: episode: 141, duration: 0.150s, episode steps:  21, steps per second: 140, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 2.626237, mae: 27.087180, mean_q: 55.393301, mean_eps: 0.484480\n",
            " 5794/10000: episode: 142, duration: 0.361s, episode steps:  55, steps per second: 153, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 5.186211, mae: 27.118050, mean_q: 55.299548, mean_eps: 0.481060\n",
            " 5994/10000: episode: 143, duration: 1.309s, episode steps: 200, steps per second: 153, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 5.167125, mae: 27.802834, mean_q: 56.730329, mean_eps: 0.469585\n",
            " 6022/10000: episode: 144, duration: 0.190s, episode steps:  28, steps per second: 148, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 6.048251, mae: 28.368374, mean_q: 57.826601, mean_eps: 0.459325\n",
            " 6061/10000: episode: 145, duration: 0.270s, episode steps:  39, steps per second: 145, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 8.524811, mae: 28.619944, mean_q: 58.282681, mean_eps: 0.456310\n",
            " 6261/10000: episode: 146, duration: 1.776s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 6.469388, mae: 28.964321, mean_q: 58.945030, mean_eps: 0.445555\n",
            " 6372/10000: episode: 147, duration: 1.060s, episode steps: 111, steps per second: 105, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 6.144072, mae: 29.493236, mean_q: 60.057010, mean_eps: 0.431560\n",
            " 6540/10000: episode: 148, duration: 1.273s, episode steps: 168, steps per second: 132, episode reward: 168.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 6.262803, mae: 30.082452, mean_q: 61.365473, mean_eps: 0.419005\n",
            " 6706/10000: episode: 149, duration: 1.125s, episode steps: 166, steps per second: 148, episode reward: 166.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 7.179381, mae: 30.590011, mean_q: 62.187972, mean_eps: 0.403975\n",
            " 6906/10000: episode: 150, duration: 1.325s, episode steps: 200, steps per second: 151, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.463296, mae: 31.250558, mean_q: 63.773512, mean_eps: 0.387505\n",
            " 7106/10000: episode: 151, duration: 1.306s, episode steps: 200, steps per second: 153, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.752952, mae: 32.064748, mean_q: 65.509641, mean_eps: 0.369505\n",
            " 7306/10000: episode: 152, duration: 1.294s, episode steps: 200, steps per second: 155, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 7.815260, mae: 32.981215, mean_q: 66.991655, mean_eps: 0.351505\n",
            " 7506/10000: episode: 153, duration: 1.291s, episode steps: 200, steps per second: 155, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 7.063830, mae: 33.591118, mean_q: 68.394350, mean_eps: 0.333505\n",
            " 7566/10000: episode: 154, duration: 0.407s, episode steps:  60, steps per second: 147, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 7.701922, mae: 33.923858, mean_q: 69.088064, mean_eps: 0.321805\n",
            " 7766/10000: episode: 155, duration: 1.291s, episode steps: 200, steps per second: 155, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 7.784167, mae: 34.331098, mean_q: 69.828796, mean_eps: 0.310105\n",
            " 7865/10000: episode: 156, duration: 0.667s, episode steps:  99, steps per second: 148, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 6.424783, mae: 34.765153, mean_q: 70.835276, mean_eps: 0.296650\n",
            " 8065/10000: episode: 157, duration: 1.732s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 9.010580, mae: 35.535894, mean_q: 72.191212, mean_eps: 0.283195\n",
            " 8265/10000: episode: 158, duration: 1.893s, episode steps: 200, steps per second: 106, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 7.885576, mae: 35.842170, mean_q: 72.993033, mean_eps: 0.265195\n",
            " 8465/10000: episode: 159, duration: 1.338s, episode steps: 200, steps per second: 149, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 7.424187, mae: 36.602935, mean_q: 74.507558, mean_eps: 0.247195\n",
            " 8665/10000: episode: 160, duration: 1.321s, episode steps: 200, steps per second: 151, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 7.996576, mae: 37.289628, mean_q: 75.603242, mean_eps: 0.229195\n",
            " 8865/10000: episode: 161, duration: 1.295s, episode steps: 200, steps per second: 154, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 9.612532, mae: 37.806004, mean_q: 76.698310, mean_eps: 0.211195\n",
            " 9065/10000: episode: 162, duration: 1.324s, episode steps: 200, steps per second: 151, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 9.752027, mae: 38.179104, mean_q: 77.292340, mean_eps: 0.193195\n",
            " 9265/10000: episode: 163, duration: 1.331s, episode steps: 200, steps per second: 150, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 9.518311, mae: 38.730242, mean_q: 78.540964, mean_eps: 0.175195\n",
            " 9465/10000: episode: 164, duration: 1.318s, episode steps: 200, steps per second: 152, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 9.525469, mae: 38.971051, mean_q: 78.995645, mean_eps: 0.157195\n",
            " 9665/10000: episode: 165, duration: 1.309s, episode steps: 200, steps per second: 153, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 9.531065, mae: 39.312214, mean_q: 79.652903, mean_eps: 0.139195\n",
            " 9865/10000: episode: 166, duration: 1.665s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 8.478889, mae: 39.419552, mean_q: 80.100731, mean_eps: 0.121195\n",
            "done, took 73.078 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABkpklEQVR4nO29d5gkV3X3/z1VnaYnz+5sztJKQnElFgUQyUIgMCDAYMAYsNHPMrYwYL+vDTY2xsb4xWDgZ6IRRkhE49dCIKIRQghQZJVWK2kl7a42p9nZyT0dquq+f9y6VbeqqzpN93TPzvk8zzzdXZ1u98zcU+d7EgkhwDAMwzAKo90LYBiGYToLNgwMwzBMADYMDMMwTAA2DAzDMEwANgwMwzBMgES7FzBXli5dKjZs2NDuZTAMwywoHnjggRNCiOGo+xa8YdiwYQO2bdvW7mUwDMMsKIhoX9x9LCUxDMMwAdgwMAzDMAHYMDAMwzAB2DAwDMMwAdgwMAzDMAFaahiIaC0R3UFEjxPRY0T0Hvf4EBHdRkRPu5eD7nEiok8T0S4i2k5EF7VyfQzDMEw5rfYYLAD/SwhxNoBLAVxHRGcDeD+A24UQmwHc7t4GgJcD2Oz+XAvgCy1eH8MwDBOipXUMQogjAI6416eI6AkAqwFcDeBF7sNuAvALAO9zj39VyF7g9xLRABGtdF+HYRimYfaMTGP3yAyuPHt57GNmChZ++vhRvPbCNYHjv9l7En2ZJM5c0Vv2nOOTeXzr/gOwHSd4BxGu3rIKpw33wHEE/vuBg3jdRauRMA3sH83h5gcPYq5jDy5cN4gXn7VsTq8RxbwVuBHRBgAXArgPwHJtsz8KQP2mVgM4oD3toHssYBiI6FpIjwLr1q1r3aIZhjlluPHuvfjavfvw/XddjnNX90c+5rbHj+HPv/0Itq4fwtqhrHf87767A6cN9+BzbylXt7/z0CF86mdPAQCI/ONCABO5Iv7h6nPx8MFx/NXN27FqoAuXb16Kb9y/D1+8c0/g8Y3wh8/duHANAxH1ALgZwHuFEJOkfRtCCEFEdZlNIcT1AK4HgK1bt/KkIYZhqlK0HAgBfPB7O/Df73wuDKN8Vy5a8qy/ZAfP/ou2g4JlR77uVL4E0yDs+sjLoe9tz/nIz1C0ReB1i7bt3e7NJPDoh1429w/WAlqelURESUij8A0hxHfcw8eIaKV7/0oAx93jhwCs1Z6+xj3GMAwzJyxHbtIP7h/HLQ9Fbyu2K+04IYnHcYS3yYeZKdjoTpkBowAAJhEc9z3VZcl9DcsWSEQYpk6h1VlJBODLAJ4QQnxSu+tWAG93r78dwPe0429zs5MuBTDB8QWGYZqB7QisGezC5mU9+O8HDsY+BgCckA2whYAV8iIUU3kLvZlk2XHTIM/QeJfuC1uOQMLs3GqBVktJzwPwVgCPEtHD7rG/AfBRAP9FRNcA2Afgd937fgTgFQB2AcgB+MMWr49hmEWC7QgkTQPL+zKYLUXLQk5oA/eOO/IsP4qZgoXutFl23DCChgDwJSrLdjraY2h1VtKvAcR9+isiHi8AXNfKNTEMszixHQHTIBCVb/z6Y/RL/XgpnHXkMl2w0J0u30oThuF7IKHXtR2BhNm5hqFzfRmGYZgmYjnyLN00KDZNVG3c4bullBT9nOmChZ4Iw2BQhITkvkbJEUgYnbv9du7KGIZhmojtAAYRTPK1//LHBGMCCiFEWaaSYibGMJiGFnwWQUnJdjpbSmLDwDDMosB2HCRMAhEhZo8vO8P3nyu8TT1MnJRkEHnP8S9VOqyUtToVNgwMwywKLDfGYBqIlZIcT0qKMAwx1iROSkqYVBZbUFISxxgYhmE6ANsRMEnGGOKDz/5jdRzh1yDoCCHipSRNsvKlJL+AjmMMDMMwbcbPSqoQYxDRMQYpJZV7DLMlG44AejIRUpJmgJTBsfSsJJaSGIZh2ouSb0yisqwjhROTleTEZCVNFywAiIwxmKQbBlW/oFU+s5TEMAzTXixHyKykSlJSXIGbEChGxBhmCrJQrieiwM2s4DHI1NnO3X47d2UMwzBNxBFSvqmlwC3cK0kGnyM8hrz0GHrS0S0xnJA0pQLYFgefGYZh2o9lC5iG4UpJtRsGIQQcgcgYgy8lVfEYXIOgZydxjIFhGKbNyOBzsLld1GPkpX9MORclW5QZlJmC8hii6xj8gjn/NQCWkhiGYToCW8g2FJUK3BxR7jHoslNYgpquYBgSmgFywkFoR8BkKYlhGKa9qHTVSgVu4aZ3QNBIhKufKxkGma7qvq7weyQBUkpKspTEMAzTXizHkYahQh1DOFisHwPKJ7tVS1ct66qqVT6bLCUxDMO0F8eBX+BWNSup/BhQPpNhpmCBCMimooPPKmCtXqOkVT4nWUpiGIZpL8G229GPUQ5BQErSnITwTIbpgoWeVKJsrCcgpST1MuE5D0rW6lTYMDAMsyjwYwyVPIbgGT4QlJXCHsN0PrqzKuAGn8Ntt9U8BttBsoNHe7Z65vMNRHSciHZox75NRA+7P3vVyE8i2kBEs9p9/97KtTEMs7hQ3VWJUKFXkrx0aowxzBStyD5JQDBdNdx2u9M9hlbPfL4RwGcBfFUdEEK8UV0nok8AmNAev1sIsaXFa2IYZhHieQwVCtzCg3X0Y0B5h9Xpgh3rMZiGlv4aNcGtg2MMrZ75/Esi2hB1H0lR7ncB/FYr18AwDAP4HU0rS0kRwedAumooxpAvoTfWMFCgm6p8PndXrcbzARwTQjytHdtIRA8R0Z1E9Py4JxLRtUS0jYi2jYyMtH6lDMMseCxHwHCzkhwRXcsQ1USvclaSHdkOAwiO9vR6JTkOhBCuYVikMYYqvBnAt7TbRwCsE0JcCOAvAHyTiPqiniiEuF4IsVUIsXV4eHgelsowzELHUR6Dm0EUpSZFS0n+/VF1DLFSklYvofdIUl4DewwhiCgB4HUAvq2OCSEKQohR9/oDAHYDOKMd62MY5tRCCOEGnw2oZKCoAHS4hUX4cVGVz3FSUnBQjy8lKa8jsVizkirwEgA7hRAH1QEiGiYi072+CcBmAHvatD6GYU4h1H5uEnk1B1FxhnDTO/nc6KwkNdazoscQTlfVJsEtWo+BiL4F4B4AZxLRQSK6xr3rTQjKSADwAgDb3fTV/wbwTiHEyVauj2GYxYHaoBMmeWmiUVJSZK+kmBhDwXJgOSLeMJgRHoPtaB5D5xqGVmclvTnm+B9EHLsZwM2tXA/DMIsTtTGbWowhUkqKiDHEZSWpPkm9MXUMJlHAU1CvvxBiDK2uY2AYhmk7akOXUpI8FiUlRTXR0x+n6hiOTMyiUJKv2Z2KT1cNeyAl2/GlpA6OMbBhYBjmlEed6KvKZyAmXTVSSvLvt2yB45N5PPejP8dlm5YAiO6sCsjKZ5UWqxQofUToYq58ZhiGaTv+Wbq/GUcGn72WGP6xcPB5LFeCEMDdu0cBxEtJSiqyHaF5DL6UxN1VGYZh2ogyAoaelRThMYTnJ4QfV7IdFCwbALB+SRYAMJBNRr6nYfjvo/dIUo36OnkeA3sMDMOc8qjNPaG1wq6YlRTTK8lyBAqW3Ng/9KpzkDQNnL0ysg7Xk4ocx2/nbTmOF6fgCW4MwzAt5F3ffBAf+eHjsffrur5X4FahjiFu5rNlO17QuSeTwOWbl0bOYgDgZT9ZjhPITtIzpDoV9hgYhlnwPH1sGhOzpdj79TqGkh08Fnic18Ki/BggYwRKSkonKp9XBz0GvyWGKpLr5HkMbBgYhlnwWI6DvNrxI+/3Ywyml5VU/jglG4mYXkmW43hSUjoR3TxPYWoxBr8lhsMeA8MwzHxgOwKzFQyD48UYDAjhBoJr7K7qNOgxGFpWUtBj6PzK5871ZRiGYWrEcgTyJSf+fi3GUKnAze+VFFP5bAsvxpBOVpGStJ5MdmSvpM7dfjt3ZQzDMDViOwKzxXiPIdASw+uVFJ+uqt8VzEqqR0py31uIwGsUrfKaik6DpSSGYRY8JVt4ElEUerqqValXUpVBPfUFn+X9jtYfCYDn2XCvJIZhmBZia2fycfcDSkqq1HbbvRTRMQY9XbW6YVCvKQKvoYLkLCUxDMO0EMsNPkfJQ0C4jqFS223HvU/3GPz7ZeWzA9Ogqk3wDK+OQQSMUN71ODpZSmLDwDDMgsd2BIRArNegPIBaC9xis5IcKSWlaqhB8OoYRNAwFBaAlMSGgWGYBY/S8ONqGbwCN6NKrySvC6p+LCQlWU7VjCT1Xuq9Iz0GlpIYhjnV+PGjR/DwgfF2LwOAv/HHpax6BW7aoJ5KbbeDUlJ5umq1+ALgS0l6uqq+xkUrJRHRDUR0nIh2aMc+RESHiOhh9+cV2n1/TUS7iOhJInpZK9fGMMzc+D8/3omv3PVMu5ch5x24m3dckZujeQxeRXKEDfGykiIMQ9IkT0qqlqoKBKUkJyAlKY9hkRoGADcCuCri+KeEEFvcnx8BABGdDTkL+hz3OZ8nourfPsMwbSFfsr2c/Hain9HrtQxFy8E37tsXGKdZrcBNbeBR8xjSCdOXkmrxGAwt+CyEZyi8rKQO7pXU0pUJIX4J4GSND78awH8KIQpCiGcA7AJwccsWxzDMnChYTkcYBr1GQPcY7tkzig/csgOPHByPnPkcKSWJiAlu7tV0wnDrGOqLMTiOgG0Lz5goKamTeyW1y2S9i4i2u1LToHtsNYAD2mMOusfKIKJriWgbEW0bGRlp9VoZhomgaDkoRukx80yweMw3DLNFyztmRUlJIcPguJlNQHSBWzphuJXPNUpJoRiDZxjc4DNPcAvyBQCnAdgC4AiAT9T7AkKI64UQW4UQW4eHh5u8PIZhaqFg2V4L6XZi29FSkjozL9m+xm8aRmyBW1xRm7qeShj1BZ8D3VX9FhrKeLHHoCGEOCaEsIWsX/8SfLnoEIC12kPXuMcYhukwLNuBI9AhUpK/Bl1KUhtwyXIiPYawkhRXu+B7DCZKtvSSajEMppau6giBVEhKSnK6qg8RrdRuvhaAyli6FcCbiChNRBsBbAZw/3yvj2GY6qhCspJdrtM3i/2jOYzNFKs+zo6JMXiGwXa8imY9XTXsMcRNbfMMQ9KQlc8lp66sJNsRsDRjki/ZIPI9ik6kpb2SiOhbAF4EYCkRHQTw9wBeRERbAAgAewH8MQAIIR4jov8C8DgAC8B1Qoj4dokMw7SNomcYWucxvOOm3+CyTUvw4decW/FxVkQqKOAbr6LteKmpCT0rKeQy2BEBZ3ld3sgkTOQtW8YYagg+KwPkCAFH+G2685bT0d4C0GLDIIR4c8ThL1d4/EcAfKR1K2IYphnom26rmJgtYWSqUPVx8R6D79XoTfTi2m47MdXOXlZS0sBUwao5XVWvl7Ad4XkZhZLd0fEFoA4piYjeQ0R9JPkyET1IRC9t5eIYhulMlMfQyhiD7QjMuJlFlQikqxb99ajsn5LtxxhMii9wiypq06+nTEOrY6guJfmVzw5sIbz+SvmS3dFVz0B9MYZ3CCEmAbwUwCCAtwL4aEtWxTBMR1PQNt1WUbIdzBRqMAx2dPBZNasrWtqcZZNg1CQl6TOf/RiD5QgUSnZjHkPSDz53ctUzUJ9hUJ/kFQC+JoR4TDvGMMwiYj6Cz7YjMFOoHmaMq2PQPQa9iZ4RU+AWMAyavbO1yudSHU30zEC6arCOoZOrnoH6DMMDRPRTSMPwP0TUC6D9uWoMw8w7hXmQkiy7NikpriWGMhJFTUoyAlJSjXUMWq+kgpv6Wk9WkvJo9DqGTvcY6gk+XwNZlLZHCJEjoiUA/rAlq2IYpqMpzkPw2XJqlJJigs9KSipZwpOPdI+hLF1VjyuEgs9qMI9aT01Skvs+6rvS6xg6PcZQs2EQQjhEtAHA7xORAPBrIcQtLVsZwzAdix5jEEJ41cTNwnFkiudMsbqUZGu6Tz6QruqvUZ29mwZ59QMVC9xCRsIkQtIg5Iq1zXsGAJWRWvI8Bv85nTyLAagvK+nzAN4J4FHIorQ/JqLPtWphDMN0LuosWIjgGXuzUK9ZtJyqAW7LjvYY/HRVGWMwCCDSCtzCMYaIFFVAGgnDCHZDTSerS0lq8y/afozCv+8U8RgA/BaAZwk3YkNEN0EWozEMs8jQR2iWbAfJJgdT9TYXMwULA9lU7GP1wHI+ovK5aDsgIm+j9rKSKklJoesGUeAz1uMxKCOqB6xPmToGyDbY67TbawE83dzlMAyzENCDziVLYDJfwtWfuwu7jk835fV1L6SanKQe25NJBD0GV0oqWg4cbR6CEVPgFhd89qQkLS5QT3dVL8agGZZmG9JmU8/qegE8QUS/IKI7IL2FPiK6lYhubc3yGIbpRHSPoWDb2D+awyMHxvH4kcmmvL4uD1ULQCvvoiedCGQlFTQpybJ9wxDXK0mf2RDOSjIMCsQF6qlj8GIMC8hjqEdK+mDLVsEwzIKiaPkbsBxeI2/rgeC5EJaSKj7WNSI96QSm8v5j/ToG2RLD8xi8GEPwdXRJKtw3SWYlaR5DHXUMpVC6KtDZsxiA+rKS7iSi9QA2CyF+RkRdABJCiKnWLY9hmE4kEGOwHO3svDmB6KDHUFlKUpt4byaB41pvJRV8LtqyJUXCk5Lk/XEFbinTCASfbaFiDHVKSe77FSOykjrdY6gnK+mPAPw3gC+6h9YA+G4L1sQwTIdTDAWflaGImqPcCPrrTFeVknyPIarAreS2xNBTVqPWquSjZMIok5JMA3VLScYiiTFcB+B5ACYBQAjxNIBlrVgUwzCdTSDGYDmelGQ1qeBNT1HNVal+tr3gcxJ5y/Y8gYIVHWMw4tJV3bdMmhSTleSf5afqiDEowyDjFEHj1KnUYxgKQghvagYRJSBnKjAMs8jQK55LthNocd0M9I25evDZ9xiEkAbBcYQ2M0LOXA4bhrgCt6RplBW4GUTBOoY6Kp+VkUtocYpTpsANwJ1E9DcAuojoSgD/F8D3W7MshmE6GX0gTjD43BzDoBuYaumqKuDdm5Eh03zJDng0qrtq+Gw9VkoKxRiECj4bevC5hrbb7lAg9Vn0zKZOL3CrxzC8H8AIZOXzHwP4kRDiAy1ZFcMwHY3uMRQtP8ZQalJWUqMeAyCrn/VCN9VEz/A8hvL30G8nTSqbzWAa9Re4AdJrUN+NSZrH0OFZSfUYhj8TQnxJCPEGIcTrhRBfIqL3VHoCEd1ARMeJaId27ONEtJOIthPRLUQ04B7fQESzRPSw+/PvjX0khmFajcpCAuDNQQYAu0lSkm5gqgaf7ZBhKNplldmO5jEQyTP5uAK3pGkE7pNSEhoyDIZBnhGVAWwlJZ06huHtEcf+oMpzbgRwVejYbQDOFUKcD+ApAH+t3bdbCLHF/XlnHWtjGGYeKegeg+34GUAtyErKVUlX1SufgXKPQU1wMzVd3yQqDz67BiZhGmUN9QwK1THUkK6q3qekPAbD8KWkDs9KqlrHQERvBvB7ADaGKpz7AJys9FwhxC/djqz6sZ9qN+8F8PqaV8swTEdQKDlImQaKthOQkppW4KZ5HtNVs5LcGEPajzGoOELSJLfATaacKgyi2NGeqYisJCklKY+j9gK1hEFe8Nk0/PhGp3sMtRS43Q3gCIClAD6hHZ8CsH2O7/8OAN/Wbm8koocgU2L/Vgjxq6gnEdG1AK4FgHXr1kU9hGGYFlK0HfRkEjg5U3TrGFS6apMK3DQDk6s1xuAFnx2YhgpIJ73gs+4xGEa5lKQykVIJI5Cx5KisJPf56YRRc5txXUrSU147PcZQ1TAIIfYB2EdELwEw685lOAPAWZCB6IYgog8AsAB8wz10BMA6IcQoET0bwHeJ6Bx3znR4TdcDuB4Atm7dyimzDDPPFEo2etK+YVDpqs1qwa1eJ5M0qlc+R8QY1Bl5TzqBfMkOZCUBrpQUM8EtYRgxg3rk82uVkQD5vKInJZHmMXS2lFTP6n4JIENEqwH8FMBbIWMIdUNEfwDglQDeotp4CyEKQohR9/oDAHYDOKOR12cYprUUbcfbiItaumqzCtyU59Hflay58rlbz0pyN+O+roSbleR4dQWAKyXFtMRIhmIMtpvRpILPtQae1fv4wWf/NTpdSqrHMJAQIgfgdQA+L4R4A4Bz6n1DIroKwF8BeLX7eur4MBGZ7vVNADYD2FPv6zMM03oKJc0waDGGZnkMKm7Q35WsqfI5YRC63NoCPfjcm06WtcQApMTjhNaq6hhSCSqTkkzyN/NaGugpAjEGbd602eFSUl2GgYguA/AWAD90j1X0qYjoWwDuAXAmER0komsAfBayhfdtobTUFwDYTkQPQ/ZkeqcQomJwm2GY9qBiDEAwXbVZMYZSwGOonpVkGoSulNyO8rphyCS84LOu68vW2sHXUc5OWEoKD+qZi5SkspGSHS4l1dN2+z2QqaW3CCEec8/q76j0BCHEmyMOfznmsTcDuLmO9TAM0yYKlu15DCXL8VpcN89j8A1DNY/Bsp2gx1C0kXGv92QSfoFbQEoq75XkVJGS/BhDHVKSARSLC69XUj1tt38JGWdQt/cAeLe6TUSfEUL8WXOXxzBMJ1K0HGRTJgyS3oPnMTQpXVXJL/1dKeSKtjcsJwrlMWQ0KSnregx9mSQAKX3pur5B5VKS5RkGf8IbEWktMeqPMZhEnveT0AxDp89jaKY/87wmvhbDMB1MwXKQShhIurUMzU5X1T0GAJip4DVImciAaRBSCQO5ou1lSXn9kyw7cJYentIGBCuf9TWoBnypRqUkLV1VeR1mh0tJnb06hmE6kqLlIJ0wkDINlCyhBZ+b5DGEDEOuQiM9S0tFXdqdwuh00YsxKLkrV7QDMYaoAje9jgGAF4Mok5LqCD6XxRhcg7CYPAaGYRYJymNIJQwUbT/Y2zSPwZOS5MZeKWXVdnyZaLg3jZHpAgqWA4OArKqGLtrBGIOBco9BjfZ0N211v5eV1EiMgYJeykKJMTTTMHT2J2UYpilYtkz/TCdMJMs8huYWuPVnXY+hQmaS5Qgv/XO4N42RqQLyJRmATrvyT96yywrcwobBS1cNS0kqK8loTErSr/vdVTv7nLzu1RFRNuauf5vjWhiGWQAozTyVMJBMUGC0Z7OkJCskJVX2GIQn0XiGwZKGIZlQw3JCLTGiKp+dYIxBGYq5ZCWFjdEpN4+BiJ5LRI8D2OnevoCIPq/uF0Lc2PzlMQzTaSjNXMUYCrbjDe5pWq8kLSsJqDyTQWUlAcDSnjROzhSQK9pIu8FxRaCJXoXgsycluTZOCLmpe3UMdcQYjDiP4VQxDAA+BeBlAFTbikcgi9IYhllEKO9AZSXJOoYWSUlujKFSVpKqYwCkx+AI4Mh4XnoMAcMQbLsddm5UzyVPShLBrCSv8rkeKSkQ19B6JZ1KwWchxIHQocoliQzDnHL4HoPpBp8d71jTDIMth+P0pN101QoxBr3dxXBPGgBwYCzneTQK/SydIgrcwumqXvDZlZJMg2BQvQVu/nsmDD9O0elN9OqpfD5ARM8FIIgoCVkJ/URrlsUwTKeiahZS7saryzxNa6Ln1iZ0p+XZeTUpSfcYAODIRB7nre4PeQyhOoZwryT3tnqco9UxGCQnv33s9Rdg6/rBmj9HuKjOXCBSUj2G4Z2QAebVAA5Bdli9rhWLYhimcyloMYakaWAsV/TuCwd0GyXc5kKfyBZGFbgBvmGQWVNGoF6glgI3vTW2rQWflST0+mevqetzhN8z6UlJp4jHIIQ4AdlAj2GYRUwgxpAwMJX3z+ZLzfQY3KZzqu1G7GPtYPBZkUmaXrEaEJaSCOE4ue24HVBJ1THI40Igth1HNQJ1DERenGPBewxE9BkAsacBQoh3x93HMMypRzgraSpf8u5rmsfgON5ZdTphesYoCr1zanc6ge6UiZmijUwymJUUyBAiRLbdNgwZfwA0KUnzGOol4DGYC2eCWy3+zDYADwDIALgIwNPuzxYAqZatjGGYjkSXklIJ8moMUgnDaxg3V/SJa6mE4RmjKCzHCWzASk6q5DFESkmuAfBiDFpWUvM8hoVR+VzLaM+bAICI/gTA5UIIy7397wAiZzIzDHPqomclJU3Dk1x60okmdlcVWnqo4QW8o9CDz4A0DHtHcxF1DCEpKaLATU8pVfc7jkCjIYFA8NnwYwvJDo8x1LO6QQB92u0e9xjDMAuEyXwJn/zpkxWDudXQs5L0DS6bMpsmJekB5XTS8Np6R2GFqpp1jyEQfA6dvUd6DAaBKMJjaIaURKdmr6SPAniIiG4kopsAPAjgn1uzLIZhWsHdu07g0z/fhdseP9bwawRiDJpU05NONE1KKmlFa6q6Og477DH0aFKS7jFUm+Am5OuEg8+qV1IjxFU+d/oEt5pXJ4T4CoBLANwCOWntMiUzxUFENxDRcSLaoR0bIqLbiOhp93LQPU5E9Gki2kVE24noosY+EsMwccy6nsIdO483/Bp6VpK+8XanE032GPxK44oeg+MENn2VmZQJeTRlBW4RdQwGkScbqfvVoJ5GUMtSdRCnoscAABcDeD5kK4zn1PD4GwFcFTr2fgC3CyE2A7jdvQ0ALwew2f25FsAX6lwbwzBVmHXHTN7x5PGGN/FgjMHf4LrTiaalq+pN71R1dRy2I7z6AMCXktKh4HOgJUZc8FmTkvTuqg0bBvc9vVYYp9o8BiL6KGS18+Puz7uJqKKU5I4DPRk6fDUA5WncBOA12vGvCsm9AAaIaGWt62MYpjrKYxjLlfDwgbGGXiNQ+axtvN1NjTE43uaZThhekz7FiekC7nxqBIBqolceYygLPmt7cWSMwY0lKClJ3T23GIO8VM/3J7idIoYBwCsAXCmEuEEIcQOkJ/DKBt5zuRDiiHv9KIDl7vXVAPReTAfdY2UQ0bVEtI2Ito2MjDSwBIZZnKigs0HA7U80JicpWSe88XanE7AcASHmbhz0jqlRHsPX7tmHd9z4G9iOKI8xxAWftbVSzAQ30yAoG2OLuWcl+Z5C0GPo9F5J9a5uQLveP9c3F/IvqO6/IiHE9UKIrUKIrcPDw3NdBsMsGmaLNgwCnrNhCD9vMM5QtB0QuU3hzGDwGWhOkZtli8BgnHCMYSxXhO0I5Et2YFAPAKwf6sZgNolNS7tBpBWVBQLB5QVuthtLMMJS0hw8BvU8FYTesDSLoe4UBruTDb3efFFPr6T/A5mVdAfktLYXwI8P1MMxIlophDjiSkXqr/MQgLXa49a4xxiGaRKzJRtdSROXn74Un7jtKeSKFrKperYBGXxOJwwQUaDTqGp4JxvgzW2dluN4Z9XpZHkdw+SsrLaeLdmBttuAnPr20Adf6t1OmgZKth1MV42IMcjgs3+WL4Rwf9CwYQgHm5972lI8+HdXNvRa80k9WUnfAnApgO/Az0r6dgPveSuAt7vX3w7ge9rxt7nZSZcCmNAkJ4ZhmsBsyUZXysRgt2xaUGkyWhxFy/GykcJSEtCc1tuWnpVklktJE8owFO2A7BSFWmNZgVvIMKgKat1jUB+l0ZiA8hQabanRLuoJPj8PwKQQ4lbIQre/IqL1VZ7zLQD3ADiTiA4S0TWQ9RBXEtHTAF7i3gaAHwHYA2AXgC8B+NN6PwzDMJXJF+XIy2xKntLPFusvdCtYNtJu11O16RoEZFw3oRmtty298jmiwG3SbdyXL9llMYYwao2JULFbmZTkyCwizzAI4clJjaerLoxgc5h6fMgvALiAiC4A8BcAvgzgqwBeGPcEIcSbY+66IuKxAtzGm2FaSt6SUpKSjyoNwImjEPAY/FoDdb1ej8FxBEamC1jel/GOqXkMgCxwC3sMSkrKl5yyrKQwKXddRpmUFFqHkEFmX0ryq5/nWvm80AxDPcFny928rwbwOSHE5wD0tmZZDMO0gtmilJJUPCBXYWRmHAXL8eYeq3TVTNLwNud65z5/f/thvOBjdwS6tOpxg3SyPPg8mfdjDLYjKtYFqDVWK3BTTfTUw1TGEwA0uq8rg9CoYWkX9RiGKSL6awC/D+CHRGQA6OzQOsMwAWZLNjIJzWNoQErSYwzqMp0wPamm3iK3faM5FCwnMNfBDnkM5cFn+dhc0apagBYVY4iqY3DcLqoqLuAI4cUhGi9wO/U9hjcCKAC4RghxFDJr6OMtWRXDMC1htuQgo3sMDQSfpccQjDGkk4Z3Rl5vuqqaAKcblJLjBLqrOsKPXRQtxyvUU1JYLTGGqhPcVNttrYmecJc013TVTh/ME6aeCW5HAXxSu70fMsbAMMwCIV+0saIvje45eQw20mZQSkonDO8Mv97W2+M5KQvphsG2g/MYAGmQEqbhyUgAMF2Q1yvFGJKJmKyk0DJV220/KwlN8xganefQLqp6DET0a/dyiogmw5etXyLDMM1C1TGorKS5xhjU2XgmaXobeb3BZ+UxFC3/eaVAEz3DvV/u5CrwDMCTnyqdkae8Aje9VxIipSST/MpnR8tKanRj96SkBRZjqGVQz+XuJQeaGWaBo+oYVM1BI1lJRctBKqs8Bn/z9gxDncHnMddj0DOPZAqqkqmkEVNdXSe1WIQyDLXEGHSnIirGYDkCmaTvMTiO8B4z19GeC81jqKvk0W2FfTlkG4tfCyEeasmqGIZpCfmSrGNIJwwY1ISsJFNu2nrwuV6PYTwqxmD74zpVgDvKY1AFepVmKHt1DJpliJrg5rfdLq9jaDgraYHGGOopcPsgZDfUJQCWAriRiP62VQtjGKb55F0piYjQnUo07jGoOoaAx6DSVeuLMYzNuIbBCnoMXo1EUsUY5FondMNQg8eQiogxmEZEgZsQgcpnR69jmGPl86nsMbwFwAVCiDzgteF+GMA/tWBdDMM0mZLtoGQLZFxpJps2G/QYbKQTwaykRmMMlu140pAuJenjOpUR8qUkzTC46680ES0Vm5UUfJztyCwi9TDHEVBx9IalJApeLhTqSVc9DCCj3U6Dm9wxzIJBtdzucg1DdyrReB1DIlzHoGUl1RFj0M/+9bGglj6PIRxjcGsYsimzJo8hqrsqEcp6Jan22p6U5DShjiHCKC0E6vEYJgA8RkS3QcYYrgRwPxF9GgCEEO9uwfoYhmkSKvc/k9I8hkbrGJRhUOmqScPb/OpJV1WBZ8CPIThu87pwjEFJSZP5EpImYTCbqivGUFbgVlVKakJW0iLolXSL+6P4RXOXwjBMK8m7Yz2Vx5BNJTDTgJSkewxJrfLZ65VUh8egAs+AH3xWUpRePKfeF5DB575MEl21egwRLTHi224HK5/nnpXkv99Cop4Ct5uIqAvAOiHEky1cE8MwLWC2TEoyMTpTrPSUMmxHwHKEFmOICD7XEWMIeAyeYZCXajNNJ4IxhonZEvq7kuhKmhidLgCoVseg0lWDBW6OkDMX1Ixn1b7b1ILPc81K8gb1LLA6hnqykl4FGWz+iXt7CxHd2qJ1Mcwpw/GpPP7h+481pR31XPBiDCn5b59NJzBTp5SkztpTZVKSnq5aj5QU7zEkQoahqNUx9LqGYaqgPIYKlc9RE9y0zV+hei7pTfTmmpW0UGY8h6kn+PwhABcDGAcAIcTDADY1fUUMc4rxq6dO4Ct37cUzJ2baug4vxqCkpKSJXJ3BZ6Xzp7Xg81suWYcXnjHcUIHbRESMQT3fNwzh4HMJfZkE0knDM2wVPYbIdFV5qctJfuWzJiXNMStpofZKqscwlIQQE6Fj7T0FYpg2cXQij+t/ubumwfdqQytY7f13CRuG7nSibsMQ9hiICB957Xl49vrBBqWkKI/BlZJC/Zj04HOf6zHUMmEtboIbEGz4Z4elpGZkJS2CttuPEdHvATCJaDMRfQbA3S1aF8N0ND/ecQT//KOdODZZqPrYoruhhYfNzDf5YjDGkE3VX8egjJs+61nhSUl1fM6xnDz7B/x0VeUxJOOkpFlLxhhS/mDpurOSNK9A4bXd9ia4YdFmJdVjGP4MwDmQrbe/CZm++t5G3pSIziSih7WfSSJ6LxF9iIgOacdf0cjrM0yrURvk+Gz14K0yCOFhM/NNWfA5nUDJFt6GWwuFkMeg00iB23iuiOHeNAB/4w+P09S7qwoh/KykpGYYaihwCzTRi4sx6E309BhDoy0xFmjlc82GQQiRE0J8QAjxHPfnb1UVNAC4HkStr/WkEGKLEGILgGcDyMFPhf2Uuk8I8aNaX5Nh5hO1iekaeRzKILTbY/AMQ8r3GID6+iX5MQaz7D6/wK2+4PNQdwpJkzwpSV2qM329V1LBclC0HfR1JTxJDKh8Rn7O6j5sWTuAnrSfhKmUnUgpKRBjaE4TvVM5xlCN5zX4vCsA7BZC7GviWhimpRS11Mmqj/U8hvqrjJvJbDEUY2hgJkOxgpRkNuQxlNDflULSNGI9hoQpi+cKlu010FN1DIpKG+9zT1uK7173vICX423+ji4lqZYYWhO9JvVKWmhtt5tpGBrlTQC+pd1+FxFtJ6IbiGgw6glEdC0RbSOibSMjI/OzSobRUJv9eC2GweoMjyHcEiPbwBS3SjGGZIXuqk8fm8LeiKyssVwRg9kkkqaheQyqwM3fTNMJA4WS4/VJUsFnRb0aflSMwXIcmAaCbbed4OPrRRmEU1ZKagVElALwagD/1z30BQCnAdgC4AiAT0Q9TwhxvRBiqxBi6/Dw8HwslWECRLWAjkNtpvVo+a0gX5KtrNWGOxePISrGoPcYCvO+m7fjwz94PHBMCIGxXAmD3SmkEgaKrkHwPQb/PdIJA0XbwYTbJ6k/ZBgqBZ+jIM0rUDiOfE/faPj3N5pVdMoO6qmDRj75ywE8KIQ4BgDqEgCI6EsAftCktTFMU/GCz7XEGDooXTWTMLxN0YsxNOQxlMcYVIfTUoRnpA/X0ddTtBwMZJNI6R6De5qub/Yp5TF4UlICmaRvOOrV8P2UVP+Y7JWEYIGb05x0VXOBtVet22Mgoj4iiprm9m8NvP+boclIRLRSu++1AHY08JoM03LqijF0iMegprcpvCluTfIYDINk19IIj2G2aJfNflDtMAazMvgcjjHom306Yboegy8lBYPP9W1lUQVuKiuJSH4O0YxBPae6x0BEzwFwA4BeeZPGAbxDCPEAAAghbqznjYmoG7JD6x9rhz9GRFsgu7fuDd3HMB2Dys6pJcagHqsu20W+aAc207llJUVvxEnDCLTP9t47IvCuBvSUxxhcj0Hb7FMJAwXLxkn3OUu6UzUHn6MIF7g5oXoFgwi20NNV51b5vNDqGOqRkr4M4E+FEL8CACK6HMBXAJzfyBsLIWYgp8Hpx97ayGsxzHyzYD2GZITHUMcUt0oeAyDlHzuiV9JsyS4LSp/0DEMqYBg8jyEUfC5aDk7OFGEaVF7HUKdU49cxuHGNUBdVkwi249+/2Cqf6zEMtjIKACCE+DUR1d+zl2FOAVSG0USujgK3TjAMqbl6DPFZSYDcCMMegxDCiyfo3Uz3n8wBANYOZQPB53CvJEB5DA5GZ2QWk2FQk7KS5O1whbNhKCmpsddXqM9Qr+FqN1UNAxFd5F69k4i+CBkTEADeCJ7JwCxS6vEYvAK3dhuGMimp+R5D0jTKuqvKimXAEgIFy/HWsP9kDinTwPK+jAw+qyZ6XowhmJVUKDkYm5EFcYA/cCj82FoIF7iFPQODKDDBba5S0qnoMYRTRj/oXhKkgWCYRUdDBW7tTle1HAx0Jb3bpkHIJI2mVT6r1wwHn/X4wnTB8g3DaA5rhrpkCm2CkC+p7qpRWUkmJmZLODlTxGBWGoZm1jGEW32bKsbQrOBzJ1SM1UFVwyCEeDEAEFEGwO8A2KA9jw0DsyjxpKTZkpz8VWHnKHZIumq+aKOrLxM41l3nFDf1WZIx0kgyQkrKaz2iZgoWlvbI3kj7Tuawfijrvp6BKTelNbxJA8pjsDGdL+HMFTIpMpNsPPgcjjH4BsAvSBOiGTGG4PstFOqxY98F8CoAJQDT2g/DLDq8+cQCmK6ysaqz7LZLSSU7kPsPqLnPtUtJat4zxWx0plnuMcxqHoPa/IUQ2D86g/VLugHIfkjePAavjqG8wG0sV/KkpLl4DOGspHAbDsNNu7WduUlJKo223nTadlNP8HmNEOKqlq2EYRYQ+iY/kZPdPqs9tt3pquHgMwBkk/V5DAVt3nMUMl01aABntToJNVhndKaImaKNdcpjSPjPiws+zxZt2XQvQkqq22PweiXJ2+GeSKYRTFeda0uMhSYl1bPcu4novJathGEWEAXL8eYIVIszdEq6ariOAXA9hjoK3KTHEB1fAKJjDLrHoIzQvlGZkbR+iTQMsvI5pPcH0lVNjEwVIAS04HN5U7xaCRe4hSe1GURNyUpSjsJC65VUj8dwOYA/IKJnIGcyEAAhhGiojoFhFjJF28Gyvgwm89NV22J0UkuMrpBh6E7VN8Wt6EpJcSTM8gK3fISUtP+kbKinDINe+WxFtKFIJwzv+KBrGFKmAYPkJh4nbcUR7pXkT2qT9zcrK+mUr3yG7GvEMAxkC+3h4R7sOj69IDyGku3AckSZYcimTJyYrj6FTlGw7MqGwSgvcAtKSfL6vtEciIA1g37w2ZeS3AB3KF1VsaRbBq+JZC1DPW2+Ffr4Tv1Sr1S2HTQxK+kUNQw8L4FhfIq2400eqzbFrWBHxxg+edtTWN6XxlsuWd+aRWrkQ0N6FN3p+rOSKsUYEiaVbdQBKamgPIYcVvRlPGkr5QaXAS0QHGqip1BSkvo8s3XOrQbiC9zUcdUraa4xhoQXfF5YhmGBhUQYpjMoWg6WuYahkscghD86MzyP4QfbD+MnO462bpEaanMOxxj6MglP3qmFQjUpySAveBx+bwCYUoZhNOcFngEEuqsqwxLnMeiGIZM0G9p0wwVuYflKBZ/nOvN5MJvEX111Jl56zoqGnt8u2DAwTJ1YtgNHyA6f6YRRcbynbgzCM58LJaemtt0A8M379uOb9+1vbMEA8kX53mHD0J9NYWK2FNkRNYpileBzwoiofI7wGPadzHnxBQCBCW5KSgrGGPz3HOz2M8AySTOQ1lorZXUMIc/AJIKj1zE0GCMgIvzpi07H6oGuhp7fLtgwMEydqM0+lTDQ35Ws6DHocYWwx5Av2VVlKMXX792Hr96zt/7Fuii5KBuSkga6khACmMrXZqAKlt2wlNSTTmCmYCFXtDAyVfBqGABpGBwhz+CjCtzUe/amEwEj0dWgxxCufPakJPKlJMeZe1bSQqWZg3oYZlHg9QsyqxsGPRMpHHyeLdk1j/s8PlVAcQ51ENPumXpvJvgvP5CVZ9/juRIGsqmy54Up2g4G65WSXG9lSU8KUwULh8fzABA4i1Ybf8l2YNlCZhuFspIAPyNJ0ZU0665hAOIL3AJ1DM7c224vVNhjYABILfzzv9iF/W5+OROP3khuIJusKAfpLSR0IyGEQL5kYypvedJJHJbtYHSmgMm8VfOZfZhpN47Qk44xDDX0fAKk/FXZY4gocCvZnhGdKVg4NikNw3KtPYdqsVF0s6fC8pB6z6GQYcikzIY6l4Y9hrBkZBDBaUKvpIUKGwYGgAygfuwnT+L72w+3eykdT8GqX0rqzSQDHkPJFl5GTNTYS50T00WoQWPqbLteVNA3bBj6u+RGO15D+3BAbtzV01XL6xgySUP2ZSpYODohP8OKft8weB6D5cCynTIvQMlHS8o8BqPuzqpA+WhP/XcK+IbBnmNW0kKFDQMDwB/vONngGeliQsk/6YSB/q5UZcNgK8OQCKSr5rXr1Tbl41O+MTg8PtvQmlXQtydGSqqlSyxQm8dQFmMoylYcPW4G1LEp5TGkvcckXQ/B8xhCG3EqRkp64RnLcMVZy2pau46XleRu/NOh78eTkhwBItRdQLfQaVuMgYj2ApgCYAOwhBBbiWgIwLchO7juBfC7Qoixdq1xMaEGwk/O8uylatQVY3AzkXrSCekluJ1Y81ru/ViVzKTjk34B2qEGDUOclKRaWKsxm9WQHkOlrCQqy0pSFdc9bs3EsYk8ejMJbx4E4BuGkiVgOU6ZlKS8lLDH8HuXrKtp3WH8XknSMMyEPCrDkFlJthALrmq5GbTbY3ixEGKLEGKre/v9AG4XQmwGcLt7m5kH2GOoHV126M0kMF2wYtM9i7b8XlXQV3kQeivqiSqZScenfMPQqMegpKTuVNAwqH5PtccYqmQlxdQxZJImutMmZgo2jk7msSLU/lu9ZtF2YFfwGMIxhkYJF7gpw6nGnRok4w62s/D6HDWDdhuGMFcDuMm9fhOA17RvKYsL5THUU+y0WNGDz33u4JvpmO+toMUY9NtBKamKxzCVBxGwsj8zJ4+hJ50o2+QSpjRutdZTVI0xRKSr5t2urt3pBKbzFo5NFgLxBQBIuQHkku2gZJcbhrispEYx4qQk1zCY5GclLUK70FbDIAD8lIgeIKJr3WPLhRBH3OtHASyPeiIRXUtE24ho28jIyHys9ZTH8xhqPHNczCjDkE6Y3hl3nKflG4aEe1t+z3pjuWqb8rHJAoayKawbys4pxtCdjpaABrKV5TCF4wiUbFHFYzDKsqzyrpTUm06gaDs4OJYLZCQBmpSkPIaQlLR6sAuD2STOWdVXdZ21YFBYSpK/j263zkPPSlqMUlI76xguF0IcIqJlAG4jop36nUIIQUSR/rkQ4noA1wPA1q1beYpcE1DjHVlKqo6Sh6SUJD2BuO/Ny0pyz0TVbb2/TzUZZ2Qqj2V9Gawe6MJ9z5xsaM3TBassvqAY6ErVlJXkB90rt92OKnDryyQ9mebEdDEQeAa04LPloBSRlbSsN4OHPvjSqmuslXC66nShhEzS8AySYciMJVtUns53qtI2j0EIcci9PA7gFgAXAzhGRCsBwL083q71NcLTx6bqmp/bSajWyywlVUcPPvd1uR5DTNC+GJKSip6UpA/6qR5jWNabxqqBLhydzFete4hiqmChJ2aY0EA2WVOMQQXSKw7qMaMK3FSMwTdM4RiDnpUkPYbWbsZGqMBtumCjJx2ch+15DGwY5gci6iaiXnUdwEsB7ABwK4C3uw97O4DvtWN9jVCyHbzqs7/G1+5pXhPakzNFjEzV3hJ5Lsx4WUmnhsdg2Q52HW/N5Fk9+NxXxWMol5JU8Lm+rCRlGGxHBILRtTKdL3leS5j+rspFeoqC6ylVijGYhhFRx+Ag40pJirCU5Fc+S7mq1aMwjZDHMFOw0KNJbQa5TfQ4K2leWQ7g10T0CID7AfxQCPETAB8FcCURPQ3gJe7tBcFU3kK+5Hj/tEIIHDg5tyri9928He/99kPNWF5VlMdQsJy2j6BsBrc8dAhX/f+/xGgdswaKluMVX1V7HCA3SGUY4jwt9ViVH18MGYbedKLi2brtCIxMF7CsL43Vg7KFRCMB6JmCHRtjGMzWJiXV6jGUotJVU0bAYygzDF66qgPbcbxK6FbhN9GTt6cLVmB9BpHXK4mlpHlCCLFHCHGB+3OOEOIj7vFRIcQVQojNQoiXCCEaE1TbgGpVoC7v2jWKF3z8jjm1mHjmxEwgh72V6D35TwU5adfxaViOwLE6vr+v37sPV37yzqoDdfQmer6UFBdjUOmqoawk1zCs6M9UlJJOzhRhOwLLejNYPSA300YC0DLGEC8lTcyWvEBsHHphXxwJw4AQCLzWbFEGnwNSUigrKZnwW2IUI2IMzcbLSnL8rCQ9BmO6dQyCs5KYuaA2U3V5cCwHIYDDE41lkQDAscm8J/G0mlzB9xIqyUmzRXtBeBQHxqRBPllj4RYgz8SnChbGqpw96zEGtZnUKiX5HoO8XNGfqegxHNeqhFcN1Ocx5Eu2935T+VJZAz1Ff1cSjvBrHeJQHkO1dFUAntcghPAK3Hq1quKlPdHB55LtYGK2hP6uaCPWLKKlJN1jkEbDXqRZSWwYmsSk5zEEs3sa1exzRQtTecvLr241usdQqXfPH954P/7x+4/Px5JisR1R1qgtzMExuXmOztTuMaiUzdHpGg1DQmaxdKfMqlJSX0y66vK+TEV9X0mTw70ZZFMJDGSTNXsMb7vhfvzjDx6DEKJyVpJb/VxprgRQW1aSOtNXAWhlGDMp32MY7kmXBXRTWlbS2EzJq8huFeHRntMFK9AuRO+VxFIS0zC+x6AMgjIQjW3sSuvOFW0I0fqMXN1jqNTBc/fIDPaOzrR8PZX4xE+fxIX/eBu+8IvdgSCujorv1NrqAdAMQxVjEm641teVLDsBUJlDRdsBEdCVDKWrKimpL4PJfPygnBFXClPT4pZ0pzA2U9vJxr7RGTx1dBqzJRuOQEDK0Rlwz86reUpq4E6lGIPa8FXKqjdSNGmix626Dqeq6q9ZsgXGc8WaWoDPBS8ryf3aZ6JiDJyVxMwVtTE0y2NQ2rjliEC75lYxU7S84p641EshBMZmijU3XGsVu0fkZvcvP9mJv/vujrL7pwuWl+kTlpLedP09+Nf/eTLyddXnqiY/FS0HBvlnx72ZREBKOjw+i+d85Ge45aGD3ijMdFL+qxU0KSllGhjqTkGI+L8T1aJazZce6k7VLI9Nzlo4PpUvaxAXptbW27XEGJQkpAzjrGYYVPA7HHjWn5crWpgp2hjMtlpKkpfKY5jKl8cYbEfAFo1Pb1vI8KCeJhFnEBotGFMbAiC9hvBIxmaTK9pY3p/BnpGZ2DVPFyxYjmi7YZictXDRugH0pBN49NBE2f0Hx/yA/2hoE33q2LQXCC5/Xfm5TlSTkmzZYVR13OzLJANS0kd+9ATGciU8dWwaRUsaALWZ6llJ6aThjakcny1Ftns4PlVAf1fS+/0PZFM1ZbuVbAezJRvHpwpeu464dFV/WE81j6F6VpI6u1YekCrk60rJEZy96YQXK9FRWUhKOhtoUuuLaut0hIBlOyhYTjDG4AafVdPDxQZ7DE3CNwzyUm2ejW6iRzXDUCkA/f1HDuOVn/lV1YySaswULKx0M0XipCQlYVTTolvNVKGEvkwSawazOBKRXnrwpK/B6/KIEAJT+VLs2bkfY6gsJanNXtHXlfSM6d27T+CH22VXl5PTRRQsB6mE6W2mBds3DJmkiYEq8xCOT+UD0stQNlVV8gH83k25ou39LVWNMdTsMcSfpCS94LNrGEp24DlfevtW/MmLTot4nvx+1AlRyz0GT0oSfjuMUPDZEbLT62L0GNgwNAm1mRbdOgBlIBptY617DJUC0I8cGMeOQ5OYnmPFda5oY7gnDYPi13zS3ZCmCtacDdFcmJy10JtJYOVABhOzpbJqc+UxbBruDgSSC5Zs0BYX95msUUpSm72iN5PwvrN/+cmTWDPYhU1Lu3EyV0TBsqWUZMrHK51e9Q/qryLjyKpnX3oZdGMM1eJOugfzzAkZE4qTklQGULUiNxU4r+wxyPtsOxRjcGXKSzctiZSSlKFV6dmtDj7rvZKmCvJz6wVuqonegZOzZam1iwE2DE1C/0ecyltNlpLiN321ocz1LD5XlMG33kwyds0qkCtqSG1sJZP5Evq6kp6HE/YaDozNoitp4vThnsAm7/1OIjbhku14jQSrSklWsMOolJJkAPnxwxN45fmrsKI/g5MzRe+xKsagt93OJA0v8Bv3+1NVz4qh7iSK2lrj0H+He0ZcwxDjMSTdtNs4w/CbvSfx6s/+Giem5PdSOcYQTFdV8567qkihhkFIGIQR11sbaLHHoLfdVh6DXudhuDGGPSemsXlZT0vX0omwYWgS6qwDcA1DA8HnB/aN4c3X34vZoo2jE3lk3M1kuhC/CSgJohZ5oRKyMjaBvq5EbOql/h6T7pn6m6+/F08enZrTe9eDlIMs9GWSWNEntepwtfLBsRzWDHZhSU86uGbPiyv/nejHTlbJSlIxBkVfVwKTeTnLuGQLrB3q8oLERUs+Vp0RK50+b7lSkntm/P1HDuN1n78LTxyZDHzWkakChjUpaaDGwTr673D3iGwNEmcYANUWI/o1f/ToEWw/OIFbHjoEoMasJDsoJVUzDIA0UMc9KanVHoO8tB3heeTdgZYY8uQsX3JwOhsGplF0+UXq2PWnq/70saO4Z88o7t97EscmC9i4VP5B5iqcnauzvFr76UdhO7IIKZsy0ZsuT71U6GffE7Ml7D4+g3v2jOLePaMNv3e95Io2bEegN5PAqoEYj+HkrDQM3SmM5Upa5ombORYxWEfp66ZBZQHrMEXLDsQYejNJ2I7AU8ekgVwzmMUS1zCorCTDICRN8jwG1VhO1TfcvvM4Htw/jvu17qnjuRKKthOQkoaUYahyIjAV5THESEmAPEPfdzIXKVE9uH8cAPC4a7QqeQwqZqLW50tJ1beapEne/0urDQMRgdw4gjIMegGgqnwGwIaBaZypfMk7KxqdKXpnSvV4DDvdM++7d5/A8ak8Ng13A6gcY1BSUq0TuKJQa+1OJdyz3xgpKRc0DCdct7+efkRzRa2tryvpadVHQgVf0mPIYrA7BVvLotLPosODddRj1g521VTglgpJSYC/ca4d7MJgt5wFPVv0J56lTEPzGGRjuYRp4IOvPBufeMMFAILfscrQ0YPPKnOpWhxE/6wq5lLJY3jl+avwwL4xfOq2pwLH8yUbjx+eCGQ0VfIYVvTLtSopVP1t1ZJVp143nTC8mEQrMd1ahRnPYwjWMSjYMDANM5W3/CZnbtVt0qS6DIOSZH786FGUbIHThuUfZKWsJOUpVGvdHMV//eYAvnnffs8jyabNstRLHb0L6KRmGEaqbKTNRK2tLyNTOIe6UziixWMmZkuYzFtYO9TlzQf2guba5wobP3WmunFpN6YLVmzhHFAuJakzzccOS8OwasB/72NTeX/DS5reLIdCyUbGPf6Oyzfid569RjbU075jtbkGPIbu2jwG9fl60wk4QtZcVDrTf+cLN+F3t67Bp3++Czc/cNA7/tjhCZRsgXdfsdk7ljLjX2eZa6zV2vN1SEnqdVsdX1AYRLAd/8RLH3uqDMPSnnTLi+06ETYMTWIyb3n52aodw+qBrkjZIorxXBFHJ/PoyySw381TP831GOICjUIIb15wI1LSV+/di6/es9d7/WzKlMHnGGM2NlP0zjqlxyDf+0SExzCRK+Hj/7MTtzx0sOy+uaDWpjbjlf2ZQIxBnR2vGcx6m6g6u9bllXBqprq9yTXGlc7Io9JVAeCJw5NY1ptGJml6Z/ZHJvLeY3WPQc1B1hnoTkZ6DHrwWaVxnqxS/ayMoPI6ezIJr+4iCiLCR157Hi7eMIQP//BxL4bx4L5xAMBrLlyNC9YOBOo3ouhNJ5BNmTg6Ideu1zFUI6nGd87TRmwYrpSUj5aSAOD0Zd3zspZOgw1Dk5jKl7zul6rJ2ZrBLID4ecA6SkZ608XrvGNrh7IwDYr1GGaKNkpukK8RKenYZAGHx2e91896UlJMuupMEeuXyM+kS0m6YSjZDr5y1zN44b/egc/dsRtfvHNP3euqhC4lAdIw6L2DlFFeG2kYNI8h1jB0B54TRcFyvCwjwO+D9MzoDNYOye9HvbfMSpKbYjppaFlJdtlZ9GA2FfDKVAO9ZZqU1JdJwqDqxWhK2lQnK5VkJEXSNPDh15yLqbyFT9wmq8Mf3D+GtUNdGO5N4y+uPANvu3R9xdcgIqzoy5RLSRVqH/T3B+bPY1ApqVFSkrJ9i1FGAtgwNAVZu+B4WTKHvLNWebuWlFUlI/3exeu8M8wVfRl0p0xvVkIYfXOo12Mo2Q5OTBcwmbe8FMHuVAJ9mSSmY7ycsVwRawa7YBqEidmSF1tQmvzeEzN42ad+iX/4/uM4Z1UfXnr2cuwdnamp5uGOJ4/jG/cFhxwVLBsf+8nOwLAiX0qS/8Qr+jOBYkBVFbxmsKuix1AmJbmGYeMSaRiivCBF2GNQldRC+L/zJd3+Zq7HGPTuqplk8N9vIJsKSILHJwvoSSeQTQUrcgez1dtiTOVlrYfyNmoxDABw5opevPXS9fjGffvx08eO4qH947ho3SAA4IVnDONvX3l21ddY1pf2fiezJdsLvldDGYZ58xjcGMN0wUIqYXjvD/htME4fZsPANIjacPq7EuhJJzyPQZ091lL9vPPoJAaySaxfksWWdQMgkv1xutOJ2OCzbgxqGbRyaHwW1/9yt5cGqRJQVNZKNu23Ro7ycsZyJQx1p9DflYyUkr7z0CE8MzqDL799K75+zSV44ZnDyJecwMYdx3/8ag8+cMsOfO1e3zj88qkT+PwvduO/Nc3bl5KUx9CF8VzJkywOjs2iO2ViIJssMwyTAY+hPPicThhY6Z5hVwpAlwWfu/xNd63rJapWF4BmGBJGYB5DWEoazCYDHsPIVCHgLXiP665e/ewZBlfzj2u5HcWfX3kGThvuwbVfewBHJ/O4cO1Azc8FEPAY8nW0c1Hf03xp+oYhh/FMF6yydiFKStq8vHde1tJpsGFoAmrD6etKojeT8BrgeR6DZhh+9fQItu0tnz+08+gUzlzeCyLCmy9ei1eevwpJU069ipOSlMFJmUZNUtJnf/40/vlHO3FwbDawWasRmDIrKXpUpWqgN5iVhmEyb3kGIVe0kStaOHgyh5V9GVzxrOUgImxcKs++VeVtJdR39vff24HbnzgGAPj5Tnl5j5YOOxnSg/0iN2mMD47lsHYoCyJCJmkimzI1w1DyPI2wsZ50ZwAs6ame9VOIyUoC/N+5ftab1rJtipYDx22MmI6Ukvz3PTaZD8QX/Mclq3oMk/kSejNJ7/lxnVWj6O9K4kfvfj7+7pVn47zV/bjiWctrfi4ALO/P4PhkITCLoRZSbnFcq9thKEyD3JYYVtn3o+IoLCXNI0S0lojuIKLHiegxInqPe/xDRHSIiB52f17RjvXVi/IYejPJwJmZijHom+zf3PIoPh7q7uk4Ak8encKzVvYBAF574Rp85s0XApD/0HHBZ+UxrFuSLfMYfrLjaKDZWsGyvR4++0ZzXiER4BdAZVN+Xn3YMEy5DfQGsyn0eR5Dwdv0TkwVcXBsFmtcLwmAZxj21GAYjk/m8YZnr8EZy3vx4R88DtsR+PnO4wCAbXtPevMXJvMlpBKGdxaq2hWoAPTBsVlvcwaC3Uin3AQBg8o/nxoO05tOIGUaOFGhyK1oByufM0nTk5bU7zxpGt53GfQYbM9rCG+YA1mZEaY6k4bbYSjkKM7qwWfdY6hVSlKkEgauuXwjvv9nl3ueb60s782gaDs4OVPEsclCZHPAKOZfSpKVz+GxngCwZW0/nr95aaRhXgy0y2OwAPwvIcTZAC4FcB0RKfHyU0KILe7Pj9q0vrqY0s5ilcSRNMn7o1KyxUSuhAMnZ8uklYNjs8gVbZy5otxt7U6ZsR7DuJuRtGFJd+AMeCpfwp9+4wH8x6/8wO+dT454Z9v7T+YCmTx7XMPQnU74w+1DUovKUhnsTqEvk8B4roiTM0Wc4braJ2YKOOBWHCuW92bQlTTxzEhlw5Avyd5SG5Z247oXn469ozl85udP49hkAS951jLkija2Hxz31qWfoa/ql+93ZCIPIYRrGPyNbEl3yitYm8rL5ntRmVfKMBCRNCbVpKRQyqaSk9YO+Z9/iTulzM/PN1G0HC+FMxxjUBvi+KzshXR8KtpjqKX1tvqsqgaiHilprnjGejKPHYcmcM6qvpqeN9/B54FsCgfHZiOlpKvOXYmvXXNJxQysU5l2zXw+IoR40L0+BeAJAKvbsZZq/HznsapT1HyPIeH9A/Zlkl6DNHV2uuOwbBGtNjHFI+6md/bK8n8gXUr69dMnsE8bkqPOGtcvyWI85zdWe+TABBwhewYpvvfwYSzpTiFlGth3cgZHJwtImnITVLGCbMpPswwHX5X2PdSdRH9XEntPzMAR8IzZkfE8jk7mA5uyYRA2LO3GMyemK35/I96UsjRefu4KrB7owqdvfxpEwPuuOgsAcM/uUe+71DX9FZqUNJ4rYbpgBYyTbDrnewy9mejMK32c5JKeVMXq53CMAZC/byIZ81CoGIfKSlIxhrwVXfSlt7+eKljIl5yKMYZKjfT84HNjHsNcUIWH2w9OYHSmiHPrNAzz5TG8YPMw7t0zipGpQqAdBtMBMQYi2gDgQgD3uYfeRUTbiegGIhqMec61RLSNiLaNjIy0bG3HJvN4x43bcMOvn6n4uEmt6EqdzfZ3JdGTSsAgX8/e4c4OKFpO4Izvnj2j6EknIs+sulMmZoqy99LbbrgPL/nknfjIDx9HyXYwniuiK2lieV8aliM8yenB/WMA/Jz+qXwJP3viGF55/kqsGezCfldKWtab8dpKmG4BlEpH3RuSf9TmOqDFGADgLNcwbD80DiFk1a/OpqXdVWMMfiFXGgnTwNufux6OAC5YM4DNy3tx1ope3LvnpPtZrMA8hUzSxLLeNHYdn/ZSVXXjFJaSejPSK4ryGPo8w5COrOa+a9cJOUfZLjcMvZkEVvZlAsfVBheOMXi5/RExBkAaYSX1RXUiHcwmUbJFxRMW1WhwMJvEpqXdnmc3HyhjrWJF563pr+l56nvSA/et5IpnLUPRcrB7ZAY9MTM6FittNQxE1APgZgDvFUJMAvgCgNMAbAFwBMAnop4nhLheCLFVCLF1eHi4KWs5MV3A08eCzeBUodndu09UfG5QSpJnZr1dSRgGBWSLHYf9Bml6f597d4/iORsGkYioKO1OJ5Ar2Dg8PgtHAGcs78WXfvUMfrzjKMZzJQxkk2U9/R9yDcOBk7MQQuDePSdRsBy84ryVWLcki32jORydlH3+VYptNmWCiJBNJbCyP1O2mavNdcg1DArlMTzs9tPRN2VAxhkOjM16MQK5ntFACqtfyCU3lDc+Zx2WdKfwqgtWAZCtmrftOynbmc/6AWTFczYO4d49J3HANYS6nDPck8bIdEG2V3YDsiqrSmdS8xiW96ZxaDzcfymHt/zHffjmffthOwIpM7ipn76sF1vWDQSOqepnr8BNeQxukVuclDQ2U/TaTw9HBp/V46LjDCVbvkdvWha1/fx/vwhv2Lo28rGtYNiV0H719AkYBC92Vg3VmXW+spKes2HI86R62GMI0DbDQERJSKPwDSHEdwBACHFMCGELIRwAXwJw8Xyt559/+ATedP29AfdcBW8f3D+OfMlGyXY8rVtHSUk9aT/GoDYvXbbYcWiirFX0sck89pyYwWWnLYlcV4+brqrabPz9q85B0iQ8fngS4+5m5vX0d+Wkhw6MI2kSZks2Ts4U8fRxafDOXtWH9UNZGWOYzGNFf8Zbj94OYOPS7rKAscqWGewOGoaV/V3oy/iT1PRNGQA2LO12+9rL7/IXT43gTdffizuf8j09dXasZJP+riTu+esr8I7nbQAAXLppCPmSg8cOT3pnwjqXbVqCo5N5/OppacB147RmKIui5eDYVD7oMWjBZ9mT3/Je91kr+3BiuhAI0Kvv4zduRlk6tKn/6xvOx2fffFHgmJLl9BiDLiWFs5IGtN9j2FjqVGuLMRVRyTufpBIGlvakULAcnDbcE6jDqMR8S0mphIHnb14KIPj3z7QvK4kAfBnAE0KIT2rHV2oPey2A8oG+LeLhA+MYnSkGNkQlTRQtBw/uH8O//2I3Xv3ZYGtkQAZEu9XoQs8gKAMhPYapfAnPnJjBlWfL1L+jbnql6kx62aalkevKphIoWI7nvWxYksVpwz148ugkJjyPwd9Q9pyYwXiuhBeduQyAjDPsOjaNFX0Z9GaSWLdE9gLaN5rDst4MVrpSUlY7Y9q4tBt7R8sNg2kQ+jKJwMY83JPG0t40ckUbpiGrXnXCKas/e1zKCzu0kZzHpwpIGOR1DgUQaL1w9kopRTx5dMptuR38J1ZG9QePHEZfJhEwXOvdjJqdR6dgOQK9maQ01oFuuBaE8AfWnLtavp+KCQHAfvf7eGCf9MbCwWciKiviWtIdJSXZyBejq4GVYRjLFb1amOUxMQbA7wEVRs+SaxdKAlPfZS0kEwaIEPj9tZrfOkv+n1TqPLsYaZfH8DwAbwXwW6HU1I8R0aNEtB3AiwH8+XwsZipf8gzCg+4/PiA9hr6MjBPc+dQIbrpnLwDgu25fev35YU9B/XEr2UI1WHvRmcNIGITDrsdwz+5R9GUSODsmQKeCYk8fn0bKNLC0J40zV/TiyaNTGMvJugK1UYzPFvGQK+m82pVhDo7lsGtk2svHVhul7YiKHsN4rhTo+X9ypoTBrMzaUZ8taRL6uhJY6lb5ruzPlMlhmzTDIITAHW4K6k5Ntjs+VcBwbzq2OnbNYBe6UyZ2Hpl0paTgxrFpaTeW9aYxVbDKpCwVM3nMNURhj2HviRkvu0v97s5e1Qci4NGD/gnAvtGct1agcodRxVCZxxAMPof7B/WkE0gYhPHZEp46NoVV/ZnIzX2wykyGdnsMgG8Yas1IAmSMSVXWzxcvPmsZMknDy25jJO3KSvq1EIKEEOfrqalCiLcKIc5zj79aCHFkPtbzuKb9P3Rg3Lt+cGwWm5f34rzV/fjKXXtxYrqIVf0Z3PrI4YBGriQKAJqB0DyGfMk7Qz5v9QCW9/mN3+7ZM4qLNy6J/WdQ+dVPH5vCyoEMDINw1oo+HJ7I49D4bJnH8OD+MfRmEnjhmTL2sv9kDruPa4Zhib9xrujLBGIMiqj6g6MTs1ja40s9gGz7QERY2is3qrWhTRmQZ7dLe1L41dMnsPPoFA67TeV2al5XXCGXwjAIZ6zoxfZDEyhYTpmURES4dJP0GtaEgt+rBuRGs+OQfL++riT6upLIFW3sODSBF/3rL/A3tzwa+Fw96QQ2Lu0OegxaTQjQmGHoSkkpSXkr4RgDEWEgm8J4rognj07hrBhtXhXhqbRnIURA9prsII/hvDo8hne+8DR877rLW7WkSJb2pPHLv3wxXndRRyZFto22ZyV1Aioo/KyVfUGPwc3Lv3TTEhQtB2et6MX7Xn4Wjkzkcb9WvTxVKGmGwY8tqMvR6SK+8+AhrOrPYLg3jVUDsvHb4fFZ7BvNxcYXAN8wPHl0yjurUZlAuaKN/q6Ut1GO54q4d88otqwdQF9GZqRs2zuGmaLtGQa9WGlZX9rLStILfMLyj+0IbNs3hgvd4KraQJVBUAYjvCkrrn3BJtz51Ag+/IPHAQCvvXA19o7mvHz+kakChiO0dJ2zVvR6xjXqTFh9h+FirKRpYPVAl7fJ92pS0w/cgr+7do0GPhcgNzRd7tp/Mhc4+63Uwlqh2rAriUxlBqn05KjGcoPZJEamCth1fDqyrgWQJxvrhrLYfkCu7/vbj+Dif74d7/zaA9g3OtMRHsPGpVmkEkasJxyFaqM+3yzrK/d0Fzv8bUDKDMt603jp2cvx1LEpTBdk9emRiTzWDmZxuRuguubyjbjy7OXIpkx872FfTtJTKKM8htGZInYencSHX3MuAGBFfxeOTua9+MKlm4Zi16ayJfS23met9DeMgaycS9CVNHH37lHsGZnBy85ZAUAGYVVGlTIMmaTpxQFW9GW8MzvdY1BdXVX9weOHJzGVt7yzct1j0C/jKmT/4LkbsWm4G3fvHsV5q/vxgjOGYTvCa8VxfKoQqaXrnLWiz+skG5aSAOB5py0FkW/UdNYvyXrxoj63jgEA/uexo9i0tBu/fb4MbekZQOeu6seRiTxOTMvWDvtP5nDxxqGyTKNKnLG8Fz9+z/M9o3XuKnn2vG2vPPmI6iE0mE3hwf3jsBzhnQBEcdG6ATy4f8yT57IpE798egSv+dxdntwV9T3NF2+7bAN+/J7nt9VrYRpnURsGVfH76KEJnLe6HxetH4QjgEcOjOPIRB62I7BmsAuXn74U//XHl+H1z16DbCqBl52zAj/YfgRjM0XkSzYOjc16gcOlPcGzaFX9+k+vOc/rObOyP4MjE3ncvXsUA9kknrUi/qxKz+hQZ6Ar+jKeHq5kpIFsEnfvHkXCIPz2eXKjWzvU5aVG6j1f1rly0vK+DDJuHYSeCZI0DawbymLvCSmf3LNHGpfLXMOgPBT1GZXnEOcxpBIGPvSqcwDI3HF1Jrzz6JRX0xGVfaOjnz1HnQmvW5LF9657Hl7/7DXl92kGq1erNXnGzQb71O9uwX/98WXeLAYAOGe1/J08dngSI9MF5Io21g9lvWBqLVISIL1QFURfOyQzuNSkt6geQgNaH6SzKvxdXLhuEMenCjg0Pot7do/it85ahuvfuhVjuRJuefCg+1nb5zFkkqY3aIpZeCzaUPz3HzmM9/znQ/jUG7dg98g0Xn7eSmxZMwBA1gEY3j+zbMh28Ub/rP6dLzwNtz5yGP/60yexrDeD0Zki3ujmiW8a7sE3/+gSXLxBPv73LlmHC9cNeGfbgDQMRcvBz544hks2DlVsSaxXrKp5D0SEs1b24f5nTnoGqb8riSMTebzozGEvGK0CsQPZpHemC8hg7VPHpjz56KZ3XFzmwuspq/fsHsVpw91+p850AqmE4Y1xVAHs9Uvih5q84IxhfPOPLsEFawaQThhIJww8eXQSJ9yz6agKXx397DkcY1Cc7/7+wuhxld5QVtVlpy1BKmEEfr8AcI57dr/j0AS6XW9q/ZJunLu6gDufGqnZMOgQEc5d3Y+73SrucMor4AeWkyZ5syGiUK2wv/vQIRydzOPSTUtw2WlLsLwv7c1obqdhYBY2i/Yv54pnLcN5awbw3m8/DCGkptyfTeL0ZT24Z8+oJ7FEnQWfuaIXb7tsPW68ey9SpoHfPm8lnnu6n2763NP86/1dyYBRAPyNdDxX8s7C49AlHiUlAXKjlIZBbiRqQ7l6ix9EU1XIm5f1BHq+vPclZ+CNz1mrvVb5menGpd24Z/coSraD3+wdw9VbVnn3GQbhG//fJd4Z4QvPWIb/eNtWXBQq8Aqjfy+bl/dg59GpQNVzJQayKazoy7hT7uqTJ9YN+Rus9Bj8VNVLNkZ///1dsgX6tr0nPelt3ZKs1wCv1tz8MMowEEXHKQbcqt/ThnsC8wHCnLWyF5mkgRvu2gtAGjjTILz6glX40q+eQdZNn2aYRli0fznZVAI3vH2rl755risdvOr8Vbhr1yh+8dQIjFDvG533vuQMDGVTMIjwN7/9rLreW3/Ny7TNMgrdY9ANg6omVWf6Q90pdKdMvERrkaw8hnDr4BX9GVy4LrLbiMem4W7Mlmy8/+ZHMV2wygLkz9kw5L23aRBecvbyuhqOnbm8DzuPTlUs5Cp7jus11HsmrDwGg2SLERUj2bysJ7KyWPHb563EnU+N4K5dJ0AkTxKuPHs5/u1NW+qeUaBQUlQmYUZ+X8rAV4ovAFLuO3/NgCvDpb20YHViwN4CMxcWrWEApP7/jT+6FJ/83Qu8zfotl65DKmHgh9uPYEWo941Of1cSX73mYtz0jouxeqC+HGjlMQx1p3DG8so6rJ4tpOdav2bLanz89edjs7vpv/uKzbj+bVsDufEqGNyI1nv1ltV42TnLcbOrV4e9nrnyrJW9GJkq4OvuYJ5qwWfAD7rHSUlxqBhDj9siQgWfK2WDATKAahDhOw8dwqr+LqQTJkyDcPWW1TVNJItCNZQLp6oq1CyCuFRVHZUldtlpSzwjc86qPpy+rKetgWdm4bPoTytWD3ThdRf5AculPWm87sLV+M/fHAjMFohC6dD1sqQnjaRJuHTTUNWzbBWgXNKdCmz6XSkz0P/mzBW9OBPBs8zThrvxT685F686fxXqpSedwBffuhX37RnF0cm8F2huFr9z0Rrc8eRxr5/Okhpe/w+fuxFnLu+tu1NodzqBpT0pLwsom0rgE2+4oKphWNGfwasuWIVbHjoUCGDPhQ1LutGTTsRONVMeQ1yqqo6KM+hGm4jw8defX7UjMMNUYtEbhijecflGaRhismzmimkQ/uV3zq/JsBgGoTtlBmSkWiEi/H6V4e3VuKTJnoJisDuFr19zCX7x5IjXbqMaK/ozASNeD+uGsph1M7QA4HcispeiuObyjbjloUOBAPZcMAzC2av6cEKbY63z/M3DeN9VZ+F5VSRGQFbR/+XLzvSq3BXVZEKGqQYbhgjOWN6LD7/mXFxQY7vgRqhng8umE14h2qkEEeHFbq+aVvPnV57htbuuh3NX9+PvX3V2WdbSXPiLK8+InSndlTLxJy86rabXSSdMXPfi05u2LoZRUKVhHwuBrVu3im3btrV7GS3l27/Zj/VLupuu8zMMs3ghogeEEFuj7mOPYQHwxuesa/cSGIZZRCzqrCSGYRimHDYMDMMwTAA2DAzDMEwANgwMwzBMADYMDMMwTAA2DAzDMEwANgwMwzBMADYMDMMwTIAFX/lMRCMA9jX49KUATjRxOfPJQl07r3t+4XXPLwtp3euFEMNRdyx4wzAXiGhbXEl4p7NQ187rnl943fPLQl13GJaSGIZhmABsGBiGYZgAi90wXN/uBcyBhbp2Xvf8wuueXxbqugMs6hgDwzAMU85i9xgYhmGYEGwYGIZhmACL1jAQ0VVE9CQR7SKi97d7PXEQ0VoiuoOIHieix4joPe7xDxHRISJ62P15RbvXGoaI9hLRo+76trnHhojoNiJ62r3sqAHFRHSm9p0+TESTRPTeTv2+iegGIjpORDu0Y5HfMUk+7f7Nbyeiizps3R8nop3u2m4hogH3+AYimtW++3/vsHXH/m0Q0V+73/eTRPSy9qy6AYQQi+4HgAlgN4BNAFIAHgFwdrvXFbPWlQAucq/3AngKwNkAPgTgf7d7fVXWvhfA0tCxjwF4v3v9/QD+pd3rrPJ3chTA+k79vgG8AMBFAHZU+44BvALAjwEQgEsB3Ndh634pgIR7/V+0dW/QH9eB33fk34b7f/oIgDSAje6eY7b7M9Tys1g9hosB7BJC7BFCFAH8J4Cr27ymSIQQR4QQD7rXpwA8AWB1e1c1J64GcJN7/SYAr2nfUqpyBYDdQohGK+tbjhDilwBOhg7HfcdXA/iqkNwLYICIVs7LQkNErVsI8VMhhOXevBfAmnlfWBVivu84rgbwn0KIghDiGQC7IPeejmexGobVAA5otw9iAWy2RLQBwIUA7nMPvct1u2/oNEnGRQD4KRE9QETXuseWCyGOuNePAljenqXVxJsAfEu73enftyLuO15If/fvgPRuFBuJ6CEiupOInt+uRVUg6m9jIX3fARarYVhwEFEPgJsBvFcIMQngCwBOA7AFwBEAn2jf6mK5XAhxEYCXA7iOiF6g3ymkv92R+dJElALwagD/1z20EL7vMjr5O46DiD4AwALwDffQEQDrhBAXAvgLAN8kor52rS+CBfm3UYnFahgOAVir3V7jHutIiCgJaRS+IYT4DgAIIY4JIWwhhAPgS+hAF1UIcci9PA7gFsg1HlPyhXt5vH0rrMjLATwohDgGLIzvWyPuO+74v3si+gMArwTwFteowZViRt3rD0Bq9We0bZEhKvxtdPz3HcdiNQy/AbCZiDa6Z4ZvAnBrm9cUCRERgC8DeEII8UntuK4NvxbAjvBz2wkRdRNRr7oOGVjcAfk9v9192NsBfK89K6zKm6HJSJ3+fYeI+45vBfA2NzvpUgATmuTUdojoKgB/BeDVQoicdnyYiEz3+iYAmwHsac8qy6nwt3ErgDcRUZqINkKu+/75Xl9DtDv63a4fyAyNpyDPPj7Q7vVUWOflkFLAdgAPuz+vAPA1AI+6x28FsLLdaw2texNkRsYjAB5T3zGAJQBuB/A0gJ8BGGr3WiPW3g1gFEC/dqwjv29I43UEQAlSw74m7juGzEb6nPs3/yiArR227l2Qmrz6O/9397G/4/4NPQzgQQCv6rB1x/5tAPiA+30/CeDl7f57qfWHW2IwDMMwARarlMQwDMPEwIaBYRiGCcCGgWEYhgnAhoFhGIYJwIaBYRiGCcCGgWEagIj+kYhe0oTXmW7GehimmXC6KsO0ESKaFkL0tHsdDKPDHgPDuBDR7xPR/W5P/S8SkUlE00T0KZKzMG4nomH3sTcS0evd6x8lOS9jOxH9q3tsAxH93D12OxGtc49vJKJ7SM6p+KfQ+/8lEf3Gfc4/uMe6ieiHRPQIEe0gojfO77fCLEbYMDAMACJ6FoA3AnieEGILABvAWyCroLcJIc4BcCeAvw89bwlkG4RzhBDnA1Cb/WcA3OQe+waAT7vH/w3AF4QQ50FW0KrXeSlky4SLIZuxPdttOngVgMNCiAuEEOcC+EmTPzrDlMGGgWEkVwB4NoDfENHD7u1NABwA33Yf83XIFiU6EwDyAL5MRK8DoHr8XAbgm+71r2nPex78Hkxf017npe7PQ5BtH86CNBSPAriSiP6FiJ4vhJiY28dkmOok2r0AhukQCPIM/68DB4n+LvS4QFBOCGER0cWQhuT1AN4F4LeqvFdUYI8A/B8hxBfL7pAjOF8B4J+I6HYhxD9WeX2GmRPsMTCM5HYAryeiZYA3N3k95P/I693H/B6AX+tPcudk9AshfgTgzwFc4N51N2TXXkBKUr9yr98VOq74HwDvcF8PRLSaiJYR0SoAOSHE1wF8HHKsJMO0FPYYGAaAEOJxIvpbyIlzBmT3zOsAzAC42L3vOGQcQqcXwPeIKAN51v8X7vE/A/AVIvpLACMA/tA9/h7IQTPvg9ZyXAjxUzfOcY/stI5pAL8P4HQAHycix13TnzT3kzNMOZyuyjAV4HRSZjHCUhLDMAwTgD0GhmEYJgB7DAzDMEwANgwMwzBMADYMDMMwTAA2DAzDMEwANgwMwzBMgP8HZTuiVoKcoAQAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 172.000, steps: 172\n",
            "Episode 2: reward: 198.000, steps: 198\n",
            "Episode 3: reward: 188.000, steps: 188\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 177.000, steps: 177\n",
            "Episode 6: reward: 173.000, steps: 173\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 194.000, steps: 194\n",
            "Episode 9: reward: 199.000, steps: 199\n",
            "Episode 10: reward: 180.000, steps: 180\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 187.000, steps: 187\n",
            "Episode 13: reward: 175.000, steps: 175\n",
            "Episode 14: reward: 183.000, steps: 183\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 177.000, steps: 177\n",
            "Episode 19: reward: 190.000, steps: 190\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd752b51610>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.test(env, nb_episodes=20, visualize=True)"
      ],
      "metadata": {
        "id": "dVgg_-CEaAW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9583c6-cf24-4fc4-d631-ded8707533b3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd7531bfdf0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(ENV_NAME, render_mode='human')\n",
        "plt.imshow(env.render(mode='rgb_array', disable_render_order_enforcing=True))\n",
        "\n"
      ],
      "metadata": {
        "id": "0_3Oilbd9Ugb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9eziZm7v9-fK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}